/*! For license information please see 962.5569c51d.iframe.bundle.js.LICENSE.txt */
"use strict";(self.webpackChunkapp_scaffold=self.webpackChunkapp_scaffold||[]).push([[962],{"./node_modules/@tensorflow/tfjs/dist/index.js":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.r(__webpack_exports__),__webpack_require__.d(__webpack_exports__,{Abs:()=>dist.ljI,Acos:()=>dist.Vvy,Acosh:()=>dist.PH8,AdadeltaOptimizer:()=>dist.K$F,AdagradOptimizer:()=>dist.ah4,AdamOptimizer:()=>dist.FYc,AdamaxOptimizer:()=>dist.oC7,Add:()=>dist.OMN,AddN:()=>dist.EkD,All:()=>dist.u8Z,Any:()=>dist.FSt,ArgMax:()=>dist.Jp_,ArgMin:()=>dist.p_m,Asin:()=>dist.QKF,Asinh:()=>dist.epO,Atan:()=>dist.TyE,Atan2:()=>dist.lxb,Atanh:()=>dist.zP9,AvgPool:()=>dist.ho8,AvgPool3D:()=>dist.cS,AvgPool3DGrad:()=>dist.wwC,AvgPoolGrad:()=>dist.VCH,BatchMatMul:()=>dist.jAQ,BatchToSpaceND:()=>dist.Ik2,Bincount:()=>dist.N4F,BitwiseAnd:()=>dist.HNs,BroadcastArgs:()=>dist.vj7,BroadcastTo:()=>dist.LB5,Callback:()=>Callback,CallbackList:()=>CallbackList,Cast:()=>dist.KXH,Ceil:()=>dist.QDP,ClipByValue:()=>dist.vaV,Complex:()=>dist.pr3,ComplexAbs:()=>dist.$zE,Concat:()=>dist.$dB,Conv2D:()=>dist.p2J,Conv2DBackpropFilter:()=>dist.rFm,Conv2DBackpropInput:()=>dist.jfg,Conv3D:()=>dist.A1h,Conv3DBackpropFilterV2:()=>dist.iGz,Conv3DBackpropInputV2:()=>dist.gC7,Cos:()=>dist.Mn0,Cosh:()=>dist.MnK,CropAndResize:()=>dist.MRQ,Cumprod:()=>dist.jj_,Cumsum:()=>dist.nY8,CustomCallback:()=>CustomCallback,DataStorage:()=>dist.GJx,DenseBincount:()=>dist.wNW,DepthToSpace:()=>dist.TMz,DepthwiseConv2dNative:()=>dist.tGH,DepthwiseConv2dNativeBackpropFilter:()=>dist.X$8,DepthwiseConv2dNativeBackpropInput:()=>dist.nVu,Diag:()=>dist.ORI,Dilation2D:()=>dist.jxD,Dilation2DBackpropFilter:()=>dist.pk0,Dilation2DBackpropInput:()=>dist.bP9,Draw:()=>dist.XmO,ENV:()=>dist.Kmu,EarlyStopping:()=>EarlyStopping,Einsum:()=>dist.Qgm,Elu:()=>dist.Pah,EluGrad:()=>dist.rsH,Environment:()=>dist.OH$,Equal:()=>dist.BRl,Erf:()=>dist._s9,Exp:()=>dist.ox3,ExpandDims:()=>dist.ybN,Expm1:()=>dist.ybj,FFT:()=>dist.rGP,Fill:()=>dist.SQl,FlipLeftRight:()=>dist.BxF,Floor:()=>dist.ZgB,FloorDiv:()=>dist.ElG,FromPixels:()=>dist.awo,FusedBatchNorm:()=>dist.i5R,FusedConv2D:()=>dist.aAr,FusedDepthwiseConv2D:()=>dist.T7M,GPGPUContext:()=>GPGPUContext,GatherNd:()=>dist.O4G,GatherV2:()=>dist.mxL,GraphModel:()=>GraphModel,Greater:()=>dist.XhZ,GreaterEqual:()=>dist.lLS,History:()=>History,IFFT:()=>dist.OAQ,Identity:()=>dist.lzr,Imag:()=>dist.dv8,InputSpec:()=>InputSpec,IsFinite:()=>dist.gIW,IsInf:()=>dist.E3$,IsNan:()=>dist.iPs,KernelBackend:()=>dist.uI_,LRN:()=>dist.jM4,LRNGrad:()=>dist.ToN,LayerVariable:()=>LayerVariable,LayersModel:()=>LayersModel,LeakyRelu:()=>dist.X0$,Less:()=>dist.mIA,LessEqual:()=>dist.CwD,LinSpace:()=>dist.mnI,Log:()=>dist.tG8,Log1p:()=>dist.Cg$,LogSoftmax:()=>dist.zfU,LogicalAnd:()=>dist.RUm,LogicalNot:()=>dist.nZd,LogicalOr:()=>dist.LXA,LogicalXor:()=>dist.RW8,LowerBound:()=>dist.yPW,MathBackendCPU:()=>MathBackendCPU,MathBackendWebGL:()=>MathBackendWebGL,MatrixBandPart:()=>dist.WRv,Max:()=>dist.VAI,MaxPool:()=>dist.t3d,MaxPool3D:()=>dist.ySp,MaxPool3DGrad:()=>dist.cHb,MaxPoolGrad:()=>dist.RXX,MaxPoolWithArgmax:()=>dist.TL8,Maximum:()=>dist.LDN,Mean:()=>dist.g5A,Min:()=>dist.lNG,Minimum:()=>dist.LG0,MirrorPad:()=>dist.x7F,Mod:()=>dist.BLA,MomentumOptimizer:()=>dist.Qu_,Multinomial:()=>dist.WT3,Multiply:()=>dist.xu7,Neg:()=>dist.l0G,NonMaxSuppressionV3:()=>dist.SDM,NonMaxSuppressionV4:()=>dist.Zl4,NonMaxSuppressionV5:()=>dist.e0f,NotEqual:()=>dist.ylV,OP_SCOPE_SUFFIX:()=>dist.BTT,OneHot:()=>dist.urI,OnesLike:()=>dist.LWX,Optimizer:()=>dist.ELo,OptimizerConstructors:()=>dist.L5p,Pack:()=>dist.mM$,PadV2:()=>dist.ODT,Pool:()=>dist.bCz,Pow:()=>dist.pyJ,Prelu:()=>dist.Ncv,Prod:()=>dist.kdj,RMSPropOptimizer:()=>dist.PS5,RNN:()=>RNN,RaggedGather:()=>dist.oJ2,RaggedRange:()=>dist.CQC,RaggedTensorToTensor:()=>dist.mH5,Range:()=>dist.Q6t,Rank:()=>dist.rgM,Real:()=>dist.LRy,RealDiv:()=>dist.sDr,Reciprocal:()=>dist.huO,Reduction:()=>dist.iDl,Relu:()=>dist.fUj,Relu6:()=>dist.P_L,Reshape:()=>dist.R23,ResizeBilinear:()=>dist.hgw,ResizeBilinearGrad:()=>dist.FCQ,ResizeNearestNeighbor:()=>dist.jOE,ResizeNearestNeighborGrad:()=>dist.XQy,Reverse:()=>dist.D7i,RotateWithOffset:()=>dist.BK4,Round:()=>dist.hVg,Rsqrt:()=>dist.TOR,SGDOptimizer:()=>dist.SYI,ScatterNd:()=>dist.pJc,SearchSorted:()=>dist.uWl,Select:()=>dist.l6P,Selu:()=>dist.u$b,Sequential:()=>Sequential,Sigmoid:()=>dist.vI1,Sign:()=>dist.YVe,Sin:()=>dist.hql,Sinh:()=>dist.J3C,Slice:()=>dist.JiE,Softmax:()=>dist.rFG,Softplus:()=>dist.Fin,SpaceToBatchND:()=>dist.A8B,SparseFillEmptyRows:()=>dist.C8s,SparseReshape:()=>dist.BoJ,SparseSegmentMean:()=>dist.L6G,SparseSegmentSum:()=>dist.DvZ,SparseToDense:()=>dist.jgd,SplitV:()=>dist.Blb,Sqrt:()=>dist.dFH,Square:()=>dist.M6A,SquaredDifference:()=>dist.Ddj,StaticRegexReplace:()=>dist.GZp,Step:()=>dist.pnw,StridedSlice:()=>dist.UcO,StringNGrams:()=>dist.YAb,StringSplit:()=>dist.iW0,StringToHashBucketFast:()=>dist.$jE,Sub:()=>dist.PbM,Sum:()=>dist.WuN,SymbolicTensor:()=>SymbolicTensor,Tan:()=>dist.oFs,Tanh:()=>dist.iuW,Tensor:()=>dist.qYS,TensorBuffer:()=>dist.ylz,TensorScatterUpdate:()=>dist.X4r,Tile:()=>dist.FAs,TopK:()=>dist.TBb,Transform:()=>dist.dLy,Transpose:()=>dist.wx0,Unique:()=>dist.EwU,Unpack:()=>dist.dXR,UnsortedSegmentSum:()=>dist.pPe,UpperBound:()=>dist.RMm,Variable:()=>dist.rTt,ZerosLike:()=>dist.xJ3,_FusedMatMul:()=>dist.Dr,abs:()=>dist.tnl,acos:()=>dist.HQu,acosh:()=>dist.FqL,add:()=>dist.WQq,addN:()=>dist.QiD,all:()=>dist.Q7R,any:()=>dist.bzn,argMax:()=>dist.FLi,argMin:()=>dist.XRg,asin:()=>dist.qRo,asinh:()=>dist.yHs,atan:()=>dist.rYl,atan2:()=>dist.FPz,atanh:()=>dist.rfv,avgPool:()=>dist.$jT,avgPool3d:()=>dist.sub,backend:()=>dist.Hs,backend_util:()=>dist.C0T,basicLSTMCell:()=>dist.lZX,batchNorm:()=>dist.$v7,batchNorm2d:()=>dist.BFc,batchNorm3d:()=>dist.kSi,batchNorm4d:()=>dist.T5N,batchToSpaceND:()=>dist.GTe,bincount:()=>dist.HbZ,bitwiseAnd:()=>dist.vjT,booleanMaskAsync:()=>dist.ftb,broadcastArgs:()=>dist.ROE,broadcastTo:()=>dist.hOW,broadcast_util:()=>dist.ZEY,browser:()=>dist.TaL,buffer:()=>dist.ra8,callbacks:()=>callbacks,cast:()=>dist.wgE,ceil:()=>dist.mkO,clipByValue:()=>dist.zQh,clone:()=>dist.o8B,complex:()=>dist.faB,concat:()=>dist.xWs,concat1d:()=>dist.I1m,concat2d:()=>dist.RPU,concat3d:()=>dist.O5O,concat4d:()=>dist.P1l,constraints:()=>exports_constraints_namespaceObject,conv1d:()=>dist.kA9,conv2d:()=>dist.Xtf,conv2dTranspose:()=>dist.wX9,conv3d:()=>dist.IPL,conv3dTranspose:()=>dist.jIJ,copyRegisteredKernels:()=>dist.Cfv,cos:()=>dist.gnS,cosh:()=>dist.yIG,cosineWindow:()=>dist._jP,cumprod:()=>dist.Lp0,cumsum:()=>dist.rCv,customGrad:()=>dist._Xg,data:()=>tfjs_data_dist_namespaceObject,denseBincount:()=>dist.aOp,deprecationWarn:()=>dist.fLc,depthToSpace:()=>dist.Rj8,depthwiseConv2d:()=>dist.Gl3,deregisterOp:()=>deregisterOp,device_util:()=>dist.eMq,diag:()=>dist.smy,dilation2d:()=>dist.X7t,disableDeprecationWarnings:()=>dist.ISJ,dispose:()=>dist.ASo,disposeVariables:()=>dist.rm6,div:()=>dist.y4m,divNoNan:()=>dist.ek5,dot:()=>dist.Omf,dropout:()=>dist.EZY,einsum:()=>dist._3C,elu:()=>dist.Pqc,enableDebugMode:()=>dist.gYU,enableProdMode:()=>dist.SmG,enclosingPowerOfTwo:()=>dist.FJY,engine:()=>dist.Hi9,ensureShape:()=>dist.QP2,env:()=>dist._K2,equal:()=>dist.LCg,erf:()=>dist.Y12,euclideanNorm:()=>dist.p4S,exp:()=>dist.oNF,expandDims:()=>dist.UG6,expm1:()=>dist.IYd,eye:()=>dist.y5U,fft:()=>dist.hVP,fill:()=>dist.GSj,findBackend:()=>dist.goy,findBackendFactory:()=>dist.W4C,floor:()=>dist.RIf,floorDiv:()=>dist.wh_,forceHalfFloat:()=>forceHalfFloat,fused:()=>dist.cZk,gather:()=>dist.kgh,gatherND:()=>dist.SY9,gather_util:()=>dist.FJy,getBackend:()=>dist.jz4,getGradient:()=>dist.vQR,getKernel:()=>dist._5H,getKernelsForBackend:()=>dist.OpK,gpgpu_util:()=>gpgpu_util_namespaceObject,grad:()=>dist.Dvk,grads:()=>dist.ok9,greater:()=>dist.rhj,greaterEqual:()=>dist.DQN,ifft:()=>dist.KGM,imag:()=>dist.ngS,image:()=>dist.Slp,inTopKAsync:()=>dist.U4u,initializers:()=>exports_initializers_namespaceObject,input:()=>input,io:()=>dist.io,irfft:()=>dist.ggX,isFinite:()=>dist.MIs,isInf:()=>dist.EN4,isNaN:()=>dist.yrW,keep:()=>dist.aCs,kernel_impls:()=>dist.kpo,layers:()=>exports_layers_namespaceObject,leakyRelu:()=>dist.H8d,less:()=>dist.M7h,lessEqual:()=>dist.InN,linalg:()=>dist.mPL,linspace:()=>dist.mT8,loadGraphModel:()=>loadGraphModel,loadGraphModelSync:()=>loadGraphModelSync,loadLayersModel:()=>loadLayersModel,localResponseNormalization:()=>dist.Kgs,log:()=>dist.Rm2,log1p:()=>dist.Kko,logSigmoid:()=>dist.nqI,logSoftmax:()=>dist.HPB,logSumExp:()=>dist.VZ,logicalAnd:()=>dist.n76,logicalNot:()=>dist.NSZ,logicalOr:()=>dist.ztW,logicalXor:()=>dist.rxB,losses:()=>dist.YYh,lowerBound:()=>dist.yzS,matMul:()=>dist.NoW,math:()=>dist.DyF,max:()=>dist.T9B,maxPool:()=>dist.jgi,maxPool3d:()=>dist.NYV,maxPoolWithArgmax:()=>dist.RO,maximum:()=>dist.PhQ,mean:()=>dist.i2o,memory:()=>dist.m1Z,meshgrid:()=>dist.OYQ,metrics:()=>exports_metrics_namespaceObject,min:()=>dist.jkA,minimum:()=>dist.BpO,mirrorPad:()=>dist.FFZ,mod:()=>dist.ziu,model:()=>model,models:()=>exports_models_namespaceObject,moments:()=>dist.Clk,movingAverage:()=>dist.CRk,mul:()=>dist.lKK,multiRNNCell:()=>dist.YDF,multinomial:()=>dist.OjQ,neg:()=>dist.HZy,nextFrame:()=>dist.dA1,norm:()=>dist.xbf,notEqual:()=>dist.Ec,oneHot:()=>dist.Mw0,ones:()=>dist.SaS,onesLike:()=>dist.P61,op:()=>dist.op,outerProduct:()=>dist.X4o,pad:()=>dist.eVF,pad1d:()=>dist.BZs,pad2d:()=>dist.grY,pad3d:()=>dist.XHu,pad4d:()=>dist.WLX,pool:()=>dist.dzn,pow:()=>dist.n7C,prelu:()=>dist.NsG,print:()=>dist.yyV,prod:()=>dist._eU,profile:()=>dist.MEE,raggedGather:()=>dist.whe,raggedRange:()=>dist.iyU,raggedTensorToTensor:()=>dist.Q0_,rand:()=>dist._9M,randomGamma:()=>dist.pR9,randomNormal:()=>dist.FE$,randomStandardNormal:()=>dist.m0H,randomUniform:()=>dist.YeY,randomUniformInt:()=>dist.HYA,range:()=>dist.y17,ready:()=>dist.Gc4,real:()=>dist.xav,reciprocal:()=>dist.VOZ,registerBackend:()=>dist.gJX,registerCallbackConstructor:()=>registerCallbackConstructor,registerGradient:()=>dist.krJ,registerKernel:()=>dist.tAK,registerOp:()=>registerOp,regularizers:()=>exports_regularizers_namespaceObject,relu:()=>dist.VVh,relu6:()=>dist.j__,removeBackend:()=>dist.rEj,reshape:()=>dist.tQQ,reverse:()=>dist.BEg,reverse1d:()=>dist.QD2,reverse2d:()=>dist.LMr,reverse3d:()=>dist.I2l,reverse4d:()=>dist.JYU,rfft:()=>dist.z8$,round:()=>dist.LIG,rsqrt:()=>dist.Z$r,scalar:()=>dist.d_2,scatterND:()=>dist.NFr,scatter_util:()=>dist.g23,searchSorted:()=>dist.sZg,selu:()=>dist.WfX,separableConv2d:()=>dist.wdz,sequential:()=>sequential,serialization:()=>dist.JFn,setBackend:()=>dist.jh6,setPlatform:()=>dist.OkC,setWebGLContext:()=>setWebGLContext,setdiff1dAsync:()=>dist.F12,shared:()=>shared_namespaceObject,sigmoid:()=>dist.ry7,sign:()=>dist._SZ,signal:()=>dist.vPA,sin:()=>dist.F8e,sinh:()=>dist.L0l,slice:()=>dist.dik,slice1d:()=>dist.Q$M,slice2d:()=>dist.zAd,slice3d:()=>dist.wck,slice4d:()=>dist.R0O,slice_util:()=>dist.Kro,softmax:()=>dist.Vs9,softplus:()=>dist.lw0,spaceToBatchND:()=>dist.eDJ,sparse:()=>dist.lMo,sparseToDense:()=>dist.Zhr,spectral:()=>dist.lOn,split:()=>dist.lDo,sqrt:()=>dist.RZD,square:()=>dist.EwI,squaredDifference:()=>dist.Pbu,squeeze:()=>dist.r2V,stack:()=>dist.t$z,step:()=>dist.PMw,stridedSlice:()=>dist.Ym9,string:()=>dist.YjP,sub:()=>dist.jbE,sum:()=>dist.czq,sumOutType:()=>dist.chL,tan:()=>dist.Mlm,tanh:()=>dist.ymU,tensor:()=>dist.OEK,tensor1d:()=>dist.tGX,tensor2d:()=>dist.KtR,tensor3d:()=>dist.$_$,tensor4d:()=>dist.g9W,tensor5d:()=>dist.Lpo,tensor6d:()=>dist.yxw,tensorScatterUpdate:()=>dist.NNh,tensor_util:()=>dist.d_S,test_util:()=>dist.Obs,tidy:()=>dist.DZQ,tile:()=>dist.Vsq,time:()=>dist.kBw,topk:()=>dist.rfw,train:()=>dist.BaG,transpose:()=>dist.mgz,truncatedNormal:()=>dist.efE,unique:()=>dist.AmM,unregisterGradient:()=>dist.rYx,unregisterKernel:()=>dist.iPt,unsortedSegmentSum:()=>dist.zAU,unstack:()=>dist.K$i,upcastType:()=>dist.TuY,upperBound:()=>dist.rni,util:()=>dist.ZSL,valueAndGrad:()=>dist.jYt,valueAndGrads:()=>dist.muS,variable:()=>dist.bvq,variableGrads:()=>dist.y7e,version:()=>dist_version,version_converter:()=>version_version,version_core:()=>dist.bgA,version_cpu:()=>tfjs_backend_cpu_dist_version_version,version_layers:()=>version,version_webgl:()=>tfjs_backend_webgl_dist_version_version,webgl:()=>webgl,webgl_util:()=>webgl_util_namespaceObject,where:()=>dist._M9,whereAsync:()=>dist.YJN,zeros:()=>dist.Ul9,zerosLike:()=>dist.POl});var exports_constraints_namespaceObject={};__webpack_require__.r(exports_constraints_namespaceObject),__webpack_require__.d(exports_constraints_namespaceObject,{maxNorm:()=>maxNorm,minMaxNorm:()=>minMaxNorm,nonNeg:()=>nonNeg,unitNorm:()=>unitNorm});var exports_initializers_namespaceObject={};__webpack_require__.r(exports_initializers_namespaceObject),__webpack_require__.d(exports_initializers_namespaceObject,{constant:()=>constant,glorotNormal:()=>glorotNormal,glorotUniform:()=>glorotUniform,heNormal:()=>heNormal,heUniform:()=>heUniform,identity:()=>identity,leCunNormal:()=>leCunNormal,leCunUniform:()=>leCunUniform,ones:()=>exports_initializers_ones,orthogonal:()=>orthogonal,randomNormal:()=>exports_initializers_randomNormal,randomUniform:()=>randomUniform,truncatedNormal:()=>truncatedNormal,varianceScaling:()=>varianceScaling,zeros:()=>exports_initializers_zeros});var exports_layers_namespaceObject={};__webpack_require__.r(exports_layers_namespaceObject),__webpack_require__.d(exports_layers_namespaceObject,{Layer:()=>Layer,RNN:()=>RNN,RNNCell:()=>recurrent_RNNCell,activation:()=>activation,add:()=>exports_layers_add,alphaDropout:()=>alphaDropout,average:()=>exports_layers_average,averagePooling1d:()=>averagePooling1d,averagePooling2d:()=>averagePooling2d,averagePooling3d:()=>averagePooling3d,avgPool1d:()=>avgPool1d,avgPool2d:()=>avgPool2d,avgPool3d:()=>avgPool3d,avgPooling1d:()=>avgPooling1d,avgPooling2d:()=>avgPooling2d,avgPooling3d:()=>avgPooling3d,batchNormalization:()=>exports_layers_batchNormalization,bidirectional:()=>bidirectional,categoryEncoding:()=>categoryEncoding,centerCrop:()=>centerCrop,concatenate:()=>exports_layers_concatenate,conv1d:()=>exports_layers_conv1d,conv2d:()=>exports_layers_conv2d,conv2dTranspose:()=>conv2dTranspose,conv3d:()=>exports_layers_conv3d,conv3dTranspose:()=>conv3dTranspose,convLstm2d:()=>convLstm2d,convLstm2dCell:()=>convLstm2dCell,cropping2D:()=>cropping2D,dense:()=>dense,depthwiseConv2d:()=>exports_layers_depthwiseConv2d,dot:()=>exports_layers_dot,dropout:()=>exports_layers_dropout,elu:()=>exports_layers_elu,embedding:()=>embedding,flatten:()=>exports_layers_flatten,gaussianDropout:()=>gaussianDropout,gaussianNoise:()=>gaussianNoise,globalAveragePooling1d:()=>globalAveragePooling1d,globalAveragePooling2d:()=>globalAveragePooling2d,globalMaxPool1d:()=>globalMaxPool1d,globalMaxPool2d:()=>globalMaxPool2d,globalMaxPooling1d:()=>globalMaxPooling1d,globalMaxPooling2d:()=>globalMaxPooling2d,gru:()=>gru,gruCell:()=>gruCell,input:()=>input,inputLayer:()=>inputLayer,layerNormalization:()=>layerNormalization,leakyReLU:()=>leakyReLU,lstm:()=>lstm,lstmCell:()=>lstmCell,masking:()=>masking,maxPool1d:()=>maxPool1d,maxPool2d:()=>maxPool2d,maxPooling1d:()=>maxPooling1d,maxPooling2d:()=>maxPooling2d,maxPooling3d:()=>maxPooling3d,maximum:()=>exports_layers_maximum,minimum:()=>exports_layers_minimum,multiply:()=>exports_layers_multiply,permute:()=>permute,prelu:()=>exports_layers_prelu,randomWidth:()=>randomWidth,reLU:()=>reLU,repeatVector:()=>repeatVector,rescaling:()=>rescaling,reshape:()=>exports_layers_reshape,resizing:()=>resizing,rnn:()=>exports_layers_rnn,separableConv2d:()=>separableConv2d,simpleRNN:()=>simpleRNN,simpleRNNCell:()=>simpleRNNCell,softmax:()=>exports_layers_softmax,spatialDropout1d:()=>spatialDropout1d,stackedRNNCells:()=>stackedRNNCells,thresholdedReLU:()=>thresholdedReLU,timeDistributed:()=>timeDistributed,upSampling2d:()=>upSampling2d,zeroPadding2d:()=>zeroPadding2d});var exports_metrics_namespaceObject={};__webpack_require__.r(exports_metrics_namespaceObject),__webpack_require__.d(exports_metrics_namespaceObject,{MAPE:()=>exports_metrics_MAPE,MSE:()=>exports_metrics_MSE,binaryAccuracy:()=>exports_metrics_binaryAccuracy,binaryCrossentropy:()=>exports_metrics_binaryCrossentropy,categoricalAccuracy:()=>exports_metrics_categoricalAccuracy,categoricalCrossentropy:()=>exports_metrics_categoricalCrossentropy,cosineProximity:()=>exports_metrics_cosineProximity,mape:()=>exports_metrics_mape,meanAbsoluteError:()=>exports_metrics_meanAbsoluteError,meanAbsolutePercentageError:()=>exports_metrics_meanAbsolutePercentageError,meanSquaredError:()=>exports_metrics_meanSquaredError,mse:()=>exports_metrics_mse,precision:()=>exports_metrics_precision,r2Score:()=>exports_metrics_r2Score,recall:()=>exports_metrics_recall,sparseCategoricalAccuracy:()=>exports_metrics_sparseCategoricalAccuracy});var exports_models_namespaceObject={};__webpack_require__.r(exports_models_namespaceObject),__webpack_require__.d(exports_models_namespaceObject,{modelFromJSON:()=>modelFromJSON});var exports_regularizers_namespaceObject={};__webpack_require__.r(exports_regularizers_namespaceObject),__webpack_require__.d(exports_regularizers_namespaceObject,{l1:()=>exports_regularizers_l1,l1l2:()=>l1l2,l2:()=>exports_regularizers_l2});var arithmetic_namespaceObject={};__webpack_require__.r(arithmetic_namespaceObject),__webpack_require__.d(arithmetic_namespaceObject,{json:()=>json});var basic_math_namespaceObject={};__webpack_require__.r(basic_math_namespaceObject),__webpack_require__.d(basic_math_namespaceObject,{json:()=>basic_math_json});var control_namespaceObject={};__webpack_require__.r(control_namespaceObject),__webpack_require__.d(control_namespaceObject,{json:()=>control_json});var convolution_namespaceObject={};__webpack_require__.r(convolution_namespaceObject),__webpack_require__.d(convolution_namespaceObject,{json:()=>convolution_json});var creation_namespaceObject={};__webpack_require__.r(creation_namespaceObject),__webpack_require__.d(creation_namespaceObject,{json:()=>creation_json});var dynamic_namespaceObject={};__webpack_require__.r(dynamic_namespaceObject),__webpack_require__.d(dynamic_namespaceObject,{json:()=>dynamic_json});var evaluation_namespaceObject={};__webpack_require__.r(evaluation_namespaceObject),__webpack_require__.d(evaluation_namespaceObject,{json:()=>evaluation_json});var graph_namespaceObject={};__webpack_require__.r(graph_namespaceObject),__webpack_require__.d(graph_namespaceObject,{json:()=>graph_json});var hash_table_namespaceObject={};__webpack_require__.r(hash_table_namespaceObject),__webpack_require__.d(hash_table_namespaceObject,{json:()=>hash_table_json});var image_namespaceObject={};__webpack_require__.r(image_namespaceObject),__webpack_require__.d(image_namespaceObject,{json:()=>image_json});var logical_namespaceObject={};__webpack_require__.r(logical_namespaceObject),__webpack_require__.d(logical_namespaceObject,{json:()=>logical_json});var matrices_namespaceObject={};__webpack_require__.r(matrices_namespaceObject),__webpack_require__.d(matrices_namespaceObject,{json:()=>matrices_json});var op_list_normalization_namespaceObject={};__webpack_require__.r(op_list_normalization_namespaceObject),__webpack_require__.d(op_list_normalization_namespaceObject,{json:()=>normalization_json});var reduction_namespaceObject={};__webpack_require__.r(reduction_namespaceObject),__webpack_require__.d(reduction_namespaceObject,{json:()=>reduction_json});var slice_join_namespaceObject={};__webpack_require__.r(slice_join_namespaceObject),__webpack_require__.d(slice_join_namespaceObject,{json:()=>slice_join_json});var sparse_namespaceObject={};__webpack_require__.r(sparse_namespaceObject),__webpack_require__.d(sparse_namespaceObject,{json:()=>sparse_json});var spectral_namespaceObject={};__webpack_require__.r(spectral_namespaceObject),__webpack_require__.d(spectral_namespaceObject,{json:()=>spectral_json});var string_namespaceObject={};__webpack_require__.r(string_namespaceObject),__webpack_require__.d(string_namespaceObject,{json:()=>string_json});var transformation_namespaceObject={};__webpack_require__.r(transformation_namespaceObject),__webpack_require__.d(transformation_namespaceObject,{json:()=>transformation_json});var ops_for_converter_namespaceObject={};__webpack_require__.r(ops_for_converter_namespaceObject),__webpack_require__.d(ops_for_converter_namespaceObject,{OP_SCOPE_SUFFIX:()=>ops.BTT,abs:()=>ops.tnl,acos:()=>ops.HQu,acosh:()=>ops.FqL,add:()=>ops.WQq,addN:()=>ops.QiD,all:()=>ops.Q7R,any:()=>ops.bzn,argMax:()=>ops.FLi,argMin:()=>ops.XRg,asin:()=>ops.qRo,asinh:()=>ops.yHs,atan:()=>ops.rYl,atan2:()=>ops.FPz,atanh:()=>ops.rfv,avgPool:()=>ops.$jT,avgPool3d:()=>ops.sub,basicLSTMCell:()=>ops.lZX,batchNorm:()=>ops.$v7,batchNorm2d:()=>ops.BFc,batchNorm3d:()=>ops.kSi,batchNorm4d:()=>ops.T5N,batchToSpaceND:()=>ops.GTe,bincount:()=>ops.HbZ,bitwiseAnd:()=>ops.vjT,booleanMaskAsync:()=>ops.ftb,broadcastArgs:()=>ops.ROE,broadcastTo:()=>ops.hOW,buffer:()=>ops.ra8,cast:()=>ops.wgE,ceil:()=>ops.mkO,clipByValue:()=>ops.zQh,clone:()=>ops.o8B,complex:()=>ops.faB,concat:()=>ops.xWs,concat1d:()=>ops.I1m,concat2d:()=>ops.RPU,concat3d:()=>ops.O5O,concat4d:()=>ops.P1l,conv1d:()=>ops.kA9,conv2d:()=>ops.Xtf,conv2dTranspose:()=>ops.wX9,conv3d:()=>ops.IPL,conv3dTranspose:()=>ops.jIJ,cos:()=>ops.gnS,cosh:()=>ops.yIG,cosineWindow:()=>ops._jP,cumprod:()=>ops.Lp0,cumsum:()=>ops.rCv,denseBincount:()=>ops.aOp,depthToSpace:()=>ops.Rj8,depthwiseConv2d:()=>ops.Gl3,diag:()=>ops.smy,dilation2d:()=>ops.X7t,div:()=>ops.y4m,divNoNan:()=>ops.ek5,dot:()=>ops.Omf,dropout:()=>ops.EZY,einsum:()=>ops._3C,elu:()=>ops.Pqc,enclosingPowerOfTwo:()=>ops.FJY,ensureShape:()=>ops.QP2,equal:()=>ops.LCg,erf:()=>ops.Y12,euclideanNorm:()=>ops.p4S,exp:()=>ops.oNF,expandDims:()=>ops.UG6,expm1:()=>ops.IYd,eye:()=>ops.y5U,fft:()=>ops.hVP,fill:()=>ops.GSj,floor:()=>ops.RIf,floorDiv:()=>ops.wh_,fused:()=>ops.cZk,gather:()=>ops.kgh,gatherND:()=>ops.SY9,greater:()=>ops.rhj,greaterEqual:()=>ops.DQN,ifft:()=>ops.KGM,imag:()=>ops.ngS,image:()=>ops.Slp,inTopKAsync:()=>ops.U4u,irfft:()=>ops.ggX,isFinite:()=>ops.MIs,isInf:()=>ops.EN4,isNaN:()=>ops.yrW,leakyRelu:()=>ops.H8d,less:()=>ops.M7h,lessEqual:()=>ops.InN,linalg:()=>ops.mPL,linspace:()=>ops.mT8,localResponseNormalization:()=>ops.Kgs,log:()=>ops.Rm2,log1p:()=>ops.Kko,logSigmoid:()=>ops.nqI,logSoftmax:()=>ops.HPB,logSumExp:()=>ops.VZ,logicalAnd:()=>ops.n76,logicalNot:()=>ops.NSZ,logicalOr:()=>ops.ztW,logicalXor:()=>ops.rxB,losses:()=>ops.YYh,lowerBound:()=>ops.yzS,matMul:()=>ops.NoW,max:()=>ops.T9B,maxPool:()=>ops.jgi,maxPool3d:()=>ops.NYV,maxPoolWithArgmax:()=>ops.RO,maximum:()=>ops.PhQ,mean:()=>ops.i2o,meshgrid:()=>ops.OYQ,min:()=>ops.jkA,minimum:()=>ops.BpO,mirrorPad:()=>ops.FFZ,mod:()=>ops.ziu,moments:()=>ops.Clk,movingAverage:()=>ops.CRk,mul:()=>ops.lKK,multiRNNCell:()=>ops.YDF,multinomial:()=>ops.OjQ,neg:()=>ops.HZy,norm:()=>ops.xbf,notEqual:()=>ops.Ec,oneHot:()=>ops.Mw0,ones:()=>ops.SaS,onesLike:()=>ops.P61,op:()=>ops.op,outerProduct:()=>ops.X4o,pad:()=>ops.eVF,pad1d:()=>ops.BZs,pad2d:()=>ops.grY,pad3d:()=>ops.XHu,pad4d:()=>ops.WLX,pool:()=>ops.dzn,pow:()=>ops.n7C,prelu:()=>ops.NsG,print:()=>ops.yyV,prod:()=>ops._eU,raggedGather:()=>ops.whe,raggedRange:()=>ops.iyU,raggedTensorToTensor:()=>ops.Q0_,rand:()=>ops._9M,randomGamma:()=>ops.pR9,randomNormal:()=>ops.FE$,randomStandardNormal:()=>ops.m0H,randomUniform:()=>ops.YeY,randomUniformInt:()=>ops.HYA,range:()=>ops.y17,real:()=>ops.xav,reciprocal:()=>ops.VOZ,relu:()=>ops.VVh,relu6:()=>ops.j__,reshape:()=>ops.tQQ,reverse:()=>ops.BEg,reverse1d:()=>ops.QD2,reverse2d:()=>ops.LMr,reverse3d:()=>ops.I2l,reverse4d:()=>ops.JYU,rfft:()=>ops.z8$,round:()=>ops.LIG,rsqrt:()=>ops.Z$r,scalar:()=>ops.d_2,scatterND:()=>ops.NFr,searchSorted:()=>ops.sZg,selu:()=>ops.WfX,separableConv2d:()=>ops.wdz,setdiff1dAsync:()=>ops.F12,sigmoid:()=>ops.ry7,sign:()=>ops._SZ,signal:()=>ops.vPA,sin:()=>ops.F8e,sinh:()=>ops.L0l,slice:()=>ops.dik,slice1d:()=>ops.Q$M,slice2d:()=>ops.zAd,slice3d:()=>ops.wck,slice4d:()=>ops.R0O,softmax:()=>ops.Vs9,softplus:()=>ops.lw0,spaceToBatchND:()=>ops.eDJ,sparse:()=>ops.lMo,sparseToDense:()=>ops.Zhr,spectral:()=>ops.lOn,split:()=>ops.lDo,sqrt:()=>ops.RZD,square:()=>ops.EwI,squaredDifference:()=>ops.Pbu,squeeze:()=>ops.r2V,stack:()=>ops.t$z,step:()=>ops.PMw,stridedSlice:()=>ops.Ym9,string:()=>ops.YjP,sub:()=>ops.jbE,sum:()=>ops.czq,tan:()=>ops.Mlm,tanh:()=>ops.ymU,tensor:()=>ops.OEK,tensor1d:()=>ops.tGX,tensor2d:()=>ops.KtR,tensor3d:()=>ops.$_$,tensor4d:()=>ops.g9W,tensor5d:()=>ops.Lpo,tensor6d:()=>ops.yxw,tensorScatterUpdate:()=>ops.NNh,tile:()=>ops.Vsq,topk:()=>ops.rfw,transpose:()=>ops.mgz,truncatedNormal:()=>ops.efE,unique:()=>ops.AmM,unsortedSegmentSum:()=>ops.zAU,unstack:()=>ops.K$i,upperBound:()=>ops.rni,variable:()=>ops.bvq,where:()=>ops._M9,whereAsync:()=>ops.YJN,zeros:()=>ops.Ul9,zerosLike:()=>ops.POl});var tfjs_data_dist_namespaceObject={};__webpack_require__.r(tfjs_data_dist_namespaceObject),__webpack_require__.d(tfjs_data_dist_namespaceObject,{CSVDataset:()=>CSVDataset,Dataset:()=>Dataset,FileDataSource:()=>FileDataSource,TextLineDataset:()=>TextLineDataset,URLDataSource:()=>URLDataSource,array:()=>array,csv:()=>csv,func:()=>func,generator:()=>generator,microphone:()=>microphone,version_data:()=>dist_version_version,webcam:()=>webcam,zip:()=>zip});var shared_namespaceObject={};__webpack_require__.r(shared_namespaceObject),__webpack_require__.d(shared_namespaceObject,{addImpl:()=>addImpl,bincountImpl:()=>bincountImpl,bincountReduceImpl:()=>bincountReduceImpl,bitwiseAndImpl:()=>bitwiseAndImpl,castImpl:()=>castImpl,ceilImpl:()=>ceilImpl,concatImpl:()=>Concat_impl.h,equalImpl:()=>equalImpl,expImpl:()=>expImpl,expm1Impl:()=>expm1Impl,floorDivImpl:()=>floorDivImpl,floorImpl:()=>floorImpl,gatherNdImpl:()=>gatherNdImpl,gatherV2Impl:()=>gatherV2Impl,greaterEqualImpl:()=>greaterEqualImpl,greaterImpl:()=>greaterImpl,lessEqualImpl:()=>lessEqualImpl,lessImpl:()=>lessImpl,linSpaceImpl:()=>linSpaceImpl,logImpl:()=>logImpl,maxImpl:()=>maxImpl,maximumImpl:()=>maximumImpl,minimumImpl:()=>minimumImpl,multiplyImpl:()=>multiplyImpl,negImpl:()=>negImpl,notEqualImpl:()=>notEqualImpl,prodImpl:()=>prodImpl,raggedGatherImpl:()=>raggedGatherImpl,raggedRangeImpl:()=>raggedRangeImpl,raggedTensorToTensorImpl:()=>raggedTensorToTensorImpl,rangeImpl:()=>Range_impl.q,rsqrtImpl:()=>rsqrtImpl,scatterImpl:()=>scatterImpl,sigmoidImpl:()=>sigmoidImpl,simpleAbsImpl:()=>simpleAbsImpl,sliceImpl:()=>Slice.HS,sparseFillEmptyRowsImpl:()=>sparseFillEmptyRowsImpl,sparseReshapeImpl:()=>sparseReshapeImpl,sparseSegmentReductionImpl:()=>sparseSegmentReductionImpl,sqrtImpl:()=>sqrtImpl,squaredDifferenceImpl:()=>squaredDifferenceImpl,staticRegexReplaceImpl:()=>staticRegexReplaceImpl,stridedSliceImpl:()=>stridedSliceImpl,stringNGramsImpl:()=>StringNGrams_impl.G,stringSplitImpl:()=>StringSplit_impl.S,stringToHashBucketFastImpl:()=>StringToHashBucketFast_impl.f,subImpl:()=>subImpl,tileImpl:()=>tileImpl,topKImpl:()=>topKImpl,transposeImpl:()=>transposeImpl,uniqueImpl:()=>Unique_impl.w});var webgl_util_namespaceObject={};__webpack_require__.r(webgl_util_namespaceObject),__webpack_require__.d(webgl_util_namespaceObject,{assertNotComplex:()=>assertNotComplex,bindCanvasToFramebuffer:()=>bindCanvasToFramebuffer,bindColorTextureToFramebuffer:()=>bindColorTextureToFramebuffer,bindTextureToProgramUniformSampler:()=>bindTextureToProgramUniformSampler,bindTextureUnit:()=>bindTextureUnit,bindVertexBufferToProgramAttribute:()=>bindVertexBufferToProgramAttribute,callAndCheck:()=>callAndCheck,canBeRepresented:()=>canBeRepresented,createFragmentShader:()=>createFragmentShader,createFramebuffer:()=>createFramebuffer,createProgram:()=>createProgram,createStaticIndexBuffer:()=>createStaticIndexBuffer,createStaticVertexBuffer:()=>createStaticVertexBuffer,createTexture:()=>createTexture,createVertexShader:()=>createVertexShader,getBatchDim:()=>getBatchDim,getExtensionOrThrow:()=>getExtensionOrThrow,getFramebufferErrorMessage:()=>getFramebufferErrorMessage,getMaxTexturesInShader:()=>getMaxTexturesInShader,getNumChannels:()=>getNumChannels,getProgramUniformLocation:()=>getProgramUniformLocation,getProgramUniformLocationOrThrow:()=>getProgramUniformLocationOrThrow,getRowsCols:()=>getRowsCols,getShapeAs3D:()=>getShapeAs3D,getTextureShapeFromLogicalShape:()=>getTextureShapeFromLogicalShape,getWebGLDisjointQueryTimerVersion:()=>getWebGLDisjointQueryTimerVersion,getWebGLErrorMessage:()=>getWebGLErrorMessage,getWebGLMaxTextureSize:()=>getWebGLMaxTextureSize,hasExtension:()=>hasExtension,isCapableOfRenderingToFloatTexture:()=>isCapableOfRenderingToFloatTexture,isDownloadFloatTextureEnabled:()=>isDownloadFloatTextureEnabled,isReshapeFree:()=>isReshapeFree,isWebGLFenceEnabled:()=>isWebGLFenceEnabled,isWebGLVersionEnabled:()=>isWebGLVersionEnabled,linkProgram:()=>linkProgram,logShaderSourceAndInfoLog:()=>logShaderSourceAndInfoLog,resetMaxTextureSize:()=>resetMaxTextureSize,resetMaxTexturesInShader:()=>resetMaxTexturesInShader,unbindColorTextureFromFramebuffer:()=>unbindColorTextureFromFramebuffer,unbindTextureUnit:()=>unbindTextureUnit,validateFramebuffer:()=>validateFramebuffer,validateProgram:()=>validateProgram,validateTextureSize:()=>validateTextureSize});var gpgpu_util_namespaceObject={};__webpack_require__.r(gpgpu_util_namespaceObject),__webpack_require__.d(gpgpu_util_namespaceObject,{bindVertexProgramAttributeStreams:()=>bindVertexProgramAttributeStreams,createBufferFromOutputTexture:()=>createBufferFromOutputTexture,createFloat16MatrixTexture:()=>createFloat16MatrixTexture,createFloat16PackedMatrixTexture:()=>createFloat16PackedMatrixTexture,createFloat32MatrixTexture:()=>createFloat32MatrixTexture,createIndexBuffer:()=>createIndexBuffer,createPackedMatrixTexture:()=>createPackedMatrixTexture,createUnsignedBytesMatrixTexture:()=>createUnsignedBytesMatrixTexture,createVertexBuffer:()=>createVertexBuffer,createVertexShader:()=>gpgpu_util_createVertexShader,downloadByteEncodedFloatMatrixFromOutputTexture:()=>downloadByteEncodedFloatMatrixFromOutputTexture,downloadFloat32MatrixFromBuffer:()=>downloadFloat32MatrixFromBuffer,downloadMatrixFromPackedOutputTexture:()=>downloadMatrixFromPackedOutputTexture,downloadPackedMatrixFromBuffer:()=>downloadPackedMatrixFromBuffer,getInternalFormatForFloat16MatrixTexture:()=>getInternalFormatForFloat16MatrixTexture,getInternalFormatForFloat16PackedMatrixTexture:()=>getInternalFormatForFloat16PackedMatrixTexture,getInternalFormatForFloat32MatrixTexture:()=>getInternalFormatForFloat32MatrixTexture,getInternalFormatForPackedMatrixTexture:()=>getInternalFormatForPackedMatrixTexture,getInternalFormatForUnsignedBytesMatrixTexture:()=>getInternalFormatForUnsignedBytesMatrixTexture,uploadDenseMatrixToTexture:()=>uploadDenseMatrixToTexture,uploadPixelDataToTexture:()=>uploadPixelDataToTexture});var dist=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/index.js"),kernel_names=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js"),cast=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/cast.js"),mul=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/mul.js"),step=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/step.js");const absGradConfig={kernelName:kernel_names.ljI,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,mul.l)(dy,(0,step.P)((0,cast.w)(x,"float32"),-1))}}};var div=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/div.js"),neg=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/neg.js"),ops_scalar=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/scalar.js"),sqrt=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/sqrt.js"),square=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/square.js"),sub=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/sub.js");const acosGradConfig={kernelName:kernel_names.Vvy,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>{const a=(0,square.E)((0,cast.w)(x,"float32")),b=(0,sqrt.R)((0,sub.j)((0,ops_scalar.d)(1),a));return(0,neg.H)((0,div.y)(dy,b))}}}},acoshGradConfig={kernelName:kernel_names.PH8,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>{const a=(0,sqrt.R)((0,sub.j)((0,square.E)((0,cast.w)(x,"float32")),1));return(0,div.y)(dy,a)}}}};var broadcast_util=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js"),reshape=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/reshape.js"),sum=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/sum.js");const addGradConfig={kernelName:kernel_names.OMN,inputsToSave:["a","b"],gradFunc:(dy,saved)=>{const[a,b]=saved,outShape=broadcast_util.assertAndGetBroadcastShape(a.shape,b.shape);return{a:()=>{let res=dy;const reduceAxes=broadcast_util.getReductionAxes(a.shape,outShape);return reduceAxes.length>0&&(res=(0,sum.c)(res,reduceAxes)),(0,reshape.t)(res,a.shape)},b:()=>{let res=dy;const reduceAxes=broadcast_util.getReductionAxes(b.shape,outShape);return reduceAxes.length>0&&(res=(0,sum.c)(res,reduceAxes)),(0,reshape.t)(res,b.shape)}}}},addNGradConfig={kernelName:kernel_names.EkD,saveAllInputs:!0,gradFunc:(dy,saved)=>{const ders={};return saved.forEach((_,i)=>{ders[i]=()=>dy.clone()}),ders}};var zeros_like=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/zeros_like.js");const argMaxGradConfig={kernelName:kernel_names.Jp_,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,zeros_like.P)(x)}}},argMinGradConfig={kernelName:kernel_names.p_m,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,zeros_like.P)(x)}}},asinGradConfig={kernelName:kernel_names.QKF,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,div.y)(dy,(0,sqrt.R)((0,sub.j)((0,ops_scalar.d)(1),(0,square.E)((0,cast.w)(x,"float32")))))}}};var add=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/add.js");const asinhGradConfig={kernelName:kernel_names.epO,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>{const a=(0,sqrt.R)((0,add.W)((0,ops_scalar.d)(1),(0,square.E)((0,cast.w)(x,"float32"))));return(0,div.y)(dy,a)}}}},atan2GradConfig={kernelName:kernel_names.lxb,inputsToSave:["a","b"],gradFunc:(dy,saved)=>{const[a,b]=saved,outShape=(0,broadcast_util.assertAndGetBroadcastShape)(a.shape,b.shape);return{a:()=>{const d=(0,add.W)((0,square.E)(a),(0,square.E)(b));let res=(0,mul.l)(dy,(0,div.y)(b,d));const reduceAxes=(0,broadcast_util.getReductionAxes)(a.shape,outShape);return reduceAxes.length>0&&(res=(0,sum.c)(res,reduceAxes)),(0,reshape.t)(res,a.shape)},b:()=>{const d=(0,add.W)((0,square.E)(a),(0,square.E)(b));let res=(0,neg.H)((0,mul.l)(dy,(0,div.y)(a,d)));const reduceAxes=(0,broadcast_util.getReductionAxes)(b.shape,outShape);return reduceAxes.length>0&&(res=(0,sum.c)(res,reduceAxes)),(0,reshape.t)(res,b.shape)}}}},atanGradConfig={kernelName:kernel_names.TyE,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,div.y)(dy,(0,add.W)((0,square.E)((0,cast.w)(x,"float32")),1))}}},atanhGradConfig={kernelName:kernel_names.zP9,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,div.y)(dy,(0,sub.j)((0,ops_scalar.d)(1),(0,square.E)((0,cast.w)(x,"float32"))))}}};var engine=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/engine.js"),tensor_util_env=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js"),util_base=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/util_base.js"),conv_util=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js"),operation=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js");const avgPool3dGrad=(0,operation.op)({avgPool3dGrad_:function avgPool3dGrad_(dy,input,filterSize,strides,pad,dimRoundingMode){const $dy=(0,tensor_util_env.YT)(dy,"dy","avgPool3dGrad"),$input=(0,tensor_util_env.YT)(input,"input","avgPool3dGrad");let dy5D=$dy,input5D=$input,reshapedTo5D=!1;4===$input.rank&&(reshapedTo5D=!0,dy5D=(0,reshape.t)($dy,[1,$dy.shape[0],$dy.shape[1],$dy.shape[2],$dy.shape[3]]),input5D=(0,reshape.t)($input,[1,$input.shape[0],$input.shape[1],$input.shape[2],$input.shape[3]])),util_base.vA(5===dy5D.rank,()=>`Error in avgPool3dGrad: dy must be rank 5 but got rank ${dy5D.rank}.`),util_base.vA(5===input5D.rank,()=>`Error in avgPool3dGrad: input must be rank 5 but got rank ${input5D.rank}.`),(0,conv_util.s_)("avgPool3dGrad",pad,dimRoundingMode);const inputs={dy:dy5D,input:input5D},attrs={filterSize,strides,pad,dimRoundingMode},res=engine.T2.runKernel(kernel_names.wwC,inputs,attrs);return reshapedTo5D?(0,reshape.t)(res,[res.shape[1],res.shape[2],res.shape[3],res.shape[4]]):res}}),avgPool3DGradConfig={kernelName:kernel_names.cS,inputsToSave:["x"],gradFunc:(dy,saved,attrs)=>{const[x]=saved,{filterSize,strides,pad,dimRoundingMode}=attrs;return{x:()=>avgPool3dGrad(dy,x,filterSize,strides,pad,dimRoundingMode)}}};const avgPoolGrad=(0,operation.op)({avgPoolGrad_:function avgPoolGrad_(dy,input,filterSize,strides,pad){const $dy=(0,tensor_util_env.YT)(dy,"dy","avgPoolGrad"),$input=(0,tensor_util_env.YT)(input,"input","avgPoolGrad");util_base.vA($input.rank===$dy.rank,()=>`Rank of input (${$input.rank}) does not match rank of dy (${$dy.rank})`);let input4D=$input,dy4D=$dy,reshapedTo4D=!1;3===$input.rank&&(reshapedTo4D=!0,input4D=(0,reshape.t)($input,[1,$input.shape[0],$input.shape[1],$input.shape[2]]),dy4D=(0,reshape.t)($dy,[1,$dy.shape[0],$dy.shape[1],$dy.shape[2]])),util_base.vA(4===dy4D.rank,()=>`Error in avgPoolGrad: dy must be rank 4 but got rank ${dy4D.rank}.`),util_base.vA(4===input4D.rank,()=>`Error in avgPoolGrad: input must be rank 4 but got rank ${input4D.rank}.`);const inputs={dy:dy4D,input:input4D},attrs={filterSize,strides,pad},res=engine.T2.runKernel(kernel_names.VCH,inputs,attrs);return reshapedTo4D?(0,reshape.t)(res,[res.shape[1],res.shape[2],res.shape[3]]):res}}),avgPoolGradConfig={kernelName:kernel_names.ho8,inputsToSave:["x"],gradFunc:(dy,saved,attrs)=>{const[x]=saved,{filterSize,strides,pad}=attrs;return{x:()=>avgPoolGrad(dy,x,filterSize,strides,pad)}}};var mat_mul=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/mat_mul.js");const batchMatMulGradConfig={kernelName:kernel_names.jAQ,inputsToSave:["a","b"],gradFunc:(dy,saved,attrs)=>{const[a,b]=saved,{transposeA,transposeB}=attrs;return transposeA||transposeB?!transposeA&&transposeB?{a:()=>(0,mat_mul.N)(dy,b,!1,!1),b:()=>(0,mat_mul.N)(dy,a,!0,!1)}:transposeA&&!transposeB?{a:()=>(0,mat_mul.N)(b,dy,!1,!0),b:()=>(0,mat_mul.N)(a,dy,!1,!1)}:{a:()=>(0,mat_mul.N)(b,dy,!0,!0),b:()=>(0,mat_mul.N)(dy,a,!0,!0)}:{a:()=>(0,mat_mul.N)(dy,b,!1,!0),b:()=>(0,mat_mul.N)(a,dy,!0,!1)}}};var space_to_batch_nd=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js");const batchToSpaceNDGradConfig={kernelName:kernel_names.Ik2,gradFunc:(dy,saved,attrs)=>{const{blockShape,crops}=attrs;return{x:()=>(0,space_to_batch_nd.e)(dy,blockShape,crops)}}},broadcastToGradConfig={kernelName:kernel_names.LB5,gradFunc:(dy,saved,attrs)=>{const broadCastToAttrs=attrs,inputShape=broadCastToAttrs.inputShape,outputShape=broadCastToAttrs.shape,reps=Array.from(outputShape);for(let i=inputShape.length-1;i>=0;i--)if(inputShape[i]===outputShape[i])reps[i]=1;else if(1!==inputShape[i])throw new Error(`broadcastTo(): [${inputShape}] cannot be broadcast to [${outputShape}].`);const axes=[];for(let i=0;i<reps.length;i++)reps[i]>1&&axes.push(i);return{x:()=>(0,sum.c)(dy,axes,!0)}}},castGradConfig={kernelName:kernel_names.KXH,gradFunc:dy=>({x:()=>dy.clone()})},ceilGradConfig={kernelName:kernel_names.QDP,gradFunc:dy=>({x:()=>(0,zeros_like.P)(dy)})};var greater_equal=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/greater_equal.js"),less_equal=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/less_equal.js"),logical_and=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/logical_and.js"),ops_where=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/where.js");const clipByValueGradConfig={kernelName:kernel_names.vaV,inputsToSave:["x"],gradFunc:(dy,saved,attrs)=>{const[x]=saved,{clipValueMin,clipValueMax}=attrs;return{x:()=>(0,ops_where._)((0,logical_and.n)((0,greater_equal.D)(x,clipValueMin),(0,less_equal.I)(x,clipValueMax)),dy,(0,zeros_like.P)(dy))}}},complexAbsGradConfig={kernelName:kernel_names.$zE,inputsToSave:["x"],gradFunc:absGradConfig.gradFunc};var split=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/split.js");const concatGradConfig={kernelName:kernel_names.$dB,saveAllInputs:!0,gradFunc:(dy,saved,attrs)=>{const shapes=saved.map(t=>t.shape),{axis}=attrs,$axis=(0,util_base.Y6)(axis,saved[0].shape)[0],sizeSplits=shapes.map(s=>s[$axis]);return(0,split.l)(dy,sizeSplits,$axis).map(t=>()=>t)}};var conv2d_backprop_filter=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js"),conv2d_backprop_input=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js");const conv2DGradConfig={kernelName:kernel_names.p2J,inputsToSave:["x","filter"],gradFunc:(dy,saved,attrs)=>{const[x4D,$filter]=saved,{dilations,strides,pad,dataFormat}=attrs;return util_base.vA(conv_util.Dh(dilations),()=>`Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`),{x:()=>(0,conv2d_backprop_input.v)(x4D.shape,dy,$filter,strides,pad,dataFormat),filter:()=>(0,conv2d_backprop_filter.H)(x4D,dy,$filter.shape,strides,pad,dataFormat)}}};var conv2d=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d.js");const conv2DBackpropInputGradConfig={kernelName:kernel_names.jfg,inputsToSave:["dy","filter"],gradFunc:(ddx,saved,attrs)=>{const[dy,filter]=saved,{strides,pad,dataFormat,dimRoundingMode}=attrs;return{dy:()=>(0,conv2d.X)(ddx,filter,strides,pad,dataFormat,1,dimRoundingMode),filter:()=>(0,conv2d_backprop_filter.H)(ddx,dy,filter.shape,strides,pad,dataFormat,dimRoundingMode)}}};const conv3DBackpropFilter=(0,operation.op)({conv3DBackpropFilter_:function conv3DBackpropFilter_(x,dy,filterShape,strides,pad){let x5D=x;4===x.rank&&(x5D=(0,reshape.t)(x,[1,x.shape[0],x.shape[1],x.shape[2],x.shape[3]]));let dy5D=dy;4===dy5D.rank&&(dy5D=(0,reshape.t)(dy,[1,dy.shape[0],dy.shape[1],dy.shape[2],dy.shape[3]])),util_base.vA(5===x5D.rank,()=>`Error in conv3dDerFilter: input must be rank 5, but got shape ${x5D.shape}.`),util_base.vA(5===dy5D.rank,()=>`Error in conv3dDerFilter: dy must be rank 5, but got shape ${dy5D.shape}.`),util_base.vA(5===filterShape.length,()=>`Error in conv3dDerFilter: filterShape must be length 5, but got ${filterShape}.`),util_base.vA(x5D.shape[4]===filterShape[3],()=>`Error in conv3dDerFilter: depth of input ${x5D.shape[4]}) must match input depth in filter (${filterShape[3]}.`),util_base.vA(dy5D.shape[4]===filterShape[4],()=>`Error in conv3dDerFilter: depth of dy (${dy5D.shape[4]}) must match output depth for filter (${filterShape[4]}).`);const inputs={x:x5D,dy:dy5D},attrs={strides,pad,filterShape};return engine.T2.runKernel(kernel_names.iGz,inputs,attrs)}});var conv3d_backprop_input=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js");const conv3DGradConfig={kernelName:kernel_names.A1h,inputsToSave:["x","filter"],gradFunc:(dy,saved,attrs)=>{const{dilations,strides,pad}=attrs;util_base.vA((0,conv_util.Dh)(dilations),()=>`Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`);const[x5D,$filter]=saved;return{x:()=>(0,conv3d_backprop_input.c)(x5D.shape,dy,$filter,strides,pad),filter:()=>conv3DBackpropFilter(x5D,dy,$filter.shape,strides,pad)}}};var sin=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/sin.js");const cosGradConfig={kernelName:kernel_names.Mn0,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,mul.l)((0,neg.H)((0,sin.F)((0,cast.w)(x,"float32"))),dy)}}};var sinh=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/sinh.js");const coshGradConfig={kernelName:kernel_names.MnK,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,mul.l)((0,sinh.L)((0,cast.w)(x,"float32")),dy)}}};var axis_util=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js"),cumsum=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/cumsum.js"),transpose=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js");const cumsumGradConfig={kernelName:kernel_names.nY8,inputsToSave:["x"],gradFunc:(dy,saved,attrs)=>{const[x]=saved,{axis,exclusive,reverse}=attrs;return{x:()=>{const permutation=(0,axis_util.Em)([axis],x.rank);let out=(0,cumsum.r)(dy,axis,exclusive,!reverse);return null!=permutation&&(out=(0,transpose.m)(out,permutation)),out}}}};var depthwise_conv2d_native_backprop_filter=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js"),depthwise_conv2d_native_backprop_input=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js");const depthwiseConv2dNativeGradConfig={kernelName:kernel_names.tGH,inputsToSave:["x","filter"],gradFunc:(dy,saved,attrs)=>{const{dilations,strides,pad,dimRoundingMode}=attrs,$dilations=null==dilations?[1,1]:dilations;util_base.vA(conv_util.Dh($dilations),()=>`Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${$dilations}'`);const[x,filter]=saved;return util_base.vA(4===x.rank,()=>`Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${x.rank}.`),util_base.vA(4===filter.rank,()=>`Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${filter.rank}.`),util_base.vA(x.shape[3]===filter.shape[2],()=>`Error in gradient of depthwiseConv2d: number of input channels (${x.shape[3]}) must match the inChannels dimension in filter ${filter.shape[2]}.`),util_base.vA(conv_util.G0(strides,$dilations),()=>`Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${strides} and dilations '${$dilations}'.`),conv_util.s_("depthwiseConv2d",pad,dimRoundingMode),{x:()=>(0,depthwise_conv2d_native_backprop_input.l)(x.shape,dy,filter,strides,pad,$dilations,dimRoundingMode),filter:()=>(0,depthwise_conv2d_native_backprop_filter.x)(x,dy,filter.shape,strides,pad,$dilations,dimRoundingMode)}}},dilation2dGradConfig={kernelName:kernel_names.jxD,inputsToSave:["x","filter"],gradFunc:(dy,saved,attrs)=>{const[x,filter]=saved,inputInputs={x,filter,dy},filterInputs={x,filter,dy};return{x:()=>engine.T2.runKernel(kernel_names.bP9,inputInputs,attrs),filter:()=>engine.T2.runKernel(kernel_names.pk0,filterInputs,attrs)}}},eluGradConfig={kernelName:kernel_names.Pah,outputsToSave:[!0],gradFunc:(dy,saved)=>{const[y]=saved,inputs={dy,y};return{x:()=>engine.T2.runKernel(kernel_names.rsH,inputs)}}};var exp=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/exp.js");const erfGradConfig={kernelName:kernel_names._s9,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved,a=(0,mul.l)((0,exp.o)((0,neg.H)((0,square.E)(x))),2/Math.sqrt(Math.PI));return{x:()=>(0,mul.l)(dy,a)}}},expGradConfig={kernelName:kernel_names.ox3,outputsToSave:[!0],gradFunc:(dy,saved)=>{const[y]=saved;return{x:()=>(0,mul.l)(dy,y)}}},expandDimsGradConfig={kernelName:kernel_names.ybN,inputsToSave:["input"],gradFunc:(dy,saved)=>{const[input]=saved;return{input:()=>(0,reshape.t)(dy,input.shape)}}},expm1GradConfig={kernelName:kernel_names.ybj,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,mul.l)(dy,(0,exp.o)(x))}}},floorGradConfig={kernelName:kernel_names.ZgB,gradFunc:dy=>({x:()=>(0,zeros_like.P)(dy)})},floorDivGradConfig={kernelName:kernel_names.ElG,inputsToSave:["a","b"],gradFunc:(dy,saved)=>{const[a,b]=saved,outShape=(0,broadcast_util.assertAndGetBroadcastShape)(a.shape,b.shape);return{a:()=>{const res=(0,div.y)(dy,(0,cast.w)(b,"float32")),reduceAxes=(0,broadcast_util.getReductionAxes)(a.shape,outShape);return reduceAxes.length>0?(0,reshape.t)((0,sum.c)(res,reduceAxes),a.shape):res},b:()=>{let res=(0,mul.l)(dy,(0,cast.w)(a,"float32"));const reduceAxes=(0,broadcast_util.getReductionAxes)(b.shape,outShape);reduceAxes.length>0&&(res=(0,reshape.t)((0,sum.c)(res,reduceAxes),b.shape));const tmp=(0,square.E)(b);return(0,neg.H)((0,div.y)(res,(0,cast.w)(tmp,"float32")))}}}};var rsqrt=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/rsqrt.js"),tile=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/tile.js");const fusedBatchNormGradConfig={kernelName:kernel_names.i5R,inputsToSave:["x","mean","variance","scale"],gradFunc:(dy,saved,attrs)=>{const{varianceEpsilon}=attrs,[x,mean,variance,scale]=saved,scaleValue=null==scale?(0,ops_scalar.d)(1):scale,reductionAxes=(0,broadcast_util.getReductionAxes)(mean.shape,x.shape),tileShape=[];if(1===mean.rank){for(let i=0;i<x.shape.length-1;++i)tileShape.push(x.shape[i]);tileShape.push(1)}const xMinusMean=(0,sub.j)(x,mean),dyTimesScaleValue=(0,mul.l)(dy,scaleValue),oneOverSqrtVariance=(0,rsqrt.Z)((0,add.W)(variance,(0,ops_scalar.d)(varianceEpsilon))),minusHalfRCube=(0,mul.l)((0,mul.l)((0,mul.l)(oneOverSqrtVariance,oneOverSqrtVariance),oneOverSqrtVariance),(0,ops_scalar.d)(-.5));return{x:()=>1===mean.rank?(0,reshape.t)((0,mul.l)((0,mul.l)(dy,(0,tile.V)((0,reshape.t)(oneOverSqrtVariance,[1,1,1,mean.shape[0]]),tileShape)),scaleValue),x.shape):(0,reshape.t)((0,mul.l)((0,mul.l)(dy,oneOverSqrtVariance),scaleValue),x.shape),mean:()=>{let meanDer=(0,mul.l)((0,mul.l)(oneOverSqrtVariance,(0,ops_scalar.d)(-1)),dyTimesScaleValue);return 1===mean.rank&&(meanDer=(0,sum.c)(meanDer,reductionAxes)),(0,reshape.t)(meanDer,mean.shape)},variance:()=>{let varianceDer=(0,mul.l)((0,mul.l)(minusHalfRCube,xMinusMean),dyTimesScaleValue);return 1===mean.rank&&(varianceDer=(0,sum.c)(varianceDer,reductionAxes)),(0,reshape.t)(varianceDer,mean.shape)},scale:()=>{const xMinusMean2TimesRsqrt=(0,mul.l)(xMinusMean,oneOverSqrtVariance);let scaleDer=(0,mul.l)(dy,xMinusMean2TimesRsqrt);return 1===mean.rank&&(scaleDer=(0,sum.c)(scaleDer,reductionAxes)),(0,reshape.t)(scaleDer,mean.shape)},offset:()=>{let offsetDer=dy;return 1===mean.rank&&(offsetDer=(0,sum.c)(offsetDer,reductionAxes)),(0,reshape.t)(offsetDer,mean.shape)}}}};var stack=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/stack.js"),unsorted_segment_sum=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js");const gatherGradConfig={kernelName:kernel_names.mxL,inputsToSave:["x","indices"],gradFunc:(dy,saved,attrs)=>{const[x,indices]=saved,{axis,batchDims}=attrs,parsedAxis=(0,util_base.Y6)(axis,x.shape)[0],derXBatch=(x,indices,dy)=>()=>{const paramsShape=x.shape,indicesSize=indices.size,outerShape=paramsShape.slice(0,parsedAxis),outerDims=outerShape.length,innerShape=paramsShape.slice(axis,paramsShape.length).slice(1),innerDims=innerShape.length,outerAxesIndices=arrayRange(0,outerDims),innerAxesIndices=arrayRange(outerDims+1,outerDims+1+innerDims),valuesShape=arrayConcat([outerShape,[indicesSize],innerShape]),values=(0,reshape.t)(dy,valuesShape),reshapedIndices=(0,reshape.t)(indices,[indicesSize]),transposeDims=arrayConcat([[outerDims],outerAxesIndices,innerAxesIndices]),valuesTranspose=(0,transpose.m)(values,transposeDims);let paramsGrad=(0,unsorted_segment_sum.z)(valuesTranspose,reshapedIndices,x.shape[parsedAxis]);const invertTransposeDims=(0,axis_util.gx)(transposeDims);return paramsGrad=(0,transpose.m)(paramsGrad,invertTransposeDims),paramsGrad};if(1===batchDims){const batchSize=x.shape[0],xBatch=x.split(batchSize,0);return{x:()=>{const stacked=(0,stack.t)(xBatch.map((x,i)=>derXBatch(x,indices.slice(i,1),dy.slice(i,1))()));return stacked.reshape(x.shape)},indices:()=>indices}}return{x:derXBatch(x,indices,dy),indices:()=>indices}}};function arrayRange(start,stop){const result=[];for(let i=start;i<stop;++i)result.push(i);return result}function arrayConcat(arrays){const result=[];for(let i=0;i<arrays.length;++i)for(let j=0;j<arrays[i].length;++j)result.push(arrays[i][j]);return result}const greaterEqualGradConfig={kernelName:kernel_names.lLS,inputsToSave:["a","b"],gradFunc:(dy,saved)=>{const[a,b]=saved;return{a:()=>(0,zeros_like.P)(a),b:()=>(0,zeros_like.P)(b)}}},identityGradConfig={kernelName:kernel_names.lzr,gradFunc:dy=>({x:()=>(0,cast.w)(dy,"float32")})},isFiniteGradConfig={kernelName:kernel_names.gIW,gradFunc:dy=>({x:()=>(0,zeros_like.P)(dy)})},isInfGradConfig={kernelName:kernel_names.E3$,gradFunc:dy=>({x:()=>(0,zeros_like.P)(dy)})},isNanGradConfig={kernelName:kernel_names.iPs,gradFunc:dy=>({x:()=>(0,zeros_like.P)(dy)})};var greater=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/greater.js");const leakyReluGradConfig={kernelName:kernel_names.X0$,inputsToSave:["x"],gradFunc:(dy,saved,attrs)=>{const[x]=saved,{alpha}=attrs,mask=(0,greater.r)(x,0);return{x:()=>(0,ops_where._)(mask,dy,(0,mul.l)(dy,alpha))}}},log1pGradConfig={kernelName:kernel_names.Cg$,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,div.y)(dy,(0,add.W)(x,1))}}},logGradConfig={kernelName:kernel_names.tG8,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,div.y)(dy,(0,cast.w)(x,"float32"))}}},logSoftmaxGradConfig={kernelName:kernel_names.zfU,inputsToSave:[],outputsToSave:[!0],gradFunc:(dy,saved,attrs)=>{const[value]=saved,{axis}=attrs;return{logits:()=>{const softmax=(0,exp.o)(value);return(0,sub.j)(dy,(0,mul.l)((0,sum.c)(dy,axis,!0),softmax))}}}};const localResponseNormalizationBackprop=(0,operation.op)({localResponseNormalizationBackprop_:function localResponseNormalizationBackprop_(x,y,dy,depthRadius=5,bias=1,alpha=1,beta=.5){const inputs={x,y,dy},attrs={depthRadius,bias,alpha,beta};return engine.T2.runKernel(kernel_names.ToN,inputs,attrs)}}),lrnGradConfig={kernelName:kernel_names.jM4,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(dy,saved,attrs)=>{const[x,y]=saved,{depthRadius,bias,alpha,beta}=attrs;return{x:()=>localResponseNormalizationBackprop(x,y,dy,depthRadius,bias,alpha,beta)}}};var equal=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/equal.js");function gradForMinAndMax(dy,y,xOrig,origAxes){return y.rank<xOrig.rank&&(y=(0,reshape.t)(y,axis_util.SM(y.shape,origAxes))),dy.rank<xOrig.rank&&(dy=(0,reshape.t)(dy,axis_util.SM(dy.shape,origAxes))),{x:()=>(0,mul.l)(dy,(0,cast.w)((0,equal.L)(xOrig,y),dy.dtype))}}const maxGradConfig={kernelName:kernel_names.VAI,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(dy,saved,attrs)=>{const maxAttrs=attrs,{reductionIndices}=maxAttrs,x=saved[0],maxGrad=gradForMinAndMax(dy,saved[1],x,util_base.Y6(reductionIndices,x.shape));return{x:()=>maxGrad.x()}}};var less=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/less.js");const maximumGradConfig={kernelName:kernel_names.LDN,inputsToSave:["a","b"],gradFunc:(dy,saved)=>{const[a,b]=saved;return{a:()=>(0,mul.l)(dy,(0,cast.w)((0,greater_equal.D)(a,b),"float32")),b:()=>(0,mul.l)(dy,(0,cast.w)((0,less.M)(a,b),"float32"))}}};const maxPool3dGrad=(0,operation.op)({maxPool3dGrad_:function maxPool3dGrad_(dy,input,output,filterSize,strides,pad,dimRoundingMode){const $dy=(0,tensor_util_env.YT)(dy,"dy","maxPool3dGrad"),$input=(0,tensor_util_env.YT)(input,"input","maxPool3dGrad"),$output=(0,tensor_util_env.YT)(output,"output","maxPool3dGrad");let dy5D=$dy,input5D=$input,output5D=$output,reshapedTo5D=!1;4===$input.rank&&(reshapedTo5D=!0,dy5D=(0,reshape.t)($dy,[1,$dy.shape[0],$dy.shape[1],$dy.shape[2],$dy.shape[3]]),input5D=(0,reshape.t)($input,[1,$input.shape[0],$input.shape[1],$input.shape[2],$input.shape[3]]),output5D=(0,reshape.t)($output,[1,$output.shape[0],$output.shape[1],$output.shape[2],$output.shape[3]])),util_base.vA(5===dy5D.rank,()=>`Error in maxPool3dGrad: dy must be rank 5 but got rank ${dy5D.rank}.`),util_base.vA(5===input5D.rank,()=>`Error in maxPool3dGrad: input must be rank 5 but got rank ${input5D.rank}.`),util_base.vA(5===output5D.rank,()=>`Error in maxPool3dGrad: output must be rank 5 but got rank ${output5D.rank}.`),(0,conv_util.s_)("maxPool3dGrad",pad,dimRoundingMode);const inputs={dy:dy5D,input:input5D,output:output5D},attrs={filterSize,strides,pad,dimRoundingMode},res=engine.T2.runKernel(kernel_names.cHb,inputs,attrs);return reshapedTo5D?(0,reshape.t)(res,[res.shape[1],res.shape[2],res.shape[3],res.shape[4]]):res}}),maxPool3DGradConfig={kernelName:kernel_names.ySp,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(dy,saved,attrs)=>{const[x,y]=saved,{filterSize,strides,pad,dimRoundingMode}=attrs;return{x:()=>maxPool3dGrad(dy,x,y,filterSize,strides,pad,dimRoundingMode)}}};const maxPoolGrad=(0,operation.op)({maxPoolGrad_:function maxPoolGrad_(dy,input,output,filterSize,strides,pad,dimRoundingMode){const $dy=(0,tensor_util_env.YT)(dy,"dy","maxPoolGrad"),$input=(0,tensor_util_env.YT)(input,"input","maxPoolGrad"),$output=(0,tensor_util_env.YT)(output,"output","maxPoolGrad");util_base.vA($input.rank===$dy.rank,()=>`Rank of input (${$input.rank}) does not match rank of dy (${$dy.rank})`),util_base.vA(4===$dy.rank,()=>`Error in maxPoolGrad: dy must be rank 4 but got rank ${$dy.rank}.`),util_base.vA(4===$input.rank,()=>`Error in maxPoolGrad: input must be rank 4 but got rank ${$input.rank}.`),conv_util.s_("maxPoolGrad",pad,dimRoundingMode);const inputs={dy:$dy,input:$input,output:$output},attrs={filterSize,strides,pad,dimRoundingMode};return engine.T2.runKernel(kernel_names.RXX,inputs,attrs)}}),maxPoolGradConfig={kernelName:kernel_names.t3d,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(dy,saved,attrs)=>{const[x,y]=saved,{filterSize,strides,pad}=attrs;return{x:()=>maxPoolGrad(dy,x,y,filterSize,strides,pad)}}};var ones=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/ones.js");const meanGradConfig={kernelName:kernel_names.g5A,inputsToSave:["x"],gradFunc:(dy,saved,attrs)=>{const[x]=saved,{axis}=attrs,axes=util_base.Y6(axis,x.shape),reduceShape=(0,axis_util.lb)(x.shape,axes)[1],reduceSize=util_base.Ze(reduceShape);return{x:()=>{const expandedDyShape=x.shape.slice();axes.forEach(axis=>{expandedDyShape[axis]=1});const expandedDy=(0,reshape.t)(dy,expandedDyShape);return(0,div.y)((0,mul.l)(expandedDy,(0,ones.S)(x.shape,"float32")),reduceSize)}}}},minGradConfig={kernelName:kernel_names.lNG,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(dy,saved,attrs)=>{const minAttrs=attrs,{axis}=minAttrs,[x,y]=saved,minGrad=gradForMinAndMax(dy,y,x,util_base.Y6(axis,x.shape));return{x:()=>minGrad.x()}}},minimumGradConfig={kernelName:kernel_names.LG0,inputsToSave:["a","b"],gradFunc:(dy,saved)=>{const[a,b]=saved;return{a:()=>(0,mul.l)(dy,(0,cast.w)((0,less_equal.I)(a,b),"float32")),b:()=>(0,mul.l)(dy,(0,cast.w)((0,greater.r)(a,b),"float32"))}}};var slice=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/slice.js");const mirrorPadGradConfig={kernelName:kernel_names.x7F,inputsToSave:["x"],gradFunc:(dy,saved,attrs)=>{const x=saved[0],{paddings}=attrs,begin=paddings.map(p=>p[0]);return{x:()=>(0,slice.d)(dy,begin,x.shape)}}};var floor=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/floor.js");const modGradConfig={kernelName:kernel_names.BLA,inputsToSave:["a","b"],gradFunc:(dy,saved)=>{const[a,b]=saved,outShape=(0,broadcast_util.assertAndGetBroadcastShape)(a.shape,b.shape);return{a:()=>{const reduceAxes=(0,broadcast_util.getReductionAxes)(a.shape,outShape);return reduceAxes.length>0?(0,reshape.t)((0,sum.c)(dy,reduceAxes),a.shape):dy},b:()=>{const res=(0,mul.l)(dy,(0,neg.H)((0,floor.R)((0,div.y)(a,b)))),reduceAxes=(0,broadcast_util.getReductionAxes)(b.shape,outShape);return reduceAxes.length>0?(0,reshape.t)((0,sum.c)(res,reduceAxes),b.shape):res}}}},multiplyGradConfig={kernelName:kernel_names.xu7,inputsToSave:["a","b"],gradFunc:(dy,saved)=>{const[a,b]=saved,outShape=(0,broadcast_util.assertAndGetBroadcastShape)(a.shape,b.shape);return{a:()=>{const res=(0,mul.l)(dy,(0,cast.w)(b,"float32")),reduceAxes=(0,broadcast_util.getReductionAxes)(a.shape,outShape);return reduceAxes.length>0?(0,reshape.t)((0,sum.c)(res,reduceAxes),a.shape):res},b:()=>{const res=(0,mul.l)(dy,(0,cast.w)(a,"float32")),reduceAxes=(0,broadcast_util.getReductionAxes)(b.shape,outShape);return reduceAxes.length>0?(0,reshape.t)((0,sum.c)(res,reduceAxes),b.shape):res}}}},negGradConfig={kernelName:kernel_names.l0G,gradFunc:dy=>({x:()=>(0,neg.H)(dy)})};var zeros=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/zeros.js");const oneHotGradConfig={kernelName:kernel_names.urI,inputsToSave:["indices"],gradFunc:(dy,saved)=>{const indices=saved[0];return{indices:()=>(0,zeros.U)(indices.shape,"float32")}}},onesLikeGradConfig={kernelName:kernel_names.LWX,gradFunc:dy=>({x:()=>(0,zeros_like.P)(dy)})};var unstack=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/unstack.js");const packGradConfig={kernelName:kernel_names.mM$,saveAllInputs:!0,gradFunc:(dy,saved,attrs)=>{const{axis}=attrs;return(0,unstack.K)(dy,axis).map(t=>()=>t)}},padV2GradConfig={kernelName:kernel_names.ODT,inputsToSave:["x"],gradFunc:(dy,saved,attrs)=>{const x=saved[0],{paddings}=attrs,begin=paddings.map(p=>p[0]);return{x:()=>(0,slice.d)(dy,begin,x.shape)}}};var log=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/log.js"),pow=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/pow.js");const powGradConfig={kernelName:kernel_names.pyJ,inputsToSave:["a","b"],outputsToSave:[!0],gradFunc:(dy,saved)=>{const[a,b,y]=saved,base=a,exp=b,outShape=broadcast_util.assertAndGetBroadcastShape(base.shape,exp.shape);return{a:()=>{const expFloat=(0,cast.w)(exp,"float32");let res=(0,mul.l)(dy,(0,mul.l)(expFloat,(0,pow.n)(base,(0,sub.j)(expFloat,(0,ops_scalar.d)(1)))));const reduceAxes=broadcast_util.getReductionAxes(base.shape,outShape);return reduceAxes.length>0&&(res=(0,sum.c)(res,reduceAxes)),(0,reshape.t)(res,base.shape)},b:()=>{const condition=(0,greater.r)(base,0),logBase=(0,ops_where._)(condition,(0,log.R)(base),(0,zeros_like.P)(base));let res=(0,mul.l)(dy,(0,mul.l)(y,logBase));const reduceAxes=broadcast_util.getReductionAxes(exp.shape,outShape);return reduceAxes.length>0&&(res=(0,sum.c)(res,reduceAxes)),(0,reshape.t)(res,exp.shape)}}}},preluGradConfig={kernelName:kernel_names.Ncv,inputsToSave:["x","alpha"],gradFunc:(dy,saved)=>{const[x,alpha]=saved,mask=(0,greater.r)(x,0);return{x:()=>(0,ops_where._)(mask,dy,(0,mul.l)(dy,alpha)),alpha:()=>{let res=(0,ops_where._)(mask,(0,zeros_like.P)(dy),(0,mul.l)(dy,x));const reduceAxes=(0,broadcast_util.getReductionAxes)(alpha.shape,dy.shape);return reduceAxes.length>0&&(res=(0,sum.c)(res,reduceAxes)),(0,reshape.t)(res,alpha.shape)}}}};var cumprod=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/cumprod.js");function prodsGradFn_(x,dy,axis){const xRank=x.shape.length,finalProdAxis=xRank-axis.length,xPermutation=axis_util.Em(axis,xRank);let permutedX=x;null!=xPermutation&&(permutedX=(0,transpose.m)(x,xPermutation));const newShape=permutedX.shape.slice(),endPartShape=newShape.splice(xRank-axis.length,axis.length).reduce((p,c)=>p*c,1);newShape.push(endPartShape);let prodGrad=function prodGradFn_(x,dy,axis){const expandedYShape=x.shape.slice();expandedYShape[axis]=1;const expandedDy=(0,reshape.t)(dy,expandedYShape),xCumProd=(0,cumprod.L)(x,axis,!0,!1),xCumRevProd=(0,cumprod.L)(x,axis,!0,!0),dx=(0,mul.l)(xCumProd,xCumRevProd);return(0,mul.l)(expandedDy,dx)}(permutedX.reshape(newShape),dy,finalProdAxis);if(prodGrad=prodGrad.reshape(permutedX.shape),null!=xPermutation){const undoPermutation=axis_util.gx(xPermutation);prodGrad=(0,transpose.m)(prodGrad,undoPermutation)}return prodGrad}const prodGradConfig={kernelName:kernel_names.kdj,inputsToSave:["x"],gradFunc:(dy,saved,attrs)=>{const[x]=saved,{axis}=attrs;let axisArr=[];return axisArr=null==axis?x.shape.map((_,i)=>i):"number"==typeof axis?[axis]:axis,{x:()=>prodsGradFn_(x,dy,axisArr)}}},divGradConfig={kernelName:kernel_names.sDr,inputsToSave:["a","b"],gradFunc:(dy,saved)=>{const[a,b]=saved,outShape=broadcast_util.assertAndGetBroadcastShape(a.shape,b.shape);return{a:()=>{const res=(0,div.y)(dy,(0,cast.w)(b,"float32")),reduceAxes=broadcast_util.getReductionAxes(a.shape,outShape);return reduceAxes.length>0?(0,reshape.t)((0,sum.c)(res,reduceAxes),a.shape):res},b:()=>{let res=(0,mul.l)(dy,(0,cast.w)(a,"float32"));const reduceAxes=broadcast_util.getReductionAxes(b.shape,outShape);reduceAxes.length>0&&(res=(0,reshape.t)((0,sum.c)(res,reduceAxes),b.shape));const tmp=(0,square.E)(b);return(0,neg.H)((0,div.y)(res,(0,cast.w)(tmp,"float32")))}}}},reciprocalGradConfig={kernelName:kernel_names.huO,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,div.y)(dy,(0,neg.H)((0,square.E)(x)))}}},relu6GradConfig={kernelName:kernel_names.P_L,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved,mask=(0,mul.l)((0,less_equal.I)(x,6),(0,step.P)(x));return{x:()=>(0,mul.l)(dy,(0,cast.w)(mask,"float32"))}}},reluGradConfig={kernelName:kernel_names.fUj,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,mul.l)(dy,(0,cast.w)((0,step.P)(x),"float32"))}}},reshapeGradConfig={kernelName:kernel_names.R23,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,reshape.t)(dy,x.shape)}}},resizeBilinearGradConfig={kernelName:kernel_names.hgw,inputsToSave:["images"],gradFunc:(dy,saved,attrs)=>{const[images]=saved,inputs={dy,images};return{images:()=>engine.T2.runKernel(kernel_names.FCQ,inputs,attrs)}}},resizeNearestNeighborGradConfig={kernelName:kernel_names.jOE,inputsToSave:["images"],gradFunc:(dy,saved,attrs)=>{const[images]=saved,inputs={dy,images};return{images:()=>engine.T2.runKernel(kernel_names.XQy,inputs,attrs)}}};var reverse=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js");const reverseGradConfig={kernelName:kernel_names.D7i,gradFunc:(dy,saved,attrs)=>{const{dims}=attrs,axes=(0,util_base.Y6)(dims,dy.shape);return{x:()=>(0,reverse.B)(dy,axes)}}},roundGradConfig={kernelName:kernel_names.hVg,gradFunc:dy=>({x:()=>(0,zeros_like.P)(dy)})},rsqrtGradConfig={kernelName:kernel_names.TOR,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,neg.H)((0,div.y)(dy,(0,mul.l)((0,pow.n)(x,1.5),2)))}}};var logical_not=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/logical_not.js");const selectGradConfig={kernelName:kernel_names.l6P,inputsToSave:["condition"],gradFunc:(dy,saved)=>{const[condition]=saved;return{condition:()=>(0,cast.w)((0,zeros_like.P)(condition),"float32"),t:()=>(0,mul.l)(dy,(0,cast.w)(condition,dy.dtype)),e:()=>(0,mul.l)(dy,(0,cast.w)((0,logical_not.N)(condition),dy.dtype))}}};var selu_util=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js");const seluGradConfig={kernelName:kernel_names.u$b,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>{const mask=(0,greater.r)(x,(0,ops_scalar.d)(0)),scaleAlpha=(0,ops_scalar.d)(selu_util.j),scale=(0,ops_scalar.d)(selu_util.X),greaterThanZeroDer=(0,mul.l)(dy,scale),lessEqualZeroDer=(0,mul.l)((0,mul.l)(dy,scaleAlpha),(0,exp.o)((0,cast.w)(x,"float32")));return(0,ops_where._)(mask,greaterThanZeroDer,lessEqualZeroDer)}}}},sigmoidGradConfig={kernelName:kernel_names.vI1,outputsToSave:[!0],gradFunc:(dy,saved)=>{const[y]=saved;return{x:()=>(0,mul.l)(dy,(0,mul.l)(y,(0,sub.j)((0,ops_scalar.d)(1),y)))}}},signGradConfig={kernelName:kernel_names.YVe,gradFunc:dy=>({x:()=>(0,zeros_like.P)(dy)})};var cos=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/cos.js");const sinGradConfig={kernelName:kernel_names.hql,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,mul.l)((0,cos.g)((0,cast.w)(x,"float32")),dy)}}};var cosh=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/cosh.js");const sinhGradConfig={kernelName:kernel_names.J3C,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,mul.l)((0,cosh.y)((0,cast.w)(x,"float32")),dy)}}};var pad=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/pad.js"),slice_util=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js");const sliceGradConfig={kernelName:kernel_names.JiE,inputsToSave:["x"],gradFunc:(dy,saved,attrs)=>{const[x]=saved,{begin,size}=attrs,inputShape=x.shape,[begin_,size_]=(0,slice_util.parseSliceParams)(x,begin,size),paddings=[];for(let i=0;i<dy.rank;i++)paddings.push([begin_[i],inputShape[i]-begin_[i]-size_[i]]);return{x:()=>(0,pad.e)(dy,paddings)}}},softmaxGradConfig={kernelName:kernel_names.rFG,outputsToSave:[!0],gradFunc:(dy,saved,attrs)=>{const[y]=saved,{dim}=attrs,dyTimesY=(0,mul.l)(dy,y);return{logits:()=>(0,sub.j)(dyTimesY,(0,mul.l)((0,sum.c)(dyTimesY,[dim],true),y))}}};var sigmoid=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/sigmoid.js");const softplusGradConfig={kernelName:kernel_names.Fin,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,mul.l)(dy,(0,sigmoid.r)(x))}}};var batch_to_space_nd=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js");const spaceToBatchNDGradConfig={kernelName:kernel_names.A8B,gradFunc:(dy,saved,attrs)=>{const{blockShape,paddings}=attrs;return{x:()=>(0,batch_to_space_nd.G)(dy,blockShape,paddings)}}};var concat=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/concat.js");const splitVGradConfig={kernelName:kernel_names.Blb,gradFunc:(dy,saved,attrs)=>{const{axis}=attrs;return{x:()=>(0,concat.x)(dy,axis)}}},sqrtGradConfig={kernelName:kernel_names.dFH,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,div.y)(dy,(0,mul.l)((0,sqrt.R)((0,cast.w)(x,"float32")),2))}}},squareGradConfig={kernelName:kernel_names.M6A,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,mul.l)(dy,(0,mul.l)((0,cast.w)(x,"float32"),2))}}},squaredDifferenceGradConfig={kernelName:kernel_names.Ddj,inputsToSave:["a","b"],gradFunc:(dy,saved)=>{const[a,b]=saved,two=(0,ops_scalar.d)(2);return{a:()=>(0,mul.l)(dy,(0,mul.l)(two,(0,sub.j)(a,b))),b:()=>(0,mul.l)(dy,(0,mul.l)(two,(0,sub.j)(b,a)))}}},stepGradConfig={kernelName:kernel_names.pnw,gradFunc:dy=>({x:()=>(0,zeros_like.P)(dy)})},subGradConfig={kernelName:kernel_names.PbM,inputsToSave:["a","b"],gradFunc:(dy,saved)=>{const[a,b]=saved,outShape=broadcast_util.assertAndGetBroadcastShape(a.shape,b.shape);return{a:()=>{let res=dy;const reduceAxes=broadcast_util.getReductionAxes(a.shape,outShape);return reduceAxes.length>0&&(res=(0,sum.c)(res,reduceAxes)),(0,reshape.t)(res,a.shape)},b:()=>{let res=dy;const reduceAxes=broadcast_util.getReductionAxes(b.shape,outShape);return reduceAxes.length>0&&(res=(0,sum.c)(res,reduceAxes)),(0,reshape.t)((0,neg.H)(res),b.shape)}}}},sumGradConfig={kernelName:kernel_names.WuN,inputsToSave:["x"],gradFunc:(dy,saved,attrs)=>{const[x]=saved,expandedDyShape=x.shape.slice(),{axis}=attrs;(0,util_base.Y6)(axis,x.shape).forEach(axis=>{expandedDyShape[axis]=1});const expandedDy=(0,reshape.t)(dy,expandedDyShape),derX=(0,mul.l)(expandedDy,(0,ones.S)(x.shape,"float32"));return{x:()=>derX}}},tanGradConfig={kernelName:kernel_names.oFs,inputsToSave:["x"],gradFunc:(dy,saved)=>{const[x]=saved;return{x:()=>(0,div.y)(dy,(0,square.E)((0,cos.g)(x)))}}},tanhGradConfig={kernelName:kernel_names.iuW,outputsToSave:[!0],gradFunc:(dy,saved)=>{const[y]=saved;return{x:()=>(0,mul.l)((0,sub.j)((0,ops_scalar.d)(1),(0,square.E)(y)),dy)}}},tileGradConfig={kernelName:kernel_names.FAs,inputsToSave:["x"],gradFunc:(dy,saved,attrs)=>{const[x]=saved,{reps}=attrs;return{x:()=>{let xGrad=(0,zeros_like.P)(x);if(1===x.rank)for(let i=0;i<reps[0];++i)xGrad=(0,add.W)(xGrad,(0,slice.d)(dy,[i*x.shape[0]],[x.shape[0]]));else if(2===x.rank)for(let i=0;i<reps[0];++i)for(let j=0;j<reps[1];++j)xGrad=(0,add.W)(xGrad,(0,slice.d)(dy,[i*x.shape[0],j*x.shape[1]],[x.shape[0],x.shape[1]]));else if(3===x.rank)for(let i=0;i<reps[0];++i)for(let j=0;j<reps[1];++j)for(let k=0;k<reps[2];++k)xGrad=(0,add.W)(xGrad,(0,slice.d)(dy,[i*x.shape[0],j*x.shape[1],k*x.shape[2]],[x.shape[0],x.shape[1],x.shape[2]]));else{if(4!==x.rank)throw new Error(`Gradient for tile operation is not implemented for rank-${x.rank} tensors yet.`);for(let i=0;i<reps[0];++i)for(let j=0;j<reps[1];++j)for(let k=0;k<reps[2];++k)for(let l=0;l<reps[3];++l)xGrad=(0,add.W)(xGrad,(0,slice.d)(dy,[i*x.shape[0],j*x.shape[1],k*x.shape[2],l*x.shape[3]],[x.shape[0],x.shape[1],x.shape[2],x.shape[3]]))}return xGrad}}}},transposeGradConfig={kernelName:kernel_names.wx0,gradFunc:(dy,saved,attrs)=>{const transposeAttrs=attrs,{perm}=transposeAttrs,undoPerm=axis_util.gx(perm);return{x:()=>(0,transpose.m)(dy,undoPerm)}}},unpackGradConfig={kernelName:kernel_names.dXR,gradFunc:(dy,saved,attrs)=>{const unpackAttrs=attrs,{axis}=unpackAttrs;return{value:()=>(0,stack.t)(dy,axis)}}};var expand_dims=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/expand_dims.js"),gather=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/gather.js"),maximum=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/maximum.js");const unsortedSegmentSumGradConfig={kernelName:kernel_names.pPe,inputsToSave:["segmentIds"],gradFunc:(dy,saved)=>{const[segmentIds]=saved;return{x:()=>function gatherDropNegatives(x,indices){const zeroClippedIndices=(0,maximum.P)(indices,(0,zeros_like.P)(indices)),gathered=(0,gather.k)(x,zeroClippedIndices);let isPositive=(0,greater_equal.D)(indices,(0,ops_scalar.d)(0,"int32"));const numIters=gathered.rank-isPositive.rank;for(let i=0;i<numIters;++i)isPositive=(0,expand_dims.U)(isPositive,i+1);isPositive=(0,logical_and.n)(isPositive,(0,ones.S)(gathered.shape,"bool"));const zeroSlice=(0,zeros_like.P)(gathered);return(0,ops_where._)(isPositive,gathered,zeroSlice)}(dy,segmentIds)}}};const zerosLikeGradConfig={kernelName:kernel_names.xJ3,gradFunc:dy=>({x:()=>(0,zeros_like.P)(dy)})};var kernel_registry=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js");const gradConfigs=[absGradConfig,acosGradConfig,acoshGradConfig,addGradConfig,addNGradConfig,argMaxGradConfig,argMinGradConfig,asinGradConfig,asinhGradConfig,atan2GradConfig,atanGradConfig,atanhGradConfig,avgPool3DGradConfig,avgPoolGradConfig,batchMatMulGradConfig,batchToSpaceNDGradConfig,broadcastToGradConfig,castGradConfig,ceilGradConfig,clipByValueGradConfig,complexAbsGradConfig,concatGradConfig,conv2DBackpropInputGradConfig,conv2DGradConfig,conv3DGradConfig,cosGradConfig,coshGradConfig,cumsumGradConfig,depthwiseConv2dNativeGradConfig,dilation2dGradConfig,divGradConfig,eluGradConfig,erfGradConfig,expGradConfig,expandDimsGradConfig,expm1GradConfig,floorDivGradConfig,floorGradConfig,fusedBatchNormGradConfig,gatherGradConfig,greaterEqualGradConfig,identityGradConfig,isFiniteGradConfig,isInfGradConfig,isNanGradConfig,leakyReluGradConfig,log1pGradConfig,logGradConfig,logSoftmaxGradConfig,lrnGradConfig,maxGradConfig,maxGradConfig,maximumGradConfig,maxPool3DGradConfig,maxPoolGradConfig,meanGradConfig,minGradConfig,minimumGradConfig,mirrorPadGradConfig,modGradConfig,multiplyGradConfig,negGradConfig,oneHotGradConfig,onesLikeGradConfig,packGradConfig,padV2GradConfig,padV2GradConfig,powGradConfig,preluGradConfig,prodGradConfig,reciprocalGradConfig,relu6GradConfig,reluGradConfig,reshapeGradConfig,resizeBilinearGradConfig,resizeNearestNeighborGradConfig,reverseGradConfig,roundGradConfig,rsqrtGradConfig,selectGradConfig,seluGradConfig,sigmoidGradConfig,signGradConfig,sinGradConfig,sinhGradConfig,sliceGradConfig,softmaxGradConfig,softplusGradConfig,spaceToBatchNDGradConfig,spaceToBatchNDGradConfig,splitVGradConfig,splitVGradConfig,sqrtGradConfig,squaredDifferenceGradConfig,squareGradConfig,stepGradConfig,subGradConfig,sumGradConfig,tanGradConfig,tanhGradConfig,tileGradConfig,transposeGradConfig,unpackGradConfig,unsortedSegmentSumGradConfig,zerosLikeGradConfig];for(const gradientConfig of gradConfigs)(0,kernel_registry.kr)(gradientConfig);var abs=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/abs.js"),tensor=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/tensor.js");(0,tensor.tp)().prototype.abs=function(){return this.throwIfDisposed(),(0,abs.t)(this)};var acos=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/acos.js");(0,tensor.tp)().prototype.acos=function(){return this.throwIfDisposed(),(0,acos.H)(this)};var acosh=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/acosh.js");(0,tensor.tp)().prototype.acosh=function(){return this.throwIfDisposed(),(0,acosh.F)(this)},(0,tensor.tp)().prototype.add=function(b){return this.throwIfDisposed(),(0,add.W)(this,b)};var ops_all=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/all.js");(0,tensor.tp)().prototype.all=function(axis,keepDims){return this.throwIfDisposed(),(0,ops_all.Q)(this,axis,keepDims)};var any=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/any.js");(0,tensor.tp)().prototype.any=function(axis,keepDims){return this.throwIfDisposed(),(0,any.b)(this,axis,keepDims)};var arg_max=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/arg_max.js");(0,tensor.tp)().prototype.argMax=function(axis){return this.throwIfDisposed(),(0,arg_max.F)(this,axis)};var arg_min=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/arg_min.js");(0,tensor.tp)().prototype.argMin=function(axis){return this.throwIfDisposed(),(0,arg_min.X)(this,axis)},(0,tensor.tp)().prototype.asScalar=function(){return this.throwIfDisposed(),(0,util_base.vA)(1===this.size,()=>"The array must have only 1 element."),(0,reshape.t)(this,[])},(0,tensor.tp)().prototype.asType=function(dtype){return this.throwIfDisposed(),(0,cast.w)(this,dtype)},(0,tensor.tp)().prototype.as1D=function(){return this.throwIfDisposed(),(0,reshape.t)(this,[this.size])},(0,tensor.tp)().prototype.as2D=function(rows,columns){return this.throwIfDisposed(),(0,reshape.t)(this,[rows,columns])},(0,tensor.tp)().prototype.as3D=function(rows,columns,depth){return this.throwIfDisposed(),(0,reshape.t)(this,[rows,columns,depth])},(0,tensor.tp)().prototype.as4D=function(rows,columns,depth,depth2){return this.throwIfDisposed(),(0,reshape.t)(this,[rows,columns,depth,depth2])},(0,tensor.tp)().prototype.as5D=function(rows,columns,depth,depth2,depth3){return this.throwIfDisposed(),(0,reshape.t)(this,[rows,columns,depth,depth2,depth3])};var asin=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/asin.js");(0,tensor.tp)().prototype.asin=function(){return this.throwIfDisposed(),(0,asin.q)(this)};var asinh=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/asinh.js");(0,tensor.tp)().prototype.asinh=function(){return this.throwIfDisposed(),(0,asinh.y)(this)};var atan=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/atan.js");(0,tensor.tp)().prototype.atan=function(){return this.throwIfDisposed(),(0,atan.r)(this)};var atan2=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/atan2.js");(0,tensor.tp)().prototype.atan2=function(b){return this.throwIfDisposed(),(0,atan2.F)(this,b)};var atanh=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/atanh.js");(0,tensor.tp)().prototype.atanh=function(){return this.throwIfDisposed(),(0,atanh.r)(this)};var avg_pool=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool.js");(0,tensor.tp)().prototype.avgPool=function(filterSize,strides,pad,dimRoundingMode){return this.throwIfDisposed(),(0,avg_pool.$)(this,filterSize,strides,pad,dimRoundingMode)},(0,tensor.tp)().prototype.batchToSpaceND=function(blockShape,crops){return this.throwIfDisposed(),(0,batch_to_space_nd.G)(this,blockShape,crops)};var batchnorm=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js");(0,tensor.tp)().prototype.batchNorm=function(mean,variance,offset,scale,varianceEpsilon){return this.throwIfDisposed(),(0,batchnorm.$)(this,mean,variance,offset,scale,varianceEpsilon)};var broadcast_to=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_to.js");(0,tensor.tp)().prototype.broadcastTo=function(shape){return this.throwIfDisposed(),(0,broadcast_to.h)(this,shape)},(0,tensor.tp)().prototype.cast=function(dtype){return this.throwIfDisposed(),(0,cast.w)(this,dtype)};var ceil=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/ceil.js");(0,tensor.tp)().prototype.ceil=function(){return this.throwIfDisposed(),(0,ceil.m)(this)};var clip_by_value=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/clip_by_value.js");(0,tensor.tp)().prototype.clipByValue=function(min,max){return this.throwIfDisposed(),(0,clip_by_value.z)(this,min,max)},(0,tensor.tp)().prototype.concat=function(x,axis){return this.throwIfDisposed(),x instanceof tensor.qY&&(x=[x]),(0,concat.x)([this,...x],axis)};var conv1d=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/conv1d.js");(0,tensor.tp)().prototype.conv1d=function(filter,stride,pad,dataFormat,dilation,dimRoundingMode){return this.throwIfDisposed(),(0,conv1d.k)(this,filter,stride,pad,dataFormat,dilation,dimRoundingMode)};var conv2d_transpose=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_transpose.js");(0,tensor.tp)().prototype.conv2dTranspose=function(filter,outputShape,strides,pad,dimRoundingMode){return this.throwIfDisposed(),(0,conv2d_transpose.w)(this,filter,outputShape,strides,pad,dimRoundingMode)},(0,tensor.tp)().prototype.conv2d=function(filter,strides,pad,dataFormat,dilations,dimRoundingMode){return this.throwIfDisposed(),(0,conv2d.X)(this,filter,strides,pad,dataFormat,dilations,dimRoundingMode)},(0,tensor.tp)().prototype.cos=function(){return this.throwIfDisposed(),(0,cos.g)(this)},(0,tensor.tp)().prototype.cosh=function(){return this.throwIfDisposed(),(0,cosh.y)(this)},(0,tensor.tp)().prototype.cumprod=function(axis,exclusive,reverse){return this.throwIfDisposed(),(0,cumprod.L)(this,axis,exclusive,reverse)},(0,tensor.tp)().prototype.cumsum=function(axis,exclusive,reverse){return this.throwIfDisposed(),(0,cumsum.r)(this,axis,exclusive,reverse)};var depth_to_space=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/depth_to_space.js");(0,tensor.tp)().prototype.depthToSpace=function(blockSize,dataFormat){return this.throwIfDisposed(),(0,depth_to_space.R)(this,blockSize,dataFormat)};var depthwise_conv2d=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js");(0,tensor.tp)().prototype.depthwiseConv2d=function(filter,strides,pad,dataFormat,dilations,dimRoundingMode){return this.throwIfDisposed(),(0,depthwise_conv2d.G)(this,filter,strides,pad,dataFormat,dilations,dimRoundingMode)};var dilation2d=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/dilation2d.js");(0,tensor.tp)().prototype.dilation2d=function(filter,strides,pad,dilations,dataFormat){return this.throwIfDisposed(),(0,dilation2d.X)(this,filter,strides,pad,dilations,dataFormat)};var div_no_nan=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/div_no_nan.js");(0,tensor.tp)().prototype.divNoNan=function(b){return this.throwIfDisposed(),(0,div_no_nan.e)(this,b)},(0,tensor.tp)().prototype.div=function(b){return this.throwIfDisposed(),(0,div.y)(this,b)};var dot=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/dot.js");(0,tensor.tp)().prototype.dot=function(b){return this.throwIfDisposed(),(0,dot.O)(this,b)};var elu=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/elu.js");(0,tensor.tp)().prototype.elu=function(){return this.throwIfDisposed(),(0,elu.P)(this)},(0,tensor.tp)().prototype.equal=function(b){return this.throwIfDisposed(),(0,equal.L)(this,b)};var erf=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/erf.js");(0,tensor.tp)().prototype.erf=function(){return this.throwIfDisposed(),(0,erf.Y)(this)};var euclidean_norm=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/euclidean_norm.js");(0,tensor.tp)().prototype.euclideanNorm=function(axis,keepDims){return this.throwIfDisposed(),(0,euclidean_norm.p)(this,axis,keepDims)},(0,tensor.tp)().prototype.exp=function(){return this.throwIfDisposed(),(0,exp.o)(this)},(0,tensor.tp)().prototype.expandDims=function(axis){return this.throwIfDisposed(),(0,expand_dims.U)(this,axis)};var expm1=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/expm1.js");(0,tensor.tp)().prototype.expm1=function(){return this.throwIfDisposed(),(0,expm1.I)(this)};var fft=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/fft.js");(0,tensor.tp)().prototype.fft=function(){return this.throwIfDisposed(),(0,fft.h)(this)},(0,tensor.tp)().prototype.flatten=function(){return this.throwIfDisposed(),(0,reshape.t)(this,[this.size])},(0,tensor.tp)().prototype.floor=function(){return this.throwIfDisposed(),(0,floor.R)(this)};var floorDiv=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/floorDiv.js");(0,tensor.tp)().prototype.floorDiv=function(b){return this.throwIfDisposed(),(0,floorDiv.w)(this,b)},(0,tensor.tp)().prototype.gather=function(indices,axis,batchDims){return this.throwIfDisposed(),(0,gather.k)(this,indices,axis,batchDims)},(0,tensor.tp)().prototype.greaterEqual=function(b){return this.throwIfDisposed(),(0,greater_equal.D)(this,b)},(0,tensor.tp)().prototype.greater=function(b){return this.throwIfDisposed(),(0,greater.r)(this,b)};var ifft=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/ifft.js");(0,tensor.tp)().prototype.ifft=function(){return this.throwIfDisposed(),(0,ifft.K)(this)};var irfft=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/irfft.js");(0,tensor.tp)().prototype.irfft=function(){return this.throwIfDisposed(),(0,irfft.g)(this)};var is_finite=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/is_finite.js");(0,tensor.tp)().prototype.isFinite=function(){return this.throwIfDisposed(),(0,is_finite.M)(this)};var is_inf=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/is_inf.js");(0,tensor.tp)().prototype.isInf=function(){return this.throwIfDisposed(),(0,is_inf.E)(this)};var is_nan=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/is_nan.js");(0,tensor.tp)().prototype.isNaN=function(){return this.throwIfDisposed(),(0,is_nan.y)(this)};var leaky_relu=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/leaky_relu.js");(0,tensor.tp)().prototype.leakyRelu=function(alpha){return this.throwIfDisposed(),(0,leaky_relu.H)(this,alpha)},(0,tensor.tp)().prototype.lessEqual=function(b){return this.throwIfDisposed(),(0,less_equal.I)(this,b)},(0,tensor.tp)().prototype.less=function(b){return this.throwIfDisposed(),(0,less.M)(this,b)};var local_response_normalization=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/local_response_normalization.js");(0,tensor.tp)().prototype.localResponseNormalization=function(depthRadius,bias,alpha,beta){return this.throwIfDisposed(),(0,local_response_normalization.K)(this,depthRadius,bias,alpha,beta)};var log_sigmoid=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/log_sigmoid.js");(0,tensor.tp)().prototype.logSigmoid=function(){return this.throwIfDisposed(),(0,log_sigmoid.n)(this)};var log_softmax=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/log_softmax.js");(0,tensor.tp)().prototype.logSoftmax=function(axis){return this.throwIfDisposed(),(0,log_softmax.H)(this,axis)};var log_sum_exp=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/log_sum_exp.js");(0,tensor.tp)().prototype.logSumExp=function(axis,keepDims){return this.throwIfDisposed(),(0,log_sum_exp.V)(this,axis,keepDims)},(0,tensor.tp)().prototype.log=function(){return this.throwIfDisposed(),(0,log.R)(this)};var log1p=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/log1p.js");(0,tensor.tp)().prototype.log1p=function(){return this.throwIfDisposed(),(0,log1p.K)(this)},(0,tensor.tp)().prototype.logicalAnd=function(b){return this.throwIfDisposed(),(0,logical_and.n)(this,b)},(0,tensor.tp)().prototype.logicalNot=function(){return this.throwIfDisposed(),(0,logical_not.N)(this)};var logical_or=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/logical_or.js");(0,tensor.tp)().prototype.logicalOr=function(b){return this.throwIfDisposed(),(0,logical_or.z)(this,b)};var logical_xor=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/logical_xor.js");(0,tensor.tp)().prototype.logicalXor=function(b){return this.throwIfDisposed(),(0,logical_xor.r)(this,b)},(0,tensor.tp)().prototype.matMul=function(b,transposeA,transposeB){return this.throwIfDisposed(),(0,mat_mul.N)(this,b,transposeA,transposeB)};var max_pool=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/max_pool.js");(0,tensor.tp)().prototype.maxPool=function(filterSize,strides,pad,dimRoundingMode){return this.throwIfDisposed(),(0,max_pool.j)(this,filterSize,strides,pad,dimRoundingMode)};var max=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/max.js");(0,tensor.tp)().prototype.max=function(axis,keepDims){return this.throwIfDisposed(),(0,max.T)(this,axis,keepDims)},(0,tensor.tp)().prototype.maximum=function(b){return this.throwIfDisposed(),(0,maximum.P)(this,b)};var mean=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/mean.js");(0,tensor.tp)().prototype.mean=function(axis,keepDims){return this.throwIfDisposed(),(0,mean.i)(this,axis,keepDims)};var min=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/min.js");(0,tensor.tp)().prototype.min=function(axis,keepDims){return this.throwIfDisposed(),(0,min.j)(this,axis,keepDims)};var minimum=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/minimum.js");(0,tensor.tp)().prototype.minimum=function(b){return this.throwIfDisposed(),(0,minimum.B)(this,b)};var mirror_pad=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/mirror_pad.js");(0,tensor.tp)().prototype.mirrorPad=function(paddings,mode){return this.throwIfDisposed(),(0,mirror_pad.F)(this,paddings,mode)};var mod=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/mod.js");(0,tensor.tp)().prototype.mod=function(b){return this.throwIfDisposed(),(0,mod.z)(this,b)},(0,tensor.tp)().prototype.mul=function(b){return this.throwIfDisposed(),(0,mul.l)(this,b)},(0,tensor.tp)().prototype.neg=function(){return this.throwIfDisposed(),(0,neg.H)(this)};var norm=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/norm.js");(0,tensor.tp)().prototype.norm=function(ord,axis,keepDims){return this.throwIfDisposed(),(0,norm.x)(this,ord,axis,keepDims)};var not_equal=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/not_equal.js");(0,tensor.tp)().prototype.notEqual=function(b){return this.throwIfDisposed(),(0,not_equal.E)(this,b)};var one_hot=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/one_hot.js");(0,tensor.tp)().prototype.oneHot=function(depth,onValue=1,offValue=0){return this.throwIfDisposed(),(0,one_hot.M)(this,depth,onValue,offValue)};var ones_like=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/ones_like.js");(0,tensor.tp)().prototype.onesLike=function(){return this.throwIfDisposed(),(0,ones_like.P)(this)},(0,tensor.tp)().prototype.pad=function(paddings,constantValue){return this.throwIfDisposed(),(0,pad.e)(this,paddings,constantValue)};var pool=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/pool.js");(0,tensor.tp)().prototype.pool=function(windowShape,poolingType,padding,dilationRate,strides,dimRoundingMode){return this.throwIfDisposed(),(0,pool.d)(this,windowShape,poolingType,padding,dilationRate,strides,dimRoundingMode)},(0,tensor.tp)().prototype.pow=function(exp){return this.throwIfDisposed(),(0,pow.n)(this,exp)};var prelu=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/prelu.js");(0,tensor.tp)().prototype.prelu=function(alpha){return this.throwIfDisposed(),(0,prelu.N)(this,alpha)};var prod=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/prod.js");(0,tensor.tp)().prototype.prod=function(axis,keepDims){return this.throwIfDisposed(),(0,prod._)(this,axis,keepDims)};var reciprocal=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/reciprocal.js");(0,tensor.tp)().prototype.reciprocal=function(){return this.throwIfDisposed(),(0,reciprocal.V)(this)};var relu=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/relu.js");(0,tensor.tp)().prototype.relu=function(){return this.throwIfDisposed(),(0,relu.V)(this)};var relu6=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/relu6.js");(0,tensor.tp)().prototype.relu6=function(){return this.throwIfDisposed(),(0,relu6.j)(this)},(0,tensor.tp)().prototype.reshapeAs=function(x){return this.throwIfDisposed(),(0,reshape.t)(this,x.shape)},(0,tensor.tp)().prototype.reshape=function(shape){return this.throwIfDisposed(),(0,reshape.t)(this,shape)};var resize_bilinear=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_bilinear.js");(0,tensor.tp)().prototype.resizeBilinear=function(newShape2D,alignCorners,halfPixelCenters){return this.throwIfDisposed(),(0,resize_bilinear.v)(this,newShape2D,alignCorners,halfPixelCenters)};var resize_nearest_neighbor=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_nearest_neighbor.js");(0,tensor.tp)().prototype.resizeNearestNeighbor=function(newShape2D,alignCorners,halfFloatCenters){return this.throwIfDisposed(),(0,resize_nearest_neighbor.b)(this,newShape2D,alignCorners,halfFloatCenters)},(0,tensor.tp)().prototype.reverse=function(axis){return this.throwIfDisposed(),(0,reverse.B)(this,axis)};var rfft=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/rfft.js");(0,tensor.tp)().prototype.rfft=function(){return this.throwIfDisposed(),(0,rfft.z)(this)};var round=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/round.js");(0,tensor.tp)().prototype.round=function(){return this.throwIfDisposed(),(0,round.L)(this)},(0,tensor.tp)().prototype.rsqrt=function(){return this.throwIfDisposed(),(0,rsqrt.Z)(this)};var selu=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/selu.js");(0,tensor.tp)().prototype.selu=function(){return this.throwIfDisposed(),(0,selu.W)(this)};var separable_conv2d=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/separable_conv2d.js");(0,tensor.tp)().prototype.separableConv2d=function(depthwiseFilter,pointwiseFilter,strides,pad,dilation,dataFormat){return this.throwIfDisposed(),(0,separable_conv2d.w)(this,depthwiseFilter,pointwiseFilter,strides,pad,dilation,dataFormat)},(0,tensor.tp)().prototype.sigmoid=function(){return this.throwIfDisposed(),(0,sigmoid.r)(this)};var sign=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/sign.js");(0,tensor.tp)().prototype.sign=function(){return this.throwIfDisposed(),(0,sign._)(this)},(0,tensor.tp)().prototype.sin=function(){return this.throwIfDisposed(),(0,sin.F)(this)},(0,tensor.tp)().prototype.sinh=function(){return this.throwIfDisposed(),(0,sinh.L)(this)},(0,tensor.tp)().prototype.slice=function(begin,size){return this.throwIfDisposed(),(0,slice.d)(this,begin,size)};var softmax=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js");(0,tensor.tp)().prototype.softmax=function(dim){return this.throwIfDisposed(),(0,softmax.V)(this,dim)};var softplus=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/softplus.js");(0,tensor.tp)().prototype.softplus=function(){return this.throwIfDisposed(),(0,softplus.l)(this)},(0,tensor.tp)().prototype.spaceToBatchND=function(blockShape,paddings){return this.throwIfDisposed(),(0,space_to_batch_nd.e)(this,blockShape,paddings)},(0,tensor.tp)().prototype.split=function(numOrSizeSplits,axis){return this.throwIfDisposed(),(0,split.l)(this,numOrSizeSplits,axis)},(0,tensor.tp)().prototype.sqrt=function(){return this.throwIfDisposed(),(0,sqrt.R)(this)},(0,tensor.tp)().prototype.square=function(){return this.throwIfDisposed(),(0,square.E)(this)};var squared_difference=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js");(0,tensor.tp)().prototype.squaredDifference=function(b){return this.throwIfDisposed(),(0,squared_difference.P)(this,b)};var squeeze=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/squeeze.js");(0,tensor.tp)().prototype.squeeze=function(axis){return this.throwIfDisposed(),(0,squeeze.r)(this,axis)},(0,tensor.tp)().prototype.stack=function(x,axis){this.throwIfDisposed();const tensorsToBeStacked=x instanceof tensor.qY?[this,x]:[this,...x];return(0,stack.t)(tensorsToBeStacked,axis)},(0,tensor.tp)().prototype.step=function(alpha){return this.throwIfDisposed(),(0,step.P)(this,alpha)};var strided_slice=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js");(0,tensor.tp)().prototype.stridedSlice=function(begin,end,strides,beginMask,endMask,ellipsisMask,newAxisMask,shrinkAxisMask){return this.throwIfDisposed(),(0,strided_slice.Y)(this,begin,end,strides,beginMask,endMask,ellipsisMask,newAxisMask,shrinkAxisMask)},(0,tensor.tp)().prototype.sub=function(b){return this.throwIfDisposed(),(0,sub.j)(this,b)},(0,tensor.tp)().prototype.sum=function(axis,keepDims){return this.throwIfDisposed(),(0,sum.c)(this,axis,keepDims)};var tan=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/tan.js");(0,tensor.tp)().prototype.tan=function(){return this.throwIfDisposed(),(0,tan.M)(this)};var tanh=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/tanh.js");(0,tensor.tp)().prototype.tanh=function(){return this.throwIfDisposed(),(0,tanh.y)(this)},(0,tensor.tp)().prototype.tile=function(reps){return this.throwIfDisposed(),(0,tile.V)(this,reps)},(0,tensor.tp)().prototype.toBool=function(){return this.throwIfDisposed(),(0,cast.w)(this,"bool")},(0,tensor.tp)().prototype.toFloat=function(){return this.throwIfDisposed(),(0,cast.w)(this,"float32")},(0,tensor.tp)().prototype.toInt=function(){return this.throwIfDisposed(),(0,cast.w)(this,"int32")};var topk=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/topk.js");(0,tensor.tp)().prototype.topk=function(k,sorted){return this.throwIfDisposed(),(0,topk.r)(this,k,sorted)},(0,tensor.tp)().prototype.transpose=function(perm){return this.throwIfDisposed(),(0,transpose.m)(this,perm)};var unique=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/unique.js");(0,tensor.tp)().prototype.unique=function(axis){return this.throwIfDisposed(),(0,unique.A)(this,axis)},(0,tensor.tp)().prototype.unsortedSegmentSum=function(segmentIds,numSegments){return this.throwIfDisposed(),(0,unsorted_segment_sum.z)(this,segmentIds,numSegments)},(0,tensor.tp)().prototype.unstack=function(axis){return this.throwIfDisposed(),(0,unstack.K)(this,axis)},(0,tensor.tp)().prototype.where=function(condition,x){return this.throwIfDisposed(),(0,ops_where._)(condition,this,x)},(0,tensor.tp)().prototype.zerosLike=function(){return this.throwIfDisposed(),(0,zeros_like.P)(this)};class AttributeError extends Error{constructor(message){super(message),Object.setPrototypeOf(this,AttributeError.prototype)}}class RuntimeError extends Error{constructor(message){super(message),Object.setPrototypeOf(this,RuntimeError.prototype)}}class errors_ValueError extends Error{constructor(message){super(message),Object.setPrototypeOf(this,errors_ValueError.prototype)}}class errors_NotImplementedError extends Error{constructor(message){super(message),Object.setPrototypeOf(this,errors_NotImplementedError.prototype)}}class AssertionError extends Error{constructor(message){super(message),Object.setPrototypeOf(this,AssertionError.prototype)}}Error;class LruCache{constructor(maxEntries){this.maxEntries=maxEntries||100,this.cache=new Map}get(key){let entry;return this.cache.has(key)&&(entry=this.cache.get(key),this.cache.delete(key),this.cache.set(key,entry)),entry}put(key,value){if(this.cache.has(key))this.cache.delete(key);else if(this.cache.size>=this.maxEntries){const keyToDelete=this.cache.keys().next().value;this.cache.delete(keyToDelete)}this.cache.set(key,value)}getMaxEntries(){return this.maxEntries}setMaxEntries(maxEntries){if(maxEntries<0)throw new Error(`The maxEntries of LRU caches must be at least 0, but got ${maxEntries}.`);if(this.maxEntries>maxEntries)for(let i=0;i<this.maxEntries-maxEntries;i++){const keyToDelete=this.cache.keys().next().value;this.cache.delete(keyToDelete)}this.maxEntries=maxEntries}}function pyListRepeat(value,numValues){if(Array.isArray(value)){let newArray=[];for(let i=0;i<numValues;i++)newArray=newArray.concat(value);return newArray}{const newArray=new Array(numValues);return newArray.fill(value),newArray}}function assert(val,message){if(!val)throw new AssertionError(message)}function count(array,refernce){let counter=0;for(const item of array)item===refernce&&counter++;return counter}function singletonOrArray(xs){return 1===xs.length?xs[0]:xs}function toList(x){return Array.isArray(x)?x:[x]}function toSnakeCase(name){const insecure=name.replace(/(.)([A-Z][a-z0-9]+)/g,"$1_$2").replace(/([a-z])([A-Z])/g,"$1_$2").toLowerCase();return"_"!==insecure[0]?insecure:"private"+insecure}function toCamelCase(identifier){return identifier.length<=1||-1===identifier.indexOf("_")?identifier:identifier.replace(/[_]+(\w|$)/g,(m,p1)=>p1.toUpperCase())}let _GLOBAL_CUSTOM_OBJECTS={};function serializeKerasObject(instance){if(null==instance)return null;const dict={};return dict.className=instance.getClassName(),dict.config=instance.getConfig(),dict}function convertNDArrayScalarsInConfig(config){if(null!=config&&"object"==typeof config)if(Array.isArray(config))config.forEach(configItem=>convertNDArrayScalarsInConfig(configItem));else{const fields=Object.keys(config);for(const field of fields){const value=config[field];null!=value&&"object"==typeof value&&(Array.isArray(value)||"ndarray"!==value.type||"number"!=typeof value.value?convertNDArrayScalarsInConfig(value):config[field]=value.value)}}}function deserializeKerasObject(identifier,moduleObjects={},customObjects={},printableModuleName="object",fastWeightInit=!1){if("string"==typeof identifier){const functionName=identifier;let fn;if(functionName in customObjects)fn=customObjects[functionName];else if(functionName in _GLOBAL_CUSTOM_OBJECTS)fn=_GLOBAL_CUSTOM_OBJECTS[functionName];else if(fn=moduleObjects[functionName],null==fn)throw new errors_ValueError(`Unknown ${printableModuleName}: ${identifier}. This may be due to one of the following reasons:\n1. The ${printableModuleName} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${printableModuleName} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);return fn}{const config=identifier;if(null==config.className||null==config.config)throw new errors_ValueError(`${printableModuleName}: Improper config format: ${JSON.stringify(config)}.\n'className' and 'config' must set.`);const className=config.className;let cls,fromConfig;if(className in customObjects?[cls,fromConfig]=customObjects[className]:className in _GLOBAL_CUSTOM_OBJECTS?[cls,fromConfig]=_GLOBAL_CUSTOM_OBJECTS.className:className in moduleObjects&&([cls,fromConfig]=moduleObjects[className]),null==cls)throw new errors_ValueError(`Unknown ${printableModuleName}: ${className}. This may be due to one of the following reasons:\n1. The ${printableModuleName} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${printableModuleName} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);if(null!=fromConfig){const customObjectsCombined={};for(const key of Object.keys(_GLOBAL_CUSTOM_OBJECTS))customObjectsCombined[key]=_GLOBAL_CUSTOM_OBJECTS[key];for(const key of Object.keys(customObjects))customObjectsCombined[key]=customObjects[key];config.config.customObjects=customObjectsCombined;const backupCustomObjects=Object.assign({},_GLOBAL_CUSTOM_OBJECTS);for(const key of Object.keys(customObjects))_GLOBAL_CUSTOM_OBJECTS[key]=customObjects[key];convertNDArrayScalarsInConfig(config.config);const returnObj=fromConfig(cls,config.config,customObjects,fastWeightInit);return _GLOBAL_CUSTOM_OBJECTS=Object.assign({},backupCustomObjects),returnObj}{const backupCustomObjects=Object.assign({},_GLOBAL_CUSTOM_OBJECTS);for(const key of Object.keys(customObjects))_GLOBAL_CUSTOM_OBJECTS[key]=customObjects[key];const returnObj=new cls(config.config);return _GLOBAL_CUSTOM_OBJECTS=Object.assign({},backupCustomObjects),returnObj}}}function reverseNumberCompare(a,b){return-1*function numberCompare(a,b){return a<b?-1:a>b?1:0}(a,b)}function generic_utils_unique(xs){if(null==xs)return xs;const out=[];for(const x of xs)-1===out.indexOf(x)&&out.push(x);return out}function isObjectEmpty(obj){if(null==obj)throw new errors_ValueError(`Invalid value in obj: ${JSON.stringify(obj)}`);for(const key in obj)if(obj.hasOwnProperty(key))return!1;return!0}function checkStringTypeUnionValue(values,label,value){if(null!=value&&values.indexOf(value)<0)throw new errors_ValueError(`${value} is not a valid ${label}.  Valid values are ${values} or null/undefined.`)}function checkArrayTypeAndLength(x,expectedType,minLength=0,maxLength=1/0){return assert(minLength>=0),assert(maxLength>=minLength),Array.isArray(x)&&x.length>=minLength&&x.length<=maxLength&&x.every(e=>typeof e===expectedType)}function assertPositiveInteger(value,name){Array.isArray(value)?(dist.ZSL.assert(value.length>0,()=>`${name} is unexpectedly an empty array.`),value.forEach((v,i)=>assertPositiveInteger(v,`element ${i+1} of ${name}`))):dist.ZSL.assert(Number.isInteger(value)&&value>0,()=>`Expected ${name} to be a positive integer, but got ${formatAsFriendlyString(value)}.`)}function formatAsFriendlyString(value){return null===value?"null":Array.isArray(value)?"["+value.map(v=>formatAsFriendlyString(v)).join(",")+"]":"string"==typeof value?`"${value}"`:`${value}`}function mapActivationToFusedKernel(activationName){return"relu"===activationName?"relu":"linear"===activationName?"linear":"elu"===activationName?"elu":null}let _nextUniqueTensorId=0;function getNextUniqueTensorId(){return _nextUniqueTensorId++}const _uidPrefixes={};function getUid(prefix=""){return prefix in _uidPrefixes||(_uidPrefixes[prefix]=0),_uidPrefixes[prefix]+=1,prefix+_uidPrefixes[prefix].toString()}const VALID_DATA_FORMAT_VALUES=["channelsFirst","channelsLast"],VALID_INTERPOLATION_FORMAT_VALUES=["nearest","bilinear"],VALID_PADDING_MODE_VALUES=["valid","same","causal"],VALID_POOL_MODE_VALUES=["max","avg"],VALID_BIDIRECTIONAL_MERGE_MODES=["sum","mul","concat","ave"],nameMap=new Map;function common_checkDataFormat(value){checkStringTypeUnionValue(VALID_DATA_FORMAT_VALUES,"DataFormat",value)}function checkPaddingMode(value){checkStringTypeUnionValue(VALID_PADDING_MODE_VALUES,"PaddingMode",value)}function checkPoolMode(value){checkStringTypeUnionValue(VALID_POOL_MODE_VALUES,"PoolMode",value)}const _nameScopeStack=[];function nameScope(name,fn){_nameScopeStack.push(name);try{const val=fn();return _nameScopeStack.pop(),val}catch(e){throw _nameScopeStack.pop(),e}}function getScopedTensorName(tensorName){if(!isValidTensorName(tensorName))throw new Error("Not a valid tensor name: '"+tensorName+"'");return function currentNameScopePrefix(){return 0===_nameScopeStack.length?"":_nameScopeStack.join("/")+"/"}()+tensorName}function getUniqueTensorName(scopedName){if(!isValidTensorName(scopedName))throw new Error("Not a valid tensor name: '"+scopedName+"'");nameMap.has(scopedName)||nameMap.set(scopedName,0);const index=nameMap.get(scopedName);if(nameMap.set(scopedName,nameMap.get(scopedName)+1),index>0){const result=`${scopedName}_${index}`;return nameMap.set(result,1),result}return scopedName}const tensorNameRegex=new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);function isValidTensorName(name){return!!name.match(tensorNameRegex)}function isInteger(x){return x===parseInt(x.toString(),10)}function arrayProd(array,begin,end){null==begin&&(begin=0),null==end&&(end=array.length);let prod=1;for(let i=begin;i<end;++i)prod*=array[i];return prod}function math_utils_min(array){if(0===array.length)return Number.NaN;let min=Number.POSITIVE_INFINITY;for(let i=0;i<array.length;i++){const value=array[i];value<min&&(min=value)}return min}function math_utils_max(array){if(0===array.length)return Number.NaN;let max=Number.NEGATIVE_INFINITY;for(let i=0;i<array.length;i++){const value=array[i];value>max&&(max=value)}return max}function range(begin,end){if(end<begin)throw new errors_ValueError(`end (${end}) < begin (${begin}) is forbidden.`);const out=[];for(let i=begin;i<end;++i)out.push(i);return out}let _epsilon;function epsilon(){return null==_epsilon&&(_epsilon=(0,dist.Hs)().epsilon()),_epsilon}function tfjs_backend_cast(x,dtype){return dist.wgE(x,dtype)}function expandDims(x,axis=-1){const outShape=x.shape.slice();return axis<0&&(axis=outShape.length+axis+1),outShape.splice(axis,0,1),dist.tQQ(x,outShape)}function sliceAlongFirstAxis(array,start,size){return(0,dist.DZQ)(()=>{switch(array.rank){case 1:return dist.Q$M(array,start,size);case 2:return dist.zAd(array,[start,0],[size,array.shape[1]]);case 3:return dist.wck(array,[start,0,0],[size,array.shape[1],array.shape[2]]);case 4:return dist.R0O(array,[start,0,0,0],[size,array.shape[1],array.shape[2],array.shape[3]]);case 5:return dist.dik(array,[start,0,0,0,0],[size,array.shape[1],array.shape[2],array.shape[3],array.shape[4]]);case 6:return dist.dik(array,[start,0,0,0,0,0],[size,array.shape[1],array.shape[2],array.shape[3],array.shape[4],array.shape[5]]);default:throw new errors_ValueError(`sliceAlongFirstAxis() received an unsupported tensor rank: ${array.rank}`)}})}function sliceAlongLastAxis(array,start,size){return(0,dist.DZQ)(()=>{switch(array.rank){case 1:return dist.Q$M(array,start,size);case 2:return dist.zAd(array,[0,start],[array.shape[0],size]);case 3:return dist.wck(array,[0,0,start],[array.shape[0],array.shape[1],size]);case 4:return dist.R0O(array,[0,0,0,start],[array.shape[0],array.shape[1],array.shape[2],size]);default:throw new errors_ValueError(`sliceAlongLastAxis() received an unsupported tensor rank: ${array.rank}`)}})}function sliceAlongAxis(array,start,size,axis){return(0,dist.DZQ)(()=>{switch(array.rank){case 1:return dist.Q$M(array,start,size);case 2:switch(axis){case 1:return sliceAlongFirstAxis(array,start,size);case 2:return sliceAlongLastAxis(array,start,size);default:throw new errors_ValueError(`The axis is not within the rank of the tensor ${axis}`)}case 3:switch(axis){case 1:return sliceAlongFirstAxis(array,start,size);case 2:return dist.wck(array,[0,start,0],[array.shape[0],size,array.shape[2]]);case 3:return sliceAlongLastAxis(array,start,size);default:throw new errors_ValueError(`The axis is not within the rank of the tensor ${axis}`)}case 4:switch(axis){case 1:return sliceAlongFirstAxis(array,start,size);case 2:return dist.R0O(array,[0,start,0,0],[array.shape[0],size,array.shape[2],array.shape[3]]);case 3:return dist.R0O(array,[0,0,start,0],[array.shape[0],array.shape[1],size,array.shape[3]]);case 4:return sliceAlongLastAxis(array,start,size);default:throw new errors_ValueError(`The axis is not within the rank of the tensor ${axis}`)}default:throw new errors_ValueError(`sliceAlongLastAxis() received an unsupported tensor rank: ${array.rank}`)}})}function concatenate(tensors,axis=-1){let rank;return axis<0&&(rank=tensors[0].rank,axis=0!==rank?rank:0),axis===tensors[0].rank&&(axis=-1),dist.xWs(tensors,axis)}function concatAlongFirstAxis(a,b){switch(a.rank){case 1:return dist.I1m([a,b]);case 2:return dist.RPU([a,b],0);case 3:return dist.O5O([a,b],0);case 4:return dist.P1l([a,b],0);default:throw new errors_ValueError(`concatAlongFirstAxis() received an unsupported tensor rank: ${a.rank}`)}}function tfjs_backend_tile(x,n){if(Array.isArray(n)||(n=[n]),x.rank!==n.length)throw new errors_ValueError(`The length of input n (${n.length}) does not match the number of dimensions in input x (${x.rank})`);return dist.Vsq(x,n)}function randomNormal(shape,mean=0,stddev=1,dtype,seed){return dist.FE$(shape,mean,stddev,dtype,seed)}function tfjs_backend_dot(a,b,activation,bias){if(a.rank<2||b.rank<2)throw new errors_NotImplementedError(`dot requires both inputs to be rank >= 2 but got x shape = ${a.shape} and y shape = ${b.shape}`);if(b.rank>=3){if(a.shape.slice(-1)[0]!==b.shape.slice(-2)[0])throw new errors_NotImplementedError(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${a.shape} and  y shape = ${b.shape}`)}if(2===a.rank&&2===b.rank){const transposeA=!1,transposeB=!1;return dist.cZk.matMul({a,b,transposeA,transposeB,bias:bias?reshapeBias(a.rank,bias,"channelsLast"):null,activation})}{const aFirstDims=a.shape.slice(),aLastDim=aFirstDims.pop();a=dist.tQQ(a,[-1,aLastDim]);const bShape=b.shape.slice(),bLastDim=bShape.pop(),ySecondLastDim=bShape.pop(),yOtherDims=[...bShape,bLastDim],perm=Array.from({length:b.rank},(_,i)=>0===i?b.rank-2:i<=b.rank-2?i-1:i);b=dist.tQQ(dist.mgz(b,perm),[ySecondLastDim,-1]);const outputShape=[...aFirstDims,...yOtherDims],transposeA=!1,transposeB=!1;return dist.tQQ(dist.cZk.matMul({a,b,transposeA,transposeB,bias:bias?reshapeBias(a.rank,bias,"channelsLast"):null,activation}),outputShape)}}function tfjs_backend_gather(reference,indices,axis){return(0,dist.DZQ)(()=>(indices=Array.isArray(indices)?(0,dist.tGX)(indices,"int32"):dist.wgE(indices,"int32"),dist.kgh(reference,indices,axis)))}function tfjs_backend_square(x){return dist.lKK(x,x)}function reshapeBias(xRank,bias,dataFormat){const biasShape=bias.shape;if(1!==bias.rank&&bias.rank!==xRank)throw new errors_ValueError(`Unexpected bias dimensions: ${bias.rank}; expected it to be 1 or ${xRank}`);if(5===xRank){if("channelsFirst"===dataFormat)return 1===biasShape.length?dist.tQQ(bias,[1,biasShape[0],1,1,1]):dist.tQQ(bias,[1,biasShape[3],biasShape[0],biasShape[1],biasShape[2]]);if("channelsLast"===dataFormat)return 1===biasShape.length?dist.tQQ(bias,[1,1,1,1,biasShape[0]]):dist.tQQ(bias,[1].concat(biasShape))}else if(4===xRank){if("channelsFirst"===dataFormat)return 1===biasShape.length?dist.tQQ(bias,[1,biasShape[0],1,1]):dist.tQQ(bias,[1,biasShape[2],biasShape[0],biasShape[1]]);if("channelsLast"===dataFormat)return 1===biasShape.length?dist.tQQ(bias,[1,1,1,biasShape[0]]):dist.tQQ(bias,[1].concat(biasShape))}else if(3===xRank){if("channelsFirst"===dataFormat)return 1===biasShape.length?dist.tQQ(bias,[1,biasShape[0],1]):dist.tQQ(bias,[1,biasShape[1],biasShape[0]]);if("channelsLast"===dataFormat)return 1===biasShape.length?dist.tQQ(bias,[1,1,biasShape[0]]):dist.tQQ(bias,[1].concat(biasShape))}else if(xRank<3)return bias;throw new errors_ValueError(`Unsupported input rank by biasAdd: ${bias.rank}`)}function biasAdd(x,bias,dataFormat){return(0,dist.DZQ)(()=>(null==dataFormat&&(dataFormat="channelsLast"),common_checkDataFormat(dataFormat),dist.WQq(x,reshapeBias(x.rank,bias,dataFormat))))}function dropout(x,level,noiseShape,seed){return(0,dist.DZQ)(()=>dist.EZY(x,level,noiseShape,seed))}function inTrainPhase(x,alt,training=!1){return training?x():alt()}const VALID_FAN_MODE_VALUES=["fanIn","fanOut","fanAvg"],VALID_DISTRIBUTION_VALUES=["normal","uniform","truncatedNormal"];var console=__webpack_require__("./node_modules/console-browserify/index.js");class Initializer extends dist.JFn.Serializable{fromConfigUsesCustomObjects(){return!1}getConfig(){return{}}}class Zeros extends Initializer{apply(shape,dtype){return(0,dist.Ul9)(shape,dtype)}}Zeros.className="Zeros",dist.JFn.registerClass(Zeros);class Ones extends Initializer{apply(shape,dtype){return(0,dist.SaS)(shape,dtype)}}Ones.className="Ones",dist.JFn.registerClass(Ones);class Constant extends Initializer{constructor(args){if(super(),"object"!=typeof args)throw new errors_ValueError(`Expected argument of type ConstantConfig but got ${args}`);if(void 0===args.value)throw new errors_ValueError(`config must have value set but got ${args}`);this.value=args.value}apply(shape,dtype){return(0,dist.DZQ)(()=>(0,dist.lKK)((0,dist.d_2)(this.value),(0,dist.SaS)(shape,dtype)))}getConfig(){return{value:this.value}}}Constant.className="Constant",dist.JFn.registerClass(Constant);class RandomUniform extends Initializer{constructor(args){super(),this.DEFAULT_MINVAL=-.05,this.DEFAULT_MAXVAL=.05,this.minval=args.minval||this.DEFAULT_MINVAL,this.maxval=args.maxval||this.DEFAULT_MAXVAL,this.seed=args.seed}apply(shape,dtype){return(0,dist.YeY)(shape,this.minval,this.maxval,dtype,this.seed)}getConfig(){return{minval:this.minval,maxval:this.maxval,seed:this.seed}}}RandomUniform.className="RandomUniform",dist.JFn.registerClass(RandomUniform);class RandomNormal extends Initializer{constructor(args){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=args.mean||this.DEFAULT_MEAN,this.stddev=args.stddev||this.DEFAULT_STDDEV,this.seed=args.seed}apply(shape,dtype){if("float32"!==(dtype=dtype||"float32")&&"int32"!==dtype)throw new errors_NotImplementedError(`randomNormal does not support dType ${dtype}.`);return randomNormal(shape,this.mean,this.stddev,dtype,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}RandomNormal.className="RandomNormal",dist.JFn.registerClass(RandomNormal);class TruncatedNormal extends Initializer{constructor(args){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=args.mean||this.DEFAULT_MEAN,this.stddev=args.stddev||this.DEFAULT_STDDEV,this.seed=args.seed}apply(shape,dtype){if("float32"!==(dtype=dtype||"float32")&&"int32"!==dtype)throw new errors_NotImplementedError(`truncatedNormal does not support dType ${dtype}.`);return(0,dist.efE)(shape,this.mean,this.stddev,dtype,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}TruncatedNormal.className="TruncatedNormal",dist.JFn.registerClass(TruncatedNormal);class Identity extends Initializer{constructor(args){super(),this.gain=null!=args.gain?args.gain:1}apply(shape,dtype){return(0,dist.DZQ)(()=>{if(2!==shape.length||shape[0]!==shape[1])throw new errors_ValueError("Identity matrix initializer can only be used for 2D square matrices.");return(0,dist.lKK)(this.gain,(0,dist.y5U)(shape[0]))})}getConfig(){return{gain:this.gain}}}Identity.className="Identity",dist.JFn.registerClass(Identity);class VarianceScaling extends Initializer{constructor(args){if(super(),args.scale<0)throw new errors_ValueError(`scale must be a positive float. Got: ${args.scale}`);this.scale=null==args.scale?1:args.scale,this.mode=null==args.mode?"fanIn":args.mode,function checkFanMode(value){checkStringTypeUnionValue(VALID_FAN_MODE_VALUES,"FanMode",value)}(this.mode),this.distribution=null==args.distribution?"normal":args.distribution,function checkDistribution(value){checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES,"Distribution",value)}(this.distribution),this.seed=args.seed}apply(shape,dtype){const fans=function computeFans(shape,dataFormat="channelsLast"){let fanIn,fanOut;if(common_checkDataFormat(dataFormat),2===shape.length)fanIn=shape[0],fanOut=shape[1];else if(-1!==[3,4,5].indexOf(shape.length)){if("channelsFirst"===dataFormat){const receptiveFieldSize=arrayProd(shape,2);fanIn=shape[1]*receptiveFieldSize,fanOut=shape[0]*receptiveFieldSize}else if("channelsLast"===dataFormat){const receptiveFieldSize=arrayProd(shape,0,shape.length-2);fanIn=shape[shape.length-2]*receptiveFieldSize,fanOut=shape[shape.length-1]*receptiveFieldSize}}else{const shapeProd=arrayProd(shape);fanIn=Math.sqrt(shapeProd),fanOut=Math.sqrt(shapeProd)}return[fanIn,fanOut]}(shape),fanIn=fans[0],fanOut=fans[1];let scale=this.scale;if("fanIn"===this.mode?scale/=Math.max(1,fanIn):"fanOut"===this.mode?scale/=Math.max(1,fanOut):scale/=Math.max(1,(fanIn+fanOut)/2),"normal"===this.distribution){const stddev=Math.sqrt(scale);if("float32"!==(dtype=dtype||"float32")&&"int32"!==dtype)throw new errors_NotImplementedError(`${this.getClassName()} does not support dType ${dtype}.`);return(0,dist.efE)(shape,0,stddev,dtype,this.seed)}{const limit=Math.sqrt(3*scale);return(0,dist.YeY)(shape,-limit,limit,dtype,this.seed)}}getConfig(){return{scale:this.scale,mode:this.mode,distribution:this.distribution,seed:this.seed}}}VarianceScaling.className="VarianceScaling",dist.JFn.registerClass(VarianceScaling);class GlorotUniform extends VarianceScaling{constructor(args){super({scale:1,mode:"fanAvg",distribution:"uniform",seed:null==args?null:args.seed})}getClassName(){return VarianceScaling.className}}GlorotUniform.className="GlorotUniform",dist.JFn.registerClass(GlorotUniform);class GlorotNormal extends VarianceScaling{constructor(args){super({scale:1,mode:"fanAvg",distribution:"normal",seed:null==args?null:args.seed})}getClassName(){return VarianceScaling.className}}GlorotNormal.className="GlorotNormal",dist.JFn.registerClass(GlorotNormal);class HeNormal extends VarianceScaling{constructor(args){super({scale:2,mode:"fanIn",distribution:"normal",seed:null==args?null:args.seed})}getClassName(){return VarianceScaling.className}}HeNormal.className="HeNormal",dist.JFn.registerClass(HeNormal);class HeUniform extends VarianceScaling{constructor(args){super({scale:2,mode:"fanIn",distribution:"uniform",seed:null==args?null:args.seed})}getClassName(){return VarianceScaling.className}}HeUniform.className="HeUniform",dist.JFn.registerClass(HeUniform);class LeCunNormal extends VarianceScaling{constructor(args){super({scale:1,mode:"fanIn",distribution:"normal",seed:null==args?null:args.seed})}getClassName(){return VarianceScaling.className}}LeCunNormal.className="LeCunNormal",dist.JFn.registerClass(LeCunNormal);class LeCunUniform extends VarianceScaling{constructor(args){super({scale:1,mode:"fanIn",distribution:"uniform",seed:null==args?null:args.seed})}getClassName(){return VarianceScaling.className}}LeCunUniform.className="LeCunUniform",dist.JFn.registerClass(LeCunUniform);class Orthogonal extends Initializer{constructor(args){super(),this.DEFAULT_GAIN=1,this.ELEMENTS_WARN_SLOW=2e3,this.gain=null==args.gain?this.DEFAULT_GAIN:args.gain,this.seed=args.seed}apply(shape,dtype){return(0,dist.DZQ)(()=>{if(shape.length<2)throw new errors_NotImplementedError("Shape must be at least 2D.");if("int32"!==dtype&&"float32"!==dtype&&void 0!==dtype)throw new TypeError(`Unsupported data type ${dtype}.`);const numRows=dist.ZSL.sizeFromShape(shape.slice(0,-1)),numCols=shape[shape.length-1],numElements=numRows*numCols;numElements>this.ELEMENTS_WARN_SLOW&&console.warn(`Orthogonal initializer is being called on a matrix with more than ${this.ELEMENTS_WARN_SLOW} (${numElements}) elements: Slowness may result.`);const randNormalMat=randomNormal([Math.max(numCols,numRows),Math.min(numCols,numRows)],0,1,dtype,this.seed),qr=dist.mPL.qr(randNormalMat,!1);let qMat=qr[0];const diag=qr[1].flatten().stridedSlice([0],[Math.min(numCols,numRows)*Math.min(numCols,numRows)],[Math.min(numCols,numRows)+1]);return qMat=(0,dist.lKK)(qMat,diag.sign()),numRows<numCols&&(qMat=qMat.transpose()),(0,dist.lKK)((0,dist.d_2)(this.gain),qMat.reshape(shape))})}getConfig(){return{gain:this.gain,seed:this.seed}}}Orthogonal.className="Orthogonal",dist.JFn.registerClass(Orthogonal);const INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP={constant:"Constant",glorotNormal:"GlorotNormal",glorotUniform:"GlorotUniform",heNormal:"HeNormal",heUniform:"HeUniform",identity:"Identity",leCunNormal:"LeCunNormal",leCunUniform:"LeCunUniform",ones:"Ones",orthogonal:"Orthogonal",randomNormal:"RandomNormal",randomUniform:"RandomUniform",truncatedNormal:"TruncatedNormal",varianceScaling:"VarianceScaling",zeros:"Zeros"};function deserializeInitializer(config,customObjects={}){return deserializeKerasObject(config,dist.JFn.SerializationMap.getMap().classNameMap,customObjects,"initializer")}function serializeInitializer(initializer){return serializeKerasObject(initializer)}function getInitializer(identifier){if("string"==typeof identifier){const className=identifier in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP?INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier]:identifier;if("GlorotNormal"===className)return new GlorotNormal;if("GlorotUniform"===className)return new GlorotUniform;if("HeNormal"===className)return new HeNormal;if("HeUniform"===className)return new HeUniform;if("LeCunNormal"===className)return new LeCunNormal;if("LeCunUniform"===className)return new LeCunUniform;{const config={};return config.className=className,config.config={},deserializeInitializer(config)}}return identifier instanceof Initializer?identifier:deserializeInitializer(identifier)}function isArrayOfShapes(x){return Array.isArray(x)&&Array.isArray(x[0])}function normalizeShapeList(x){return 0===x.length?[]:Array.isArray(x[0])?x:[x]}function getExactlyOneTensor(xs){let x;if(Array.isArray(xs)){if(1!==xs.length)throw new errors_ValueError(`Expected Tensor length to be 1; got ${xs.length}`);x=xs[0]}else x=xs;return x}function getExactlyOneShape(shapes){if(Array.isArray(shapes)&&Array.isArray(shapes[0])){if(1===shapes.length)return shapes[0];throw new errors_ValueError(`Expected exactly 1 Shape; got ${shapes.length}`)}return shapes}function countParamsInWeights(weights){let count=0;for(const weight of weights)0===weight.shape.length?count+=1:count+=weight.shape.reduce((a,b)=>a*b);return count}class LayerVariable{constructor(val,dtype="float32",name="Variable",trainable=!0,constraint=null){this.dtype=null==dtype?"float32":dtype,this.shape=val.shape,this.id=getNextUniqueTensorId(),name=null==name?"Variable":name,this.originalName=getScopedTensorName(name),this.name=getUniqueTensorName(this.originalName),this.trainable_=trainable,this.constraint=constraint,this.val=dist.bvq(val,this.trainable_,this.name,this.dtype)}read(){return this.assertNotDisposed(),this.val}write(newVal){return this.assertNotDisposed(),function checkShapesMatch(x,y){if(x.shape.toString()!==y.shape.toString())throw new Error("Shape mismatch: "+JSON.stringify(x.shape)+" vs. "+JSON.stringify(y.shape))}(this.val,newVal),this.val.id!==newVal.id&&(this.val.assign(newVal),null!=this.constraint&&this.val.assign(this.constraint.apply(this.val))),this}dispose(){this.assertNotDisposed(),this.val.dispose()}assertNotDisposed(){if(this.val.isDisposed)throw new Error(`LayersVariable ${this.name} is already disposed.`)}get trainable(){return this.trainable_}set trainable(trainable){this.trainable_=trainable,this.val.trainable=trainable}}function batchGetValue(xs){return xs.map(x=>x.read())}function batchSetValue(variablesAndValues){variablesAndValues.forEach(variableAndValue=>{variableAndValue[0].write(variableAndValue[1])})}var topology_console=__webpack_require__("./node_modules/console-browserify/index.js");class InputSpec{constructor(args){this.dtype=args.dtype,this.shape=args.shape,null!=args.shape?this.ndim=args.shape.length:this.ndim=args.ndim,this.maxNDim=args.maxNDim,this.minNDim=args.minNDim,this.axes=args.axes||{}}}class SymbolicTensor{constructor(dtype,shape,sourceLayer,inputs,callArgs,name,outputTensorIndex){this.dtype=dtype,this.shape=shape,this.sourceLayer=sourceLayer,this.inputs=inputs,this.callArgs=callArgs,this.outputTensorIndex=outputTensorIndex,this.id=getNextUniqueTensorId(),null!=name&&(this.originalName=getScopedTensorName(name),this.name=getUniqueTensorName(this.originalName)),this.rank=shape.length}}let _nextNodeID=0;class Node{constructor(args,callArgs){this.callArgs=callArgs,this.id=_nextNodeID++,this.outboundLayer=args.outboundLayer,this.inboundLayers=args.inboundLayers,this.nodeIndices=args.nodeIndices,this.tensorIndices=args.tensorIndices,this.inputTensors=args.inputTensors,this.outputTensors=args.outputTensors,this.inputMasks=args.inputMasks,this.outputMasks=args.outputMasks,this.inputShapes=args.inputShapes,this.outputShapes=args.outputShapes;for(const layer of args.inboundLayers)null!=layer&&layer.outboundNodes.push(this);args.outboundLayer.inboundNodes.push(this)}getConfig(){const inboundNames=[];for(const layer of this.inboundLayers)null!=layer?inboundNames.push(layer.name):inboundNames.push(null);return{outboundLayer:this.outboundLayer?this.outboundLayer.name:null,inboundLayers:inboundNames,nodeIndices:this.nodeIndices,tensorIndices:this.tensorIndices}}}let _nextLayerID=0;class Layer extends dist.JFn.Serializable{constructor(args={}){super(),this._callHook=null,this._addedWeightNames=[],this._stateful=!1,this.id=_nextLayerID++,this.activityRegularizer=null,this.inputSpec=null,this.supportsMasking=!1,this._trainableWeights=[],this._nonTrainableWeights=[],this._losses=[],this._updates=[],this._built=!1,this.inboundNodes=[],this.outboundNodes=[];let name=args.name;if(!name){const prefix=this.getClassName();name=toSnakeCase(prefix)+"_"+getUid(prefix)}if(this.name=name,this.trainable_=null==args.trainable||args.trainable,null!=args.inputShape||null!=args.batchInputShape){let batchInputShape;if(null!=args.batchInputShape)batchInputShape=args.batchInputShape;else if(null!=args.inputShape){let batchSize=null;null!=args.batchSize&&(batchSize=args.batchSize),batchInputShape=[batchSize].concat(args.inputShape)}this.batchInputShape=batchInputShape;let dtype=args.dtype;null==dtype&&(dtype=args.inputDType),null==dtype&&(dtype="float32"),this.dtype=dtype}null!=args.weights?this.initialWeights=args.weights:this.initialWeights=null,this._refCount=null,this.fastWeightInitDuringBuild=!1}static nodeKey(layer,nodeIndex){return layer.name+"_ib-"+nodeIndex.toString()}getNodeAtIndex(nodeIndex,attrName){if(0===this.inboundNodes.length)throw new RuntimeError(`The layer has never been called and thus has no defined ${attrName}.`);if(this.inboundNodes.length<=nodeIndex)throw new errors_ValueError(`Asked to get ${attrName} at node ${nodeIndex}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);return this.inboundNodes[nodeIndex]}getInputAt(nodeIndex){return singletonOrArray(this.getNodeAtIndex(nodeIndex,"input").inputTensors)}getOutputAt(nodeIndex){return singletonOrArray(this.getNodeAtIndex(nodeIndex,"output").outputTensors)}get input(){if(this.inboundNodes.length>1)throw new AttributeError(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);if(0===this.inboundNodes.length)throw new AttributeError(`Layer ${this.name} is not connected, no input to return.`);return singletonOrArray(this.getNodeAtIndex(0,"input").inputTensors)}get output(){if(0===this.inboundNodes.length)throw new AttributeError(`Layer ${this.name} has no inbound nodes.`);if(this.inboundNodes.length>1)throw new AttributeError(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);return singletonOrArray(this.getNodeAtIndex(0,"output").outputTensors)}get losses(){return this._losses}calculateLosses(){return this.losses.map(lossFn=>lossFn())}get updates(){return this._updates}get built(){return this._built}set built(built){this._built=built}get trainable(){return this.trainable_}set trainable(trainable){this._trainableWeights.forEach(w=>w.trainable=trainable),this.trainable_=trainable}get trainableWeights(){return this.trainable_?this._trainableWeights.filter(w=>w.trainable):[]}set trainableWeights(weights){this._trainableWeights=weights}get nonTrainableWeights(){return this.trainable?this._trainableWeights.filter(w=>!w.trainable).concat(this._nonTrainableWeights):this._trainableWeights.concat(this._nonTrainableWeights)}set nonTrainableWeights(weights){this._nonTrainableWeights=weights}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}get stateful(){return this._stateful}resetStates(){if(!this.stateful)throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.")}assertInputCompatibility(inputs){const inputsList=toList(inputs);if(null==this.inputSpec||0===this.inputSpec.length)return;const inputSpec=toList(this.inputSpec);if(inputsList.length!==inputSpec.length)throw new errors_ValueError(`Layer ${this.name} expects ${inputSpec.length} inputs, but it received ${inputsList.length} input tensors. Input received: ${inputs}`);for(let inputIndex=0;inputIndex<inputsList.length;inputIndex++){const x=inputsList[inputIndex],spec=inputSpec[inputIndex];if(null==spec)continue;const ndim=x.rank;if(null!=spec.ndim&&ndim!==spec.ndim)throw new errors_ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected ndim=${spec.ndim}, found ndim=${ndim}`);if(null!=spec.maxNDim&&ndim>spec.maxNDim)throw new errors_ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected max_ndim=${spec.maxNDim}, found ndim=${ndim}`);if(null!=spec.minNDim&&ndim<spec.minNDim)throw new errors_ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected min_ndim=${spec.minNDim}, found ndim=${ndim}.`);if(null!=spec.dtype&&x.dtype!==spec.dtype)throw new errors_ValueError(`Input ${inputIndex} is incompatible with layer ${this.name} : expected dtype=${spec.dtype}, found dtype=${x.dtype}.`);if(spec.axes){const xShape=x.shape;for(const key in spec.axes){const axis=Number(key),value=spec.axes[key],xShapeAtAxis=axis>=0?xShape[axis]:xShape[xShape.length+axis];if(null!=value&&-1===[value,null].indexOf(xShapeAtAxis))throw new errors_ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected axis ${axis} of input shape to have value ${value} but got shape ${xShape}.`)}}if(null!=spec.shape)for(let i=0;i<spec.shape.length;++i){const specDim=spec.shape[i],dim=x.shape[i];if(null!=specDim&&null!=dim&&specDim!==dim)throw new errors_ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected shape=${spec.shape}, found shape=${x.shape}.`)}}}call(inputs,kwargs){return inputs}invokeCallHook(inputs,kwargs){null!=this._callHook&&this._callHook(inputs,kwargs)}setCallHook(callHook){this._callHook=callHook}clearCallHook(){this._callHook=null}apply(inputs,kwargs){kwargs=kwargs||{},this.assertNotDisposed();const inputsList=toList(inputs),allAreSymbolic=function checkAllSymbolic(tensors){let allAreSymbolic=!0;for(const tensor of toList(tensors))if(!(tensor instanceof SymbolicTensor)){allAreSymbolic=!1;break}return allAreSymbolic}(inputs),noneAreSymbolic=function checkNoneSymbolic(tensors){let noneAreSymbolic=!0;for(const tensor of toList(tensors))if(tensor instanceof SymbolicTensor){noneAreSymbolic=!1;break}return noneAreSymbolic}(inputs);if(allAreSymbolic===noneAreSymbolic)throw new errors_ValueError("Arguments to apply() must be all SymbolicTensors or all Tensors");return nameScope(this.name,()=>{if(!this.built){this.assertInputCompatibility(inputs);const inputShapes=[];for(const xElem of toList(inputs))inputShapes.push(xElem.shape);this.build(singletonOrArray(inputShapes)),this.built=!0,this.initialWeights&&this.setWeights(this.initialWeights),null===this._refCount&&noneAreSymbolic&&(this._refCount=1)}if(this.assertInputCompatibility(inputs),noneAreSymbolic){let output=this.call(inputs,kwargs);this.supportsMasking&&this.setMaskMetadata(inputs,output);const outputList=toList(output),outputListCopy=[];for(let x of outputList)-1!==inputsList.indexOf(x)&&(x=x.clone()),outputListCopy.push(x);if(output=singletonOrArray(outputListCopy),null!=this.activityRegularizer)throw new errors_NotImplementedError("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return output}{const inputShape=function collectInputShape(inputTensors){inputTensors=toList(inputTensors);const shapes=[];for(const x of inputTensors)shapes.push(x.shape);return singletonOrArray(shapes)}(inputs),outputShape=this.computeOutputShape(inputShape);let output;const outputDType="float32";if(this.warnOnIncompatibleInputShape(Array.isArray(inputs)?inputShape[0]:inputShape),output=null!=outputShape&&outputShape.length>0&&Array.isArray(outputShape[0])?outputShape.map((shape,index)=>new SymbolicTensor(outputDType,shape,this,toList(inputs),kwargs,this.name,index)):new SymbolicTensor(outputDType,outputShape,this,toList(inputs),kwargs,this.name),this.addInboundNode(inputs,output,null,null,inputShape,outputShape,kwargs),this._refCount++,null!=this.activityRegularizer)throw new errors_NotImplementedError("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return output}})}warnOnIncompatibleInputShape(inputShape){if(null!=this.batchInputShape)if(inputShape.length!==this.batchInputShape.length)topology_console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(inputShape)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);else{let dimMismatch=!1;this.batchInputShape.forEach((dimension,i)=>{null!=dimension&&null!=inputShape[i]&&inputShape[i]!==dimension&&(dimMismatch=!0)}),dimMismatch&&topology_console.warn(`The shape of the input tensor (${JSON.stringify(inputShape)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`)}}get outputShape(){if(null==this.inboundNodes||0===this.inboundNodes.length)throw new AttributeError(`The layer ${this.name} has never been called and thus has no defined output shape.`);const allOutputShapes=[];for(const node of this.inboundNodes){const shapeString=JSON.stringify(node.outputShapes);-1===allOutputShapes.indexOf(shapeString)&&allOutputShapes.push(shapeString)}if(1===allOutputShapes.length){const outputShapes=this.inboundNodes[0].outputShapes;return Array.isArray(outputShapes)&&Array.isArray(outputShapes[0])&&1===outputShapes.length?outputShapes[0]:outputShapes}throw new AttributeError(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`)}countParams(){if(!this.built)throw new RuntimeError(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);return countParamsInWeights(this.weights)}build(inputShape){this.built=!0}getWeights(trainableOnly=!1){return batchGetValue(trainableOnly?this.trainableWeights:this.weights)}setWeights(weights){(0,dist.DZQ)(()=>{const params=this.weights;if(params.length!==weights.length)throw new errors_ValueError(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${weights.length}, but the layer was expecting ${params.length} weights. Provided weights: ${weights}...`);if(0===params.length)return;const weightValueTuples=[],paramValues=batchGetValue(params);for(let i=0;i<paramValues.length;++i){const pv=paramValues[i],p=params[i],w=weights[i];if(!dist.ZSL.arraysEqual(pv.shape,w.shape))throw new errors_ValueError(`Layer weight shape ${pv.shape} not compatible with provided weight shape ${w.shape}`);weightValueTuples.push([p,w])}batchSetValue(weightValueTuples)})}addWeight(name,shape,dtype,initializer,regularizer,trainable,constraint,getInitializerFunc){if(-1!==this._addedWeightNames.indexOf(name))throw new errors_ValueError(`Duplicate weight name ${name} for layer ${this.name}`);this._addedWeightNames.push(name),null==dtype&&(dtype="float32"),this.fastWeightInitDuringBuild&&(initializer=null!=getInitializerFunc?getInitializerFunc():getInitializer("zeros"));const initValue=initializer.apply(shape,dtype),weight=new LayerVariable(initValue,dtype,name,trainable,constraint);return initValue.dispose(),null!=regularizer&&this.addLoss(()=>regularizer.apply(weight.read())),null==trainable&&(trainable=!0),trainable?this._trainableWeights.push(weight):this._nonTrainableWeights.push(weight),weight}setFastWeightInitDuringBuild(value){this.fastWeightInitDuringBuild=value}addLoss(losses){null==losses||Array.isArray(losses)&&0===losses.length||(losses=toList(losses),void 0!==this._losses&&null!==this._losses&&this.losses.push(...losses))}computeOutputShape(inputShape){return inputShape}computeMask(inputs,mask){if(!this.supportsMasking){if(null!=mask){if(!Array.isArray(mask))throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);mask.forEach(maskElement=>{if(null!=maskElement)throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`)})}return null}return mask}setMaskMetadata(inputs,outputs,previousMask){if(!this.supportsMasking)return;const outputMasks=this.computeMask(inputs,previousMask),outputsList=toList(outputs),outputMasksList=toList(outputMasks);if(outputsList.length!==outputMasksList.length)throw new Error(`${this.name} outputs ${outputsList.length} tensors but ${outputsList.length} masks for those tensors`);for(let i=0;i<outputsList.length;i++)outputsList[i].kerasMask=outputMasksList[i]}addInboundNode(inputTensors,outputTensors,inputMasks,outputMasks,inputShapes,outputShapes,kwargs=null){const inputTensorList=toList(inputTensors);outputTensors=toList(outputTensors),inputMasks=toList(inputMasks),outputMasks=toList(outputMasks),inputShapes=normalizeShapeList(inputShapes),outputShapes=normalizeShapeList(outputShapes);const inboundLayers=[],nodeIndices=[],tensorIndices=[];for(const x of inputTensorList)inboundLayers.push(x.sourceLayer),nodeIndices.push(x.nodeIndex),tensorIndices.push(x.tensorIndex);new Node({outboundLayer:this,inboundLayers,nodeIndices,tensorIndices,inputTensors:inputTensorList,outputTensors,inputMasks,outputMasks,inputShapes,outputShapes},kwargs);for(let i=0;i<outputTensors.length;i++)outputTensors[i].sourceLayer=this,outputTensors[i].nodeIndex=this.inboundNodes.length-1,outputTensors[i].tensorIndex=i}getConfig(){const config={name:this.name,trainable:this.trainable};return null!=this.batchInputShape&&(config.batchInputShape=this.batchInputShape),null!=this.dtype&&(config.dtype=this.dtype),config}disposeWeights(){return this.weights.forEach(weight=>weight.dispose()),this.weights.length}assertNotDisposed(){if(0===this._refCount)throw new Error(`Layer '${this.name}' is already disposed.`)}dispose(){if(!this.built)throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);if(null===this._refCount)throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);this.assertNotDisposed();let numDisposedVariables=0;return 0===--this._refCount&&(numDisposedVariables=this.disposeWeights()),{refCountAfterDispose:this._refCount,numDisposedVariables}}}function getSourceInputs(tensor,layer,nodeIndex){if((null==layer||null!=nodeIndex&&nodeIndex>0)&&(layer=tensor.sourceLayer,nodeIndex=tensor.nodeIndex),0===layer.inboundNodes.length)return[tensor];{const node=layer.inboundNodes[nodeIndex];if(0===node.inboundLayers.length)return node.inputTensors;{const sourceTensors=[];for(let i=0;i<node.inboundLayers.length;i++){const previousSources=getSourceInputs(node.inputTensors[i],node.inboundLayers[i],node.nodeIndices[i]);for(const x of previousSources)-1===sourceTensors.indexOf(x)&&sourceTensors.push(x)}return sourceTensors}}}class InputLayer extends Layer{constructor(args){if(super({dtype:args.dtype,name:null!=args.name?args.name:getUid("input").toString()}),null==args.batchSize&&(args.batchSize=null),null==args.sparse&&(args.sparse=!1),this.trainable=!1,this.built=!0,this.sparse=args.sparse,null!=args.inputShape&&null!=args.batchInputShape)throw new errors_ValueError("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");let batchInputShape=args.batchInputShape;if(null==batchInputShape){if(null==args.inputShape)throw new errors_ValueError("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");batchInputShape=[args.batchSize].concat(args.inputShape)}else if(null!=args.batchSize)throw new errors_ValueError("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");const dtype=args.dtype||"float32";this.batchInputShape=batchInputShape,this.dtype=dtype,this.inputSpec=[{shape:batchInputShape}];const inputTensor=new SymbolicTensor(this.dtype,this.batchInputShape,this,[],{},this.name);inputTensor.nodeIndex=0,inputTensor.tensorIndex=0,new Node({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:[inputTensor],outputTensors:[inputTensor],inputMasks:[null],outputMasks:[null],inputShapes:[batchInputShape],outputShapes:[batchInputShape]})}apply(inputs,kwargs){throw new errors_ValueError(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`)}dispose(){return{refCountAfterDispose:this._refCount,numDisposedVariables:0}}getConfig(){return{batchInputShape:this.batchInputShape,dtype:this.dtype,sparse:this.sparse,name:this.name}}}function Input(config){if(null==config.batchShape&&null==config.shape)throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");if(null!=config.batchShape&&null!=config.shape)throw new errors_ValueError("Please provide either a `shape` or `batchShape` argument to Input, but not both.");let batchShape=config.batchShape;null!=config.shape&&null==batchShape&&(batchShape=[null].concat(config.shape));let dtype=config.dtype;null==dtype&&(dtype="float32");return new InputLayer({batchInputShape:batchShape,name:config.name,dtype,sparse:config.sparse}).inboundNodes[0].outputTensors[0]}InputLayer.className="InputLayer",dist.JFn.registerClass(InputLayer);class FeedDict{constructor(feeds){if(this.id2Value={},this.id2Mask={},this.name2Id={},feeds instanceof FeedDict)for(const id in feeds.id2Value)this.id2Value[id]=feeds.id2Value[id],id in feeds.id2Mask&&(this.id2Mask[id]=feeds.id2Mask[id]);else{if(null==feeds)return;for(const feed of feeds)this.add(feed.key,feed.value)}}add(key,value,mask){if(null!=this.id2Value[key.id])throw new errors_ValueError(`Duplicate key: name=${key.name}, id=${key.id}`);return this.id2Value[key.id]=function assertFeedCompatibility(key,val){if(null==key.dtype||key.dtype===val.dtype)return val;try{return(0,dist.wgE)(val,key.dtype)}catch(err){throw new errors_ValueError(`The dtype of the feed (${val.dtype}) can not be cast to the dtype of the key '${key.name}' (${key.dtype}).`)}}(key,value),this.name2Id[key.name]=key.id,null!=mask&&(this.id2Mask[key.id]=mask),this}addFeed(feed){this.add(feed.key,feed.value)}hasKey(key){return null!=this.id2Value[key.id]}names(){return Object.keys(this.name2Id)}getValue(key){if(key instanceof SymbolicTensor){if(null==this.id2Value[key.id])throw new errors_ValueError(`Nonexistent key: ${key.name}`);return this.id2Value[key.id]}{const id=this.name2Id[key];if(null==id)throw new errors_ValueError(`Feed dict has no SymbolicTensor name: ${key}`);return this.id2Value[id]}}getMask(key){if(key instanceof SymbolicTensor){if(null==this.id2Value[key.id])throw new errors_ValueError(`Nonexistent key: ${key.name}`);return this.id2Mask[key.id]}{const id=this.name2Id[key];if(null==id)throw new errors_ValueError(`Feed dict has no SymbolicTensor name: ${key}`);return this.id2Mask[id]}}disposeMasks(){null!=this.id2Mask&&(0,dist.ASo)(this.id2Mask)}}const cachedSorted=new LruCache,cachedRecipientCounts=new LruCache;function execute(fetches,feedDict,kwargs,probe){const training=null!=kwargs&&kwargs.training,arrayFetches=Array.isArray(fetches),fetchArray=arrayFetches?fetches:[fetches],outputNames=fetchArray.map(t=>t.name),finalOutputs=[],feedNames=feedDict.names();for(const outputName of outputNames)-1!==feedNames.indexOf(outputName)?finalOutputs.push(feedDict.getValue(outputName)):finalOutputs.push(null);null!=probe&&(probe.maxNumTensors=-1/0,probe.minNumTensors=1/0);const fetchAndFeedKey=outputNames.join(",")+"|"+feedDict.names().sort().join(",");let recipientCounts,sorted=cachedSorted.get(fetchAndFeedKey);if(null==sorted){const out=function getTopologicalSortAndRecipientCounts(fetches,feedDict){dist.ZSL.assert(null!=fetches&&fetches.length>0,()=>"Expected at least one fetch, got none");let finalSorted=[],finalRecipientMap={};if(1===fetches.length){const out=getTopologicalSortAndRecipientCountsForOneFetch(fetches[0],feedDict);finalSorted=out.sorted,finalRecipientMap=out.recipientMap}else{const visited=new Set;for(const fetch of fetches){const{sorted,recipientMap}=getTopologicalSortAndRecipientCountsForOneFetch(fetch,feedDict);for(const symbolicTensor of sorted)visited.has(symbolicTensor.name)||(finalSorted.push(symbolicTensor),visited.add(symbolicTensor.name));for(const name in recipientMap)null==finalRecipientMap[name]&&(finalRecipientMap[name]=new Set),recipientMap[name].forEach(recipient=>finalRecipientMap[name].add(recipient))}}return{sorted:finalSorted,recipientCounts:recipientMap2Counts(finalRecipientMap)}}(fetchArray,feedDict);sorted=out.sorted,recipientCounts=out.recipientCounts,cachedSorted.put(fetchAndFeedKey,sorted),cachedRecipientCounts.put(fetchAndFeedKey,recipientCounts)}recipientCounts={},training||Object.assign(recipientCounts,cachedRecipientCounts.get(fetchAndFeedKey));const internalFeedDict=new FeedDict(feedDict);for(let i=0;i<sorted.length;++i){if(null!=probe){const numTensors=(0,dist.m1Z)().numTensors;numTensors>probe.maxNumTensors&&(probe.maxNumTensors=numTensors),numTensors<probe.minNumTensors&&(probe.minNumTensors=numTensors)}const symbolic=sorted[i],srcLayer=symbolic.sourceLayer;if(srcLayer instanceof InputLayer)continue;const inputValues=[],inputMasks=[],tensorsToDispose=[];let maskExists=!1;for(const input of symbolic.inputs){const value=internalFeedDict.getValue(input),mask=internalFeedDict.getMask(input);inputValues.push(value),inputMasks.push(mask),null!=mask&&(maskExists=!0),training||(recipientCounts[input.name]--,0!==recipientCounts[input.name]||feedDict.hasKey(input)||-1!==outputNames.indexOf(input.name)||value.isDisposed||!0===input.sourceLayer.stateful||tensorsToDispose.push(value))}maskExists&&((kwargs=kwargs||{}).mask=inputMasks[0]);const outputTensors=toList(srcLayer.apply(inputValues,kwargs));let outputMask=null;srcLayer.supportsMasking&&(outputMask=srcLayer.computeMask(inputValues,inputMasks));const layerOutputs=getNodeOutputs(symbolic),outputSymbolicTensors=Array.isArray(layerOutputs)?layerOutputs:[layerOutputs];for(let i=0;i<outputSymbolicTensors.length;++i){internalFeedDict.hasKey(outputSymbolicTensors[i])||internalFeedDict.add(outputSymbolicTensors[i],outputTensors[i],Array.isArray(outputMask)?outputMask[0]:outputMask);const index=outputNames.indexOf(outputSymbolicTensors[i].name);-1!==index&&(finalOutputs[index]=outputTensors[i])}training||(0,dist.ASo)(tensorsToDispose)}return internalFeedDict.disposeMasks(),arrayFetches?finalOutputs:finalOutputs[0]}function recipientMap2Counts(recipientMap){const recipientCounts={};for(const name in recipientMap)recipientCounts[name]=recipientMap[name].size;return recipientCounts}function getTopologicalSortAndRecipientCountsForOneFetch(fetch,feedDict){const visited=new Set,sorted=[],recipientMap={};for(const key of feedDict.names())visited.add(key);const stack=[],marks=[];for(stack.push(fetch);stack.length>0;){const top=stack[stack.length-1];if(visited.has(top.name)){stack.pop();continue}const topIsMarked=marks[marks.length-1]===stack.length-1;if(0===top.inputs.length||topIsMarked)stack.pop(),sorted.push(top),visited.add(top.name),topIsMarked&&marks.pop();else{marks.push(stack.length-1);for(const input of top.inputs)null==recipientMap[input.name]&&(recipientMap[input.name]=new Set),recipientMap[input.name].add(top.name),visited.has(input.name)||stack.push(input)}}return{sorted,recipientMap}}function getNodeOutputs(fetch){let layerOutputs;if(1===fetch.sourceLayer.inboundNodes.length)layerOutputs=fetch.sourceLayer.output;else{let nodeIndex=null;for(let i=0;i<fetch.sourceLayer.inboundNodes.length;++i)for(const outputTensor of fetch.sourceLayer.inboundNodes[i].outputTensors)if(outputTensor.id===fetch.id){nodeIndex=i;break}layerOutputs=fetch.sourceLayer.getOutputAt(nodeIndex)}return layerOutputs}function calcL2Norms(w,axis){return(0,dist.DZQ)(()=>dist.RZD(dist.czq(dist.lKK(w,w),axis,!0)))}(0,dist._K2)().registerFlag("TOPOLOGICAL_SORT_CACHE_MAX_ENTRIES",()=>100,function updateCacheMaxEntries(maxEntries){null!=cachedSorted&&cachedSorted.setMaxEntries(maxEntries),null!=cachedRecipientCounts&&cachedRecipientCounts.setMaxEntries(maxEntries)});class Constraint extends dist.JFn.Serializable{getConfig(){return{}}}class MaxNorm extends Constraint{constructor(args){super(),this.defaultMaxValue=2,this.defaultAxis=0,this.maxValue=null!=args.maxValue?args.maxValue:this.defaultMaxValue,this.axis=null!=args.axis?args.axis:this.defaultAxis}apply(w){return(0,dist.DZQ)(()=>{const norms=calcL2Norms(w,this.axis),desired=dist.zQh(norms,0,this.maxValue);return dist.lKK(w,dist.y4m(desired,dist.WQq(epsilon(),norms)))})}getConfig(){return{maxValue:this.maxValue,axis:this.axis}}}MaxNorm.className="MaxNorm",dist.JFn.registerClass(MaxNorm);class UnitNorm extends Constraint{constructor(args){super(),this.defaultAxis=0,this.axis=null!=args.axis?args.axis:this.defaultAxis}apply(w){return(0,dist.DZQ)(()=>dist.y4m(w,dist.WQq(epsilon(),calcL2Norms(w,this.axis))))}getConfig(){return{axis:this.axis}}}UnitNorm.className="UnitNorm",dist.JFn.registerClass(UnitNorm);class NonNeg extends Constraint{apply(w){return dist.VVh(w)}}NonNeg.className="NonNeg",dist.JFn.registerClass(NonNeg);class MinMaxNorm extends Constraint{constructor(args){super(),this.defaultMinValue=0,this.defaultMaxValue=1,this.defaultRate=1,this.defaultAxis=0,this.minValue=null!=args.minValue?args.minValue:this.defaultMinValue,this.maxValue=null!=args.maxValue?args.maxValue:this.defaultMaxValue,this.rate=null!=args.rate?args.rate:this.defaultRate,this.axis=null!=args.axis?args.axis:this.defaultAxis}apply(w){return(0,dist.DZQ)(()=>{const norms=calcL2Norms(w,this.axis),desired=dist.WQq(dist.lKK(this.rate,dist.zQh(norms,this.minValue,this.maxValue)),dist.lKK(1-this.rate,norms));return dist.lKK(w,dist.y4m(desired,dist.WQq(epsilon(),norms)))})}getConfig(){return{minValue:this.minValue,maxValue:this.maxValue,rate:this.rate,axis:this.axis}}}MinMaxNorm.className="MinMaxNorm",dist.JFn.registerClass(MinMaxNorm);const CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP={maxNorm:"MaxNorm",minMaxNorm:"MinMaxNorm",nonNeg:"NonNeg",unitNorm:"UnitNorm"};function serializeConstraint(constraint){return serializeKerasObject(constraint)}function deserializeConstraint(config,customObjects={}){return deserializeKerasObject(config,dist.JFn.SerializationMap.getMap().classNameMap,customObjects,"constraint")}function getConstraint(identifier){if(null==identifier)return null;if("string"==typeof identifier){return deserializeConstraint({className:identifier in CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP?CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier]:identifier,config:{}})}return identifier instanceof Constraint?identifier:deserializeConstraint(identifier)}function maxNorm(args){return new MaxNorm(args)}function unitNorm(args){return new UnitNorm(args)}function nonNeg(){return new NonNeg}function minMaxNorm(config){return new MinMaxNorm(config)}function exports_initializers_zeros(){return new Zeros}function exports_initializers_ones(){return new Ones}function constant(args){return new Constant(args)}function randomUniform(args){return new RandomUniform(args)}function exports_initializers_randomNormal(args){return new RandomNormal(args)}function truncatedNormal(args){return new TruncatedNormal(args)}function identity(args){return new Identity(args)}function varianceScaling(config){return new VarianceScaling(config)}function glorotUniform(args){return new GlorotUniform(args)}function glorotNormal(args){return new GlorotNormal(args)}function heNormal(args){return new HeNormal(args)}function heUniform(args){return new HeUniform(args)}function leCunNormal(args){return new LeCunNormal(args)}function leCunUniform(args){return new LeCunUniform(args)}function orthogonal(args){return new Orthogonal(args)}async function resolveScalarsInLogs(logs){if(null==logs)return;const promises=[],keys=[],scalarsToDispose=[];for(const key in logs){const value=logs[key];if("number"!=typeof value){const valueScalar=value;promises.push(valueScalar.data()),keys.push(key),scalarsToDispose.push(valueScalar)}}if(promises.length>0){const values=await Promise.all(promises);for(let i=0;i<values.length;++i)logs[keys[i]]=values[i][0];(0,dist.ASo)(scalarsToDispose)}}function disposeTensorsInLogs(logs){if(null!=logs)for(const key in logs){const value=logs[key];"number"!=typeof value&&value.dispose()}}var ModelLoggingVerbosity;!function(ModelLoggingVerbosity){ModelLoggingVerbosity[ModelLoggingVerbosity.SILENT=0]="SILENT",ModelLoggingVerbosity[ModelLoggingVerbosity.VERBOSE=1]="VERBOSE"}(ModelLoggingVerbosity||(ModelLoggingVerbosity={}));class BaseCallback{constructor(){this.validationData=null}setParams(params){this.params=params}async onEpochBegin(epoch,logs){}async onEpochEnd(epoch,logs){}async onBatchBegin(batch,logs){}async onBatchEnd(batch,logs){}async onTrainBegin(logs){}async onTrainEnd(logs){}setModel(model){}}class CallbackList{constructor(callbacks,queueLength=10){null==callbacks&&(callbacks=[]),this.callbacks=callbacks,this.queueLength=queueLength}append(callback){this.callbacks.push(callback)}setParams(params){for(const callback of this.callbacks)callback.setParams(params)}setModel(model){for(const callback of this.callbacks)callback.setModel(model)}async onEpochBegin(epoch,logs){null==logs&&(logs={});for(const callback of this.callbacks)await callback.onEpochBegin(epoch,logs)}async onEpochEnd(epoch,logs){null==logs&&(logs={});for(const callback of this.callbacks)await callback.onEpochEnd(epoch,logs)}async onBatchBegin(batch,logs){null==logs&&(logs={});for(const callback of this.callbacks)await callback.onBatchBegin(batch,logs)}async onBatchEnd(batch,logs){null==logs&&(logs={});for(const callback of this.callbacks)await callback.onBatchEnd(batch,logs)}async onTrainBegin(logs){null==logs&&(logs={});for(const callback of this.callbacks)await callback.onTrainBegin(logs)}async onTrainEnd(logs){null==logs&&(logs={});for(const callback of this.callbacks)await callback.onTrainEnd(logs)}}class BaseLogger extends BaseCallback{constructor(){super()}async onEpochBegin(epoch){this.seen=0,this.totals={}}async onBatchEnd(batch,logs){null==logs&&(logs={});const batchSize=null==logs.size?0:logs.size;this.seen+=batchSize;for(const key in logs){const value=logs[key];if("number"==typeof value)this.totals.hasOwnProperty(key)||(this.totals[key]=0),this.totals[key]=this.totals[key]+value*batchSize;else{let oldTotalsToDispose;key in this.totals?oldTotalsToDispose=this.totals[key]:this.totals[key]=0;const total=(0,dist.DZQ)(()=>(0,dist.WQq)(this.totals[key],(0,dist.lKK)(value,batchSize)));this.totals[key]=total,null!=oldTotalsToDispose&&oldTotalsToDispose.dispose()}}}async onEpochEnd(epoch,logs){if(null!=logs)for(const key of this.params.metrics)null!=this.totals[key]&&("number"==typeof this.totals[key]?logs[key]=this.totals[key]/this.seen:(0,dist.DZQ)(()=>{const log=(0,dist.lKK)((0,dist.y4m)(1,this.seen),this.totals[key]);logs[key]=log,this.totals[key].dispose(),(0,dist.aCs)(logs[key])}))}}class History extends BaseCallback{async onTrainBegin(logs){this.epoch=[],this.history={}}async onEpochEnd(epoch,logs){null==logs&&(logs={}),this.epoch.push(epoch);for(const key in logs)null==this.history[key]&&(this.history[key]=[]),this.history[key].push(logs[key])}async syncData(){const promises=[],keys=[],indices=[];for(const key in this.history){const valueArray=this.history[key];for(let i=0;i<valueArray.length;++i)if("number"!=typeof valueArray[i]){const valueScalar=valueArray[i];promises.push(valueScalar.data()),keys.push(key),indices.push(i)}}const values=await Promise.all(promises);for(let n=0;n<values.length;++n){this.history[keys[n]][indices[n]].dispose(),this.history[keys[n]][indices[n]]=values[n][0]}}}class CustomCallback extends BaseCallback{constructor(args,yieldEvery){if(super(),this.currentEpoch=0,this.nowFunc=args.nowFunc,this.nextFrameFunc=args.nextFrameFunc||dist.dA1,this.yieldEvery=yieldEvery||"auto","auto"===this.yieldEvery&&(this.yieldEvery=125),"never"===this.yieldEvery&&null!=args.onYield)throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");dist.ZSL.isNumber(this.yieldEvery)&&(this.maybeWait=function debounce(f,waitMs,nowFunc){let lastResult,lastTime=null!=nowFunc?nowFunc():dist.ZSL.now();return(...args)=>{const now=null!=nowFunc?nowFunc():dist.ZSL.now();return now-lastTime<waitMs||(lastTime=now,lastResult=f(...args)),lastResult}}(this.maybeWait.bind(this),this.yieldEvery,this.nowFunc)),this.trainBegin=args.onTrainBegin,this.trainEnd=args.onTrainEnd,this.epochBegin=args.onEpochBegin,this.epochEnd=args.onEpochEnd,this.batchBegin=args.onBatchBegin,this.batchEnd=args.onBatchEnd,this.yield=args.onYield}async maybeWait(epoch,batch,logs){const ps=[];null!=this.yield&&(await resolveScalarsInLogs(logs),ps.push(this.yield(epoch,batch,logs))),ps.push(this.nextFrameFunc()),await Promise.all(ps)}async onEpochBegin(epoch,logs){this.currentEpoch=epoch,null!=this.epochBegin&&(await resolveScalarsInLogs(logs),await this.epochBegin(epoch,logs))}async onEpochEnd(epoch,logs){const ps=[];null!=this.epochEnd&&(await resolveScalarsInLogs(logs),ps.push(this.epochEnd(epoch,logs))),"epoch"===this.yieldEvery&&ps.push(this.nextFrameFunc()),await Promise.all(ps)}async onBatchBegin(batch,logs){null!=this.batchBegin&&(await resolveScalarsInLogs(logs),await this.batchBegin(batch,logs))}async onBatchEnd(batch,logs){const ps=[];null!=this.batchEnd&&(await resolveScalarsInLogs(logs),ps.push(this.batchEnd(batch,logs))),"batch"===this.yieldEvery?ps.push(this.nextFrameFunc()):dist.ZSL.isNumber(this.yieldEvery)&&ps.push(this.maybeWait(this.currentEpoch,batch,logs)),await Promise.all(ps)}async onTrainBegin(logs){null!=this.trainBegin&&(await resolveScalarsInLogs(logs),await this.trainBegin(logs))}async onTrainEnd(logs){null!=this.trainEnd&&(await resolveScalarsInLogs(logs),await this.trainEnd(logs))}}function standardizeCallbacks(callbacks,yieldEvery){if(null==callbacks&&(callbacks={}),callbacks instanceof BaseCallback)return[callbacks];if(Array.isArray(callbacks)&&callbacks[0]instanceof BaseCallback)return callbacks;return toList(callbacks).map(callbackConfig=>new CustomCallback(callbackConfig,yieldEvery))}class CallbackConstructorRegistry{constructor(){}static registerCallbackConstructor(verbosityLevel,callbackConstructor){dist.ZSL.assert(verbosityLevel>=0&&Number.isInteger(verbosityLevel),()=>`Verbosity level is expected to be an integer >= 0, but got ${verbosityLevel}`),CallbackConstructorRegistry.checkForDuplicate(callbackConstructor),null==CallbackConstructorRegistry.constructors[verbosityLevel]&&(CallbackConstructorRegistry.constructors[verbosityLevel]=[]),CallbackConstructorRegistry.constructors[verbosityLevel].push(callbackConstructor)}static checkForDuplicate(callbackConstructor){for(const levelName in CallbackConstructorRegistry.constructors){CallbackConstructorRegistry.constructors[+levelName].forEach(ctor=>{if(ctor===callbackConstructor)throw new errors_ValueError("Duplicate callback constructor.")})}}static clear(){CallbackConstructorRegistry.constructors={}}static createCallbacks(verbosityLevel){const constructors=[];for(const levelName in CallbackConstructorRegistry.constructors){const level=+levelName;verbosityLevel>=level&&constructors.push(...CallbackConstructorRegistry.constructors[level])}return constructors.map(ctor=>new ctor)}}function configureCallbacks(callbacks,verbose,epochs,initialEpoch,numTrainSamples,stepsPerEpoch,batchSize,doValidation,callbackMetrics){const history=new History,actualCallbacks=[new BaseLogger,...CallbackConstructorRegistry.createCallbacks(verbose)];null!=callbacks&&actualCallbacks.push(...callbacks),actualCallbacks.push(history);const callbackList=new CallbackList(actualCallbacks);return callbackList.setParams({epochs,initialEpoch,samples:numTrainSamples,steps:stepsPerEpoch,batchSize,verbose,doValidation,metrics:callbackMetrics}),{callbackList,history}}function deserialize(config,customObjects={},fastWeightInit=!1){return deserializeKerasObject(config,dist.JFn.SerializationMap.getMap().classNameMap,customObjects,"layer",fastWeightInit)}function l2Normalize(x,axis){return(0,dist.DZQ)(()=>{"float32"!==x.dtype&&(x=dist.wgE(x,"float32"));const squareSum=dist.czq(tfjs_backend_square(x),axis,!0),epsilonTensor=dist.GSj(squareSum.shape,epsilon()),norm=dist.RZD(dist.PhQ(squareSum,epsilonTensor));return dist.y4m(x,norm)})}function meanSquaredError(yTrue,yPred){return(0,dist.DZQ)(()=>dist.i2o(tfjs_backend_square(dist.jbE(yPred,yTrue)),-1))}function meanAbsoluteError(yTrue,yPred){return(0,dist.DZQ)(()=>dist.i2o(dist.tnl(dist.jbE(yPred,yTrue)),-1))}function meanAbsolutePercentageError(yTrue,yPred){return(0,dist.DZQ)(()=>{const diff=dist.jbE(yTrue,yPred),clippedTrue=dist.zQh(dist.tnl(yTrue),epsilon(),Number.MAX_VALUE),absResult=dist.tnl(dist.y4m(diff,clippedTrue));return dist.lKK(100,dist.i2o(absResult,-1))})}function meanSquaredLogarithmicError(yTrue,yPred){return(0,dist.DZQ)(()=>{const clippedPred=dist.zQh(yPred,epsilon(),Number.MAX_VALUE),firstLog=dist.Rm2(dist.WQq(1,clippedPred)),clippedTrue=dist.zQh(yTrue,epsilon(),Number.MAX_VALUE),secondLog=dist.Rm2(dist.WQq(1,clippedTrue));return dist.i2o(tfjs_backend_square(dist.jbE(firstLog,secondLog)),-1)})}function categoricalCrossentropy(target,output,fromLogits=!1){return(0,dist.DZQ)(()=>{if(fromLogits)output=dist.Vs9(output);else{const outputSum=dist.czq(output,output.shape.length-1,!0);output=dist.y4m(output,outputSum)}return output=dist.zQh(output,epsilon(),1-epsilon()),dist.HZy(dist.czq(dist.lKK(dist.wgE(target,"float32"),dist.Rm2(output)),output.shape.length-1))})}function sparseCategoricalCrossentropy(target,output,fromLogits=!1){return(0,dist.DZQ)(()=>{const flatTarget=dist.wgE(dist.RIf(function flatten(x){const newShape=[arrayProd(x.shape)];return dist.tQQ(x,newShape)}(target)),"int32"),outputShape=(output=dist.zQh(output,epsilon(),1-epsilon())).shape;return categoricalCrossentropy(dist.tQQ(dist.Mw0(flatTarget,outputShape[outputShape.length-1]),outputShape),output,fromLogits)})}function binaryCrossentropy(yTrue,yPred){return(0,dist.DZQ)(()=>{let y;return y=dist.zQh(yPred,epsilon(),1-epsilon()),y=dist.Rm2(dist.y4m(y,dist.jbE(1,y))),dist.i2o(function sigmoidCrossEntropyWithLogits(labels,logits){if(!dist.ZSL.arraysEqual(labels.shape,logits.shape))throw new errors_ValueError(`logits and labels must have the same shape, but got shapes ${JSON.stringify(labels.shape)} and ${JSON.stringify(logits.shape)}`);return(0,dist.DZQ)(()=>{const reluLogits=dist.VVh(logits),negAbsLogits=dist.HZy(dist.tnl(logits));return dist.WQq(dist.jbE(reluLogits,dist.lKK(logits,labels)),dist.Kko(dist.oNF(negAbsLogits)))})}(yTrue,y),-1)})}function kullbackLeiblerDivergence(yTrue,yPred){return(0,dist.DZQ)(()=>{const clippedTrue=dist.zQh(yTrue,epsilon(),1),clippedPred=dist.zQh(yPred,epsilon(),1);return dist.czq(dist.lKK(yTrue,dist.Rm2(dist.y4m(clippedTrue,clippedPred))),-1)})}function cosineProximity(yTrue,yPred){return(0,dist.DZQ)(()=>{const trueNormalized=l2Normalize(yTrue,-1),predNormalized=l2Normalize(yPred,-1),trueXPred=dist.lKK(trueNormalized,predNormalized);return dist.HZy(dist.czq(trueXPred,-1))})}CallbackConstructorRegistry.constructors={};const lossesMap={meanSquaredError,meanAbsoluteError,meanAbsolutePercentageError,meanSquaredLogarithmicError,squaredHinge:function squaredHinge(yTrue,yPred){return(0,dist.DZQ)(()=>{const maxResult=dist.PhQ(0,dist.jbE(1,dist.lKK(yTrue,yPred)));return dist.i2o(tfjs_backend_square(maxResult),-1)})},hinge:function hinge(yTrue,yPred){return(0,dist.DZQ)(()=>{const maxResult=dist.PhQ(0,dist.jbE(1,dist.lKK(yTrue,yPred)));return dist.i2o(maxResult,-1)})},categoricalHinge:function categoricalHinge(yTrue,yPred){return(0,dist.DZQ)(()=>{const pos=dist.czq(dist.lKK(yTrue,yPred),-1),neg=dist.T9B(dist.lKK(dist.jbE(1,yTrue),yPred),-1);return dist.PhQ(0,dist.WQq(1,dist.jbE(neg,pos)))})},logcosh:function logcosh(yTrue,yPred){return(0,dist.DZQ)(()=>{const log2=Math.log(2),predictionDiff=dist.jbE(yPred,yTrue),logcoshResult=dist.jbE(dist.WQq(predictionDiff,dist.lw0(dist.lKK(-2,predictionDiff))),log2);return dist.i2o(logcoshResult,-1)})},categoricalCrossentropy,sparseCategoricalCrossentropy,binaryCrossentropy,kullbackLeiblerDivergence,poisson:function poisson(yTrue,yPred){return(0,dist.DZQ)(()=>{const logPred=dist.Rm2(dist.WQq(epsilon(),yPred));return dist.i2o(dist.jbE(yPred,dist.lKK(yTrue,logPred)),-1)})},cosineProximity};function get(identifierOrFn){if("string"==typeof identifierOrFn){if(identifierOrFn in lossesMap)return lossesMap[identifierOrFn];let errMsg=`Unknown loss ${identifierOrFn}`;throw identifierOrFn.toLowerCase().includes("softmaxcrossentropy")&&(errMsg=`Unknown loss ${identifierOrFn}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`),new errors_ValueError(errMsg)}return identifierOrFn}function binaryAccuracy(yTrue,yPred){return(0,dist.DZQ)(()=>{const threshold=dist.lKK(.5,dist.P61(yPred)),yPredThresholded=tfjs_backend_cast(dist.rhj(yPred,threshold),yTrue.dtype);return dist.i2o(dist.LCg(yTrue,yPredThresholded),-1)})}function categoricalAccuracy(yTrue,yPred){return(0,dist.DZQ)(()=>tfjs_backend_cast(dist.LCg(dist.FLi(yTrue,-1),dist.FLi(yPred,-1)),"float32"))}function truePositives(yTrue,yPred){return(0,dist.DZQ)(()=>dist.wgE(dist.czq(dist.n76(dist.LCg(yTrue,1),dist.LCg(yPred,1))),"float32"))}function precision(yTrue,yPred){return(0,dist.DZQ)(()=>{const tp=truePositives(yTrue,yPred),fp=function falsePositives(yTrue,yPred){return(0,dist.DZQ)(()=>dist.wgE(dist.czq(dist.n76(dist.LCg(yTrue,0),dist.LCg(yPred,1))),"float32"))}(yTrue,yPred),denominator=dist.WQq(tp,fp);return dist.wgE(dist._M9(dist.rhj(denominator,0),dist.y4m(tp,denominator),0),"float32")})}function recall(yTrue,yPred){return(0,dist.DZQ)(()=>{const tp=truePositives(yTrue,yPred),fn=function falseNegatives(yTrue,yPred){return(0,dist.DZQ)(()=>dist.wgE(dist.czq(dist.n76(dist.LCg(yTrue,1),dist.LCg(yPred,0))),"float32"))}(yTrue,yPred),denominator=dist.WQq(tp,fn);return dist.wgE(dist._M9(dist.rhj(denominator,0),dist.y4m(tp,denominator),0),"float32")})}function metrics_binaryCrossentropy(yTrue,yPred){return binaryCrossentropy(yTrue,yPred)}function sparseCategoricalAccuracy(yTrue,yPred){return yTrue.rank===yPred.rank&&(yTrue=dist.r2V(yTrue,[yTrue.rank-1])),(yPred=dist.FLi(yPred,-1)).dtype!==yTrue.dtype&&(yPred=dist.wgE(yPred,yTrue.dtype)),dist.wgE(dist.LCg(yTrue,yPred),"float32")}const metrics_categoricalCrossentropy=categoricalCrossentropy,metrics_sparseCategoricalCrossentropy=sparseCategoricalCrossentropy,metricsMap={binaryAccuracy,categoricalAccuracy,precision,categoricalCrossentropy:metrics_categoricalCrossentropy,sparseCategoricalCrossentropy:metrics_sparseCategoricalCrossentropy,mse:meanSquaredError,MSE:meanSquaredError,mae:meanAbsoluteError,MAE:meanAbsoluteError,mape:meanAbsolutePercentageError,MAPE:meanAbsolutePercentageError,cosine:cosineProximity};function metrics_get(identifier){if("string"==typeof identifier&&identifier in metricsMap)return metricsMap[identifier];if("string"!=typeof identifier&&null!=identifier)return identifier;throw new errors_ValueError(`Unknown metric ${identifier}`)}function getLossOrMetricName(fn){if(assert(null!==fn,`Unknown LossOrMetricFn ${fn}`),"string"==typeof fn)return fn;{let fnName;for(const key of Object.keys(lossesMap))if(lossesMap[key]===fn){fnName=key;break}if(void 0!==fnName)return fnName;for(const key of Object.keys(metricsMap))if(metricsMap[key]===fn){fnName=key;break}return void 0!==fnName?fnName:fn.name}}var user_defined_metadata_console=__webpack_require__("./node_modules/console-browserify/index.js");function checkUserDefinedMetadata(userDefinedMetadata,modelName,checkSize=!1){if(null==userDefinedMetadata||"object"!=typeof userDefinedMetadata||Object.getPrototypeOf(userDefinedMetadata)!==Object.prototype||!plainObjectCheck(userDefinedMetadata))throw new Error("User-defined metadata is expected to be a JSON object, but is not.");if(checkSize){const out=JSON.stringify(userDefinedMetadata);out.length>1048576&&user_defined_metadata_console.warn(`User-defined metadata of model "${modelName}" is too large in size (length=${out.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= 1048576.`)}}function plainObjectCheck(x){if(null===x)return!0;if("object"==typeof x){if(Object.getPrototypeOf(x)===Object.prototype){const keys=Object.keys(x);for(const key of keys){if("string"!=typeof key)return!1;if(!plainObjectCheck(x[key]))return!1}return!0}if(Array.isArray(x)){for(const item of x)if(!plainObjectCheck(item))return!1;return!0}return!1}{const xType=typeof x;return"string"===xType||"number"===xType||"boolean"===xType}}var layer_utils_console=__webpack_require__("./node_modules/console-browserify/index.js");function printSummary(model,lineLength,positions,printFn=layer_utils_console.log){const sequentialLike=function isModelSequentialLike(model){let sequentialLike=!0;const nodesByDepth=[],nodes=[];for(const depth in model.nodesByDepth)nodesByDepth.push(model.nodesByDepth[depth]);for(const depthNodes of nodesByDepth){if(depthNodes.length>1||1===depthNodes.length&&depthNodes[0].inboundLayers.length>1){sequentialLike=!1;break}nodes.push(...depthNodes)}if(sequentialLike)for(const layer of model.layers){let flag=!1;for(const node of layer.inboundNodes)if(-1!==nodes.indexOf(node)){if(flag){sequentialLike=!1;break}flag=!0}if(!sequentialLike)break}return sequentialLike}(model),toDisplay=["Layer (type)","Input Shape","Output shape","Param #"];let relevantNodes;if(sequentialLike?(lineLength=lineLength||90,positions=positions||[.32,.61,.89,1]):(lineLength=lineLength||115,positions=positions||[.24,.48,.7,.8,1]),positions[positions.length-1]<=1&&(positions=positions.map(p=>Math.floor(lineLength*p))),!sequentialLike){toDisplay.push("Receives inputs"),relevantNodes=[];for(const depth in model.nodesByDepth)relevantNodes.push(...model.nodesByDepth[depth])}printFn("_".repeat(lineLength)),printRow(toDisplay,positions,printFn),printFn("=".repeat(lineLength));const layers=model.layers;for(let i=0;i<layers.length;++i)sequentialLike?printLayerSummary(layers[i],positions,printFn):printLayerSummaryWithConnections(layers[i],positions,relevantNodes,printFn),printFn((i===layers.length-1?"=":"_").repeat(lineLength));model.checkTrainableWeightsConsistency();const trainableCount=function countTrainableParams(model){let trainableCount;trainableCount=null!=model.collectedTrainableWeights?countParamsInWeights(model.collectedTrainableWeights):countParamsInWeights(model.trainableWeights);return trainableCount}(model),nonTrainableCount=countParamsInWeights(model.nonTrainableWeights);printFn(`Total params: ${trainableCount+nonTrainableCount}`),printFn(`Trainable params: ${trainableCount}`),printFn(`Non-trainable params: ${nonTrainableCount}`),printFn("_".repeat(lineLength))}function printRow(fields,positions,printFn=layer_utils_console.log){let line="";for(let i=0;i<fields.length;++i)i>0&&(line=line.slice(0,line.length-1)+" "),line+=fields[i],line=line.slice(0,positions[i]),line+=" ".repeat(positions[i]-line.length);printFn(line)}function printLayerSummary(layer,positions,printFn){let outputShape,inputShape;try{inputShape=layer.inboundNodes.map(x=>JSON.stringify(x.inputShapes)).join(",")}catch(err){inputShape="multiple"}try{outputShape=JSON.stringify(layer.outputShape)}catch(err){outputShape="multiple"}printRow([`${layer.name} (${layer.getClassName()})`,inputShape,outputShape,layer.countParams().toString()],positions,printFn)}function printLayerSummaryWithConnections(layer,positions,relevantNodes,printFn){let outputShape,inputShape;try{inputShape=layer.inboundNodes.map(x=>JSON.stringify(x.inputShapes)).join(",")}catch(err){inputShape="multiple"}try{outputShape=JSON.stringify(layer.outputShape)}catch(err){outputShape="multiple"}const connections=[];for(const node of layer.inboundNodes)if(!(null!=relevantNodes&&relevantNodes.length>0&&-1===relevantNodes.indexOf(node)))for(let i=0;i<node.inboundLayers.length;++i){const inboundLayer=node.inboundLayers[i].name,inboundLayerIndex=node.nodeIndices[i],inboundTensorIndex=node.tensorIndices[i];connections.push(`${inboundLayer}[${inboundLayerIndex}][${inboundTensorIndex}]`)}const name=layer.name,className=layer.getClassName(),firstConnection=0===connections.length?"":connections[0];printRow([`${name} (${className})`,inputShape,outputShape,layer.countParams().toString(),firstConnection],positions,printFn);for(let i=1;i<connections.length;++i)printRow(["","","","",connections[i]],positions,printFn)}function isArrayItemInputOrOutputName(key,index,value){return("inboundNodes"===key||"outputLayers"===key||"inputLayers"===key)&&0===index&&"string"==typeof value}function convertPythonicToTs(pythonicConfig,key){if(null===pythonicConfig)return null;if("string"==typeof pythonicConfig)return toCamelCase(pythonicConfig);if("number"==typeof pythonicConfig||"boolean"==typeof pythonicConfig)return pythonicConfig;if(pythonicConfig instanceof Array){const tsArray=[],arrayLength=pythonicConfig.length;for(let i=0;i<arrayLength;++i){const item=pythonicConfig[i];isArrayItemInputOrOutputName(key,i,item)?tsArray.push(item):tsArray.push(convertPythonicToTs(item,key))}return tsArray}{const tsDict={};for(const pythonicKey of Object.keys(pythonicConfig)){const pythonicValue=pythonicConfig[pythonicKey];if("name"===pythonicKey&&"string"==typeof pythonicValue)tsDict[pythonicKey]=pythonicValue;else{const tsKey=toCamelCase(pythonicKey);tsDict[tsKey]=convertPythonicToTs(pythonicValue,tsKey)}}return tsDict}}function convertTsToPythonic(tsConfig,key){if(null==tsConfig)return null;if("string"==typeof tsConfig)return toSnakeCase(tsConfig);if("number"==typeof tsConfig||"boolean"==typeof tsConfig)return tsConfig;if(tsConfig instanceof Array){const pyArray=[],arrayLength=tsConfig.length;for(let i=0;i<arrayLength;++i){const item=tsConfig[i];isArrayItemInputOrOutputName(key,i,item)?pyArray.push(item):pyArray.push(convertTsToPythonic(item,key))}return pyArray}{const pyDict={};for(const tsKey of Object.keys(tsConfig)){const tsValue=tsConfig[tsKey],pyKey=toSnakeCase(tsKey);pyDict[pyKey]="name"!==tsKey&&"className"!==tsKey||"string"!=typeof tsValue?convertTsToPythonic(tsValue,tsKey):tsValue}return pyDict}}const version="4.22.0";var container_console=__webpack_require__("./node_modules/console-browserify/index.js");class Container extends Layer{constructor(args){if(super({}),this.containerNodes=new Set,this.name=args.name,null==this.name){const prefix=this.getClassName().toLowerCase();this.name=getUid(prefix)}if(this.supportsMasking=!1,this.trainable_=!0,Array.isArray(args.inputs)?this.inputs=args.inputs.slice():this.inputs=[args.inputs],Array.isArray(args.outputs)?this.outputs=args.outputs.slice():this.outputs=[args.outputs],generic_utils_unique(this.inputs).length!==this.inputs.length)throw new errors_ValueError(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map(x=>x.name)}`);generic_utils_unique(this.outputs).length!==this.outputs.length&&container_console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map(x=>x.name)}`),this.inputLayers=[],this.inputLayersNodeIndices=[],this.inputLayersTensorIndices=[],this.outputLayers=[],this.outputLayersNodeIndices=[],this.outputLayersTensorIndices=[],this.layers=[],this.internalContainerRefs=[];for(const x of this.outputs){const layer=x.sourceLayer,nodeIndex=x.nodeIndex,tensorIndex=x.tensorIndex;this.outputLayers.push(layer),this.outputLayersNodeIndices.push(nodeIndex),this.outputLayersTensorIndices.push(tensorIndex)}for(const x of this.inputs){const layer=x.sourceLayer,nodeIndex=x.nodeIndex,tensorIndex=x.tensorIndex;assert(0===nodeIndex,"input layer has >1 nodes"),assert(0===tensorIndex,"input layer has >1 tensors"),this.inputLayers.push(layer),this.inputLayersNodeIndices.push(nodeIndex),this.inputLayersTensorIndices.push(tensorIndex)}this.inputNames=[],this.outputNames=[],this.feedInputShapes=[],this.feedInputNames=[],this.feedOutputNames=[];for(let i=0;i<this.inputLayers.length;i++){const layer=this.inputLayers[i];if(!(layer instanceof InputLayer))throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${args.inputs}. Input ${i} (0-based) originates from layer type ${layer.getClassName()}.`);this.inputNames.push(layer.name),this.feedInputShapes.push(layer.batchInputShape),this.feedInputNames.push(layer.name)}for(const layer of this.outputLayers)this.outputNames.push(layer.name);this.internalInputShapes=this.inputs.map(x=>x.shape),this.internalOutputShapes=this.outputs.map(x=>x.shape);const nodesDepths={},nodeIDToNode={},layersDepths={},layerIDToLayer={},layerIndices={},nodesInDecreasingDepth=[],buildMapOfGraph=(tensor,finishedNodes,nodesInProgress,layer,nodeIndex,tensorIndex)=>{null!=layer&&null!=nodeIndex&&null!=tensorIndex||(layer=tensor.sourceLayer,nodeIndex=tensor.nodeIndex,tensorIndex=tensor.tensorIndex);const node=layer.inboundNodes[nodeIndex];if(-1!==nodesInProgress.indexOf(node))throw new RuntimeError(`The tensor ${tensor.name} at layer "${layer.name}" is part of a cycle.`);if(-1!==finishedNodes.indexOf(node))return;this.containerNodes.add(Container.nodeKey(layer,nodeIndex)),layer.id in layerIndices||(layerIndices[layer.id]=Object.keys(layerIndices).length),-1===nodesInProgress.indexOf(node)&&nodesInProgress.push(node);const numInboundLayers=node.inboundLayers.length;for(let i=0;i<numInboundLayers;i++){const x=node.inputTensors[i],layer=node.inboundLayers[i],nodeIndex=node.nodeIndices[i],tensorIndex=node.tensorIndices[i];buildMapOfGraph(x,finishedNodes,nodesInProgress,layer,nodeIndex,tensorIndex)}for(finishedNodes.push(node);nodesInProgress.indexOf(node)>=0;)nodesInProgress.splice(nodesInProgress.indexOf(node),1);nodesInDecreasingDepth.push(node)},finishedNodes=[],nodesInProgress=[];for(const x of this.outputs)buildMapOfGraph(x,finishedNodes,nodesInProgress);const reversedNodesInDecreasingDepth=nodesInDecreasingDepth.slice().reverse();for(const node of reversedNodesInDecreasingDepth){nodeIDToNode[node.id]=node,node.id in nodesDepths||(nodesDepths[node.id]=0);let depth=nodesDepths[node.id];const previousDepth=null==layersDepths[node.outboundLayer.id]?0:layersDepths[node.outboundLayer.id];depth=Math.max(depth,previousDepth),layersDepths[node.outboundLayer.id]=depth,layerIDToLayer[node.outboundLayer.id]=node.outboundLayer,nodesDepths[node.id]=depth;for(let i=0;i<node.inboundLayers.length;i++){const inboundLayer=node.inboundLayers[i],nodeIndex=node.nodeIndices[i],inboundNode=inboundLayer.inboundNodes[nodeIndex],previousDepth=null==nodesDepths[inboundNode.id]?0:nodesDepths[inboundNode.id];nodesDepths[inboundNode.id]=Math.max(depth+1,previousDepth),nodeIDToNode[inboundNode.id]=inboundNode}}const nodesByDepth={};for(const nodeID in nodesDepths){const depth=nodesDepths[nodeID];depth in nodesByDepth||(nodesByDepth[depth]=[]),nodesByDepth[depth].push(nodeIDToNode[nodeID])}const layersByDepth={};for(const layerID in layersDepths){const depth=layersDepths[layerID];depth in layersByDepth||(layersByDepth[depth]=[]),layersByDepth[depth].push(layerIDToLayer[layerID])}let depthKeys=Object.keys(layersByDepth).map(x=>parseInt(x,10)).sort(reverseNumberCompare);this.layers=[];for(const depth of depthKeys){const layersForDepth=layersByDepth[depth];layersForDepth.sort((a,b)=>{const aIndex=layerIndices[a.id],bIndex=layerIndices[b.id];return aIndex<bIndex?-1:aIndex>bIndex?1:0});for(const layer of layersForDepth)layer instanceof Container&&this.internalContainerRefs.push(layer),this.layers.push(layer)}this.layersByDepth=layersByDepth,depthKeys=Object.keys(nodesByDepth).map(x=>parseInt(x,10)).sort(reverseNumberCompare);const computableTensors=this.inputs.slice(),layersWithCompleteInput=[];for(const depth of depthKeys)for(const node of nodesByDepth[depth]){const layer=node.outboundLayer;if(null!=layer){for(const x of node.inputTensors)if(-1===computableTensors.indexOf(x))throw new RuntimeError(`Graph disconnected: cannot obtain value for tensor ${x} at layer "${layer.name}". The following previous layers were accessed without issue: ${layersWithCompleteInput}`);for(const x of node.outputTensors)computableTensors.push(x);layersWithCompleteInput.push(layer.name)}}this.nodesByDepth=nodesByDepth;const allNames=this.layers.map(x=>x.name);for(const name of allNames){const numOccurrences=allNames.filter(x=>x===name).length;if(1!==numOccurrences)throw new RuntimeError(`The name "${name}" is used ${numOccurrences} times in the model. All layer names should be unique. Layer names: `+JSON.stringify(allNames))}this.outboundNodes=[],this.inboundNodes=[],new Node({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:this.inputs.map(x=>null),outputMasks:this.outputs.map(x=>null),inputShapes:this.inputs.map(x=>x.shape),outputShapes:this.outputs.map(x=>x.shape)}),this.built=!0,this._refCount=1}assertNotDisposed(){if(0===this._refCount)throw new Error(`Container '${this.name}' is already disposed.`)}dispose(){this.assertNotDisposed();const result={refCountAfterDispose:null,numDisposedVariables:0};if(0===--this._refCount){for(const layer of this.layers)result.numDisposedVariables+=layer.dispose().numDisposedVariables;for(const container of this.internalContainerRefs)result.numDisposedVariables+=container.dispose().numDisposedVariables}return result.refCountAfterDispose=this._refCount,result}get trainable(){return this.trainable_}set trainable(trainable){this.layers.forEach(layer=>{layer._trainableWeights.forEach(w=>w.trainable=trainable)}),this.trainable_=trainable}get trainableWeights(){if(this._trainableWeights.length>0)throw new errors_ValueError("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");if(!this.trainable)return[];let weights=[];for(const layer of this.layers)weights=weights.concat(layer.trainableWeights);return weights}get nonTrainableWeights(){const weights=[];for(const layer of this.layers)weights.push(...layer.nonTrainableWeights);if(!this.trainable){const trainableWeights=[];for(const layer of this.layers)trainableWeights.push(...layer.trainableWeights);return trainableWeights.concat(weights)}return weights}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}loadWeights(weights,strict=!0){const nameToWeight={};let totalWeightsCount=0;const modelIsKerasSavedModelFormat=(weights=>{const keys=Object.keys(weights);if(0===keys.length)return!1;const key=keys[0].split("/");return!isNaN(parseInt(key[key.length-1],10))})(weights);modelIsKerasSavedModelFormat&&this.parseWeights(weights);for(const layer of this.layers)for(const[index,weight]of layer.weights.entries()){const parsedName=modelIsKerasSavedModelFormat?`${weight.name.split("/").slice(0,-1).join("/")+"/"}${index}`:weight.originalName;if(null!=nameToWeight[parsedName])throw new errors_ValueError(`Duplicate weight name: ${parsedName}`);nameToWeight[parsedName]=weight,totalWeightsCount++}const weightValueTuples=[];for(const name in weights){let validatedName=name;if(null==nameToWeight[name]){const tokens=name.split("/");validatedName=tokens.slice(0,-2).concat([tokens[tokens.length-1]]).join("/")}if(null!=nameToWeight[validatedName])weightValueTuples.push([nameToWeight[validatedName],weights[name]]);else if(strict)throw new errors_ValueError(`Provided weight data has no target variable: ${name}`);delete nameToWeight[validatedName]}if(strict){const unsetNames=[];for(const name in nameToWeight)unsetNames.push(name);if(unsetNames.length>0)throw new errors_ValueError(`${unsetNames.length} of ${totalWeightsCount} weights are not set: ${unsetNames}`)}batchSetValue(weightValueTuples)}parseWeights(weights){for(const key in Object.keys(weights)){const listParts=key.split("/"),list=["vars","layer_checkpoint_dependencies"],newKey=listParts.map(str=>str.startsWith("_")?str.slice(1):str).filter(str=>!list.includes(str)).join("/");newKey!==key&&(weights[newKey]=weights[key],delete weights[key])}}updatedConfig(){const theConfig=this.getConfig(),modelConfig={};return modelConfig.className=this.getClassName(),modelConfig.config=theConfig,modelConfig.kerasVersion=`tfjs-layers ${version}`,modelConfig.backend="TensorFlow.js",modelConfig}toJSON(unused,returnString=!0){const modelConfig=convertTsToPythonic(this.updatedConfig());return returnString?JSON.stringify(modelConfig):modelConfig}call(inputs,kwargs){return(0,dist.DZQ)(()=>{inputs=toList(inputs);const feedDict=new FeedDict;for(let i=0;i<this.inputs.length;++i)feedDict.add(this.inputs[i],inputs[i]);return execute(this.outputs,feedDict,kwargs)})}computeMask(inputs,mask){return(0,dist.DZQ)(()=>{let masks;return inputs=toList(inputs),masks=null==mask?pyListRepeat(null,inputs.length):toList(mask),this.runInternalGraph(inputs,masks)[1]})}computeOutputShape(inputShape){const inputShapes=normalizeShapeList(inputShape);if(inputShapes.length!==this.inputLayers.length)throw new errors_ValueError(`Invalid inputShape argument ${inputShape}: model has ${this.inputLayers.length} tensor inputs.`);const layersToOutputShapes={};for(let i=0;i<inputShapes.length;i++){const layer=this.inputLayers[i],inputShape=inputShapes[i];layersToOutputShapes[layer.name+"_0_0"]=inputShape}const depthKeys=Object.keys(this.nodesByDepth).map(x=>parseInt(x,10)).sort(reverseNumberCompare);if(depthKeys.length>1)for(const depth of depthKeys){const nodes=this.nodesByDepth[depth];for(const node of nodes){const layer=node.outboundLayer;if(-1!==this.inputLayers.map(x=>x.id).indexOf(layer.id))continue;const inputShapes=[];for(let j=0;j<node.inboundLayers.length;j++){const inboundLayer=node.inboundLayers[j],nodeIndex=node.nodeIndices[j],tensorIndex=node.tensorIndices[j],inputShape=layersToOutputShapes[`${inboundLayer.name}_${nodeIndex}_${tensorIndex}`];inputShapes.push(inputShape)}const outputShapes=normalizeShapeList(layer.computeOutputShape(singletonOrArray(inputShapes))),nodeIndex=layer.inboundNodes.indexOf(node);for(let j=0;j<outputShapes.length;j++){layersToOutputShapes[`${layer.name}_${nodeIndex}_${j}`]=outputShapes[j]}}}const outputShapes=[],outputShapeKeys=[];for(let i=0;i<this.outputLayers.length;i++){const layer=this.outputLayers[i],nodeIndex=this.outputLayersNodeIndices[i],tensorIndex=this.outputLayersTensorIndices[i],shapeKey=`${layer.name}_${nodeIndex}_${tensorIndex}`;outputShapeKeys.push(shapeKey)}for(let i=0;i<outputShapeKeys.length;i++){const key=outputShapeKeys[i];assert(key in layersToOutputShapes),outputShapes.push(layersToOutputShapes[key])}return singletonOrArray(outputShapes)}runInternalGraph(inputs,masks){null==masks&&(masks=pyListRepeat(null,inputs.length));const tensorMap={};for(let i=0;i<this.inputs.length;++i){const x=this.inputs[i],y=inputs[i],mask=masks[i];tensorMap[x.id]=[y,mask]}const depthKeys=Object.keys(this.nodesByDepth).map(x=>parseInt(x,10)).sort(reverseNumberCompare);for(const depth of depthKeys){const nodes=this.nodesByDepth[depth];for(const node of nodes){const layer=node.outboundLayer,referenceInputTensors=node.inputTensors,referenceOutputTensors=node.outputTensors,computedData=new Array;for(const x of referenceInputTensors)x.id in tensorMap&&computedData.push(tensorMap[x.id]);if(computedData.length===referenceInputTensors.length){let computedTensors,computedMasks,outputTensors,outputMasks,kwargs={};if(null!=node.callArgs&&(kwargs=node.callArgs),1===computedData.length){const[computedTensor,computedMask]=computedData[0];null==kwargs.mask&&(kwargs.mask=computedMask),outputTensors=toList(layer.call(computedTensor,kwargs)),outputMasks=toList(layer.computeMask(computedTensor,computedMask)),computedTensors=[computedTensor],computedMasks=[computedMask]}else computedTensors=computedData.map(x=>x[0]),computedMasks=computedData.map(x=>x[1]),null==kwargs.mask&&(kwargs.mask=computedMasks),outputTensors=toList(layer.call(computedTensors,kwargs)),outputMasks=toList(layer.computeMask(computedTensors,computedMasks));if(layer.activityRegularizer)throw new errors_NotImplementedError("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");for(let i=0;i<referenceOutputTensors.length;++i){const x=referenceOutputTensors[i],y=outputTensors[i],mask=outputMasks[i];tensorMap[x.id]=[y,mask]}}}}const outputTensors=[],outputMasks=[],outputShapes=[];for(const x of this.outputs){assert(x.id in tensorMap,`Could not compute output ${x.name} : ${x.id}`);const[tensor,mask]=tensorMap[x.id];outputShapes.push(tensor.shape),outputTensors.push(tensor),outputMasks.push(mask)}return[outputTensors,outputMasks,outputShapes]}buildNodeConversionMap(layers){const nodeConversionMap={};let keptNodes;for(const layer of this.layers){keptNodes=layer instanceof Container?1:0;for(let originalNodeIndex=0;originalNodeIndex<layer.inboundNodes.length;originalNodeIndex++){const nodeKey=Container.nodeKey(layer,originalNodeIndex);this.containerNodes.has(nodeKey)&&(nodeConversionMap[nodeKey]=keptNodes,keptNodes+=1)}}return nodeConversionMap}getLayer(nameOrIndex,index){if(null!=index)return this.findLayer(index);if(null==nameOrIndex)throw new errors_ValueError("Provide either a layer name or layer index");if("number"==typeof nameOrIndex)return this.findLayer(nameOrIndex);for(const layer of this.layers)if(layer.name===nameOrIndex)return layer;throw new errors_ValueError(`No such layer: ${nameOrIndex}`)}findLayer(index){if(this.layers.length<=index)throw new errors_ValueError(`Was asked to retrieve layer at index ${index}, but model only has ${this.layers.length} layer(s).`);return this.layers[index]}calculateLosses(){return(0,dist.DZQ)(()=>{const losses=[];for(const layer of this.layers)for(let nodeIndex=0;nodeIndex<layer.inboundNodes.length;++nodeIndex){const nodeKey=Container.nodeKey(layer,nodeIndex);this.containerNodes.has(nodeKey)&&losses.push(...layer.calculateLosses())}return losses})}getConfig(){const config={name:this.name},nodeConversionMap=this.buildNodeConversionMap(this.layers),layerConfigs=[];for(const layer of this.layers){const layerClassName=layer.getClassName(),layerConfig=layer.getConfig(),filteredInboundNodes=[];for(let originalNodeIndex=0;originalNodeIndex<layer.inboundNodes.length;originalNodeIndex++){const node=layer.inboundNodes[originalNodeIndex],nodeKey=Container.nodeKey(layer,originalNodeIndex);let kwargs={};if(this.containerNodes.has(nodeKey)){if(node.callArgs)try{JSON.stringify(node.callArgs),kwargs=node.callArgs}catch(err){container_console.warn(`Layer ${layer.name} was passed non-serializable keyword arguments: ${node.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`),kwargs={}}if(node.inboundLayers.length>0){const nodeData=[];for(let i=0;i<node.inboundLayers.length;i++){const inboundLayer=node.inboundLayers[i],nodeIndex=node.nodeIndices[i],tensorIndex=node.tensorIndices[i];let newNodeIndex=nodeConversionMap[Container.nodeKey(inboundLayer,nodeIndex)];null==newNodeIndex&&(newNodeIndex=0),nodeData.push([inboundLayer.name,newNodeIndex,tensorIndex,kwargs])}filteredInboundNodes.push(nodeData)}}}const dict={};dict.name=layer.name,dict.className=layerClassName,dict.config=layerConfig,dict.inboundNodes=filteredInboundNodes,layerConfigs.push(dict)}config.layers=layerConfigs;const modelInputs=[];for(let i=0;i<this.inputLayers.length;i++){const layer=this.inputLayers[i],nodeIndex=this.inputLayersNodeIndices[i],nodeKey=Container.nodeKey(layer,nodeIndex);if(!this.containerNodes.has(nodeKey))continue;let newNodeIndex=nodeConversionMap[nodeKey];null==newNodeIndex&&(newNodeIndex=0);const tensorIndex=this.inputLayersTensorIndices[i];modelInputs.push([layer.name,newNodeIndex,tensorIndex])}config.inputLayers=modelInputs;const modelOutputs=[];for(let i=0;i<this.outputLayers.length;i++){const layer=this.outputLayers[i],nodeIndex=this.outputLayersNodeIndices[i],nodeKey=Container.nodeKey(layer,nodeIndex);if(!this.containerNodes.has(nodeKey))continue;let newNodeIndex=nodeConversionMap[nodeKey];null==newNodeIndex&&(newNodeIndex=0);const tensorIndex=this.outputLayersTensorIndices[i];modelOutputs.push([layer.name,newNodeIndex,tensorIndex])}return config.outputLayers=modelOutputs,config}static fromConfig(cls,config,customObjects={},fastWeightInit=!1){const createdLayers={},unprocessedNodes={};function addUnprocessedNode(layer,nodeData){layer.name in unprocessedNodes?unprocessedNodes[layer.name].push(nodeData):unprocessedNodes[layer.name]=[nodeData]}function processNode(layer,nodeData){const inputTensors=[];let kwargs;for(const inputData of nodeData){const inboundLayerName=inputData[0],inboundNodeIndex=inputData[1],inboundTensorIndex=inputData[2];if(kwargs=null==inputData[3]?{}:inputData[3],!(inboundLayerName in createdLayers))return void addUnprocessedNode(layer,nodeData);const inboundLayer=createdLayers[inboundLayerName];if(inboundLayer.inboundNodes.length<=inboundNodeIndex)return void addUnprocessedNode(layer,nodeData);const inboundNode=inboundLayer.inboundNodes[inboundNodeIndex];inputTensors.push(inboundNode.outputTensors[inboundTensorIndex])}inputTensors.length>0&&layer.apply(singletonOrArray(inputTensors),kwargs)}function processLayer(layerData){const layerName=layerData.name,layer=deserialize(layerData,null!=config.customObjects?config.customObjects:{});layer.setFastWeightInitDuringBuild(fastWeightInit),createdLayers[layerName]=layer;layerData.inboundNodes.forEach(nodeData=>{if(!(nodeData instanceof Array))throw new errors_ValueError(`Corrupted configuration, expected array for nodeData: ${nodeData}`);addUnprocessedNode(layer,nodeData)})}const name=config.name,layersFromConfig=config.layers;for(const layerData of layersFromConfig)processLayer(layerData);for(;!isObjectEmpty(unprocessedNodes);)for(const layerData of layersFromConfig){const layer=createdLayers[layerData.name];if(layer.name in unprocessedNodes){const currentUnprocessedNodesForLayer=unprocessedNodes[layer.name];delete unprocessedNodes[layer.name];for(const nodeData of currentUnprocessedNodesForLayer)processNode(layer,nodeData)}}const inputTensors=[],outputTensors=[],inputLayersFromConfig=config.inputLayers;for(const layerData of inputLayersFromConfig){const layerName=layerData[0],nodeIndex=layerData[1],tensorIndex=layerData[2];assert(layerName in createdLayers);const layerOutputTensors=createdLayers[layerName].inboundNodes[nodeIndex].outputTensors;inputTensors.push(layerOutputTensors[tensorIndex])}const outputLayersFromConfig=config.outputLayers;for(const layerData of outputLayersFromConfig){const layerName=layerData[0],nodeIndex=layerData[1],tensorIndex=layerData[2];assert(layerName in createdLayers);const layerOutputTensors=createdLayers[layerName].inboundNodes[nodeIndex].outputTensors;outputTensors.push(layerOutputTensors[tensorIndex])}return new cls({inputs:inputTensors,outputs:outputTensors,name})}get stateful(){if(this._stateful)throw new errors_ValueError("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");for(const layer of this.layers)if(layer.stateful)return!0;return!1}resetStates(){(0,dist.DZQ)(()=>{this.layers.forEach(layer=>{layer.stateful&&layer.resetStates()})})}}function standardizeSampleOrClassWeights(xWeight,outputNames,weightType){const numOutputs=outputNames.length;if(null==xWeight||Array.isArray(xWeight)&&0===xWeight.length)return outputNames.map(name=>null);if(1===numOutputs)return Array.isArray(xWeight)&&1===xWeight.length?xWeight:"object"==typeof xWeight&&outputNames[0]in xWeight?[xWeight[outputNames[0]]]:[xWeight];if(Array.isArray(xWeight)){if(xWeight.length!==numOutputs)throw new Error(`Provided ${weightType} is an array of ${xWeight.length} element(s), but the model has ${numOutputs} outputs. Make sure a set of weights is provided for each model output.`);return xWeight}if("object"==typeof xWeight&&Object.keys(xWeight).length>0&&"object"==typeof xWeight[Object.keys(xWeight)[0]]){const output=[];return outputNames.forEach(outputName=>{outputName in xWeight?output.push(xWeight[outputName]):output.push(null)}),output}throw new Error(`The model has multiple (${numOutputs}) outputs, so ${weightType} must be either an array with ${numOutputs} elements or an object with ${outputNames} keys. Provided ${weightType} not understood: ${JSON.stringify(xWeight)}`)}function standardizeClassWeights(classWeight,outputNames){return standardizeSampleOrClassWeights(classWeight,outputNames,"classWeight")}async function standardizeWeights(y,sampleWeight,classWeight,sampleWeightMode){if(null!=sampleWeight||null!=sampleWeightMode)throw new Error("Support sampleWeight is not implemented yet");if(null!=classWeight){const yClasses=(0,dist.DZQ)(()=>{if(1===y.shape.length)return(0,dist.o8B)(y);if(2===y.shape.length){if(y.shape[1]>1){const axis=1;return(0,dist.FLi)(y,axis)}if(1===y.shape[1])return(0,dist.tQQ)(y,[y.shape[0]]);throw new Error(`Encountered unexpected last-dimension size (${y.shape[1]}) during handling of class weights. The size is expected to be >= 1.`)}throw new Error(`Unexpected rank of target (y) tensor (${y.rank}) during handling of class weights. The rank is expected to be 1 or 2.`)}),yClassIndices=Array.from(await yClasses.data());(0,dist.ASo)(yClasses);const classSampleWeight=[];return yClassIndices.forEach(classIndex=>{if(null==classWeight[classIndex])throw new Error(`classWeight must contain all classes in the training data. The class ${classIndex} exists in the data but not in classWeight`);classSampleWeight.push(classWeight[classIndex])}),(0,dist.tGX)(classSampleWeight,"float32")}return null}function computeWeightedLoss(losses,sampleWeights){return(0,dist.lKK)(losses,sampleWeights)}var training_dataset_console=__webpack_require__("./node_modules/console-browserify/index.js");function standardizeDataIteratorOutput(model,iteratorOut){let xs,ys;const iteratorOutObj=iteratorOut;xs=iteratorOutObj.xs,ys=iteratorOutObj.ys,dist.ZSL.assert(null!=xs&&null!=ys,()=>`A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${iteratorOut}`);const flattenedXs=flattenTensorOrArrayOrMap("input",model.inputNames,xs),flattenedYs=flattenTensorOrArrayOrMap("output",model.outputNames,ys),batchSize=flattenedXs[0].shape[0];dist.ZSL.assert(flattenedXs.length===model.inputs.length,()=>`LayersModel has ${model.inputs.length} inputs, but the dataset provides ${flattenedXs.length} inputs.  (Expected input keys: ${JSON.stringify(model.inputNames)})`),dist.ZSL.assert(flattenedYs.length===model.outputs.length,()=>`LayersModel has ${model.outputs.length} outputs, but the dataset provides ${flattenedYs.length} outputs.  (Expected output keys: ${JSON.stringify(model.outputNames)})`);for(let xIndex=0;xIndex<flattenedXs.length;xIndex++)dist.ZSL.assert(flattenedXs[xIndex].shape[0]===batchSize,()=>`Batch size mismatch: input ${model.inputNames[xIndex]} has ${flattenedXs[xIndex].shape[0]}; expected  ${batchSize} based on input ${model.inputNames[0]}.`);for(let yIndex=0;yIndex<flattenedYs.length;yIndex++)dist.ZSL.assert(flattenedYs[yIndex].shape[0]===batchSize,()=>`Batch size mismatch: output ${model.outputNames[yIndex]} has ${flattenedYs[yIndex].shape[0]}; expected  ${batchSize} based on input ${model.inputNames[0]}.`);return{xs:flattenedXs,ys:flattenedYs}}function flattenTensorOrArrayOrMap(inputOrOutput,names,values){if(values instanceof dist.qYS)return[values];if(Array.isArray(values))return dist.ZSL.assert(values.length===names.length,()=>`Received an array of ${values.length} Tensors, but expected ${names.length} to match the ${inputOrOutput} keys ${names}.`),values;{const result=[];for(const name of names){if(null==values[name])throw new errors_ValueError(`The feature data generated by the dataset lacks the required ${inputOrOutput} key '${name}'.`);result.push(values[name])}return result}}async function fitDataset(model,dataset,args){const hasBatchesPerEpoch=null!=args.batchesPerEpoch;if(dist.ZSL.assert(null!=model.optimizer,()=>"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig)."),dist.ZSL.assert(null!=args,()=>"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call."),dist.ZSL.assert(null!=args.epochs&&args.epochs>0&&Number.isInteger(args.epochs),()=>`For fitDataset(), config.epochs is expected to be a positive integer, but got ${args.epochs}`),dist.ZSL.assert(!hasBatchesPerEpoch||args.batchesPerEpoch>0&&Number.isInteger(args.batchesPerEpoch),()=>`For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${args.batchesPerEpoch}`),dist.ZSL.assert(null==args.validationSplit,()=>"`validationSplit` is not supported by `fitDataset()`. Use validationData instead."),model.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");model.isTraining=!0;try{const doValidation=null!=args.validationData;let valXs,valYs;if(doValidation)if(isDatasetObject(args.validationData))dist.ZSL.assert(null==args.validationBatches||args.validationBatches>0&&Number.isInteger(args.validationBatches),()=>`For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${args.validationBatches}`);else{const validationData=function standardizeTensorValidationData(data){if(3===data.length)throw new errors_NotImplementedError("Validation with sample weights is not implemented yet.");return{xs:data[0],ys:data[1]}}(args.validationData);valXs=validationData.xs,valYs=validationData.ys}const trainFunction=model.makeTrainFunction(),outLabels=model.getDedupedMetricsNames();let callbackMetrics;callbackMetrics=doValidation?outLabels.slice().concat(outLabels.map(n=>"val_"+n)):outLabels.slice();const callbacks=standardizeCallbacks(args.callbacks,args.yieldEvery),verbose=null==args.verbose?1:args.verbose,{callbackList,history}=configureCallbacks(callbacks,verbose,args.epochs,null,null,function getStepsPerEpoch(dataset,args){let stepsPerEpoch=null;null!=args.batchesPerEpoch?stepsPerEpoch=args.batchesPerEpoch:Number.isFinite(dataset.size)&&(stepsPerEpoch=dataset.size);return stepsPerEpoch}(dataset,args),null,doValidation,callbackMetrics);callbackList.setModel(model),model.history=history,await callbackList.onTrainBegin(),model.stopTraining_=!1;let epoch=null==args.initialEpoch?0:args.initialEpoch,dataIterator=await dataset.iterator();for(;epoch<args.epochs;){const epochLogs={};await callbackList.onEpochBegin(epoch);let stepsDone=0,batchIndex=0;for(hasBatchesPerEpoch||(dataIterator=await dataset.iterator());!hasBatchesPerEpoch||stepsDone<args.batchesPerEpoch;){const iteratorOut=await dataIterator.next();if(hasBatchesPerEpoch&&iteratorOut.done){training_dataset_console.warn(`You provided \`batchesPerEpoch\` as ${args.batchesPerEpoch}, but your dataset iterator ran out of data after ${stepsDone} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, `+args.batchesPerEpoch*args.epochs+" batches). You may need to use the repeat() function when building your dataset.");break}if(null!=iteratorOut.value){const{xs,ys}=standardizeDataIteratorOutput(model,iteratorOut.value),batchLogs={};batchLogs.batch=batchIndex,batchLogs.size=xs[0].shape[0],await callbackList.onBatchBegin(batchIndex,batchLogs);const sampleWeights=[];if(null!=args.classWeight){const standardClassWeights=standardizeClassWeights(args.classWeight,model.outputNames);for(let i=0;i<standardClassWeights.length;++i)sampleWeights.push(await standardizeWeights(ys[i],null,standardClassWeights[i]))}const ins=xs.concat(ys).concat(sampleWeights),outs=trainFunction(ins);dist.ASo(ins);for(let i=0;i<outLabels.length;++i){const label=outLabels[i],out=outs[i];batchLogs[label]=out,dist.aCs(out)}await callbackList.onBatchEnd(batchIndex,batchLogs),disposeTensorsInLogs(batchLogs),batchIndex++,stepsDone++}if(hasBatchesPerEpoch?stepsDone>=args.batchesPerEpoch:iteratorOut.done){if(doValidation){let valOuts;valOuts=isDatasetObject(args.validationData)?toList(await model.evaluateDataset(args.validationData,{batches:args.validationBatches})):toList(model.evaluate(valXs,valYs,{batchSize:null==args.validationBatchSize?32:args.validationBatchSize,verbose:0}));for(let i=0;i<model.metricsNames.length;++i)epochLogs[`val_${model.metricsNames[i]}`]=valOuts[i]}break}if(model.stopTraining_)break}if(await callbackList.onEpochEnd(epoch,epochLogs),epoch++,model.stopTraining_)break}return await callbackList.onTrainEnd(),await model.history.syncData(),model.history}finally{model.isTraining=!1}}function isDatasetObject(dataset){return"function"==typeof dataset.iterator}function checkBatchSize(batchSize){dist.ZSL.assert(batchSize>0&&Number.isInteger(batchSize),()=>`batchSize is required to be a positive integer, but got ${batchSize}`)}function sliceArrays(arrays,start,stop){return null==arrays?[null]:Array.isArray(arrays)?arrays.map(array=>sliceAlongFirstAxis(array,start,stop-start)):sliceAlongFirstAxis(arrays,start,stop-start)}function sliceArraysByIndices(arrays,indices){return dist.DZQ(()=>null==arrays?null:Array.isArray(arrays)?arrays.map(array=>sliceArraysByIndices(array,indices)):tfjs_backend_gather(arrays,"int32"===indices.dtype?indices:dist.wgE(indices,"int32")))}function makeBatches(size,batchSize){const output=[];let batchStart=0,batchEnd=null;for(;batchStart<size;)batchEnd=batchStart+batchSize,batchEnd>=size&&(batchEnd=size),output.push([batchStart,batchEnd]),batchStart=batchEnd;return output}function ensureTensorsRank2OrHigher(tensors){const outs=[];tensors instanceof dist.qYS&&(tensors=[tensors]);for(let i=0;i<tensors.length;++i){const tensor=tensors[i];if(1===tensor.rank)outs.push(expandDims(tensor,1));else{if(0===tensor.rank)throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");outs.push(tensor)}}return outs}function disposeNewTensors(tensors,refTensors){if(null==tensors)return;const oldTensorIds=[];if(refTensors instanceof dist.qYS)oldTensorIds.push(refTensors.id);else if(Array.isArray(refTensors))refTensors.forEach(t=>oldTensorIds.push(t.id));else if(null!=refTensors)for(const name in refTensors){const oldTensor=refTensors[name];oldTensorIds.push(oldTensor.id)}const tensorsToDispose=[];if(tensors instanceof dist.qYS)-1===oldTensorIds.indexOf(tensors.id)&&tensorsToDispose.push(tensors);else if(Array.isArray(tensors))tensors.forEach(t=>{-1===oldTensorIds.indexOf(t.id)&&tensorsToDispose.push(t)});else if(null!=tensors)for(const name in tensors){const tensor=tensors[name];-1===oldTensorIds.indexOf(tensor.id)&&tensorsToDispose.push(tensor)}tensorsToDispose.forEach(t=>{t.isDisposed||t.dispose()})}var training_console=__webpack_require__("./node_modules/console-browserify/index.js");function isDataArray(x){return Array.isArray(x)}function isDataDict(x){return!function isDataTensor(x){return x instanceof dist.qYS}(x)&&!isDataArray(x)}function standardizeInputData(data,names,shapes,checkBatchAxis=!0,exceptionPrefix=""){if(null==names||0===names.length){if(null!=data){let gotUnexpectedData=!1;if(isDataArray(data)&&data.length>0)gotUnexpectedData=!0;else if(isDataDict(data)){for(const key in data)if(data.hasOwnProperty(key)){gotUnexpectedData=!0;break}}else gotUnexpectedData=!0;if(gotUnexpectedData)throw new errors_ValueError(`Error when checking model ${exceptionPrefix} expected no data, but got ${data}`)}return[]}if(null==data)return names.map(name=>null);let arrays;if(isDataDict(data)){arrays=[];for(const name of names){if(null==data[name])throw new errors_ValueError(`No data provided for "${name}". Need data for each key in: ${names}`);arrays.push(data[name])}}else if(isDataArray(data)){if(data.length!==names.length)throw new errors_ValueError(`Error when checking model ${exceptionPrefix}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${names.length} Tensor(s), but instead got the following list of Tensor(s): ${data}`);arrays=data}else{if(names.length>1)throw new errors_ValueError(`The model ${exceptionPrefix} expects ${names.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${data.shape}`);arrays=[data]}if(arrays=ensureTensorsRank2OrHigher(arrays),null!=shapes)for(let i=0;i<names.length;++i){if(null==shapes[i])continue;const array=arrays[i];if(array.shape.length!==shapes[i].length)throw new errors_ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} to have ${shapes[i].length} dimension(s). but got array with shape ${array.shape}`);for(let j=0;j<shapes[i].length;++j){if(0===j&&!checkBatchAxis)continue;const dim=array.shape[j],refDim=shapes[i][j];if(null!=refDim&&refDim>=0&&dim!==refDim)throw new errors_ValueError(`${exceptionPrefix} expected a batch of elements where each example has shape [${shapes[i].slice(1,shapes[i].length)}] (i.e.,tensor shape [*,${shapes[i].slice(1,shapes[i].length)}]) but the ${exceptionPrefix} received an input with ${array.shape[0]} examples, each with shape [${array.shape.slice(1,array.shape.length)}] (tensor shape [${array.shape}])`)}}return arrays}function checkInputData(data,names,shapes,checkBatchAxis=!0,exceptionPrefix=""){let arrays;if(Array.isArray(data)){if(data.length!==names.length)throw new errors_ValueError(`Error when checking model ${exceptionPrefix}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${names.length} Tensor(s), but instead got ${data.length} Tensors(s).`);arrays=data}else{if(names.length>1)throw new errors_ValueError(`The model expects ${names.length} ${exceptionPrefix} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(data.shape)}.`);arrays=[data]}if(null!=shapes)for(let i=0;i<names.length;++i){if(null==shapes[i])continue;const array=arrays[i];if(array.shape.length!==shapes[i].length)throw new errors_ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} to have ${shapes[i].length} dimension(s), but got array with shape ${JSON.stringify(array.shape)}`);for(let j=0;j<shapes[i].length;++j){if(0===j&&!checkBatchAxis)continue;const dim=array.shape[j],refDim=shapes[i][j];if(null!=refDim&&refDim!==dim)throw new errors_ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} to have shape ${JSON.stringify(shapes[i])} but got array with shape ${JSON.stringify(array.shape)}.`)}}}class LayersModel extends Container{constructor(args){super(args),this.isTraining=!1}summary(lineLength,positions,printFn=training_console.log){if(!this.built)throw new errors_ValueError("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");printSummary(this,lineLength,positions,printFn)}compile(args){if(null==args.loss&&(args.loss=[]),this.loss=args.loss,"string"==typeof args.optimizer)this.optimizer_=function getOptimizer(identifier){const optimizerMap={Adagrad:()=>dist.BaG.adagrad(.01),Adadelta:()=>dist.BaG.adadelta(1,.95,epsilon()),Adam:()=>dist.BaG.adam(.001,.9,.999,epsilon()),Adamax:()=>dist.BaG.adamax(.002,.9,.999,epsilon(),0),RMSProp:()=>dist.BaG.rmsprop(.001,.9,0,epsilon()),SGD:()=>dist.BaG.sgd(.01)};if(optimizerMap.adagrad=optimizerMap.Adagrad,optimizerMap.adadelta=optimizerMap.Adadelta,optimizerMap.adam=optimizerMap.Adam,optimizerMap.adamax=optimizerMap.Adamax,optimizerMap.rmsprop=optimizerMap.RMSProp,optimizerMap.sgd=optimizerMap.SGD,identifier in optimizerMap)return optimizerMap[identifier]();throw new errors_ValueError(`Unknown Optimizer ${identifier}`)}(args.optimizer),this.isOptimizerOwned=!0;else{if(!(args.optimizer instanceof dist.ELo))throw new errors_ValueError("User-defined optimizer must be an instance of tf.Optimizer.");this.optimizer_=args.optimizer,this.isOptimizerOwned=!1}let lossFunctions=[];if(Array.isArray(args.loss)||"string"==typeof args.loss||"function"==typeof args.loss)if(Array.isArray(args.loss)){if(args.loss.length!==this.outputs.length)throw new errors_ValueError(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${args.loss}.`);const theLosses=args.loss;lossFunctions=theLosses.map(l=>get(l))}else{const lossFunction=get(args.loss);this.outputs.forEach(_=>{lossFunctions.push(lossFunction)})}else{args.loss=args.loss;for(const name in args.loss)if(-1===this.outputNames.indexOf(name))throw new errors_ValueError(`Unknown entry in loss dictionary: "${name}". Only expected the following keys: ${this.outputNames}`);for(const name of this.outputNames)null==args.loss[name]&&training_console.warn(`Output "${name}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${name} during training`),lossFunctions.push(get(args.loss[name]))}this.lossFunctions=lossFunctions,this.feedOutputNames=[],this.feedOutputShapes=[],this.feedLossFns=[];for(let i=0;i<this.outputs.length;++i){const shape=this.internalOutputShapes[i],name=this.outputNames[i];this.feedOutputNames.push(name),this.feedOutputShapes.push(shape),this.feedLossFns.push(this.lossFunctions[i])}const skipTargetIndices=[];this.metrics=args.metrics,this.metricsNames=["loss"],this.metricsTensors=[],nameScope("loss",()=>{for(let i=0;i<this.outputs.length;++i){if(-1!==skipTargetIndices.indexOf(i))continue;const weightedLoss=this.lossFunctions[i];this.outputs.length>1&&(this.metricsTensors.push([weightedLoss,i]),this.metricsNames.push(this.outputNames[i]+"_loss"))}});const nestedMetrics=function collectMetrics(metrics,outputNames){if(null==metrics||Array.isArray(metrics)&&0===metrics.length)return outputNames.map(name=>[]);let wrappedMetrics;if("string"==typeof metrics||"function"==typeof metrics)wrappedMetrics=[metrics];else{if(!Array.isArray(metrics)&&"object"!=typeof metrics)throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${metrics}`);wrappedMetrics=metrics}if(Array.isArray(wrappedMetrics))return outputNames.map(name=>wrappedMetrics);{const nestedMetrics=[];for(const name of outputNames){let outputMetrics=wrappedMetrics.hasOwnProperty(name)?wrappedMetrics[name]:[];Array.isArray(outputMetrics)||(outputMetrics=[outputMetrics]),nestedMetrics.push(outputMetrics)}return nestedMetrics}}(args.metrics,this.outputNames),appendMetric=(outputIndex,metricName,metricTensor)=>{this.outputNames.length>1&&(metricName=this.outputNames[outputIndex]+"_"+metricName),this.metricsNames.push(metricName),this.metricsTensors.push([metricTensor,outputIndex])};nameScope("metric",()=>{for(let i=0;i<this.outputs.length;++i){if(-1!==skipTargetIndices.indexOf(i))continue;(metrics=>{let metricName,accFn,weightedMetricFn;for(const metric of metrics){if("string"==typeof metric&&-1!==["accuracy","acc","crossentropy","ce"].indexOf(metric)){const outputShape=this.internalOutputShapes[i];let suffix;1===outputShape[outputShape.length-1]||this.lossFunctions[i]===binaryCrossentropy?-1!==["accuracy","acc"].indexOf(metric)?accFn=binaryAccuracy:-1!==["crossentropy","ce"].indexOf(metric)&&(accFn=metrics_binaryCrossentropy):this.lossFunctions[i]===sparseCategoricalCrossentropy?-1!==["accuracy","acc"].indexOf(metric)?accFn=sparseCategoricalAccuracy:-1!==["crossentropy","ce"].indexOf(metric)&&(accFn=metrics_sparseCategoricalCrossentropy):-1!==["accuracy","acc"].indexOf(metric)?accFn=categoricalAccuracy:-1!==["crossentropy","ce"].indexOf(metric)&&(accFn=metrics_categoricalCrossentropy),-1!==["accuracy","acc"].indexOf(metric)?suffix="acc":-1!==["crossentropy","ce"].indexOf(metric)&&(suffix="ce"),weightedMetricFn=accFn,metricName=""+suffix}else{const metricFn=metrics_get(metric);weightedMetricFn=metricFn,metricName=""+getLossOrMetricName(metric)}let metricResult;nameScope(metricName,()=>{metricResult=weightedMetricFn}),appendMetric(i,metricName,metricResult)}})(nestedMetrics[i])}}),this.collectedTrainableWeights=this.trainableWeights}checkTrainableWeightsConsistency(){null!=this.collectedTrainableWeights&&this.trainableWeights.length!==this.collectedTrainableWeights.length&&training_console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?")}evaluate(x,y,args={}){const batchSize=null==args.batchSize?32:args.batchSize;checkBatchSize(batchSize);const standardizedOuts=this.standardizeUserDataXY(x,y,!0,batchSize);try{const ins=standardizedOuts[0].concat(standardizedOuts[1]);this.makeTestFunction();const f=this.testFunction;return singletonOrArray(this.testLoop(f,ins,batchSize,args.verbose,args.steps))}finally{disposeNewTensors(standardizedOuts[0],x),disposeNewTensors(standardizedOuts[1],y)}}async evaluateDataset(dataset,args){return this.makeTestFunction(),async function evaluateDataset(model,dataset,args){const hasBatches=null!=(args=args||{}).batches,f=model.testFunction;let outs=[];if(args.verbose>0)throw new errors_NotImplementedError("Verbose mode is not implemented yet.");dist.ZSL.assert(!hasBatches||args.batches>0&&Number.isInteger(args.batches),()=>`Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(args.batches)}`);const dataIterator=function isLazyIteratorObject(iterator){return"function"==typeof iterator.next}(dataset)?dataset:await dataset.iterator();let numExamples=0,batch=0;for(;!hasBatches||batch<args.batches;){const iteratorOut=await dataIterator.next();if(outs=dist.DZQ(()=>{if(iteratorOut.value){const{xs,ys}=standardizeDataIteratorOutput(model,iteratorOut.value),xsAndYs=xs.concat(ys),batchOuts=dist.DZQ(()=>f(xsAndYs));if(dist.ASo(xsAndYs),0===batch)for(let i=0;i<batchOuts.length;++i)outs.push((0,dist.d_2)(0));const batchSize=xsAndYs[0].shape[0];for(let i=0;i<batchOuts.length;++i){const batchOut=batchOuts[i],oldScalar=outs[i];outs[i]=dist.DZQ(()=>dist.WQq(outs[i],dist.lKK(batchSize,batchOut))),batch>0&&dist.ASo(oldScalar)}dist.ASo(batchOuts),numExamples+=batchSize,++batch}return outs}),iteratorOut.done){hasBatches&&training_dataset_console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${args.batches} batches). You may need to use the repeat() function when building your dataset.`);break}}for(let i=0;i<outs.length;++i){const oldScalar=outs[i];outs[i]=dist.y4m(outs[i],numExamples),dist.ASo(oldScalar)}return singletonOrArray(outs)}(this,dataset,args)}checkNumSamples(ins,batchSize,steps,stepsName="steps"){let numSamples;if(null!=steps){if(numSamples=null,null!=batchSize)throw new errors_ValueError(`If ${stepsName} is set, batchSize must be null or undefined.Got batchSize = ${batchSize}`)}else{if(null==ins)throw new errors_ValueError(`Either the input data should have a defined shape, or ${stepsName} shoud be specified.`);numSamples=Array.isArray(ins)?ins[0].shape[0]:ins.shape[0]}return numSamples}execute(inputs,outputs){if(Array.isArray(outputs)&&0===outputs.length)throw new errors_ValueError("`outputs` is an empty Array, which is not allowed.");const outputsIsArray=Array.isArray(outputs),outputNames=outputsIsArray?outputs:[outputs],outputSymbolicTensors=this.retrieveSymbolicTensors(outputNames),feedDict=new FeedDict;if(inputs instanceof dist.qYS&&(inputs=[inputs]),Array.isArray(inputs)){if(inputs.length!==this.inputs.length)throw new errors_ValueError(`The number of inputs provided (${inputs.length}) does not match the number of inputs of this model (${this.inputs.length}).`);for(let i=0;i<this.inputs.length;++i)feedDict.add(this.inputs[i],inputs[i])}else for(const input of this.inputs){const tensorValue=inputs[input.name];if(null==tensorValue)throw new errors_ValueError(`No value is provided for the model's input ${input.name}`);feedDict.add(input,tensorValue)}const executeOutputs=execute(outputSymbolicTensors,feedDict);return outputsIsArray?executeOutputs:executeOutputs[0]}retrieveSymbolicTensors(symbolicTensorNames){const outputSymbolicTensors=pyListRepeat(null,symbolicTensorNames.length);let outputsRemaining=symbolicTensorNames.length;for(const layer of this.layers){const layerOutputs=Array.isArray(layer.output)?layer.output:[layer.output],layerOutputNames=layerOutputs.map(output=>output.name);for(let i=0;i<symbolicTensorNames.length;++i){const index=layerOutputNames.indexOf(symbolicTensorNames[i]);if(-1!==index&&(outputSymbolicTensors[i]=layerOutputs[index],outputsRemaining--),0===outputsRemaining)break}if(0===outputsRemaining)break}if(outputsRemaining>0){const remainingNames=[];throw outputSymbolicTensors.forEach((tensor,i)=>{null==tensor&&remainingNames.push(symbolicTensorNames[i])}),new errors_ValueError(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(remainingNames)}`)}return outputSymbolicTensors}predictLoop(ins,batchSize=32,verbose=!1){return dist.DZQ(()=>{const numSamples=this.checkNumSamples(ins);if(verbose)throw new errors_NotImplementedError("Verbose predictLoop() is not implemented yet.");const batches=makeBatches(numSamples,batchSize),outsBatches=this.outputs.map(output=>[]);for(let batchIndex=0;batchIndex<batches.length;++batchIndex){dist.DZQ(()=>{const batchStart=batches[batchIndex][0],batchEnd=batches[batchIndex][1],insBatch=sliceArrays(ins,batchStart,batchEnd),feeds=[];if(Array.isArray(insBatch))for(let i=0;i<insBatch.length;++i)feeds.push({key:this.inputs[i],value:insBatch[i]});else feeds.push({key:this.inputs[0],value:insBatch});const feedDict=new FeedDict(feeds);return execute(this.outputs,feedDict)}).forEach((batchOut,i)=>outsBatches[i].push(batchOut))}return singletonOrArray(outsBatches.map(batches=>dist.xWs(batches,0)))})}predict(x,args={}){const xsRank2OrHigher=ensureTensorsRank2OrHigher(x);checkInputData(xsRank2OrHigher,this.inputNames,this.feedInputShapes,!1);try{const batchSize=null==args.batchSize?32:args.batchSize;return checkBatchSize(batchSize),this.predictLoop(xsRank2OrHigher,batchSize)}finally{disposeNewTensors(xsRank2OrHigher,x)}}predictOnBatch(x){checkInputData(x,this.inputNames,this.feedInputShapes,!0);const batchSize=(Array.isArray(x)?x[0]:x).shape[0];return this.predictLoop(x,batchSize)}standardizeUserDataXY(x,y,checkBatchAxis=!0,batchSize){if(null==this.optimizer_)throw new RuntimeError("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");const outputShapes=[];for(let i=0;i<this.feedOutputShapes.length;++i){const outputShape=this.feedOutputShapes[i];this.feedLossFns[i]===sparseCategoricalCrossentropy?outputShapes.push(outputShape.slice(0,outputShape.length-1).concat([1])):outputShapes.push(outputShape)}if(function checkArrayLengths(inputs,targets,weights){const setX=generic_utils_unique(inputs.map(input=>input.shape[0]));setX.sort();const setY=generic_utils_unique(targets.map(target=>target.shape[0]));if(setY.sort(),setX.length>1)throw new errors_ValueError(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(inputs.map(input=>input.shape))}`);if(setY.length>1)throw new errors_ValueError(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(targets.map(target=>target.shape))}`);if(setX.length>0&&setY.length>0&&!dist.ZSL.arraysEqual(setX,setY))throw new errors_ValueError(`Input Tensors should have the same number of samples as target Tensors. Found ${setX[0]} input sample(s) and ${setY[0]} target sample(s).`)}(x=standardizeInputData(x,this.feedInputNames,this.feedInputShapes,!1,"input"),y=standardizeInputData(y,this.feedOutputNames,outputShapes,!1,"target")),function checkLossAndTargetCompatibility(targets,lossFns,outputShapes){const keyLosses=[meanSquaredError,binaryCrossentropy,categoricalCrossentropy];for(let i=0;i<targets.length;++i){const y=targets[i],loss=lossFns[i],shape=outputShapes[i];if(null!=loss){if(loss===categoricalCrossentropy&&1===y.shape[y.shape.length-1])throw new errors_ValueError(`You are passing a target array of shape ${y.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);if(-1!==keyLosses.indexOf(loss)){const slicedYShape=y.shape.slice(1),slicedShape=shape.slice(1);for(let j=0;j<slicedYShape.length;++j){const targetDim=slicedYShape[j],outDim=slicedShape[j];if(null!=outDim&&targetDim!==outDim)throw new errors_ValueError(`A target Tensor with shape ${y.shape} was passed for an output of shape ${shape}, while using a loss function that expects targets to have the same shape as the output.`)}}}}}(y,this.feedLossFns,this.feedOutputShapes),this.stateful&&null!=batchSize&&batchSize>0&&x[0].shape[0]%batchSize!==0)throw new errors_ValueError(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${batchSize}. Found: ${x[0].shape[0]} sample(s).`);return[x,y]}async standardizeUserData(x,y,sampleWeight,classWeight,checkBatchAxis=!0,batchSize){const[standardXs,standardYs]=this.standardizeUserDataXY(x,y,checkBatchAxis,batchSize);if(null!=sampleWeight)throw new Error("sample weight is not supported yet.");let standardSampleWeights=null;if(null!=classWeight){const classWeights=standardizeClassWeights(classWeight,this.outputNames);standardSampleWeights=[];for(let i=0;i<classWeights.length;++i)standardSampleWeights.push(await standardizeWeights(standardYs[i],null,classWeights[i]))}return[standardXs,standardYs,standardSampleWeights]}testLoop(f,ins,batchSize,verbose=0,steps){return dist.DZQ(()=>{const numSamples=this.checkNumSamples(ins,batchSize,steps,"steps"),outs=[];if(verbose>0)throw new errors_NotImplementedError("Verbose mode is not implemented yet.");if(null!=steps)throw new errors_NotImplementedError("steps mode in testLoop() is not implemented yet");{const batches=makeBatches(numSamples,batchSize),indexArray=(0,dist.tGX)(range(0,numSamples));for(let batchIndex=0;batchIndex<batches.length;++batchIndex){const batchStart=batches[batchIndex][0],batchEnd=batches[batchIndex][1],batchIds=sliceAlongFirstAxis(indexArray,batchStart,batchEnd-batchStart),insBatch=sliceArraysByIndices(ins,batchIds),batchOuts=f(insBatch);if(0===batchIndex)for(let i=0;i<batchOuts.length;++i)outs.push((0,dist.d_2)(0));for(let i=0;i<batchOuts.length;++i){const batchOut=batchOuts[i];outs[i]=dist.WQq(outs[i],dist.lKK(batchEnd-batchStart,batchOut))}}for(let i=0;i<outs.length;++i)outs[i]=dist.y4m(outs[i],numSamples)}return outs})}getDedupedMetricsNames(){const outLabels=this.metricsNames,dedupedOutLabels=[];for(let i=0;i<outLabels.length;++i){const label=outLabels[i];let newLabel=label;if(count(outLabels,label)>1){newLabel+=`_${count(outLabels.slice(0,i),label)}`}dedupedOutLabels.push(newLabel)}return dedupedOutLabels}makeTrainFunction(){return data=>{const lossValues=[],inputs=data.slice(0,this.inputs.length),targets=data.slice(this.inputs.length,this.inputs.length+this.outputs.length),sampleWeights=data.slice(this.inputs.length+this.outputs.length,this.inputs.length+2*this.outputs.length),metricsValues=[],variables=this.collectedTrainableWeights.map(param=>param.read());return[this.optimizer_.minimize(()=>{const feeds=[];for(let i=0;i<this.inputs.length;++i)feeds.push({key:this.inputs[i],value:inputs[i]});const feedDict=new FeedDict(feeds),outputs=execute(this.outputs,feedDict,{training:!0});let totalLoss;for(let i=0;i<this.lossFunctions.length;++i){let loss=(0,this.lossFunctions[i])(targets[i],outputs[i]);null!=sampleWeights[i]&&(loss=computeWeightedLoss(loss,sampleWeights[i]));const meanLoss=dist.i2o(loss);lossValues.push(meanLoss),totalLoss=0===i?loss:dist.WQq(totalLoss,loss)}for(let i=0;i<this.metricsTensors.length;++i){let weightedMetric;if(this.outputs.length>1&&i<this.outputs.length)weightedMetric=lossValues[i];else{const metric=this.metricsTensors[i][0],outputIndex=this.metricsTensors[i][1];weightedMetric=dist.i2o(metric(targets[outputIndex],outputs[outputIndex]))}dist.aCs(weightedMetric),metricsValues.push(weightedMetric)}return totalLoss=dist.i2o(totalLoss),this.calculateLosses().forEach(regularizerLoss=>{totalLoss=dist.WQq(totalLoss,regularizerLoss)}),totalLoss},!0,variables)].concat(metricsValues)}}makeTestFunction(){this.testFunction=data=>dist.DZQ(()=>{const valOutputs=[];let totalLoss;const inputs=data.slice(0,this.inputs.length),targets=data.slice(this.inputs.length,this.inputs.length+this.outputs.length),feeds=[];for(let i=0;i<this.inputs.length;++i)feeds.push({key:this.inputs[i],value:inputs[i]});const feedDict=new FeedDict(feeds),outputs=execute(this.outputs,feedDict);for(let i=0;i<this.lossFunctions.length;++i){const lossFunction=this.lossFunctions[i],loss=dist.i2o(lossFunction(targets[i],outputs[i]));totalLoss=0===i?loss:dist.WQq(totalLoss,loss),valOutputs.push(totalLoss)}for(let i=0;i<this.metricsTensors.length;++i){const metric=this.metricsTensors[i][0],outputIndex=this.metricsTensors[i][1],meanMetric=dist.i2o(metric(targets[outputIndex],outputs[outputIndex]));valOutputs.push(meanMetric)}return valOutputs})}async fit(x,y,args={}){if(this.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");let inputs,targets,originalInputs,originalTargets,inputValX,inputValY,valX,valY,sampleWeights;this.isTraining=!0;try{const batchSize=null==args.batchSize?32:args.batchSize;checkBatchSize(batchSize);const checkBatchAxis=!1,standardizedOuts=await this.standardizeUserData(x,y,args.sampleWeight,args.classWeight,checkBatchAxis,batchSize);inputs=standardizedOuts[0],targets=standardizedOuts[1],sampleWeights=standardizedOuts[2];let valIns,doValidation=!1;if(null!=args.validationData&&args.validationData.length>0){if(doValidation=!0,2!==args.validationData.length)throw 3===args.validationData.length?new errors_NotImplementedError("validationData including sample weights is not supported yet."):new errors_ValueError(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${args.validationData} is invalid.`);inputValX=args.validationData[0],inputValY=args.validationData[1];const checkBatchAxis=!0,valStandardized=await this.standardizeUserData(inputValX,inputValY,null,null,checkBatchAxis,batchSize);valX=valStandardized[0],valY=valStandardized[1],valIns=valX.concat(valY)}else if(null!=args.validationSplit&&args.validationSplit>0&&args.validationSplit<1){doValidation=!0;const splitAt=Math.floor(inputs[0].shape[0]*(1-args.validationSplit)),originalBatchSize=inputs[0].shape[0];valX=sliceArrays(inputs,splitAt,originalBatchSize),originalInputs=inputs,inputs=sliceArrays(inputs,0,splitAt),valY=sliceArrays(targets,splitAt,originalBatchSize),originalTargets=targets,targets=sliceArrays(targets,0,splitAt),valIns=valX.concat(valY)}else null!=args.validationSteps&&(doValidation=!0);const ins=inputs.concat(targets).concat(sampleWeights);this.checkTrainableWeightsConsistency();const trainFunction=this.makeTrainFunction(),outLabels=this.getDedupedMetricsNames();let valFunction,callbackMetrics;doValidation?(this.makeTestFunction(),valFunction=this.testFunction,callbackMetrics=outLabels.slice().concat(outLabels.map(n=>"val_"+n))):(valFunction=null,valIns=[],callbackMetrics=outLabels.slice());const callbacks=standardizeCallbacks(args.callbacks,args.yieldEvery);return await this.fitLoop(trainFunction,ins,outLabels,batchSize,args.epochs,args.verbose,callbacks,valFunction,valIns,args.shuffle,callbackMetrics,args.initialEpoch,null,null)}finally{this.isTraining=!1,disposeNewTensors(inputs,x),disposeNewTensors(targets,y),disposeNewTensors(originalInputs,x),disposeNewTensors(originalTargets,y),disposeNewTensors(valX,inputValX),disposeNewTensors(valY,inputValY),null!=sampleWeights&&dist.ASo(sampleWeights)}}async fitLoop(f,ins,outLabels,batchSize,epochs,verbose,callbacks,valF,valIns,shuffle,callbackMetrics,initialEpoch,stepsPerEpoch,validationSteps){null==batchSize&&(batchSize=32),null==epochs&&(epochs=1),null==shuffle&&(shuffle=!0),null==initialEpoch&&(initialEpoch=0);let doValidation=!1;if(null!=valF&&null!=valIns&&(doValidation=!0),null!=validationSteps&&(doValidation=!0,null==stepsPerEpoch))throw new errors_ValueError("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");const numTrainSamples=this.checkNumSamples(ins,batchSize,stepsPerEpoch,"steps_per_epoch");let indexArray;null!=numTrainSamples&&(indexArray=range(0,numTrainSamples)),null==verbose&&(verbose=1);const{callbackList,history}=configureCallbacks(callbacks,verbose,epochs,initialEpoch,numTrainSamples,stepsPerEpoch,batchSize,doValidation,callbackMetrics);callbackList.setModel(this),this.history=history,await callbackList.onTrainBegin(),this.stopTraining_=!1;for(let epoch=initialEpoch;epoch<epochs;++epoch){await callbackList.onEpochBegin(epoch);const epochLogs={};if(null!=stepsPerEpoch)throw new errors_NotImplementedError("stepsPerEpoch mode is not implemented yet.");{if("batch"===shuffle)throw new errors_NotImplementedError("batch shuffling is not implemneted yet");shuffle&&dist.ZSL.shuffle(indexArray);const epochIndexArray1D=(0,dist.tGX)(indexArray),batches=makeBatches(numTrainSamples,batchSize);for(let batchIndex=0;batchIndex<batches.length;++batchIndex){const batchLogs={};if(await callbackList.onBatchBegin(batchIndex,batchLogs),dist.DZQ(()=>{const batchStart=batches[batchIndex][0],batchEnd=batches[batchIndex][1],batchIds=sliceAlongFirstAxis(epochIndexArray1D,batchStart,batchEnd-batchStart);batchLogs.batch=batchIndex,batchLogs.size=batchEnd-batchStart;const insBatch=sliceArraysByIndices(ins,batchIds),outs=f(insBatch);for(let i=0;i<outLabels.length;++i){const label=outLabels[i],out=outs[i];batchLogs[label]=out,dist.aCs(out)}if(batchIndex===batches.length-1&&doValidation){const valOuts=this.testLoop(valF,valIns,batchSize);for(let i=0;i<outLabels.length;++i){const label=outLabels[i],out=valOuts[i];dist.aCs(out),epochLogs["val_"+label]=out}}}),await callbackList.onBatchEnd(batchIndex,batchLogs),disposeTensorsInLogs(batchLogs),this.stopTraining_)break}epochIndexArray1D.dispose()}if(await callbackList.onEpochEnd(epoch,epochLogs),this.stopTraining_)break}return await callbackList.onTrainEnd(),await this.history.syncData(),this.history}async fitDataset(dataset,args){return fitDataset(this,dataset,args)}async trainOnBatch(x,y){const standardizeOut=await this.standardizeUserData(x,y),inputs=standardizeOut[0],targets=standardizeOut[1],losses=this.makeTrainFunction()(inputs.concat(targets)),lossValues=[];for(const loss of losses){const v=await loss.data();lossValues.push(v[0])}return dist.ASo(losses),disposeNewTensors(standardizeOut[0],x),disposeNewTensors(standardizeOut[1],y),singletonOrArray(lossValues)}getNamedWeights(config){const namedWeights=[],trainableOnly=null!=config&&config.trainableOnly,weights=trainableOnly?this.trainableWeights:this.weights,weightValues=this.getWeights(trainableOnly);for(let i=0;i<weights.length;++i)trainableOnly&&!weights[i].trainable||namedWeights.push({name:weights[i].originalName,tensor:weightValues[i]});return namedWeights}set stopTraining(stop){this.stopTraining_=stop}get stopTraining(){return this.stopTraining_}get optimizer(){return this.optimizer_}set optimizer(optimizer){this.optimizer_!==optimizer&&(this.optimizer_=optimizer,this.isOptimizerOwned=!1)}dispose(){const result=super.dispose();if(0===result.refCountAfterDispose&&null!=this.optimizer&&this.isOptimizerOwned){const numTensorsBeforeOptmizerDisposal=dist.m1Z().numTensors;this.optimizer_.dispose(),result.numDisposedVariables+=numTensorsBeforeOptmizerDisposal-dist.m1Z().numTensors}return result}getLossIdentifiers(){let lossNames;if("string"==typeof this.loss)lossNames=toSnakeCase(this.loss);else if(Array.isArray(this.loss)){for(const loss of this.loss)if("string"!=typeof loss)throw new Error("Serialization of non-string loss is not supported.");lossNames=this.loss.map(name=>toSnakeCase(name))}else{const outputNames=Object.keys(this.loss);lossNames={};const losses=this.loss;for(const outputName of outputNames){if("string"!=typeof losses[outputName])throw new Error("Serialization of non-string loss is not supported.");lossNames[outputName]=toSnakeCase(losses[outputName])}}return lossNames}getMetricIdentifiers(){if("string"==typeof this.metrics||"function"==typeof this.metrics)return[toSnakeCase(getLossOrMetricName(this.metrics))];if(Array.isArray(this.metrics))return this.metrics.map(metric=>toSnakeCase(getLossOrMetricName(metric)));{const metricsIdentifiers={};for(const key in this.metrics)metricsIdentifiers[key]=toSnakeCase(getLossOrMetricName(this.metrics[key]));return metricsIdentifiers}}getTrainingConfig(){return{loss:this.getLossIdentifiers(),metrics:this.getMetricIdentifiers(),optimizer_config:{class_name:this.optimizer.getClassName(),config:this.optimizer.getConfig()}}}loadTrainingConfig(trainingConfig){if(null!=trainingConfig.weighted_metrics)throw new Error("Loading weight_metrics is not supported yet.");if(null!=trainingConfig.loss_weights)throw new Error("Loading loss_weights is not supported yet.");if(null!=trainingConfig.sample_weight_mode)throw new Error("Loading sample_weight_mode is not supported yet.");const optimizer=deserialize(convertPythonicToTs(trainingConfig.optimizer_config));let loss,metrics;if("string"==typeof trainingConfig.loss)loss=toCamelCase(trainingConfig.loss);else if(Array.isArray(trainingConfig.loss))loss=trainingConfig.loss.map(lossEntry=>toCamelCase(lossEntry));else if(null!=trainingConfig.loss){loss={};for(const key in trainingConfig.loss)loss[key]=toCamelCase(trainingConfig.loss[key])}if(Array.isArray(trainingConfig.metrics))metrics=trainingConfig.metrics.map(metric=>toCamelCase(metric));else if(null!=trainingConfig.metrics){metrics={};for(const key in trainingConfig.metrics)metrics[key]=toCamelCase(trainingConfig.metrics[key])}this.compile({loss,metrics,optimizer})}async save(handlerOrURL,config){if("string"==typeof handlerOrURL){const handlers=dist.io.getSaveHandlers(handlerOrURL);if(0===handlers.length)throw new errors_ValueError(`Cannot find any save handlers for URL '${handlerOrURL}'`);if(handlers.length>1)throw new errors_ValueError(`Found more than one (${handlers.length}) save handlers for URL '${handlerOrURL}'`);handlerOrURL=handlers[0]}if(null==handlerOrURL.save)throw new errors_ValueError("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");const weightDataAndSpecs=await dist.io.encodeWeights(this.getNamedWeights(config)),modelArtifacts={modelTopology:this.toJSON(null,!1),format:"layers-model",generatedBy:`TensorFlow.js tfjs-layers v${version}`,convertedBy:null};if(null!=config&&config.includeOptimizer&&null!=this.optimizer){modelArtifacts.trainingConfig=this.getTrainingConfig();const weightType="optimizer",{data:optimizerWeightData,specs:optimizerWeightSpecs}=await dist.io.encodeWeights(await this.optimizer.getWeights(),weightType);weightDataAndSpecs.specs.push(...optimizerWeightSpecs),weightDataAndSpecs.data=dist.io.concatenateArrayBuffers([weightDataAndSpecs.data,optimizerWeightData])}if(null!=this.userDefinedMetadata){const checkSize=!0;checkUserDefinedMetadata(this.userDefinedMetadata,this.name,checkSize),modelArtifacts.userDefinedMetadata=this.userDefinedMetadata}return modelArtifacts.weightData=weightDataAndSpecs.data,modelArtifacts.weightSpecs=weightDataAndSpecs.specs,handlerOrURL.save(modelArtifacts)}setUserDefinedMetadata(userDefinedMetadata){checkUserDefinedMetadata(userDefinedMetadata,this.name),this.userDefinedMetadata=userDefinedMetadata}getUserDefinedMetadata(){return this.userDefinedMetadata}}LayersModel.className="Model",dist.JFn.registerClass(LayersModel);class Functional extends LayersModel{}Functional.className="Functional",dist.JFn.registerClass(Functional);var models_console=__webpack_require__("./node_modules/console-browserify/index.js");async function modelFromJSON(modelAndWeightsConfig,customObjects){"modelTopology"in modelAndWeightsConfig||(modelAndWeightsConfig={modelTopology:modelAndWeightsConfig});let modelTopology=modelAndWeightsConfig.modelTopology;null!=modelTopology.model_config&&(modelTopology=modelTopology.model_config);const model=deserialize(convertPythonicToTs(modelTopology),customObjects);if(null!=modelAndWeightsConfig.weightsManifest){const weightValues=await dist.io.loadWeights(modelAndWeightsConfig.weightsManifest,modelAndWeightsConfig.pathPrefix,model.weights.map(weight=>weight.originalName)),uniqueWeightValues={};for(const weight of model.weights)uniqueWeightValues[weight.originalName]=weightValues[weight.originalName];model.loadWeights(uniqueWeightValues),(0,dist.ASo)(weightValues)}return model}async function loadLayersModel(pathOrIOHandler,options){if(null==options&&(options={}),"string"==typeof pathOrIOHandler){const handlers=dist.io.getLoadHandlers(pathOrIOHandler,options);if(0===handlers.length)handlers.push(dist.io.browserHTTPRequest(pathOrIOHandler,options));else if(handlers.length>1)throw new errors_ValueError(`Found more than one (${handlers.length}) load handlers for URL '${pathOrIOHandler}'`);pathOrIOHandler=handlers[0]}return async function loadLayersModelFromIOHandler(handler,customObjects,options){null==options&&(options={});if(null==handler.load)throw new errors_ValueError("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const artifacts=await handler.load();let modelTopology=artifacts.modelTopology;null!=modelTopology.model_config&&(modelTopology=modelTopology.model_config);const strict=null==options.strict||options.strict,fastWeightInit=null!=artifacts.weightData&&null!=artifacts.weightSpecs&&strict,model=deserialize(convertPythonicToTs(modelTopology),customObjects,fastWeightInit),trainingConfig=artifacts.trainingConfig;null!=trainingConfig&&model.loadTrainingConfig(trainingConfig);null!=artifacts.userDefinedMetadata&&model.setUserDefinedMetadata(artifacts.userDefinedMetadata);if(null!=artifacts.weightData){if(null==artifacts.weightSpecs)throw new errors_ValueError("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");const{modelWeights,optimizerWeights}=function decodeModelAndOptimizerWeights(weightData,specs){const name2Tensor=dist.io.decodeWeights(weightData,specs),modelWeights={},optimizerWeights=[];return specs.forEach(spec=>{"optimizer"===spec.group?optimizerWeights.push({name:spec.name,tensor:name2Tensor[spec.name]}):modelWeights[spec.name]=name2Tensor[spec.name]}),{modelWeights,optimizerWeights}}(artifacts.weightData,artifacts.weightSpecs);model.loadWeights(modelWeights,strict),null!=model.optimizer&&optimizerWeights.length>0&&await model.optimizer.setWeights(optimizerWeights),(0,dist.ASo)(modelWeights),(0,dist.ASo)(optimizerWeights.map(w=>w.tensor))}return model}(pathOrIOHandler,void 0,options)}class Sequential extends LayersModel{constructor(args){if(super({inputs:[],outputs:[]}),args=args||{},this.trainable=!0,this.built=!1,this.name=null!=args.name?args.name:getUid("sequential_"),null!=args.layers)for(const layer of args.layers)this.add(layer)}checkShape(layer){if(layer.inboundNodes[0].outputTensors[0].shape.some(x=>x<0))throw new errors_ValueError(`Negative dimension size caused by adding layer ${layer.name} with input shape [${layer.inboundNodes[0].inputTensors[0].shape}]`)}add(layer){const isLayerModelInstance=layer instanceof Sequential||layer instanceof LayersModel;let modelLayer;if(isLayerModelInstance){if(modelLayer=layer,1!==modelLayer.outputs.length)throw new errors_ValueError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");if(1!==modelLayer.inputs.length)throw new errors_ValueError("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.")}if(0===this.outputs.length){if(0===layer.inboundNodes.length){if(null==layer.batchInputShape)throw new errors_ValueError("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");const x=Input({batchShape:layer.batchInputShape,dtype:layer.dtype,name:layer.name+"_input"});layer.apply(x)}if(isLayerModelInstance)this.outputs=modelLayer.outputs,this.inputs=modelLayer.inputs;else{if(1!==layer.inboundNodes.length)throw new errors_ValueError(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${layer.name} which has ${layer.inboundNodes.length} pre-existing inbound connections.`);if(1!==layer.inboundNodes[0].outputTensors.length)throw new errors_ValueError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(layer),this.outputs=[layer.inboundNodes[0].outputTensors[0]],this.inputs=getSourceInputs(this.outputs[0])}this.inboundNodes=[],new Node({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:pyListRepeat(null,this.inputs.length),outputMasks:[null],inputShapes:this.inputs.map(x=>x.shape),outputShapes:this.outputs[0].shape})}else{const outputTensor=layer.apply(this.outputs[0]);if(Array.isArray(outputTensor))throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(layer),this.outputs=[outputTensor],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}this.layers.push(layer),this.built=!1}pop(){if(0===this.layers.length)throw new TypeError("There are no layers in the model.");if(this.layers.pop(),0===this.layers.length)this.outputs=[],this.inboundNodes=[],this.outboundNodes=[];else{const lastLayerIndex=this.layers.length-1;this.layers[lastLayerIndex].outboundNodes=[],this.outputs=[this.layers[lastLayerIndex].output],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}}call(inputs,kwargs){return null==this.model&&this.build(),this.model.call(inputs,kwargs)}build(inputShape){if(getExactlyOneShape(inputShape),0===this.inputs.length||0===this.outputs.length)throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");this.model=new LayersModel({inputs:this.inputs,outputs:this.outputs[0],name:this.name+"_model"}),this.model.trainable=this.trainable,this.supportsMasking=this.model.supportsMasking,this.inputLayers=this.model.inputLayers,this.inputLayersNodeIndices=this.model.inputLayersNodeIndices,this.inputLayersTensorIndices=this.model.inputLayersTensorIndices,this.outputLayers=this.model.outputLayers,this.outputLayersNodeIndices=this.model.outputLayersNodeIndices,this.outputLayersTensorIndices=this.model.outputLayersTensorIndices,this.nodesByDepth=this.model.nodesByDepth,this.containerNodes=this.model.containerNodes,this.outputNames=this.model.outputNames,this.inputNames=this.model.inputNames,this.built=!0}countParams(){return this.built||this.build(),super.countParams()}summary(lineLength,positions,printFn=models_console.log){this.built||this.build(),super.summary(lineLength,positions,printFn)}setWeights(weights){null==this.model&&this.build(),this.model.setWeights(weights)}evaluate(x,y,args={}){if(!this.built)throw new RuntimeError("The model needs to be compiled before being used.");return this.model.evaluate(x,y,args)}async evaluateDataset(dataset,args){if(!this.built)throw new RuntimeError("The model needs to be compiled before being used.");return this.model.evaluateDataset(dataset,args)}predict(x,args={}){return null==this.model&&this.build(),this.model.predict(x,args)}predictOnBatch(x){return null==this.model&&this.build(),this.model.predictOnBatch(x)}compile(args){this.build(),this.model.compile(args),this.optimizer_=this.model.optimizer,this.isOptimizerOwned=this.model.isOptimizerOwned,this.loss=this.model.loss,this.metrics=this.model.metrics,this.metricsTensors=this.model.metricsTensors,this.metricsNames=this.model.metricsNames}get optimizer(){return null==this.model?void 0:this.model.optimizer}set optimizer(optimizer){this.model.optimizer=optimizer}async fit(x,y,args={}){if(!this.built)throw new RuntimeError("The model needs to be compiled before being used.");return this.model.fit(x,y,args)}async fitDataset(dataset,args){if(!this.built)throw new RuntimeError("The model needs to be compiled before being used.");return this.model.fitDataset(dataset,args)}async trainOnBatch(x,y){return this.model.trainOnBatch(x,y)}static fromConfig(cls,config,customObjects={},fastWeightInit=!1){let configArray,extraModelConfig={};if(config instanceof Array){if(null==config[0].className||"Merge"===config[0].className)throw new errors_ValueError("Legacy serialization format not supported yet.");configArray=config}else dist.ZSL.assert(null!=config.layers,()=>"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field."),configArray=config.layers,delete config.layers,extraModelConfig=config;const model=new cls(extraModelConfig);if(!(model instanceof Sequential))throw new errors_NotImplementedError(`Sequential.fromConfig called on non-Sequential input: ${model}`);for(const conf of configArray){const layer=deserialize(conf,void 0,fastWeightInit);fastWeightInit&&layer.setFastWeightInitDuringBuild(!0),model.add(layer)}return model}set stopTraining(stop){if(null==this.model)throw new errors_ValueError("Cannot set the stopTraining property of a sequential model before it is compiled.");this.model.stopTraining=stop}get stopTraining(){if(null==this.model)throw new errors_ValueError("Cannot get the stopTraining property of a sequential model before it is compiled.");return this.model.stopTraining}getConfig(){const layers=[];for(const layer of this.layers){const dict={};dict.className=layer.getClassName(),dict.config=layer.getConfig(),layers.push(dict)}return{name:this.name,layers}}}function model(args){return new LayersModel(args)}function sequential(config){return new Sequential(config)}function input(config){return Input(config)}function registerCallbackConstructor(verbosityLevel,callbackConstructor){CallbackConstructorRegistry.registerCallbackConstructor(verbosityLevel,callbackConstructor)}Sequential.className="Sequential",dist.JFn.registerClass(Sequential);class Activation extends dist.JFn.Serializable{getConfig(){return{}}}class Elu extends Activation{apply(x,alpha=1){return function tfjs_backend_elu(x,alpha=1){if(1!==alpha)throw new errors_NotImplementedError(`Support for alpha values other than 1 (${alpha}) is not implemented yet.`);return dist.Pqc(x)}(x,alpha)}}Elu.className="elu",dist.JFn.registerClass(Elu);class Selu extends Activation{apply(x){return dist.WfX(x)}}Selu.className="selu",dist.JFn.registerClass(Selu);class Relu extends Activation{apply(x){return dist.VVh(x)}}Relu.className="relu",dist.JFn.registerClass(Relu);class Relu6 extends Activation{apply(x){return(0,dist.DZQ)(()=>dist.BpO(6,dist.VVh(x)))}}Relu6.className="relu6",dist.JFn.registerClass(Relu6);class Linear extends Activation{apply(x){return x}}Linear.className="linear",dist.JFn.registerClass(Linear);class Sigmoid extends Activation{apply(x){return dist.ry7(x)}}Sigmoid.className="sigmoid",dist.JFn.registerClass(Sigmoid);class HardSigmoid extends Activation{apply(x){return function hardSigmoid(x){return(0,dist.DZQ)(()=>{const y=dist.WQq(.5,dist.lKK(.2,x));return dist.zQh(y,0,1)})}(x)}}HardSigmoid.className="hardSigmoid",dist.JFn.registerClass(HardSigmoid);class Softplus extends Activation{apply(x){return dist.lw0(x)}}Softplus.className="softplus",dist.JFn.registerClass(Softplus);class Softsign extends Activation{apply(x){return function softsign(x){return(0,dist.DZQ)(()=>dist.y4m(x,dist.WQq(dist.tnl(x),1)))}(x)}}Softsign.className="softsign",dist.JFn.registerClass(Softsign);class Tanh extends Activation{apply(x){return dist.ymU(x)}}Tanh.className="tanh",dist.JFn.registerClass(Tanh);class activations_Softmax extends Activation{apply(x,axis=-1){return dist.Vs9(x,axis)}}activations_Softmax.className="softmax",dist.JFn.registerClass(activations_Softmax);class LogSoftmax extends Activation{apply(x,axis=-1){return dist.HPB(x,axis)}}LogSoftmax.className="logSoftmax",dist.JFn.registerClass(LogSoftmax);class Gelu extends Activation{apply(x){return(0,dist.DZQ)(()=>dist.DZQ(()=>{const sqrtTwo=Math.sqrt(2),cdf=dist.lKK(.5,dist.WQq(1,dist.Y12(dist.y4m(x,sqrtTwo))));return dist.lKK(x,cdf)}))}}Gelu.className="gelu",dist.JFn.registerClass(Gelu);class GeluNew extends Activation{apply(x){return(0,dist.DZQ)(()=>dist.lKK(.5,dist.lKK(x,dist.WQq(1,dist.ymU(dist.lKK(dist.RZD(dist.y4m(2,Math.PI)),dist.WQq(x,dist.lKK(.044715,dist.n7C(x,3)))))))))}}GeluNew.className="gelu_new",dist.JFn.registerClass(GeluNew);class Mish extends Activation{apply(x){return(0,dist.DZQ)(()=>dist.lKK(x,dist.ymU(dist.lw0(x))))}}Mish.className="mish",dist.JFn.registerClass(Mish);class Swish extends Activation{apply(x,alpha=1){return(0,dist.DZQ)(()=>dist.lKK(dist.ry7(dist.lKK(x,alpha)),x))}}function serializeActivation(activation){return activation.getClassName()}function deserializeActivation(config,customObjects={}){return deserializeKerasObject(config,dist.JFn.SerializationMap.getMap().classNameMap,customObjects,"activation")}function getActivation(identifier){if(null==identifier){const config={className:"linear",config:{}};return deserializeActivation(config)}if("string"==typeof identifier){const config={};return config.className=identifier,config.config={},deserializeActivation(config)}return identifier instanceof Activation?identifier:deserializeActivation(identifier)}function assertObjectArgs(args){if(null!=args&&"object"!=typeof args)throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${args}`)}Swish.className="swish",dist.JFn.registerClass(Swish);class Regularizer extends dist.JFn.Serializable{}class L1L2 extends Regularizer{constructor(args){super(),assertObjectArgs(args),this.l1=null==args||null==args.l1?.01:args.l1,this.l2=null==args||null==args.l2?.01:args.l2,this.hasL1=0!==this.l1,this.hasL2=0!==this.l2}apply(x){return(0,dist.DZQ)(()=>{let regularization=(0,dist.Ul9)([1]);return this.hasL1&&(regularization=(0,dist.WQq)(regularization,(0,dist.czq)(dist.lKK(this.l1,(0,dist.tnl)(x))))),this.hasL2&&(regularization=(0,dist.WQq)(regularization,(0,dist.czq)(dist.lKK(this.l2,tfjs_backend_square(x))))),dist.tQQ(regularization,[])})}getConfig(){return{l1:this.l1,l2:this.l2}}static fromConfig(cls,config){return new cls({l1:config.l1,l2:config.l2})}}L1L2.className="L1L2",dist.JFn.registerClass(L1L2);const REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP={l1l2:"L1L2"};function serializeRegularizer(constraint){return serializeKerasObject(constraint)}function deserializeRegularizer(config,customObjects={}){return deserializeKerasObject(config,dist.JFn.SerializationMap.getMap().classNameMap,customObjects,"regularizer")}function getRegularizer(identifier){if(null==identifier)return null;if("string"==typeof identifier){return deserializeRegularizer({className:identifier in REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP?REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier]:identifier,config:{}})}return identifier instanceof Regularizer?identifier:deserializeRegularizer(identifier)}class ReLU extends Layer{constructor(args){super(null==args?{}:args),this.supportsMasking=!0,null!=args&&(this.maxValue=args.maxValue)}call(inputs,kwargs){inputs=getExactlyOneTensor(inputs);let output=(0,dist.VVh)(inputs);return null!=this.maxValue&&(output=(0,dist.zQh)(output,0,this.maxValue)),output}computeOutputShape(inputShape){return inputShape}getConfig(){const config={maxValue:this.maxValue},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}ReLU.className="ReLU",dist.JFn.registerClass(ReLU);class LeakyReLU extends Layer{constructor(args){super(null==args?{}:args),this.DEFAULT_ALPHA=.3,null==args&&(args={}),this.alpha=null==args.alpha?this.DEFAULT_ALPHA:args.alpha}call(inputs,kwargs){const x=getExactlyOneTensor(inputs);return(0,dist.H8d)(x,this.alpha)}computeOutputShape(inputShape){return inputShape}getConfig(){const config={alpha:this.alpha},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}LeakyReLU.className="LeakyReLU",dist.JFn.registerClass(LeakyReLU);class PReLU extends Layer{constructor(args){if(super(null==args?{}:args),this.DEFAULT_ALPHA_INITIALIZER="zeros",null==args&&(args={}),this.supportsMasking=!0,this.alphaInitializer=getInitializer(args.alphaInitializer||this.DEFAULT_ALPHA_INITIALIZER),this.alphaRegularizer=getRegularizer(args.alphaRegularizer),this.alphaConstraint=getConstraint(args.alphaConstraint),null==args.sharedAxes)this.sharedAxes=null;else if(Array.isArray(args.sharedAxes))this.sharedAxes=args.sharedAxes;else{if("number"!=typeof args.sharedAxes)throw new errors_ValueError(`Expected sharedAxes to be a number or an array of numbers, but got ${args.sharedAxes}`);this.sharedAxes=[args.sharedAxes]}}build(inputShape){const paramShape=(inputShape=getExactlyOneShape(inputShape)).slice(1);if(null!=this.sharedAxes)for(const i of this.sharedAxes)paramShape[i-1]=1;this.alpha=this.addWeight("alpha",paramShape,"float32",this.alphaInitializer,this.alphaRegularizer,!0,this.alphaConstraint);const axes={};if(null!=this.sharedAxes)for(let i=1;i<inputShape.length;++i)axes[i]=inputShape[i];this.inputSpec=[new InputSpec({ndim:inputShape.length,axes})],this.built=!0}call(inputs,kwargs){return inputs=getExactlyOneTensor(inputs),(0,dist.NsG)(inputs,this.alpha.read())}getConfig(){const config={alphaInitializer:serializeInitializer(this.alphaInitializer),alphaRegularizer:serializeRegularizer(this.alphaRegularizer),alphaConstraint:serializeConstraint(this.alphaConstraint),sharedAxes:this.sharedAxes},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}PReLU.className="PReLU",dist.JFn.registerClass(PReLU);class ELU extends Layer{constructor(args){if(super(null==args?{}:args),this.DEFAULT_ALPHA=1,null==args&&(args={}),null!=args.alpha&&args.alpha!==this.DEFAULT_ALPHA)throw new errors_NotImplementedError(`Non-default alpha value (${args.alpha}) is not supported by the ELU layer yet.`);this.alpha=null==args.alpha?this.DEFAULT_ALPHA:args.alpha}call(inputs,kwargs){const x=getExactlyOneTensor(inputs);return(0,dist.Pqc)(x)}computeOutputShape(inputShape){return inputShape}getConfig(){const config={alpha:this.alpha},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}ELU.className="ELU",dist.JFn.registerClass(ELU);class ThresholdedReLU extends Layer{constructor(args){super(null==args?{}:args),this.DEFAULT_THETA=1,null==args&&(args={}),this.theta=null==args.theta?this.DEFAULT_THETA:args.theta}call(inputs,kwargs){const x=getExactlyOneTensor(inputs);return(0,dist.lKK)(x,(0,dist.wgE)((0,dist.rhj)(x,this.theta),"float32"))}computeOutputShape(inputShape){return inputShape}getConfig(){const config={theta:this.theta},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}ThresholdedReLU.className="ThresholdedReLU",dist.JFn.registerClass(ThresholdedReLU);class Softmax extends Layer{constructor(args){super(null==args?{}:args),this.DEFAULT_AXIS=1,null==args&&(args={}),this.softmax=(new activations_Softmax).apply,this.axis=null==args.axis?this.DEFAULT_AXIS:args.axis}call(inputs,kwargs){return(0,dist.DZQ)(()=>{let x=getExactlyOneTensor(inputs);const mask=kwargs.mask;if(null!=mask){const adder=(0,dist.lKK)((0,dist.jbE)((0,dist.SaS)(x.shape),(0,dist.wgE)(mask,x.dtype)),(0,dist.d_2)(-1e9));x=(0,dist.WQq)(x,adder)}return this.axis instanceof Array?this.axis.length>1?(0,dist.oNF)((0,dist.jbE)(x,(0,dist.VZ)(x,this.axis,!0))):this.softmax(x,this.axis[0]):this.softmax(x,this.axis)})}computeOutputShape(inputShape){return inputShape}getConfig(){const config={axis:this.axis},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}function normalizeArray(value,n,name){if("number"==typeof value)return pyListRepeat(value,n);if(value.length!==n)throw new errors_ValueError(`The ${name} argument must be an integer or tuple of ${n} integers. Received: ${value.length} elements.`);for(let i=0;i<n;++i){const singleValue=value[i];if(!isInteger(singleValue))throw new errors_ValueError(`The ${name} argument must be an integer or tuple of ${n} integers. Received: ${JSON.stringify(value)} including a non-integer number ${singleValue}`)}return value}function convOutputLength(inputLength,filterSize,padding,stride,dilation=1){if(null==inputLength)return inputLength;let outputLength;return outputLength="same"===padding?inputLength:inputLength-(filterSize+(filterSize-1)*(dilation-1))+1,Math.floor((outputLength+stride-1)/stride)}function deconvLength(dimSize,strideSize,kernelSize,padding){if(null==dimSize)return null;if("valid"===padding)dimSize=dimSize*strideSize+math_utils_max([kernelSize-strideSize,0]);else{if("same"!==padding)throw new errors_ValueError(`Unsupport padding mode: ${padding}.`);dimSize*=strideSize}return dimSize}function preprocessConv2DInput(x,dataFormat){return(0,dist.DZQ)(()=>(common_checkDataFormat(dataFormat),"channelsFirst"===dataFormat?dist.mgz(x,[0,2,3,1]):x))}function preprocessConv3DInput(x,dataFormat){return(0,dist.DZQ)(()=>(common_checkDataFormat(dataFormat),"channelsFirst"===dataFormat?dist.mgz(x,[0,2,3,4,1]):x))}function conv1dWithBias(x,kernel,bias,strides=1,padding="valid",dataFormat,dilationRate=1){return(0,dist.DZQ)(()=>{if(null==dataFormat&&(dataFormat="channelsLast"),common_checkDataFormat(dataFormat),3!==x.shape.length)throw new errors_ValueError(`The input of a conv1dWithBias operation should be 3, but is ${x.shape.length} instead.`);if(3!==kernel.shape.length)throw new errors_ValueError(`The kernel for a conv1dWithBias operation should be 3, but is ${kernel.shape.length} instead`);if(null!=bias&&1!==bias.shape.length)throw new errors_ValueError(`The bias for a conv1dWithBias operation should be 1, but is ${bias.shape.length} instead`);if("channelsFirst"===dataFormat&&(x=dist.mgz(x,[0,2,1])),"causal"===padding)throw new errors_NotImplementedError("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let y=dist.kA9(x,kernel,strides,"same"===padding?"same":"valid","NWC",dilationRate);return null!=bias&&(y=biasAdd(y,bias)),y})}function conv2dWithBiasActivation(x,kernel,bias,strides=[1,1],padding="valid",dataFormat,dilationRate,activation=null){return(0,dist.DZQ)(()=>{if(null==dataFormat&&(dataFormat="channelsLast"),common_checkDataFormat(dataFormat),3!==x.rank&&4!==x.rank)throw new errors_ValueError(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${x.rank}.`);if(3!==kernel.rank&&4!==kernel.rank)throw new errors_ValueError(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${x.rank}.`);let y=preprocessConv2DInput(x,dataFormat);if("causal"===padding)throw new errors_NotImplementedError("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return y=dist.cZk.conv2d({x:y,filter:kernel,strides,pad:"same"===padding?"same":"valid",dilations:dilationRate,dataFormat:"NHWC",bias,activation}),"channelsFirst"===dataFormat&&(y=dist.mgz(y,[0,3,1,2])),y})}function conv3dWithBias(x,kernel,bias,strides=[1,1,1],padding="valid",dataFormat,dilationRate){return(0,dist.DZQ)(()=>{if(null==dataFormat&&(dataFormat="channelsLast"),common_checkDataFormat(dataFormat),4!==x.rank&&5!==x.rank)throw new errors_ValueError(`conv3dWithBias expects input to be of rank 4 or 5, but received ${x.rank}.`);if(4!==kernel.rank&&5!==kernel.rank)throw new errors_ValueError(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${x.rank}.`);let y=preprocessConv3DInput(x,dataFormat);if("causal"===padding)throw new errors_NotImplementedError("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return y=dist.IPL(y,kernel,strides,"same"===padding?"same":"valid","NDHWC",dilationRate),null!=bias&&(y=biasAdd(y,bias)),"channelsFirst"===dataFormat&&(y=dist.mgz(y,[0,4,1,2,3])),y})}Softmax.className="Softmax",dist.JFn.registerClass(Softmax);class BaseConv extends Layer{constructor(rank,args){if(super(args),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",BaseConv.verifyArgs(args),this.rank=rank,assertPositiveInteger(this.rank,"rank"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new errors_NotImplementedError(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=normalizeArray(args.kernelSize,rank,"kernelSize"),this.strides=normalizeArray(null==args.strides?1:args.strides,rank,"strides"),this.padding=null==args.padding?"valid":args.padding,checkPaddingMode(this.padding),this.dataFormat=null==args.dataFormat?"channelsLast":args.dataFormat,common_checkDataFormat(this.dataFormat),this.activation=getActivation(args.activation),this.useBias=null==args.useBias||args.useBias,this.biasInitializer=getInitializer(args.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=getConstraint(args.biasConstraint),this.biasRegularizer=getRegularizer(args.biasRegularizer),this.activityRegularizer=getRegularizer(args.activityRegularizer),this.dilationRate=normalizeArray(null==args.dilationRate?1:args.dilationRate,rank,"dilationRate"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new errors_ValueError(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);if(2===this.rank){if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new errors_ValueError(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`)}else if(3===this.rank)if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new errors_ValueError(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`)}static verifyArgs(args){if(assert("kernelSize"in args,"required key 'kernelSize' not in config"),"number"!=typeof args.kernelSize&&!checkArrayTypeAndLength(args.kernelSize,"number",1,3))throw new errors_ValueError(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(args.kernelSize)}.`)}getConfig(){const config={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:serializeActivation(this.activation),useBias:this.useBias,biasInitializer:serializeInitializer(this.biasInitializer),biasRegularizer:serializeRegularizer(this.biasRegularizer),activityRegularizer:serializeRegularizer(this.activityRegularizer),biasConstraint:serializeConstraint(this.biasConstraint)},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}class Conv extends BaseConv{constructor(rank,args){super(rank,args),this.kernel=null,Conv.verifyArgs(args),this.filters=args.filters,assertPositiveInteger(this.filters,"filters"),this.kernelInitializer=getInitializer(args.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=getConstraint(args.kernelConstraint),this.kernelRegularizer=getRegularizer(args.kernelRegularizer)}build(inputShape){inputShape=getExactlyOneShape(inputShape);const channelAxis="channelsFirst"===this.dataFormat?1:inputShape.length-1;if(null==inputShape[channelAxis])throw new errors_ValueError(`The channel dimension of the input should be defined. Found ${inputShape[channelAxis]}`);const inputDim=inputShape[channelAxis],kernelShape=this.kernelSize.concat([inputDim,this.filters]);this.kernel=this.addWeight("kernel",kernelShape,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[channelAxis]:inputDim}}],this.built=!0}call(inputs,kwargs){return(0,dist.DZQ)(()=>{let outputs;inputs=getExactlyOneTensor(inputs);const biasValue=null==this.bias?null:this.bias.read(),fusedActivationName=mapActivationToFusedKernel(this.activation.getClassName());if(null!=fusedActivationName&&2===this.rank)outputs=conv2dWithBiasActivation(inputs,this.kernel.read(),biasValue,this.strides,this.padding,this.dataFormat,this.dilationRate,fusedActivationName);else{if(1===this.rank)outputs=conv1dWithBias(inputs,this.kernel.read(),biasValue,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)outputs=conv2dWithBiasActivation(inputs,this.kernel.read(),biasValue,this.strides,this.padding,this.dataFormat,this.dilationRate);else{if(3!==this.rank)throw new errors_NotImplementedError("convolutions greater than 3D are not implemented yet.");outputs=conv3dWithBias(inputs,this.kernel.read(),biasValue,this.strides,this.padding,this.dataFormat,this.dilationRate)}null!=this.activation&&(outputs=this.activation.apply(outputs))}return outputs})}computeOutputShape(inputShape){inputShape=getExactlyOneShape(inputShape);const newSpace=[],space="channelsLast"===this.dataFormat?inputShape.slice(1,inputShape.length-1):inputShape.slice(2);for(let i=0;i<space.length;++i){const newDim=convOutputLength(space[i],this.kernelSize[i],this.padding,this.strides[i],"number"==typeof this.dilationRate?this.dilationRate:this.dilationRate[i]);newSpace.push(newDim)}let outputShape=[inputShape[0]];return"channelsLast"===this.dataFormat?(outputShape=outputShape.concat(newSpace),outputShape.push(this.filters)):(outputShape.push(this.filters),outputShape=outputShape.concat(newSpace)),outputShape}getConfig(){const config={filters:this.filters,kernelInitializer:serializeInitializer(this.kernelInitializer),kernelRegularizer:serializeRegularizer(this.kernelRegularizer),kernelConstraint:serializeConstraint(this.kernelConstraint)},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}static verifyArgs(args){if(!("filters"in args)||"number"!=typeof args.filters||args.filters<1)throw new errors_ValueError(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(args.filters)}`)}}class Conv2D extends Conv{constructor(args){super(2,args),Conv2D.verifyArgs(args)}getConfig(){const config=super.getConfig();return delete config.rank,config}static verifyArgs(args){if("number"!=typeof args.kernelSize&&!checkArrayTypeAndLength(args.kernelSize,"number",1,2))throw new errors_ValueError(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(args.kernelSize)}.`)}}Conv2D.className="Conv2D",dist.JFn.registerClass(Conv2D);class Conv3D extends Conv{constructor(args){super(3,args),Conv3D.verifyArgs(args)}getConfig(){const config=super.getConfig();return delete config.rank,config}static verifyArgs(args){if("number"!=typeof args.kernelSize&&(!Array.isArray(args.kernelSize)||1!==args.kernelSize.length&&3!==args.kernelSize.length))throw new errors_ValueError(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(args.kernelSize)}.`)}}Conv3D.className="Conv3D",dist.JFn.registerClass(Conv3D);class Conv2DTranspose extends Conv2D{constructor(args){if(super(args),this.inputSpec=[new InputSpec({ndim:4})],"same"!==this.padding&&"valid"!==this.padding)throw new errors_ValueError(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(inputShape){if(4!==(inputShape=getExactlyOneShape(inputShape)).length)throw new errors_ValueError("Input should have rank 4; Received input shape: "+JSON.stringify(inputShape));const channelAxis="channelsFirst"===this.dataFormat?1:inputShape.length-1;if(null==inputShape[channelAxis])throw new errors_ValueError("The channel dimension of the inputs should be defined. Found `None`.");const inputDim=inputShape[channelAxis],kernelShape=this.kernelSize.concat([this.filters,inputDim]);this.kernel=this.addWeight("kernel",kernelShape,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new InputSpec({ndim:4,axes:{[channelAxis]:inputDim}})],this.built=!0}call(inputs,kwargs){return dist.DZQ(()=>{let input=getExactlyOneTensor(inputs);if(4!==input.shape.length)throw new errors_ValueError(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${input.shape.length}`);const inputShape=input.shape,batchSize=inputShape[0];let hAxis,wAxis;"channelsFirst"===this.dataFormat?(hAxis=2,wAxis=3):(hAxis=1,wAxis=2);const height=inputShape[hAxis],width=inputShape[wAxis],kernelH=this.kernelSize[0],kernelW=this.kernelSize[1],strideH=this.strides[0],strideW=this.strides[1],outputShape=[batchSize,deconvLength(height,strideH,kernelH,this.padding),deconvLength(width,strideW,kernelW,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(input=dist.mgz(input,[0,2,3,1]));let outputs=dist.wX9(input,this.kernel.read(),outputShape,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(outputs=dist.mgz(outputs,[0,3,1,2])),null!=this.bias&&(outputs=biasAdd(outputs,this.bias.read(),this.dataFormat)),null!=this.activation&&(outputs=this.activation.apply(outputs)),outputs})}computeOutputShape(inputShape){const outputShape=(inputShape=getExactlyOneShape(inputShape)).slice();let channelAxis,heightAxis,widthAxis;"channelsFirst"===this.dataFormat?(channelAxis=1,heightAxis=2,widthAxis=3):(channelAxis=3,heightAxis=1,widthAxis=2);const kernelH=this.kernelSize[0],kernelW=this.kernelSize[1],strideH=this.strides[0],strideW=this.strides[1];return outputShape[channelAxis]=this.filters,outputShape[heightAxis]=deconvLength(outputShape[heightAxis],strideH,kernelH,this.padding),outputShape[widthAxis]=deconvLength(outputShape[widthAxis],strideW,kernelW,this.padding),outputShape}getConfig(){const config=super.getConfig();return delete config.dilationRate,config}}Conv2DTranspose.className="Conv2DTranspose",dist.JFn.registerClass(Conv2DTranspose);class Conv3DTranspose extends Conv3D{constructor(args){if(super(args),this.inputSpec=[new InputSpec({ndim:5})],"same"!==this.padding&&"valid"!==this.padding)throw new errors_ValueError(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(inputShape){if(5!==(inputShape=getExactlyOneShape(inputShape)).length)throw new errors_ValueError("Input should have rank 5; Received input shape: "+JSON.stringify(inputShape));const channelAxis="channelsFirst"===this.dataFormat?1:inputShape.length-1;if(null==inputShape[channelAxis])throw new errors_ValueError("The channel dimension of the inputs should be defined. Found `None`.");const inputDim=inputShape[channelAxis],kernelShape=this.kernelSize.concat([this.filters,inputDim]);this.kernel=this.addWeight("kernel",kernelShape,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new InputSpec({ndim:5,axes:{[channelAxis]:inputDim}})],this.built=!0}call(inputs,kwargs){return dist.DZQ(()=>{let input=getExactlyOneTensor(inputs);if(5!==input.shape.length)throw new errors_ValueError(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${input.shape.length}`);const inputShape=input.shape,batchSize=inputShape[0];let hAxis,wAxis,dAxis;"channelsFirst"===this.dataFormat?(dAxis=2,hAxis=3,wAxis=4):(dAxis=1,hAxis=2,wAxis=3);const depth=inputShape[dAxis],height=inputShape[hAxis],width=inputShape[wAxis],kernelD=this.kernelSize[0],kernelH=this.kernelSize[1],kernelW=this.kernelSize[2],strideD=this.strides[0],strideH=this.strides[1],strideW=this.strides[2],outputShape=[batchSize,deconvLength(depth,strideD,kernelD,this.padding),deconvLength(height,strideH,kernelH,this.padding),deconvLength(width,strideW,kernelW,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(input=dist.mgz(input,[0,2,3,4,1]));let outputs=dist.jIJ(input,this.kernel.read(),outputShape,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(outputs=dist.mgz(outputs,[0,4,1,2,3])),null!==this.bias&&(outputs=biasAdd(outputs,this.bias.read(),this.dataFormat)),null!==this.activation&&(outputs=this.activation.apply(outputs)),outputs})}computeOutputShape(inputShape){const outputShape=(inputShape=getExactlyOneShape(inputShape)).slice();let channelAxis,depthAxis,heightAxis,widthAxis;"channelsFirst"===this.dataFormat?(channelAxis=1,depthAxis=2,heightAxis=3,widthAxis=4):(channelAxis=4,depthAxis=1,heightAxis=2,widthAxis=3);const kernelD=this.kernelSize[0],kernelH=this.kernelSize[1],kernelW=this.kernelSize[2],strideD=this.strides[0],strideH=this.strides[1],strideW=this.strides[2];return outputShape[channelAxis]=this.filters,outputShape[depthAxis]=deconvLength(outputShape[depthAxis],strideD,kernelD,this.padding),outputShape[heightAxis]=deconvLength(outputShape[heightAxis],strideH,kernelH,this.padding),outputShape[widthAxis]=deconvLength(outputShape[widthAxis],strideW,kernelW,this.padding),outputShape}getConfig(){const config=super.getConfig();return delete config.dilationRate,config}}Conv3DTranspose.className="Conv3DTranspose",dist.JFn.registerClass(Conv3DTranspose);class SeparableConv extends Conv{constructor(rank,config){if(super(rank,config),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,null==config.filters)throw new errors_ValueError("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(null!=config.kernelInitializer||null!=config.kernelRegularizer||null!=config.kernelConstraint)throw new errors_ValueError("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(null!=config.padding&&"same"!==config.padding&&"valid"!==config.padding)throw new errors_ValueError(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(config.padding)}`);this.depthMultiplier=null==config.depthMultiplier?1:config.depthMultiplier,this.depthwiseInitializer=getInitializer(config.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=getRegularizer(config.depthwiseRegularizer),this.depthwiseConstraint=getConstraint(config.depthwiseConstraint),this.pointwiseInitializer=getInitializer(config.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=getRegularizer(config.pointwiseRegularizer),this.pointwiseConstraint=getConstraint(config.pointwiseConstraint)}build(inputShape){if((inputShape=getExactlyOneShape(inputShape)).length<this.rank+2)throw new errors_ValueError(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank+2}, but received input shape: ${JSON.stringify(inputShape)}`);const channelAxis="channelsFirst"===this.dataFormat?1:inputShape.length-1;if(null==inputShape[channelAxis]||inputShape[channelAxis]<0)throw new errors_ValueError(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(inputShape[channelAxis])}`);const inputDim=inputShape[channelAxis],depthwiseKernelShape=this.kernelSize.concat([inputDim,this.depthMultiplier]),pointwiseKernelShape=[];for(let i=0;i<this.rank;++i)pointwiseKernelShape.push(1);pointwiseKernelShape.push(inputDim*this.depthMultiplier,this.filters);this.depthwiseKernel=this.addWeight("depthwise_kernel",depthwiseKernelShape,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,true,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",pointwiseKernelShape,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,true,this.pointwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,true,this.biasConstraint):this.bias=null,this.inputSpec=[new InputSpec({ndim:this.rank+2,axes:{[channelAxis]:inputDim}})],this.built=!0}call(inputs,kwargs){return(0,dist.DZQ)(()=>{let output;if(inputs=getExactlyOneTensor(inputs),1===this.rank)throw new errors_NotImplementedError("1D separable convolution is not implemented yet.");return 2===this.rank&&("channelsFirst"===this.dataFormat&&(inputs=dist.mgz(inputs,[0,2,3,1])),output=dist.wdz(inputs,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(output=biasAdd(output,this.bias.read(),this.dataFormat)),null!=this.activation&&(output=this.activation.apply(output)),"channelsFirst"===this.dataFormat&&(output=dist.mgz(output,[0,3,1,2])),output})}getConfig(){const config=super.getConfig();return delete config.rank,delete config.kernelInitializer,delete config.kernelRegularizer,delete config.kernelConstraint,config.depthwiseInitializer=serializeInitializer(this.depthwiseInitializer),config.pointwiseInitializer=serializeInitializer(this.pointwiseInitializer),config.depthwiseRegularizer=serializeRegularizer(this.depthwiseRegularizer),config.pointwiseRegularizer=serializeRegularizer(this.pointwiseRegularizer),config.depthwiseConstraint=serializeConstraint(this.depthwiseConstraint),config.pointwiseConstraint=serializeConstraint(this.pointwiseConstraint),config}}SeparableConv.className="SeparableConv";class SeparableConv2D extends SeparableConv{constructor(args){super(2,args)}}SeparableConv2D.className="SeparableConv2D",dist.JFn.registerClass(SeparableConv2D);class Conv1D extends Conv{constructor(args){super(1,args),Conv1D.verifyArgs(args),this.inputSpec=[{ndim:3}]}getConfig(){const config=super.getConfig();return delete config.rank,delete config.dataFormat,config}static verifyArgs(args){if("number"!=typeof args.kernelSize&&!checkArrayTypeAndLength(args.kernelSize,"number",1,1))throw new errors_ValueError(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(args.kernelSize)}.`)}}Conv1D.className="Conv1D",dist.JFn.registerClass(Conv1D);class Cropping2D extends Layer{constructor(args){super(args),"number"==typeof args.cropping?this.cropping=[[args.cropping,args.cropping],[args.cropping,args.cropping]]:"number"==typeof args.cropping[0]?this.cropping=[[args.cropping[0],args.cropping[0]],[args.cropping[1],args.cropping[1]]]:this.cropping=args.cropping,this.dataFormat=void 0===args.dataFormat?"channelsLast":args.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(inputShape){return"channelsFirst"===this.dataFormat?[inputShape[0],inputShape[1],inputShape[2]-this.cropping[0][0]-this.cropping[0][1],inputShape[3]-this.cropping[1][0]-this.cropping[1][1]]:[inputShape[0],inputShape[1]-this.cropping[0][0]-this.cropping[0][1],inputShape[2]-this.cropping[1][0]-this.cropping[1][1],inputShape[3]]}call(inputs,kwargs){return(0,dist.DZQ)(()=>{if(inputs=getExactlyOneTensor(inputs),"channelsLast"===this.dataFormat){const hSliced=sliceAlongAxis(inputs,this.cropping[0][0],inputs.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return sliceAlongAxis(hSliced,this.cropping[1][0],inputs.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{const hSliced=sliceAlongAxis(inputs,this.cropping[0][0],inputs.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return sliceAlongAxis(hSliced,this.cropping[1][0],inputs.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}})}getConfig(){const config={cropping:this.cropping,dataFormat:this.dataFormat},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}Cropping2D.className="Cropping2D",dist.JFn.registerClass(Cropping2D);class UpSampling2D extends Layer{constructor(args){super(args),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==args.size?this.DEFAULT_SIZE:args.size,this.dataFormat=null==args.dataFormat?"channelsLast":args.dataFormat,common_checkDataFormat(this.dataFormat),this.interpolation=null==args.interpolation?"nearest":args.interpolation,function checkInterpolationFormat(value){checkStringTypeUnionValue(VALID_INTERPOLATION_FORMAT_VALUES,"InterpolationFormat",value)}(this.interpolation)}computeOutputShape(inputShape){if("channelsFirst"===this.dataFormat){const height=null==inputShape[2]?null:this.size[0]*inputShape[2],width=null==inputShape[3]?null:this.size[1]*inputShape[3];return[inputShape[0],inputShape[1],height,width]}{const height=null==inputShape[1]?null:this.size[0]*inputShape[1],width=null==inputShape[2]?null:this.size[1]*inputShape[2];return[inputShape[0],height,width,inputShape[3]]}}call(inputs,kwargs){return dist.DZQ(()=>{let input=getExactlyOneTensor(inputs);const inputShape=input.shape;if("channelsFirst"===this.dataFormat){input=dist.mgz(input,[0,2,3,1]);const height=this.size[0]*inputShape[2],width=this.size[1]*inputShape[3],resized="nearest"===this.interpolation?dist.Slp.resizeNearestNeighbor(input,[height,width]):dist.Slp.resizeBilinear(input,[height,width]);return dist.mgz(resized,[0,3,1,2])}{const height=this.size[0]*inputShape[1],width=this.size[1]*inputShape[2];return"nearest"===this.interpolation?dist.Slp.resizeNearestNeighbor(input,[height,width]):dist.Slp.resizeBilinear(input,[height,width])}})}getConfig(){const config={size:this.size,dataFormat:this.dataFormat,interpolation:this.interpolation},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}UpSampling2D.className="UpSampling2D",dist.JFn.registerClass(UpSampling2D);class DepthwiseConv2D extends BaseConv{constructor(args){super(2,args),this.depthwiseKernel=null,this.depthMultiplier=null==args.depthMultiplier?1:args.depthMultiplier,this.depthwiseInitializer=getInitializer(args.depthwiseInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.depthwiseConstraint=getConstraint(args.depthwiseConstraint),this.depthwiseRegularizer=getRegularizer(args.depthwiseRegularizer)}build(inputShape){if((inputShape=getExactlyOneShape(inputShape)).length<4)throw new errors_ValueError(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(inputShape)}.`);const channelAxis="channelsFirst"===this.dataFormat?1:3;if(null==inputShape[channelAxis]||inputShape[channelAxis]<0)throw new errors_ValueError(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${inputShape[channelAxis]}).`);const inputDim=inputShape[channelAxis],depthwiseKernelShape=[this.kernelSize[0],this.kernelSize[1],inputDim,this.depthMultiplier];this.depthwiseKernel=this.addWeight("depthwise_kernel",depthwiseKernelShape,null,this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[inputDim*this.depthMultiplier],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(inputs,kwargs){return(0,dist.DZQ)(()=>{let outputs=function depthwiseConv2d(x,depthwiseKernel,strides=[1,1],padding="valid",dataFormat,dilationRate){return(0,dist.DZQ)(()=>{null==dataFormat&&(dataFormat="channelsLast"),common_checkDataFormat(dataFormat);let y=preprocessConv2DInput(x,dataFormat);if(4!==x.rank)throw new errors_ValueError(`Input for depthwiseConv2d is required to be 4-D, but is instead ${x.rank}-D`);if(4!==depthwiseKernel.rank)throw new errors_ValueError(`depthwiseKernel is required to be 4-D, but is instead ${depthwiseKernel.rank}-D`);return y=dist.Gl3(y,depthwiseKernel,strides,"same"===padding?"same":"valid","NHWC",dilationRate),"channelsFirst"===dataFormat&&(y=dist.mgz(y,[0,3,1,2])),y})}(inputs=getExactlyOneTensor(inputs),this.depthwiseKernel.read(),this.strides,this.padding,this.dataFormat,null);return this.useBias&&(outputs=biasAdd(outputs,this.bias.read(),this.dataFormat)),null!=this.activation&&(outputs=this.activation.apply(outputs)),outputs})}computeOutputShape(inputShape){inputShape=getExactlyOneShape(inputShape);const rows="channelsFirst"===this.dataFormat?inputShape[2]:inputShape[1],cols="channelsFirst"===this.dataFormat?inputShape[3]:inputShape[2],outFilters="channelsFirst"===this.dataFormat?inputShape[1]*this.depthMultiplier:inputShape[3]*this.depthMultiplier,outRows=convOutputLength(rows,this.kernelSize[0],this.padding,this.strides[0]),outCols=convOutputLength(cols,this.kernelSize[1],this.padding,this.strides[1]);return"channelsFirst"===this.dataFormat?[inputShape[0],outFilters,outRows,outCols]:[inputShape[0],outRows,outCols,outFilters]}getConfig(){const config=super.getConfig();return config.depthMultiplier=this.depthMultiplier,config.depthwiseInitializer=serializeInitializer(this.depthwiseInitializer),config.depthwiseRegularizer=serializeRegularizer(this.depthwiseRegularizer),config.depthwiseConstraint=serializeConstraint(this.depthwiseRegularizer),config}}DepthwiseConv2D.className="DepthwiseConv2D",dist.JFn.registerClass(DepthwiseConv2D);var recurrent_console=__webpack_require__("./node_modules/console-browserify/index.js");function standardizeArgs(inputs,initialState,constants,numConstants){if(Array.isArray(inputs)){if(null!=initialState||null!=constants)throw new errors_ValueError("When inputs is an array, neither initialState or constants should be provided");null!=numConstants&&(constants=inputs.slice(inputs.length-numConstants,inputs.length),inputs=inputs.slice(0,inputs.length-numConstants)),inputs.length>1&&(initialState=inputs.slice(1,inputs.length)),inputs=inputs[0]}function toListOrNull(x){return null==x||Array.isArray(x)?x:[x]}return{inputs,initialState:initialState=toListOrNull(initialState),constants:constants=toListOrNull(constants)}}function rnn(stepFunction,inputs,initialStates,goBackwards=!1,mask,constants,unroll=!1,needPerStepOutputs=!1){return dist.DZQ(()=>{const ndim=inputs.shape.length;if(ndim<3)throw new errors_ValueError(`Input should be at least 3D, but is ${ndim}D.`);const axes=[1,0].concat(range(2,ndim));if(inputs=dist.mgz(inputs,axes),null!=constants)throw new errors_NotImplementedError("The rnn() functoin of the deeplearn.js backend does not support constants yet.");unroll&&recurrent_console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."),null!=mask&&((mask=dist.wgE(dist.wgE(mask,"bool"),"float32")).rank===ndim-1&&(mask=dist.UG6(mask,-1)),mask=dist.mgz(mask,axes)),goBackwards&&(inputs=dist.BEg(inputs,0),null!=mask&&(mask=dist.BEg(mask,0)));const perStepOutputs=[];let lastOutput,states=initialStates;const timeSteps=inputs.shape[0],perStepInputs=dist.K$i(inputs);let perStepMasks,outputs;null!=mask&&(perStepMasks=dist.K$i(mask));for(let t=0;t<timeSteps;++t){const currentInput=perStepInputs[t],stepOutputs=dist.DZQ(()=>stepFunction(currentInput,states));if(null==mask)lastOutput=stepOutputs[0],states=stepOutputs[1];else{const maskedOutputs=dist.DZQ(()=>{const stepMask=perStepMasks[t],negStepMask=dist.jbE(dist.P61(stepMask),stepMask);return{output:dist.WQq(dist.lKK(stepOutputs[0],stepMask),dist.lKK(states[0],negStepMask)),newStates:states.map((state,i)=>dist.WQq(dist.lKK(stepOutputs[1][i],stepMask),dist.lKK(state,negStepMask)))}});lastOutput=maskedOutputs.output,states=maskedOutputs.newStates}needPerStepOutputs&&perStepOutputs.push(lastOutput)}if(needPerStepOutputs){const axis=1;outputs=dist.t$z(perStepOutputs,axis)}return[lastOutput,outputs,states]})}class RNN extends Layer{constructor(args){let cell;if(super(args),null==args.cell)throw new errors_ValueError("cell property is missing for the constructor of RNN.");if(cell=Array.isArray(args.cell)?new StackedRNNCells({cells:args.cell}):args.cell,null==cell.stateSize)throw new errors_ValueError("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");this.cell=cell,this.returnSequences=null!=args.returnSequences&&args.returnSequences,this.returnState=null!=args.returnState&&args.returnState,this.goBackwards=null!=args.goBackwards&&args.goBackwards,this._stateful=null!=args.stateful&&args.stateful,this.unroll=null!=args.unroll&&args.unroll,this.supportsMasking=!0,this.inputSpec=[new InputSpec({ndim:3})],this.stateSpec=null,this.states_=null,this.numConstants=null,this.keptStates=[]}getStates(){if(null==this.states_){return range(0,Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1).map(x=>null)}return this.states_}setStates(states){this.states_=states}computeOutputShape(inputShape){isArrayOfShapes(inputShape)&&(inputShape=inputShape[0]);let stateSize=this.cell.stateSize;Array.isArray(stateSize)||(stateSize=[stateSize]);const outputDim=stateSize[0];let outputShape;if(outputShape=this.returnSequences?[inputShape[0],inputShape[1],outputDim]:[inputShape[0],outputDim],this.returnState){const stateShape=[];for(const dim of stateSize)stateShape.push([inputShape[0],dim]);return[outputShape].concat(stateShape)}return outputShape}computeMask(inputs,mask){return dist.DZQ(()=>{Array.isArray(mask)&&(mask=mask[0]);const outputMask=this.returnSequences?mask:null;if(this.returnState){const stateMask=this.states.map(s=>null);return[outputMask].concat(stateMask)}return outputMask})}get states(){if(null==this.states_){const numStates=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1,output=[];for(let i=0;i<numStates;++i)output.push(null);return output}return this.states_}set states(s){this.states_=s}build(inputShape){if(null!=this.numConstants)throw new errors_NotImplementedError("Constants support is not implemented in RNN yet.");isArrayOfShapes(inputShape)&&(inputShape=inputShape[0]);const batchSize=this.stateful?inputShape[0]:null,inputDim=inputShape.slice(2);this.inputSpec[0]=new InputSpec({shape:[batchSize,null,...inputDim]});const stepInputShape=[inputShape[0]].concat(inputShape.slice(2));let stateSize;if(this.cell.build(stepInputShape),stateSize=Array.isArray(this.cell.stateSize)?this.cell.stateSize:[this.cell.stateSize],null!=this.stateSpec){if(!dist.ZSL.arraysEqual(this.stateSpec.map(spec=>spec.shape[spec.shape.length-1]),stateSize))throw new errors_ValueError(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`)}else this.stateSpec=stateSize.map(dim=>new InputSpec({shape:[null,dim]}));this.stateful&&this.resetStates()}resetStates(states,training=!1){(0,dist.DZQ)(()=>{if(!this.stateful)throw new AttributeError("Cannot call resetStates() on an RNN Layer that is not stateful.");const batchSize=this.inputSpec[0].shape[0];if(null==batchSize)throw new errors_ValueError("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.states_)Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(dim=>dist.Ul9([batchSize,dim])):this.states_=[dist.Ul9([batchSize,this.cell.stateSize])];else if(null==states)dist.ASo(this.states_),null!=this.keptStates&&(dist.ASo(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(dim=>dist.Ul9([batchSize,dim])):this.states_[0]=dist.Ul9([batchSize,this.cell.stateSize]);else{if(Array.isArray(states)||(states=[states]),states.length!==this.states_.length)throw new errors_ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${states.length} state value(s). Input received: ${states}`);!0===training?this.keptStates.push(this.states_.slice()):dist.ASo(this.states_);for(let index=0;index<this.states_.length;++index){const value=states[index],dim=Array.isArray(this.cell.stateSize)?this.cell.stateSize[index]:this.cell.stateSize,expectedShape=[batchSize,dim];if(!dist.ZSL.arraysEqual(value.shape,expectedShape))throw new errors_ValueError(`State ${index} is incompatible with layer ${this.name}: expected shape=${expectedShape}, received shape=${value.shape}`);this.states_[index]=value}}this.states_=this.states_.map(state=>dist.aCs(state.clone()))})}apply(inputs,kwargs){let initialState=null==kwargs?null:kwargs.initialState,constants=null==kwargs?null:kwargs.constants;null==kwargs&&(kwargs={});const standardized=standardizeArgs(inputs,initialState,constants,this.numConstants);inputs=standardized.inputs,initialState=standardized.initialState,constants=standardized.constants;let additionalInputs=[],additionalSpecs=[];if(null!=initialState){kwargs.initialState=initialState,additionalInputs=additionalInputs.concat(initialState),this.stateSpec=[];for(const state of initialState)this.stateSpec.push(new InputSpec({shape:state.shape}));additionalSpecs=additionalSpecs.concat(this.stateSpec)}null!=constants&&(kwargs.constants=constants,additionalInputs=additionalInputs.concat(constants),this.numConstants=constants.length);if(additionalInputs[0]instanceof SymbolicTensor){const fullInput=[inputs].concat(additionalInputs),fullInputSpec=this.inputSpec.concat(additionalSpecs),originalInputSpec=this.inputSpec;this.inputSpec=fullInputSpec;const output=super.apply(fullInput,kwargs);return this.inputSpec=originalInputSpec,output}return super.apply(inputs,kwargs)}call(inputs,kwargs){return(0,dist.DZQ)(()=>{const mask=null==kwargs?null:kwargs.mask,training=null==kwargs?null:kwargs.training;let initialState=null==kwargs?null:kwargs.initialState;inputs=getExactlyOneTensor(inputs),null==initialState&&(initialState=this.stateful?this.states_:this.getInitialState(inputs));const numStates=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;if(initialState.length!==numStates)throw new errors_ValueError(`RNN Layer has ${numStates} state(s) but was passed ${initialState.length} initial state(s).`);this.unroll&&recurrent_console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");const cellCallKwargs={training},rnnOutputs=rnn((inputs,states)=>{const outputs=this.cell.call([inputs].concat(states),cellCallKwargs);return[outputs[0],outputs.slice(1)]},inputs,initialState,this.goBackwards,mask,null,this.unroll,this.returnSequences),lastOutput=rnnOutputs[0],outputs=rnnOutputs[1],states=rnnOutputs[2];this.stateful&&this.resetStates(states,training);const output=this.returnSequences?outputs:lastOutput;return this.returnState?[output].concat(states):output})}getInitialState(inputs){return(0,dist.DZQ)(()=>{let initialState=dist.Ul9(inputs.shape);return initialState=dist.czq(initialState,[1,2]),initialState=expandDims(initialState),Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(dim=>dim>1?tfjs_backend_tile(initialState,[1,dim]):initialState):this.cell.stateSize>1?[tfjs_backend_tile(initialState,[1,this.cell.stateSize])]:[initialState]})}get trainableWeights(){return this.trainable?this.cell.trainableWeights:[]}get nonTrainableWeights(){return this.trainable?this.cell.nonTrainableWeights:this.cell.weights}setFastWeightInitDuringBuild(value){super.setFastWeightInitDuringBuild(value),null!=this.cell&&this.cell.setFastWeightInitDuringBuild(value)}getConfig(){const baseConfig=super.getConfig(),config={returnSequences:this.returnSequences,returnState:this.returnState,goBackwards:this.goBackwards,stateful:this.stateful,unroll:this.unroll};null!=this.numConstants&&(config.numConstants=this.numConstants);const cellConfig=this.cell.getConfig();return this.getClassName()===RNN.className&&(config.cell={className:this.cell.getClassName(),config:cellConfig}),Object.assign(Object.assign(Object.assign({},cellConfig),baseConfig),config)}static fromConfig(cls,config,customObjects={}){const cell=deserialize(config.cell,customObjects);return new cls(Object.assign(config,{cell}))}}RNN.className="RNN",dist.JFn.registerClass(RNN);class recurrent_RNNCell extends Layer{}class SimpleRNNCell extends recurrent_RNNCell{constructor(args){super(args),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=args.units,assertPositiveInteger(this.units,"units"),this.activation=getActivation(null==args.activation?this.DEFAULT_ACTIVATION:args.activation),this.useBias=null==args.useBias||args.useBias,this.kernelInitializer=getInitializer(args.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=getInitializer(args.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=getInitializer(args.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=getRegularizer(args.kernelRegularizer),this.recurrentRegularizer=getRegularizer(args.recurrentRegularizer),this.biasRegularizer=getRegularizer(args.biasRegularizer),this.kernelConstraint=getConstraint(args.kernelConstraint),this.recurrentConstraint=getConstraint(args.recurrentConstraint),this.biasConstraint=getConstraint(args.biasConstraint),this.dropout=math_utils_min([1,math_utils_max([0,null==args.dropout?0:args.dropout])]),this.recurrentDropout=math_utils_min([1,math_utils_max([0,null==args.recurrentDropout?0:args.recurrentDropout])]),this.dropoutFunc=args.dropoutFunc,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(inputShape){inputShape=getExactlyOneShape(inputShape),this.kernel=this.addWeight("kernel",[inputShape[inputShape.length-1],this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(inputs,kwargs){return(0,dist.DZQ)(()=>{if(2!==inputs.length)throw new errors_ValueError(`SimpleRNNCell expects 2 input Tensors, got ${inputs.length}.`);let prevOutput=inputs[1];inputs=inputs[0];const training=null!=kwargs.training&&kwargs.training;let h;0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=generateDropoutMask({ones:()=>dist.P61(inputs),rate:this.dropout,training,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=generateDropoutMask({ones:()=>dist.P61(prevOutput),rate:this.recurrentDropout,training,dropoutFunc:this.dropoutFunc}));const dpMask=this.dropoutMask,recDpMask=this.recurrentDropoutMask;h=tfjs_backend_dot(null!=dpMask?dist.lKK(inputs,dpMask):inputs,this.kernel.read()),null!=this.bias&&(h=biasAdd(h,this.bias.read())),null!=recDpMask&&(prevOutput=dist.lKK(prevOutput,recDpMask));let output=dist.WQq(h,tfjs_backend_dot(prevOutput,this.recurrentKernel.read()));return null!=this.activation&&(output=this.activation.apply(output)),[output,output]})}getConfig(){const baseConfig=super.getConfig(),config={units:this.units,activation:serializeActivation(this.activation),useBias:this.useBias,kernelInitializer:serializeInitializer(this.kernelInitializer),recurrentInitializer:serializeInitializer(this.recurrentInitializer),biasInitializer:serializeInitializer(this.biasInitializer),kernelRegularizer:serializeRegularizer(this.kernelRegularizer),recurrentRegularizer:serializeRegularizer(this.recurrentRegularizer),biasRegularizer:serializeRegularizer(this.biasRegularizer),activityRegularizer:serializeRegularizer(this.activityRegularizer),kernelConstraint:serializeConstraint(this.kernelConstraint),recurrentConstraint:serializeConstraint(this.recurrentConstraint),biasConstraint:serializeConstraint(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout};return Object.assign(Object.assign({},baseConfig),config)}}SimpleRNNCell.className="SimpleRNNCell",dist.JFn.registerClass(SimpleRNNCell);class SimpleRNN extends RNN{constructor(args){args.cell=new SimpleRNNCell(args),super(args)}call(inputs,kwargs){return(0,dist.DZQ)(()=>{null!=this.cell.dropoutMask&&(dist.ASo(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(dist.ASo(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const mask=null==kwargs?null:kwargs.mask,training=null==kwargs?null:kwargs.training,initialState=null==kwargs?null:kwargs.initialState;return super.call(inputs,{mask,training,initialState})})}static fromConfig(cls,config){return new cls(config)}}SimpleRNN.className="SimpleRNN",dist.JFn.registerClass(SimpleRNN);class GRUCell extends recurrent_RNNCell{constructor(args){if(super(args),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",args.resetAfter)throw new errors_ValueError("GRUCell does not support reset_after parameter set to true.");this.units=args.units,assertPositiveInteger(this.units,"units"),this.activation=getActivation(void 0===args.activation?this.DEFAULT_ACTIVATION:args.activation),this.recurrentActivation=getActivation(void 0===args.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:args.recurrentActivation),this.useBias=null==args.useBias||args.useBias,this.kernelInitializer=getInitializer(args.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=getInitializer(args.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=getInitializer(args.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=getRegularizer(args.kernelRegularizer),this.recurrentRegularizer=getRegularizer(args.recurrentRegularizer),this.biasRegularizer=getRegularizer(args.biasRegularizer),this.kernelConstraint=getConstraint(args.kernelConstraint),this.recurrentConstraint=getConstraint(args.recurrentConstraint),this.biasConstraint=getConstraint(args.biasConstraint),this.dropout=math_utils_min([1,math_utils_max([0,null==args.dropout?0:args.dropout])]),this.recurrentDropout=math_utils_min([1,math_utils_max([0,null==args.recurrentDropout?0:args.recurrentDropout])]),this.dropoutFunc=args.dropoutFunc,this.implementation=args.implementation,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(inputShape){const inputDim=(inputShape=getExactlyOneShape(inputShape))[inputShape.length-1];this.kernel=this.addWeight("kernel",[inputDim,3*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,3*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[3*this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(inputs,kwargs){return(0,dist.DZQ)(()=>{if(2!==inputs.length)throw new errors_ValueError(`GRUCell expects 2 input Tensors (inputs, h, c), got ${inputs.length}.`);const training=null!=kwargs.training&&kwargs.training;let hTMinus1=inputs[1];inputs=inputs[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=generateDropoutMask({ones:()=>dist.P61(inputs),rate:this.dropout,training,count:3,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=generateDropoutMask({ones:()=>dist.P61(hTMinus1),rate:this.recurrentDropout,training,count:3,dropoutFunc:this.dropoutFunc}));const dpMask=this.dropoutMask,recDpMask=this.recurrentDropoutMask;let z,r,hh;0<this.dropout&&this.dropout<1&&(inputs=dist.lKK(inputs,dpMask[0]));let matrixX=tfjs_backend_dot(inputs,this.kernel.read());this.useBias&&(matrixX=biasAdd(matrixX,this.bias.read())),0<this.recurrentDropout&&this.recurrentDropout<1&&(hTMinus1=dist.lKK(hTMinus1,recDpMask[0]));const recurrentKernelValue=this.recurrentKernel.read(),[rk1,rk2]=dist.lDo(recurrentKernelValue,[2*this.units,this.units],recurrentKernelValue.rank-1),matrixInner=tfjs_backend_dot(hTMinus1,rk1),[xZ,xR,xH]=dist.lDo(matrixX,3,matrixX.rank-1),[recurrentZ,recurrentR]=dist.lDo(matrixInner,2,matrixInner.rank-1);z=this.recurrentActivation.apply(dist.WQq(xZ,recurrentZ)),r=this.recurrentActivation.apply(dist.WQq(xR,recurrentR));const recurrentH=tfjs_backend_dot(dist.lKK(r,hTMinus1),rk2);hh=this.activation.apply(dist.WQq(xH,recurrentH));const h=dist.WQq(dist.lKK(z,hTMinus1),dist.lKK(dist.WQq(1,dist.HZy(z)),hh));return[h,h]})}getConfig(){const baseConfig=super.getConfig(),config={units:this.units,activation:serializeActivation(this.activation),recurrentActivation:serializeActivation(this.recurrentActivation),useBias:this.useBias,kernelInitializer:serializeInitializer(this.kernelInitializer),recurrentInitializer:serializeInitializer(this.recurrentInitializer),biasInitializer:serializeInitializer(this.biasInitializer),kernelRegularizer:serializeRegularizer(this.kernelRegularizer),recurrentRegularizer:serializeRegularizer(this.recurrentRegularizer),biasRegularizer:serializeRegularizer(this.biasRegularizer),activityRegularizer:serializeRegularizer(this.activityRegularizer),kernelConstraint:serializeConstraint(this.kernelConstraint),recurrentConstraint:serializeConstraint(this.recurrentConstraint),biasConstraint:serializeConstraint(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation,resetAfter:!1};return Object.assign(Object.assign({},baseConfig),config)}}GRUCell.className="GRUCell",dist.JFn.registerClass(GRUCell);class GRU extends RNN{constructor(args){0===args.implementation&&recurrent_console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),args.cell=new GRUCell(args),super(args)}call(inputs,kwargs){return(0,dist.DZQ)(()=>{null!=this.cell.dropoutMask&&(dist.ASo(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(dist.ASo(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const mask=null==kwargs?null:kwargs.mask,training=null==kwargs?null:kwargs.training,initialState=null==kwargs?null:kwargs.initialState;return super.call(inputs,{mask,training,initialState})})}static fromConfig(cls,config){return 0===config.implmentation&&(config.implementation=1),new cls(config)}}GRU.className="GRU",dist.JFn.registerClass(GRU);class LSTMCell extends recurrent_RNNCell{constructor(args){super(args),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=args.units,assertPositiveInteger(this.units,"units"),this.activation=getActivation(void 0===args.activation?this.DEFAULT_ACTIVATION:args.activation),this.recurrentActivation=getActivation(void 0===args.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:args.recurrentActivation),this.useBias=null==args.useBias||args.useBias,this.kernelInitializer=getInitializer(args.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=getInitializer(args.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=getInitializer(args.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.unitForgetBias=args.unitForgetBias,this.kernelRegularizer=getRegularizer(args.kernelRegularizer),this.recurrentRegularizer=getRegularizer(args.recurrentRegularizer),this.biasRegularizer=getRegularizer(args.biasRegularizer),this.kernelConstraint=getConstraint(args.kernelConstraint),this.recurrentConstraint=getConstraint(args.recurrentConstraint),this.biasConstraint=getConstraint(args.biasConstraint),this.dropout=math_utils_min([1,math_utils_max([0,null==args.dropout?0:args.dropout])]),this.recurrentDropout=math_utils_min([1,math_utils_max([0,null==args.recurrentDropout?0:args.recurrentDropout])]),this.dropoutFunc=args.dropoutFunc,this.implementation=args.implementation,this.stateSize=[this.units,this.units],this.dropoutMask=null,this.recurrentDropoutMask=null}build(inputShape){var _a;const inputDim=(inputShape=getExactlyOneShape(inputShape))[inputShape.length-1];let biasInitializer;if(this.kernel=this.addWeight("kernel",[inputDim,4*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,4*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){if(this.unitForgetBias){const capturedBiasInit=this.biasInitializer,capturedUnits=this.units;biasInitializer=new((_a=class CustomInit extends Initializer{apply(shape,dtype){const bI=capturedBiasInit.apply([capturedUnits]),bF=(new Ones).apply([capturedUnits]),bCAndH=capturedBiasInit.apply([2*capturedUnits]);return concatAlongFirstAxis(concatAlongFirstAxis(bI,bF),bCAndH)}}).className="CustomInit",_a)}else biasInitializer=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.units],null,biasInitializer,this.biasRegularizer,!0,this.biasConstraint)}else this.bias=null;this.built=!0}call(inputs,kwargs){return(0,dist.DZQ)(()=>{const training=null!=kwargs.training&&kwargs.training;if(3!==inputs.length)throw new errors_ValueError(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${inputs.length}.`);let hTMinus1=inputs[1];const cTMinus1=inputs[2];inputs=inputs[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=generateDropoutMask({ones:()=>dist.P61(inputs),rate:this.dropout,training,count:4,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=generateDropoutMask({ones:()=>dist.P61(hTMinus1),rate:this.recurrentDropout,training,count:4,dropoutFunc:this.dropoutFunc}));const dpMask=this.dropoutMask,recDpMask=this.recurrentDropoutMask;let i,f,c,o;0<this.dropout&&this.dropout<1&&(inputs=dist.lKK(inputs,dpMask[0]));let z=tfjs_backend_dot(inputs,this.kernel.read());0<this.recurrentDropout&&this.recurrentDropout<1&&(hTMinus1=dist.lKK(hTMinus1,recDpMask[0])),z=dist.WQq(z,tfjs_backend_dot(hTMinus1,this.recurrentKernel.read())),this.useBias&&(z=biasAdd(z,this.bias.read()));const[z0,z1,z2,z3]=dist.lDo(z,4,z.rank-1);i=this.recurrentActivation.apply(z0),f=this.recurrentActivation.apply(z1),c=dist.WQq(dist.lKK(f,cTMinus1),dist.lKK(i,this.activation.apply(z2))),o=this.recurrentActivation.apply(z3);const h=dist.lKK(o,this.activation.apply(c));return[h,h,c]})}getConfig(){const baseConfig=super.getConfig(),config={units:this.units,activation:serializeActivation(this.activation),recurrentActivation:serializeActivation(this.recurrentActivation),useBias:this.useBias,kernelInitializer:serializeInitializer(this.kernelInitializer),recurrentInitializer:serializeInitializer(this.recurrentInitializer),biasInitializer:serializeInitializer(this.biasInitializer),unitForgetBias:this.unitForgetBias,kernelRegularizer:serializeRegularizer(this.kernelRegularizer),recurrentRegularizer:serializeRegularizer(this.recurrentRegularizer),biasRegularizer:serializeRegularizer(this.biasRegularizer),activityRegularizer:serializeRegularizer(this.activityRegularizer),kernelConstraint:serializeConstraint(this.kernelConstraint),recurrentConstraint:serializeConstraint(this.recurrentConstraint),biasConstraint:serializeConstraint(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation};return Object.assign(Object.assign({},baseConfig),config)}}LSTMCell.className="LSTMCell",dist.JFn.registerClass(LSTMCell);class LSTM extends RNN{constructor(args){0===args.implementation&&recurrent_console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),args.cell=new LSTMCell(args),super(args)}call(inputs,kwargs){return(0,dist.DZQ)(()=>{null!=this.cell.dropoutMask&&(dist.ASo(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(dist.ASo(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const mask=null==kwargs?null:kwargs.mask,training=null==kwargs?null:kwargs.training,initialState=null==kwargs?null:kwargs.initialState;return super.call(inputs,{mask,training,initialState})})}static fromConfig(cls,config){return 0===config.implmentation&&(config.implementation=1),new cls(config)}}LSTM.className="LSTM",dist.JFn.registerClass(LSTM);class StackedRNNCells extends recurrent_RNNCell{constructor(args){super(args),this.cells=args.cells}get stateSize(){const stateSize=[];for(const cell of this.cells.slice().reverse())Array.isArray(cell.stateSize)?stateSize.push(...cell.stateSize):stateSize.push(cell.stateSize);return stateSize}call(inputs,kwargs){return(0,dist.DZQ)(()=>{let states=inputs.slice(1);const nestedStates=[];for(const cell of this.cells.slice().reverse())Array.isArray(cell.stateSize)?nestedStates.push(states.splice(0,cell.stateSize.length)):nestedStates.push(states.splice(0,1));nestedStates.reverse();const newNestedStates=[];let callInputs;for(let i=0;i<this.cells.length;++i){const cell=this.cells[i];states=nestedStates[i],callInputs=0===i?[inputs[0]].concat(states):[callInputs[0]].concat(states),callInputs=cell.call(callInputs,kwargs),newNestedStates.push(callInputs.slice(1))}states=[];for(const cellStates of newNestedStates.slice().reverse())states.push(...cellStates);return[callInputs[0]].concat(states)})}build(inputShape){let outputDim;isArrayOfShapes(inputShape)&&(inputShape=inputShape[0]),this.cells.forEach((cell,i)=>{nameScope(`RNNCell_${i}`,()=>{cell.build(inputShape),outputDim=Array.isArray(cell.stateSize)?cell.stateSize[0]:cell.stateSize,inputShape=[inputShape[0],outputDim]})}),this.built=!0}getConfig(){const baseConfig=super.getConfig(),config={cells:this.cells.map(cell=>({className:cell.getClassName(),config:cell.getConfig()}))};return Object.assign(Object.assign({},baseConfig),config)}static fromConfig(cls,config,customObjects={}){const cells=[];for(const cellConfig of config.cells)cells.push(deserialize(cellConfig,customObjects));return new cls({cells})}get trainableWeights(){if(!this.trainable)return[];const weights=[];for(const cell of this.cells)weights.push(...cell.trainableWeights);return weights}get nonTrainableWeights(){const weights=[];for(const cell of this.cells)weights.push(...cell.nonTrainableWeights);if(!this.trainable){const trainableWeights=[];for(const cell of this.cells)trainableWeights.push(...cell.trainableWeights);return trainableWeights.concat(weights)}return weights}getWeights(){const weights=[];for(const cell of this.cells)weights.push(...cell.weights);return batchGetValue(weights)}setWeights(weights){const tuples=[];for(const cell of this.cells){const numParams=cell.weights.length,inputWeights=weights.splice(numParams);for(let i=0;i<cell.weights.length;++i)tuples.push([cell.weights[i],inputWeights[i]])}batchSetValue(tuples)}}function generateDropoutMask(args){const{ones,rate,training=!1,count=1,dropoutFunc}=args,droppedInputs=()=>null!=dropoutFunc?dropoutFunc(ones(),rate):dropout(ones(),rate),createMask=()=>inTrainPhase(droppedInputs,ones,training);if(!count||count<=1)return dist.aCs(createMask().clone());return Array(count).fill(void 0).map(createMask).map(m=>dist.aCs(m.clone()))}StackedRNNCells.className="StackedRNNCells",dist.JFn.registerClass(StackedRNNCells);var __rest=function(s,e){var t={};for(var p in s)Object.prototype.hasOwnProperty.call(s,p)&&e.indexOf(p)<0&&(t[p]=s[p]);if(null!=s&&"function"==typeof Object.getOwnPropertySymbols){var i=0;for(p=Object.getOwnPropertySymbols(s);i<p.length;i++)e.indexOf(p[i])<0&&Object.prototype.propertyIsEnumerable.call(s,p[i])&&(t[p[i]]=s[p[i]])}return t};class ConvRNN2D extends RNN{constructor(args){if(args.unroll)throw new errors_NotImplementedError("Unrolling is not possible with convolutional RNNs.");if(Array.isArray(args.cell))throw new errors_NotImplementedError("It is not possible at the moment to stack convolutional cells.");super(args),this.inputSpec=[new InputSpec({ndim:5})]}call(inputs,kwargs){return dist.DZQ(()=>{if(null!=this.cell.dropoutMask&&(dist.ASo(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(dist.ASo(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),kwargs&&kwargs.constants)throw new errors_ValueError("ConvRNN2D cell does not support constants");const mask=null==kwargs?null:kwargs.mask,training=null==kwargs?null:kwargs.training,initialState=null==kwargs?null:kwargs.initialState;return super.call(inputs,{mask,training,initialState})})}computeOutputShape(inputShape){let outShape=this.computeSingleOutputShape(inputShape);return this.returnSequences||(outShape=[outShape[0],...outShape.slice(2)]),this.returnState&&(outShape=[outShape,...Array(2).fill([inputShape[0],...outShape.slice(-3)])]),outShape}getInitialState(inputs){return dist.DZQ(()=>{const{stateSize}=this.cell,inputShape=inputs.shape,outputShape=this.computeSingleOutputShape(inputShape),stateShape=[outputShape[0],...outputShape.slice(2)],initialState=dist.Ul9(stateShape);return Array.isArray(stateSize)?Array(stateSize.length).fill(initialState):[initialState]})}resetStates(states,training=!1){dist.DZQ(()=>{if(!this.stateful)throw new AttributeError("Cannot call resetStates() on an RNN Layer that is not stateful.");const inputShape=this.inputSpec[0].shape,outputShape=this.computeSingleOutputShape(inputShape),stateShape=[outputShape[0],...outputShape.slice(2)];if(null==inputShape[0])throw new errors_ValueError("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.getStates())Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(()=>dist.Ul9(stateShape)):this.states_=[dist.Ul9(stateShape)];else if(null==states)dist.ASo(this.states_),null!=this.keptStates&&(dist.ASo(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(()=>dist.Ul9(stateShape)):this.states_[0]=dist.Ul9(stateShape);else{if(Array.isArray(states)||(states=[states]),states.length!==this.states_.length)throw new errors_ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${states.length} state value(s). Input received: ${states}`);training?this.keptStates.push(this.states_.slice()):dist.ASo(this.states_);for(let index=0;index<this.states_.length;++index){const value=states[index],expectedShape=stateShape;if(!dist.ZSL.arraysEqual(value.shape,expectedShape))throw new errors_ValueError(`State ${index} is incompatible with layer ${this.name}: expected shape=${expectedShape}, received shape=${value.shape}`);this.states_[index]=value}}this.states_=this.states_.map(state=>dist.aCs(state.clone()))})}computeSingleOutputShape(inputShape){const{dataFormat,filters,kernelSize,padding,strides,dilationRate}=this.cell,isChannelsFirst="channelsFirst"===dataFormat,h=inputShape[isChannelsFirst?3:2],w=inputShape[isChannelsFirst?4:3],hOut=convOutputLength(h,kernelSize[0],padding,strides[0],dilationRate[0]),wOut=convOutputLength(w,kernelSize[1],padding,strides[1],dilationRate[1]);return[...inputShape.slice(0,2),...isChannelsFirst?[filters,hOut,wOut]:[hOut,wOut,filters]]}}ConvRNN2D.className="ConvRNN2D";class ConvLSTM2DCell extends LSTMCell{constructor(args){const{filters,kernelSize,strides,padding,dataFormat,dilationRate}=args;super(Object.assign(Object.assign({},args),{units:filters})),this.filters=filters,assertPositiveInteger(this.filters,"filters"),this.kernelSize=normalizeArray(kernelSize,2,"kernelSize"),this.kernelSize.forEach(size=>assertPositiveInteger(size,"kernelSize")),this.strides=normalizeArray(strides||1,2,"strides"),this.strides.forEach(stride=>assertPositiveInteger(stride,"strides")),this.padding=padding||"valid",checkPaddingMode(this.padding),this.dataFormat=dataFormat||"channelsLast",common_checkDataFormat(this.dataFormat),this.dilationRate=normalizeArray(dilationRate||1,2,"dilationRate"),this.dilationRate.forEach(rate=>assertPositiveInteger(rate,"dilationRate"))}build(inputShape){var _a;inputShape=getExactlyOneShape(inputShape);const channelAxis="channelsFirst"===this.dataFormat?1:inputShape.length-1;if(null==inputShape[channelAxis])throw new errors_ValueError(`The channel dimension of the input should be defined. Found ${inputShape[channelAxis]}`);const inputDim=inputShape[channelAxis],kernelShape=this.kernelSize.concat([inputDim,4*this.filters]);this.kernel=this.addWeight("kernel",kernelShape,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint);const recurrentKernelShape=this.kernelSize.concat([this.filters,4*this.filters]);if(this.recurrentKernel=this.addWeight("recurrent_kernel",recurrentKernelShape,null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){let biasInitializer;if(this.unitForgetBias){const init=this.biasInitializer,filters=this.filters;biasInitializer=new((_a=class CustomInit extends Initializer{apply(shape,dtype){return concatenate([init.apply([filters]),dist.SaS([filters]),init.apply([2*filters])])}}).className="CustomInit",_a)}else biasInitializer=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.filters],null,biasInitializer,this.biasRegularizer,!0,this.biasConstraint)}this.built=!0}call(inputs,kwargs){return dist.DZQ(()=>{if(3!==inputs.length)throw new errors_ValueError(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${inputs.length}.`);const training=kwargs.training||!1,x=inputs[0],hTMinus1=inputs[1],cTMinus1=inputs[2];0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=generateDropoutMask({ones:()=>dist.P61(x),rate:this.dropout,training,count:4,dropoutFunc:this.dropoutFunc}));const dropoutMask=this.dropoutMask,applyDropout=(x,mask,index)=>mask&&mask[index]?dist.lKK(mask[index],x):x;let xI=applyDropout(x,dropoutMask,0),xF=applyDropout(x,dropoutMask,1),xC=applyDropout(x,dropoutMask,2),xO=applyDropout(x,dropoutMask,3);0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=generateDropoutMask({ones:()=>dist.P61(hTMinus1),rate:this.recurrentDropout,training,count:4,dropoutFunc:this.dropoutFunc}));const recDropoutMask=this.recurrentDropoutMask;let hI=applyDropout(hTMinus1,recDropoutMask,0),hF=applyDropout(hTMinus1,recDropoutMask,1),hC=applyDropout(hTMinus1,recDropoutMask,2),hO=applyDropout(hTMinus1,recDropoutMask,3);const[kernelI,kernelF,kernelC,kernelO]=dist.lDo(this.kernel.read(),4,3),[biasI,biasF,biasC,biasO]=this.useBias?dist.lDo(this.bias.read(),4):[null,null,null,null];xI=this.inputConv(xI,kernelI,biasI,this.padding),xF=this.inputConv(xF,kernelF,biasF,this.padding),xC=this.inputConv(xC,kernelC,biasC,this.padding),xO=this.inputConv(xO,kernelO,biasO,this.padding);const[recKernelI,recKernelF,recKernelC,recKernelO]=dist.lDo(this.recurrentKernel.read(),4,3);hI=this.recurrentConv(hI,recKernelI),hF=this.recurrentConv(hF,recKernelF),hC=this.recurrentConv(hC,recKernelC),hO=this.recurrentConv(hO,recKernelO);const i=this.recurrentActivation.apply(dist.WQq(xI,hI)),f=this.recurrentActivation.apply(dist.WQq(xF,hF)),c=dist.WQq(dist.lKK(f,cTMinus1),dist.lKK(i,this.activation.apply(dist.WQq(xC,hC)))),h=dist.lKK(this.recurrentActivation.apply(dist.WQq(xO,hO)),this.activation.apply(c));return[h,h,c]})}getConfig(){const _a=super.getConfig(),{units:_}=_a,baseConfig=__rest(_a,["units"]),config={filters:this.filters,kernelSize:this.kernelSize,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,strides:this.strides};return Object.assign(Object.assign({},baseConfig),config)}inputConv(x,w,b,padding){const out=dist.Xtf(x,w,this.strides,padding||"valid","channelsFirst"===this.dataFormat?"NCHW":"NHWC",this.dilationRate);return b?biasAdd(out,b,this.dataFormat):out}recurrentConv(x,w){return dist.Xtf(x,w,1,"same","channelsFirst"===this.dataFormat?"NCHW":"NHWC")}}ConvLSTM2DCell.className="ConvLSTM2DCell",dist.JFn.registerClass(ConvLSTM2DCell);class ConvLSTM2D extends ConvRNN2D{constructor(args){const cell=new ConvLSTM2DCell(args);super(Object.assign(Object.assign({},args),{cell}))}static fromConfig(cls,config){return new cls(config)}}ConvLSTM2D.className="ConvLSTM2D",dist.JFn.registerClass(ConvLSTM2D);class Dropout extends Layer{constructor(args){super(args),this.rate=Math.max(Math.min(args.rate,1),0),this.noiseShape=args.noiseShape,this.seed=args.seed,this.supportsMasking=!0}getNoiseShape(input){if(null==this.noiseShape)return this.noiseShape;const inputShape=input.shape,noiseShape=[];for(let i=0;i<this.noiseShape.length;++i)noiseShape.push(null==this.noiseShape[i]?inputShape[i]:this.noiseShape[i]);return noiseShape}call(inputs,kwargs){return(0,dist.DZQ)(()=>{this.invokeCallHook(inputs,kwargs);const input=getExactlyOneTensor(inputs);if(0<this.rate&&this.rate<1){const training=null!=kwargs.training&&kwargs.training,noiseShape=this.getNoiseShape(input);return inTrainPhase(()=>dropout(input,this.rate,noiseShape,this.seed),()=>input,training)}return inputs})}getConfig(){const config={rate:this.rate,noiseShape:this.noiseShape,seed:this.seed},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}dispose(){return super.dispose()}}Dropout.className="Dropout",dist.JFn.registerClass(Dropout);class SpatialDropout1D extends Dropout{constructor(args){super(args),this.inputSpec=[{ndim:3}]}getNoiseShape(input){const inputShape=input.shape;return[inputShape[0],1,inputShape[2]]}}SpatialDropout1D.className="SpatialDropout1D",dist.JFn.registerClass(SpatialDropout1D);class Dense extends Layer{constructor(args){if(super(args),this.activation=null,this.useBias=!0,this.kernel=null,this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",null==args.batchInputShape&&null==args.inputShape&&null!=args.inputDim){let batchSize=null;null!=args.batchSize&&(batchSize=args.batchSize),this.batchInputShape=[batchSize,args.inputDim]}this.units=args.units,assertPositiveInteger(this.units,"units"),this.activation=getActivation(args.activation),null!=args.useBias&&(this.useBias=args.useBias),this.kernelInitializer=getInitializer(args.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.biasInitializer=getInitializer(args.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelConstraint=getConstraint(args.kernelConstraint),this.biasConstraint=getConstraint(args.biasConstraint),this.kernelRegularizer=getRegularizer(args.kernelRegularizer),this.biasRegularizer=getRegularizer(args.biasRegularizer),this.activityRegularizer=getRegularizer(args.activityRegularizer),this.supportsMasking=!0,this.inputSpec=[{minNDim:2}]}build(inputShape){const inputLastDim=(inputShape=getExactlyOneShape(inputShape))[inputShape.length-1];null==this.kernel&&(this.kernel=this.addWeight("kernel",[inputLastDim,this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint))),this.inputSpec=[{minNDim:2,axes:{[-1]:inputLastDim}}],this.built=!0}computeOutputShape(inputShape){const outputShape=(inputShape=getExactlyOneShape(inputShape)).slice();return outputShape[outputShape.length-1]=this.units,outputShape}call(inputs,kwargs){return(0,dist.DZQ)(()=>{this.invokeCallHook(inputs,kwargs);const input=getExactlyOneTensor(inputs),fusedActivationName=mapActivationToFusedKernel(this.activation.getClassName());let output;return null!=fusedActivationName?output=tfjs_backend_dot(input,this.kernel.read(),fusedActivationName,this.bias?this.bias.read():null):(output=tfjs_backend_dot(input,this.kernel.read()),null!=this.bias&&(output=biasAdd(output,this.bias.read())),null!=this.activation&&(output=this.activation.apply(output))),output})}getConfig(){const config={units:this.units,activation:serializeActivation(this.activation),useBias:this.useBias,kernelInitializer:serializeInitializer(this.kernelInitializer),biasInitializer:serializeInitializer(this.biasInitializer),kernelRegularizer:serializeRegularizer(this.kernelRegularizer),biasRegularizer:serializeRegularizer(this.biasRegularizer),activityRegularizer:serializeRegularizer(this.activityRegularizer),kernelConstraint:serializeConstraint(this.kernelConstraint),biasConstraint:serializeConstraint(this.biasConstraint)},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}Dense.className="Dense",dist.JFn.registerClass(Dense);class Flatten extends Layer{constructor(args){super(args=args||{}),this.inputSpec=[{minNDim:3}],this.dataFormat=args.dataFormat}computeOutputShape(inputShape){inputShape=getExactlyOneShape(inputShape);for(const dim of inputShape.slice(1))if(null==dim)throw new errors_ValueError(`The shape of the input to "Flatten" is not fully defined (got ${inputShape.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);return[inputShape[0],arrayProd(inputShape,1)]}call(inputs,kwargs){return(0,dist.DZQ)(()=>{this.invokeCallHook(inputs,kwargs);let input=getExactlyOneTensor(inputs);if("channelsFirst"===this.dataFormat&&input.rank>1){const permutation=[0];for(let i=2;i<input.rank;++i)permutation.push(i);permutation.push(1),input=(0,dist.mgz)(input,permutation)}return function batchFlatten(x){if(x.rank<=1)throw new errors_ValueError(`batchFlatten requires a minimum rank of 2. Got rank: ${x.rank}.`);const newShape=[x.shape[0],arrayProd(x.shape,1)];return dist.tQQ(x,newShape)}(input)})}getConfig(){const config={};null!=this.dataFormat&&(config.dataFormat=this.dataFormat);const baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}Flatten.className="Flatten",dist.JFn.registerClass(Flatten);class core_Activation extends Layer{constructor(args){super(args),this.supportsMasking=!0,this.activation=getActivation(args.activation)}call(inputs,kwargs){return(0,dist.DZQ)(()=>{this.invokeCallHook(inputs,kwargs);const input=getExactlyOneTensor(inputs);return this.activation.apply(input)})}getConfig(){const config={activation:serializeActivation(this.activation)},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}core_Activation.className="Activation",dist.JFn.registerClass(core_Activation);class RepeatVector extends Layer{constructor(args){super(args),this.n=args.n,this.inputSpec=[{ndim:2}]}computeOutputShape(inputShape){return[inputShape[0],this.n,inputShape[1]]}call(inputs,kwargs){return(0,dist.DZQ)(()=>function repeat(x,n){return(0,dist.DZQ)(()=>{if(2!==x.shape.length)throw new errors_ValueError(`repeat() expects a rank-2 tensor, but received a rank-${x.shape.length} tensor.`);return tfjs_backend_tile(expandDims(x,1),[1,n,1])})}(inputs=getExactlyOneTensor(inputs),this.n))}getConfig(){const config={n:this.n},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}RepeatVector.className="RepeatVector",dist.JFn.registerClass(RepeatVector);class Reshape extends Layer{constructor(args){super(args),this.targetShape=args.targetShape;for(let i=0;i<this.targetShape.length;++i)this.isUnknown(this.targetShape[i])&&(this.targetShape[i]=null)}isUnknown(dim){return dim<0||null==dim}fixUnknownDimension(inputShape,outputShape){const errorMsg="Total size of new array must be unchanged.",finalShape=outputShape.slice();let known=1,unknown=null;for(let i=0;i<finalShape.length;++i){const dim=finalShape[i];if(this.isUnknown(dim)){if(null!==unknown)throw new errors_ValueError("Can only specifiy one unknown dimension.");unknown=i}else known*=dim}const originalSize=arrayProd(inputShape);if(null!==unknown){if(0===known||originalSize%known!==0)throw new errors_ValueError(errorMsg);finalShape[unknown]=originalSize/known}else if(originalSize!==known)throw new errors_ValueError(errorMsg);return finalShape}computeOutputShape(inputShape){let anyUnknownDims=!1;for(let i=0;i<inputShape.length;++i)if(this.isUnknown(inputShape[i])){anyUnknownDims=!0;break}return anyUnknownDims?inputShape.slice(0,1).concat(this.targetShape):inputShape.slice(0,1).concat(this.fixUnknownDimension(inputShape.slice(1),this.targetShape))}call(inputs,kwargs){return(0,dist.DZQ)(()=>{this.invokeCallHook(inputs,kwargs);const input=getExactlyOneTensor(inputs),inputShape=input.shape,outputShape=inputShape.slice(0,1).concat(this.fixUnknownDimension(inputShape.slice(1),this.targetShape));return(0,dist.tQQ)(input,outputShape)})}getConfig(){const config={targetShape:this.targetShape},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}Reshape.className="Reshape",dist.JFn.registerClass(Reshape);class Permute extends Layer{constructor(args){if(super(args),null==args.dims)throw new Error("Required configuration field `dims` is missing during Permute constructor call.");if(!Array.isArray(args.dims))throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${args.dims} instead.`);const expectedSortedIndices=range(1,args.dims.length+1);if(!dist.ZSL.arraysEqual(args.dims.slice().sort(),expectedSortedIndices))throw new Error("Invalid permutation `dims`: "+JSON.stringify(args.dims)+" `dims` must contain consecutive integers starting from 1.");this.dims=args.dims,this.dimsIncludingBatch=[0].concat(this.dims),this.inputSpec=[new InputSpec({ndim:this.dims.length+1})]}computeOutputShape(inputShape){const outputShape=(inputShape=getExactlyOneShape(inputShape)).slice();return this.dims.forEach((dim,i)=>{outputShape[i+1]=inputShape[dim]}),outputShape}call(inputs,kwargs){return(0,dist.mgz)(getExactlyOneTensor(inputs),this.dimsIncludingBatch)}getConfig(){const config={dims:this.dims},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}Permute.className="Permute",dist.JFn.registerClass(Permute);class Masking extends Layer{constructor(args){super(null==args?{}:args),this.supportsMasking=!0,this.maskValue=null!=args?null==args.maskValue?0:args.maskValue:0}computeOutputShape(inputShape){return inputShape}getConfig(){const baseConfig=super.getConfig(),config={maskValue:this.maskValue};return Object.assign(config,baseConfig),config}computeMask(inputs,mask){const input=getExactlyOneTensor(inputs);return(0,dist.bzn)((0,dist.Ec)(input,this.maskValue),-1)}call(inputs,kwargs){return(0,dist.DZQ)(()=>{this.invokeCallHook(inputs,kwargs);const input=getExactlyOneTensor(inputs),booleanMask=(0,dist.bzn)((0,dist.Ec)(input,this.maskValue),-1,!0);return(0,dist.lKK)(input,(0,dist.wgE)(booleanMask,input.dtype))})}}Masking.className="Masking",dist.JFn.registerClass(Masking);class Embedding extends Layer{constructor(args){if(super(args),this.embeddings=null,this.DEFAULT_EMBEDDINGS_INITIALIZER="randomUniform",null==args.batchInputShape&&null==args.inputShape){let batchSize=null;null!=args.batchSize&&(batchSize=args.batchSize),null==args.inputLength?this.batchInputShape=[batchSize,null]:this.batchInputShape=[batchSize].concat(toList(args.inputLength))}this.inputDim=args.inputDim,assertPositiveInteger(this.inputDim,"inputDim"),this.outputDim=args.outputDim,assertPositiveInteger(this.outputDim,"outputDim"),this.embeddingsInitializer=getInitializer(args.embeddingsInitializer||this.DEFAULT_EMBEDDINGS_INITIALIZER),this.embeddingsRegularizer=getRegularizer(args.embeddingsRegularizer),this.activityRegularizer=getRegularizer(args.activityRegularizer),this.embeddingsConstraint=getConstraint(args.embeddingsConstraint),this.maskZero=args.maskZero,this.supportsMasking=args.maskZero,this.inputLength=args.inputLength}build(inputShape){this.embeddings=this.addWeight("embeddings",[this.inputDim,this.outputDim],this.dtype,this.embeddingsInitializer,this.embeddingsRegularizer,!0,this.embeddingsConstraint),this.built=!0}warnOnIncompatibleInputShape(inputShape){}computeMask(inputs,mask){return(0,dist.DZQ)(()=>this.maskZero?(inputs=getExactlyOneTensor(inputs),(0,dist.Ec)(inputs,(0,dist.POl)(inputs))):null)}computeOutputShape(inputShape){if(inputShape=getExactlyOneShape(inputShape),null==this.inputLength)return[...inputShape,this.outputDim];const inLens=toList(this.inputLength);if(inLens.length!==inputShape.length-1)throw new errors_ValueError(`"inputLength" is ${this.inputLength}, but received input shape has shape ${inputShape}`);{let i=0;for(let k=0;k<inLens.length;++k){const s1=inLens[k],s2=inputShape[k+1];if(null!=s1&&null!=s2&&s1!==s2)throw new errors_ValueError(`"inputLength" is ${this.inputLength}, but received input shape has shape ${inputShape}`);null==s1&&(inLens[i]=s2),i++}}return[inputShape[0],...inLens,this.outputDim]}call(inputs,kwargs){return(0,dist.DZQ)(()=>{this.invokeCallHook(inputs,kwargs);let input=getExactlyOneTensor(inputs);"int32"!==input.dtype&&(input=tfjs_backend_cast(input,"int32"));const output=tfjs_backend_gather(this.embeddings.read(),(0,dist.tQQ)(input,[input.size]));return(0,dist.tQQ)(output,getExactlyOneShape(this.computeOutputShape(input.shape)))})}getConfig(){const config={inputDim:this.inputDim,outputDim:this.outputDim,embeddingsInitializer:serializeInitializer(this.embeddingsInitializer),embeddingsRegularizer:serializeRegularizer(this.embeddingsRegularizer),activityRegularizer:serializeRegularizer(this.activityRegularizer),embeddingsConstraint:serializeConstraint(this.embeddingsConstraint),maskZero:this.maskZero,inputLength:this.inputLength},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}Embedding.className="Embedding",dist.JFn.registerClass(Embedding);class Merge extends Layer{constructor(args){super(args||{}),this.supportsMasking=!0}mergeFunction(inputs){throw new errors_NotImplementedError}computeElementwiseOpOutputShape(shape1,shape2){if(null==shape1||null==shape2)return null;if(shape1.length<shape2.length)return this.computeElementwiseOpOutputShape(shape2,shape1);if(0===shape2.length)return shape1;const outputShape=shape1.slice(0,shape1.length-shape2.length);for(let k=0;k<shape2.length;++k){const i=shape1[shape1.length-shape2.length+k],j=shape2[k];if(null==i||null==j||i<0||j<0)outputShape.push(null);else if(1===i)outputShape.push(j);else if(1===j)outputShape.push(i);else{if(i!==j)throw new errors_ValueError("Operands could not be broadcast together with shapes "+JSON.stringify(shape1)+" "+JSON.stringify(shape2));outputShape.push(i)}}return outputShape}build(inputShape){if(Array.isArray(inputShape)&&!Array.isArray(inputShape[0])&&(inputShape=[getExactlyOneShape(inputShape)]),inputShape.length<2)throw new errors_ValueError(`A merge layer should be called on an Array of at least 2 inputs. Got ${inputShape.length} input(s).`);let batchSizes=[];for(const shape of inputShape)null!=shape&&null!==shape[0]&&batchSizes.push(shape[0]);if(batchSizes=generic_utils_unique(batchSizes),batchSizes.length>1)throw new errors_ValueError(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(inputShape)}.`);let outputShape=null==inputShape[0]?null:inputShape[0].slice(1);for(let i=1;i<inputShape.length;++i){const shape=null==inputShape[i]?null:inputShape[i].slice(1);outputShape=this.computeElementwiseOpOutputShape(outputShape,shape)}const allRanks=inputShape.map(shape=>shape.length);-1===inputShape.indexOf(null)&&1===generic_utils_unique(allRanks).length?this.reshapeRequired=!1:this.reshapeRequired=!0}call(inputs,kwargs){return(0,dist.DZQ)(()=>{if(this.reshapeRequired){const reshapedInputs=[],inputDims=inputs.map(input=>input.rank);if(-1===inputDims.indexOf(null)){const maxNDim=math_utils_max(inputDims);for(let x of inputs){const xNDim=x.rank;for(let k=0;k<maxNDim-xNDim;++k)x=expandDims(x,1);reshapedInputs.push(x)}return this.mergeFunction(reshapedInputs)}{let transposed=!1;for(const x of inputs){const xNDim=x.rank;if(null==xNDim){const xShape=x.shape,batchSize=xShape[0],newShape=xShape.slice(1).concat([batchSize]);let xTransposed=dist.tQQ(x,[batchSize].concat(arrayProd(xShape.slice(1))));xTransposed=dist.mgz(xTransposed,[1,0]),xTransposed=dist.tQQ(xTransposed,newShape),reshapedInputs.push(xTransposed),transposed=!0}else if(xNDim>1){const dims=range(1,xNDim).concat([0]);reshapedInputs.push(dist.mgz(x,dims)),transposed=!0}else reshapedInputs.push(x)}let y=this.mergeFunction(reshapedInputs);const yNDim=y.rank;if(transposed)if(null==yNDim){const yShape=y.shape,batchSize=yShape[yShape.length-1],newShape=[batchSize].concat(yShape.slice(0,yShape.length-1));y=dist.tQQ(dist.mgz(dist.tQQ(y,[-1,batchSize]),[1,0]),newShape)}else if(yNDim>1){const dims=[yNDim-1].concat(range(0,yNDim-1));y=dist.mgz(y,dims)}return y}}return this.mergeFunction(inputs)})}computeOutputShape(inputShape){let outputShape;outputShape=null==inputShape[0]?null:inputShape[0].slice(1);for(let i=1;i<inputShape.length;++i){const shape=null==inputShape[i]?null:inputShape[i].slice(1);outputShape=this.computeElementwiseOpOutputShape(outputShape,shape)}let batchSizes=[];for(const shape of inputShape)null!=shape&&null!==shape[0]&&batchSizes.push(shape[0]);return batchSizes=generic_utils_unique(batchSizes),outputShape=1===batchSizes.length?batchSizes.concat(outputShape):[null].concat(outputShape),outputShape}computeMask(inputs,mask){return dist.DZQ(()=>{if(null==mask)return null;if(!Array.isArray(mask))throw new errors_ValueError("`mask` should be an Array");if(!Array.isArray(inputs))throw new errors_ValueError("`inputs` should be an Array");if(mask.length!==inputs.length)throw new errors_ValueError(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${inputs.length} vs ${mask.length})`);if(mask.every(m=>null==m))return null;let output=(mask=mask.map(m=>null==m?m:dist.UG6(m,0)))[0];for(let i=1;i<mask.length-1;++i)output=dist.n76(output,mask[i]);return output})}}class Add extends Merge{constructor(args){super(args)}mergeFunction(inputs){return(0,dist.DZQ)(()=>{let output=inputs[0].clone();for(let i=1;i<inputs.length;++i)output=dist.WQq(output,inputs[i]);return output})}}Add.className="Add",dist.JFn.registerClass(Add);class Multiply extends Merge{constructor(args){super(args)}mergeFunction(inputs){return(0,dist.DZQ)(()=>{let output=inputs[0].clone();for(let i=1;i<inputs.length;++i)output=dist.lKK(output,inputs[i]);return output})}}Multiply.className="Multiply",dist.JFn.registerClass(Multiply);class Average extends Merge{constructor(args){super(args)}mergeFunction(inputs){return(0,dist.DZQ)(()=>{let output=inputs[0].clone();for(let i=1;i<inputs.length;++i)output=dist.WQq(output,inputs[i]);return dist.lKK(1/inputs.length,output)})}}Average.className="Average",dist.JFn.registerClass(Average);class Maximum extends Merge{constructor(args){super(args)}mergeFunction(inputs){return(0,dist.DZQ)(()=>{let output=inputs[0];for(let i=1;i<inputs.length;++i)output=dist.PhQ(output,inputs[i]);return output})}}Maximum.className="Maximum",dist.JFn.registerClass(Maximum);class Minimum extends Merge{constructor(args){super(args)}mergeFunction(inputs){return(0,dist.DZQ)(()=>{let output=inputs[0];for(let i=1;i<inputs.length;++i)output=dist.BpO(output,inputs[i]);return output})}}Minimum.className="Minimum",dist.JFn.registerClass(Minimum);class Concatenate extends Merge{constructor(args){super(args),this.DEFAULT_AXIS=-1,null==args&&(args={}),this.axis=null==args.axis?this.DEFAULT_AXIS:args.axis,this.supportsMasking=!0,this.reshapeRequired=!1}build(inputShape){if(!Array.isArray(inputShape)||!Array.isArray(inputShape[0])||1===inputShape.length)throw new errors_ValueError("A `Concatenate` layer should be called on a list of at least 2 inputs");let allNoneShape=!0;for(const shape of inputShape)if(null!=shape){allNoneShape=!1;break}if(allNoneShape)return;const shapeSet=[];for(let i=0;i<inputShape.length;++i){const shapeWithoutConcatAxis=inputShape[i].slice();shapeWithoutConcatAxis.splice(this.axis,1);let exists=!1;for(const shape of shapeSet)if(dist.ZSL.arraysEqual(shape,shapeWithoutConcatAxis)){exists=!0;break}exists||shapeSet.push(shapeWithoutConcatAxis)}if(shapeSet.length>1)throw new errors_ValueError("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: "+JSON.stringify(inputShape))}mergeFunction(inputs){return(0,dist.DZQ)(()=>concatenate(inputs,this.axis))}computeOutputShape(inputShape){if(!Array.isArray(inputShape)||!Array.isArray(inputShape[0]))throw new errors_ValueError("A `Concatenate` layer should be called on a list of inputs.");const inputShapes=inputShape,outputShape=inputShapes[0].slice(),axis=this.axis<0?outputShape.length+this.axis:this.axis;for(const shape of inputShapes.slice(1)){if(null==outputShape[axis]||null==shape[axis]){outputShape[axis]=null;break}outputShape[axis]+=shape[axis]}return outputShape}computeMask(inputs,mask){if(null==mask)return null;if(!Array.isArray(mask))throw new errors_ValueError("`mask` should be an array for Concatenate");if(!Array.isArray(inputs))throw new errors_ValueError("`inputs` should be an array for Concatenate");if(mask.length!==inputs.length)throw new errors_ValueError(`Mismatch in the length of mask (${mask.length}) and the legnth of inputs (${inputs.length})`);return dist.DZQ(()=>{let allNullMasks=!0;if(mask.forEach(m=>{null==m||(allNullMasks=!1)}),allNullMasks)return null;const outputMasks=[];for(let i=0;i<inputs.length;++i)null==mask[i]?outputMasks.push(dist.wgE(dist.P61(inputs[i]),"bool")):mask[i].rank<inputs[i].rank?outputMasks.push(dist.UG6(mask[i],-1)):outputMasks.push(mask[i]);const concatenatedMasks=dist.xWs(outputMasks,this.axis);return dist.Q7R(concatenatedMasks,-1,!1)})}getConfig(){const config={axis:this.axis},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}function interpretAxis(axis,dim){for(;axis<0;)axis+=dim;return axis}Concatenate.className="Concatenate",dist.JFn.registerClass(Concatenate);class Dot extends Merge{constructor(args){super(args),this.axes=args.axes,this.normalize=null!=args.normalize&&args.normalize,this.supportsMasking=!0,this.reshapeRequired=!1}build(inputShape){dist.ZSL.assert(Array.isArray(inputShape)&&2===inputShape.length&&Array.isArray(inputShape[0])&&Array.isArray(inputShape[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const shape1=inputShape[0],shape2=inputShape[1];if(shape1.length>3||shape2.length>3)throw new errors_NotImplementedError("Dot layer does not support tensors of 4D or higher rank yet.");const axes=this.interpretAxes(shape1,shape2);if(shape1[axes[0]]!==shape2[axes[1]])throw new errors_ValueError(`Dimension incompatibility: ${shape1[axes[0]]} !== ${shape2[axes[1]]}`)}mergeFunction(inputs){if(2!==inputs.length)throw new errors_ValueError(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${inputs.length} input(s).`);let axes,x1=inputs[0],x2=inputs[1];return axes=Array.isArray(this.axes)?this.axes.map((axis,i)=>interpretAxis(axis,inputs[i].shape.length)):[interpretAxis(this.axes,x1.shape.length),interpretAxis(this.axes,x2.shape.length)],this.normalize&&(x1=l2Normalize(x1,axes[0]),x2=l2Normalize(x2,axes[1])),function batchDot(x,y,axes){if(x.shape.length>3||y.shape.length>3)throw new errors_NotImplementedError("batchDot is not implemented for tensors of 4D or higher rank yet");if(dist.ZSL.assert(x.shape.length>=2,()=>`batchDot requires the rank of x to be >= 2, but got ${x.shape.length}`),dist.ZSL.assert(x.shape.length>=2,()=>`batchDot requires the rank of y to be >= 2, but got ${y.shape.length}`),"number"==typeof axes&&(axes=[axes,axes]),"complex64"===x.dtype||"complex64"===y.dtype)throw new errors_NotImplementedError("batchDot is not implemented for complex64-type Tensors yet.");const xNDim=x.shape.length,yNDim=y.shape.length;null==axes&&(axes=[xNDim-1,yNDim-2]);const axesArray=axes;return dist.DZQ(()=>{let diff,out;if(xNDim>yNDim){diff=xNDim-yNDim;const diffShape=[];for(let i=0;i<diff;++i)diffShape.push(1);y=dist.tQQ(y,y.shape.concat(diffShape))}else if(yNDim>xNDim){diff=yNDim-xNDim;const diffShape=[];for(let i=0;i<diff;++i)diffShape.push(1);x=dist.tQQ(x,x.shape.concat(diffShape))}else diff=0;if(2===x.shape.length&&2===y.shape.length)out=axesArray[0]===axesArray[1]?dist.czq(dist.lKK(x,y),axesArray[0]):dist.czq(dist.lKK(dist.mgz(x,[1,0]),y),axesArray[1]);else{const adjX=axesArray[0]!==x.shape.length-1,adjY=axesArray[1]===y.shape.length-1;out=dist.NoW(x,y,adjX,adjY)}if(diff>0){let idx;idx=xNDim>yNDim?xNDim+yNDim-3:xNDim-1;const squeezeAxes=[];for(let i=idx;i<idx+diff;++i)squeezeAxes.push(i);out=dist.r2V(out,squeezeAxes)}return 1===out.shape.length&&(out=dist.UG6(out,1)),out})}(x1,x2,axes)}interpretAxes(shape1,shape2){let axes;return axes=Array.isArray(this.axes)?this.axes:[interpretAxis(this.axes,shape1.length),interpretAxis(this.axes,shape2.length)],axes}computeOutputShape(inputShape){dist.ZSL.assert(Array.isArray(inputShape)&&2===inputShape.length&&Array.isArray(inputShape[0])&&Array.isArray(inputShape[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const shape1=inputShape[0].slice(),shape2=inputShape[1].slice();if(shape1.length>3||shape2.length>3)throw new errors_NotImplementedError("Dot layer does not support tensors of 4D or higher rank yet.");const axes=this.interpretAxes(shape1,shape2);shape1.splice(axes[0],1),shape2.splice(axes[1],1),shape2.splice(0,1);const outputShape=shape1.concat(shape2);return 1===outputShape.length&&outputShape.push(1),outputShape}computeMask(inputs,mask){return null}getConfig(){const config={axes:this.axes,normalize:this.normalize},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}Dot.className="Dot",dist.JFn.registerClass(Dot);class GaussianNoise extends Layer{constructor(args){super(args),this.supportsMasking=!0,this.stddev=args.stddev}computeOutputShape(inputShape){return inputShape}getConfig(){const baseConfig=super.getConfig(),config={stddev:this.stddev};return Object.assign(config,baseConfig),config}call(inputs,kwargs){return(0,dist.DZQ)(()=>{this.invokeCallHook(inputs,kwargs);const input=getExactlyOneTensor(inputs);return inTrainPhase(()=>(0,dist.WQq)(randomNormal(input.shape,0,this.stddev),input),()=>input,kwargs.training||!1)})}}GaussianNoise.className="GaussianNoise",dist.JFn.registerClass(GaussianNoise);class GaussianDropout extends Layer{constructor(args){super(args),this.supportsMasking=!0,this.rate=args.rate}computeOutputShape(inputShape){return inputShape}getConfig(){const baseConfig=super.getConfig(),config={rate:this.rate};return Object.assign(config,baseConfig),config}call(inputs,kwargs){return(0,dist.DZQ)(()=>{this.invokeCallHook(inputs,kwargs);const input=getExactlyOneTensor(inputs);if(this.rate>0&&this.rate<1){return inTrainPhase(()=>{const stddev=Math.sqrt(this.rate/(1-this.rate));return(0,dist.lKK)(input,randomNormal(input.shape,1,stddev))},()=>input,kwargs.training||!1)}return input})}}GaussianDropout.className="GaussianDropout",dist.JFn.registerClass(GaussianDropout);class AlphaDropout extends Layer{constructor(args){super(args),this.supportsMasking=!0,this.rate=args.rate,this.noiseShape=args.noiseShape}_getNoiseShape(inputs){return this.noiseShape||getExactlyOneTensor(inputs).shape}computeOutputShape(inputShape){return inputShape}getConfig(){const baseConfig=super.getConfig(),config={rate:this.rate};return Object.assign(config,baseConfig),config}call(inputs,kwargs){return(0,dist.DZQ)(()=>{if(this.rate<1&&this.rate>0){const noiseShape=this._getNoiseShape(inputs),droppedInputs=()=>{const input=getExactlyOneTensor(inputs),alphaP=-1.7580993408473766;let keptIdx=(0,dist.DQN)((0,dist.YeY)(noiseShape),this.rate);keptIdx=tfjs_backend_cast(keptIdx,"float32");const a=((1-this.rate)*(1+this.rate*alphaP**2))**-.5,b=-a*alphaP*this.rate,x=(0,dist.WQq)((0,dist.lKK)(input,keptIdx),(0,dist.lKK)((0,dist.WQq)(keptIdx,-1),alphaP));return(0,dist.WQq)((0,dist.lKK)(x,a),b)};return inTrainPhase(droppedInputs,()=>getExactlyOneTensor(inputs),kwargs.training||!1)}return inputs})}}function batchNormalization(x,mean,variance,beta,gamma,epsilon=.001){let out;if(2===x.rank)out=dist.BFc(x,mean,variance,beta,gamma,epsilon);else if(3===x.rank)out=dist.kSi(x,mean,variance,beta,gamma,epsilon);else{if(4!==x.rank)throw new errors_NotImplementedError(`batchNormalization is not implemented for array of rank ${x.rank} yet`);out=dist.T5N(x,mean,variance,beta,gamma,epsilon)}return out}function normalizeBatchInTraining(x,gamma,beta,reductionAxes,epsilon=.001){return dist.ZSL.arraysEqual(reductionAxes.slice().sort(),range(0,x.rank-1))?function regularNormalizeBatchInTraining(x,gamma,beta,reductionAxes,epsilon=.001){return(0,dist.DZQ)(()=>{const meanAndVariance=dist.Clk(x,reductionAxes),mean=meanAndVariance.mean,variance=meanAndVariance.variance;return[batchNormalization(x,mean,variance,beta,gamma,epsilon),mean,variance]})}(x,gamma,beta,reductionAxes,epsilon):function broadcastNormalizeBatchInTraining(x,gamma,beta,reductionAxes,epsilon=.001){return(0,dist.DZQ)(()=>{const meanAndVariance=dist.Clk(x,reductionAxes),mean=meanAndVariance.mean,variance=meanAndVariance.variance,targetShape=[];for(const axis of range(0,x.rank))-1!==reductionAxes.indexOf(axis)?targetShape.push(1):targetShape.push(x.shape[axis]);const broadcastMean=(0,dist.tQQ)(mean,targetShape),broadcastVariance=(0,dist.tQQ)(variance,targetShape),broadcastGamma=null==gamma?null:(0,dist.tQQ)(gamma,targetShape),broadcastBeta=null==beta?null:(0,dist.tQQ)(beta,targetShape);return[batchNormalization(x,broadcastMean,broadcastVariance,broadcastBeta,broadcastGamma,epsilon),mean,variance]})}(x,gamma,beta,reductionAxes,epsilon)}AlphaDropout.className="AlphaDropout",dist.JFn.registerClass(AlphaDropout);class BatchNormalization extends Layer{constructor(args){null==args&&(args={}),super(args),this.supportsMasking=!0,this.axis=null==args.axis?-1:args.axis,this.momentum=null==args.momentum?.99:args.momentum,this.epsilon=null==args.epsilon?.001:args.epsilon,this.center=null==args.center||args.center,this.scale=null==args.scale||args.scale,this.betaInitializer=getInitializer(args.betaInitializer||"zeros"),this.gammaInitializer=getInitializer(args.gammaInitializer||"ones"),this.movingMeanInitializer=getInitializer(args.movingMeanInitializer||"zeros"),this.movingVarianceInitializer=getInitializer(args.movingVarianceInitializer||"ones"),this.betaConstraint=getConstraint(args.betaConstraint),this.gammaConstraint=getConstraint(args.gammaConstraint),this.betaRegularizer=getRegularizer(args.betaRegularizer),this.gammaRegularizer=getRegularizer(args.gammaRegularizer)}build(inputShape){inputShape=getExactlyOneShape(inputShape);const axis=this.axis>=0?this.axis:this.axis+inputShape.length,dim=inputShape[axis];if(null==dim)throw new errors_ValueError(`Axis ${axis} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(inputShape)}.`);this.inputSpec=[new InputSpec({ndim:inputShape.length,axes:{[axis]:dim}})];const shape=[dim];this.scale&&(this.gamma=this.addWeight("gamma",shape,null,this.gammaInitializer,this.gammaRegularizer,!0,this.gammaConstraint)),this.center&&(this.beta=this.addWeight("beta",shape,null,this.betaInitializer,this.betaRegularizer,!0,this.betaConstraint)),this.movingMean=this.addWeight("moving_mean",shape,null,this.movingMeanInitializer,null,!1),this.movingVariance=this.addWeight("moving_variance",shape,null,this.movingVarianceInitializer,null,!1),this.built=!0}call(inputs,kwargs){return(0,dist.DZQ)(()=>{const training=null!=kwargs.training&&kwargs.training,input=getExactlyOneTensor(inputs),inputShape=input.shape,ndim=inputShape.length,reductionAxes=range(0,ndim),axis=this.axis>=0?this.axis:this.axis+ndim;reductionAxes.splice(axis,1);const broadcastShape=pyListRepeat(1,ndim);broadcastShape[axis]=inputShape[axis];const sortedReductionAxes=reductionAxes.slice();sortedReductionAxes.sort();const needsBroadcasting=!dist.ZSL.arraysEqual(sortedReductionAxes,range(0,ndim).slice(0,ndim-1));if(!training)return(()=>{if(needsBroadcasting){const broadcastMovingMean=(0,dist.tQQ)(this.movingMean.read(),broadcastShape),broadcastMovingVariance=(0,dist.tQQ)(this.movingVariance.read(),broadcastShape),broadcastBeta=this.center?(0,dist.tQQ)(this.beta.read(),broadcastShape):null,broadcastGamma=this.scale?(0,dist.tQQ)(this.gamma.read(),broadcastShape):null;return batchNormalization(input,broadcastMovingMean,broadcastMovingVariance,broadcastBeta,broadcastGamma,this.epsilon)}return batchNormalization(input,this.movingMean.read(),this.movingVariance.read(),null==this.beta?null:this.beta.read(),null==this.gamma?null:this.gamma.read(),this.epsilon)})();const[normedTraining,mean,variance]=normalizeBatchInTraining(input,this.gamma.read(),this.beta.read(),reductionAxes,this.epsilon),doMovingAverage=(variable,value,momentum)=>{dist.DZQ(()=>{const decay=1-momentum,origValue=variable.read(),updateDelta=dist.lKK(dist.jbE(origValue,value),decay);variable.write(dist.jbE(origValue,updateDelta))})};return(()=>{doMovingAverage(this.movingMean,mean,this.momentum),doMovingAverage(this.movingVariance,variance,this.momentum)})(),normedTraining})}getConfig(){const config={axis:this.axis,momentum:this.momentum,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:serializeInitializer(this.betaInitializer),gammaInitializer:serializeInitializer(this.gammaInitializer),movingMeanInitializer:serializeInitializer(this.movingMeanInitializer),movingVarianceInitializer:serializeInitializer(this.movingVarianceInitializer),betaRegularizer:serializeRegularizer(this.betaRegularizer),gammaRegularizer:serializeRegularizer(this.gammaRegularizer),betaConstraint:serializeConstraint(this.betaConstraint),gammaConstraint:serializeConstraint(this.gammaConstraint)},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}BatchNormalization.className="BatchNormalization",dist.JFn.registerClass(BatchNormalization);class LayerNormalization extends Layer{constructor(args){if(null==args&&(args={}),super(args),this.axis=null==args.axis?-1:args.axis,"number"==typeof this.axis){if(!Number.isInteger(this.axis))throw new Error(`Expected axis to be an integer, but received ${this.axis}`)}else{if(!Array.isArray(this.axis))throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);for(const axis of this.axis)if(!Number.isInteger(axis))throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`)}this.epsilon=null==args.epsilon?.001:args.epsilon,this.center=null==args.center||args.center,this.scale=null==args.scale||args.scale,this.betaInitializer=getInitializer(args.betaInitializer||"zeros"),this.gammaInitializer=getInitializer(args.gammaInitializer||"ones"),this.betaRegularizer=getRegularizer(args.betaRegularizer),this.gammaRegularizer=getRegularizer(args.gammaRegularizer),this.supportsMasking=!0}build(inputShape){const nDims=(inputShape=getExactlyOneShape(inputShape)).length;"number"==typeof this.axis&&(this.axis=[this.axis]);for(let i=0;i<this.axis.length;++i)this.axis[i]<0&&(this.axis[i]+=nDims);for(const axis of this.axis)if(axis<0||axis>=nDims)throw new Error(`Invalid axis: ${axis}`);if(this.axis.length!==generic_utils_unique(this.axis).length)throw new Error(`Found duplicate axes in: ${this.axis}`);const paramShape=this.axis.map(axis=>inputShape[axis]);this.scale?this.gamma=this.addWeight("gamma",paramShape,"float32",this.gammaInitializer,this.gammaRegularizer,true):this.gamma=null,this.center?this.beta=this.addWeight("beta",paramShape,"float32",this.betaInitializer,this.betaRegularizer,true):this.beta=null,this.built=!0}call(inputs,kwargs){const input=getExactlyOneTensor(inputs),inputShape=input.shape,nDims=inputShape.length;return(0,dist.DZQ)(()=>{let{mean,variance}=(0,dist.Clk)(input,this.axis,!0);const broadcastShape=pyListRepeat(1,nDims);for(const dim of this.axis)broadcastShape[dim]=inputShape[dim];const broadcast=v=>null!=v&&v.shape.length!==nDims?dist.tQQ(v,broadcastShape):v;let scale=this.scale?broadcast(this.gamma.read()):null,offset=this.center?broadcast(this.beta.read()):null;const momentsTiling=[],scaleOffsetTiling=[];for(let i=0;i<nDims;++i)-1!==this.axis.indexOf(i)?(momentsTiling.push(inputShape[i]),scaleOffsetTiling.push(1)):(momentsTiling.push(1),scaleOffsetTiling.push(inputShape[i]));return mean=dist.Vsq(mean,momentsTiling),variance=dist.Vsq(variance,momentsTiling),null!=scale&&(scale=dist.Vsq(scale,scaleOffsetTiling)),null!=offset&&(offset=dist.Vsq(offset,scaleOffsetTiling)),batchNormalization(input,mean,variance,offset,scale,this.epsilon)})}getConfig(){const config={axis:this.axis,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:serializeInitializer(this.betaInitializer),gammaInitializer:serializeInitializer(this.gammaInitializer),betaRegularizer:serializeRegularizer(this.betaRegularizer),gammaRegularizer:serializeRegularizer(this.gammaRegularizer)},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}LayerNormalization.className="LayerNormalization",dist.JFn.registerClass(LayerNormalization);class ZeroPadding2D extends Layer{constructor(args){if(null==args&&(args={}),super(args),this.dataFormat=null==args.dataFormat?"channelsLast":args.dataFormat,null==args.padding)this.padding=[[1,1],[1,1]];else if("number"==typeof args.padding)this.padding=[[args.padding,args.padding],[args.padding,args.padding]];else{if(args.padding=args.padding,2!==args.padding.length)throw new errors_ValueError(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${args.padding.length} array.`);let heightPadding,widthPadding;if("number"==typeof args.padding[0])heightPadding=[args.padding[0],args.padding[0]],widthPadding=[args.padding[1],args.padding[1]];else{if(args.padding=args.padding,2!==args.padding[0].length)throw new errors_ValueError(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${args.padding[0].length} array.`);if(heightPadding=args.padding[0],2!==args.padding[1].length)throw new errors_ValueError(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${args.padding[1].length} array.`);widthPadding=args.padding[1]}this.padding=[heightPadding,widthPadding]}this.inputSpec=[new InputSpec({ndim:4})]}computeOutputShape(inputShape){let rows,cols;return inputShape=getExactlyOneShape(inputShape),"channelsFirst"===this.dataFormat?(rows=null!=inputShape[2]&&inputShape[2]>=0?inputShape[2]+this.padding[0][0]+this.padding[0][1]:null,cols=null!=inputShape[3]&&inputShape[3]>=0?inputShape[3]+this.padding[1][0]+this.padding[1][1]:null,[inputShape[0],inputShape[1],rows,cols]):(rows=null!=inputShape[1]&&inputShape[1]>=0?inputShape[1]+this.padding[0][0]+this.padding[0][1]:null,cols=null!=inputShape[2]&&inputShape[2]>=0?inputShape[2]+this.padding[1][0]+this.padding[1][1]:null,[inputShape[0],rows,cols,inputShape[3]])}call(inputs,kwargs){return(0,dist.DZQ)(()=>function spatial2dPadding(x,padding,dataFormat){return(0,dist.DZQ)(()=>{if(4!==x.rank)throw new errors_ValueError(`temporalPadding expects input tensor to be 4-D, but received a ${x.rank}-D tensor.`);if(null==padding&&(padding=[[1,1],[1,1]]),2!==padding.length||2!==padding[0].length||2!==padding[1].length)throw new errors_ValueError("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");if(null==dataFormat&&(dataFormat="channelsLast"),"channelsLast"!==dataFormat&&"channelsFirst"!==dataFormat)throw new errors_ValueError(`Unknown data format: ${dataFormat}. Supported data formats are 'channelsLast' and 'channelsFirst.`);let pattern;return pattern="channelsFirst"===dataFormat?[[0,0],[0,0],padding[0],padding[1]]:[[0,0],padding[0],padding[1],[0,0]],dist.eVF(x,pattern)})}(getExactlyOneTensor(inputs),this.padding,this.dataFormat))}getConfig(){const config={padding:this.padding,dataFormat:this.dataFormat},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}function pool2d(x,poolSize,strides,padding,dataFormat,poolMode){return(0,dist.DZQ)(()=>{let y;common_checkDataFormat(dataFormat),checkPoolMode(poolMode),checkPaddingMode(padding),null==strides&&(strides=[1,1]),null==padding&&(padding="valid"),null==dataFormat&&(dataFormat="channelsLast"),null==poolMode&&(poolMode="max"),x=preprocessConv2DInput(x,dataFormat);const paddingString="same"===padding?"same":"valid";return y="max"===poolMode?dist.jgi(x,poolSize,strides,paddingString):dist.$jT(x,poolSize,strides,paddingString),"channelsFirst"===dataFormat&&(y=dist.mgz(y,[0,3,1,2])),y})}function pool3d(x,poolSize,strides,padding,dataFormat,poolMode){return(0,dist.DZQ)(()=>{let y;common_checkDataFormat(dataFormat),checkPoolMode(poolMode),checkPaddingMode(padding),null==strides&&(strides=[1,1,1]),null==padding&&(padding="valid"),null==dataFormat&&(dataFormat="channelsLast"),null==poolMode&&(poolMode="max"),x=preprocessConv3DInput(x,dataFormat);const paddingString="same"===padding?"same":"valid";return y="max"===poolMode?dist.NYV(x,poolSize,strides,paddingString):dist.sub(x,poolSize,strides,paddingString),"channelsFirst"===dataFormat&&(y=dist.mgz(y,[0,4,1,2,3])),y})}ZeroPadding2D.className="ZeroPadding2D",dist.JFn.registerClass(ZeroPadding2D);class Pooling1D extends Layer{constructor(args){if(null==args.poolSize&&(args.poolSize=2),super(args),"number"==typeof args.poolSize)this.poolSize=[args.poolSize];else{if(!Array.isArray(args.poolSize)||1!==args.poolSize.length||"number"!=typeof args.poolSize[0])throw new errors_ValueError(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(args.poolSize)}`);this.poolSize=args.poolSize}if(assertPositiveInteger(this.poolSize,"poolSize"),null==args.strides)this.strides=this.poolSize;else if("number"==typeof args.strides)this.strides=[args.strides];else{if(!Array.isArray(args.strides)||1!==args.strides.length||"number"!=typeof args.strides[0])throw new errors_ValueError(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(args.strides)}`);this.strides=args.strides}assertPositiveInteger(this.strides,"strides"),this.padding=null==args.padding?"valid":args.padding,checkPaddingMode(this.padding),this.inputSpec=[new InputSpec({ndim:3})]}computeOutputShape(inputShape){const length=convOutputLength((inputShape=getExactlyOneShape(inputShape))[1],this.poolSize[0],this.padding,this.strides[0]);return[inputShape[0],length,inputShape[2]]}call(inputs,kwargs){return(0,dist.DZQ)(()=>{this.invokeCallHook(inputs,kwargs),inputs=expandDims(getExactlyOneTensor(inputs),2);const output=this.poolingFunction(getExactlyOneTensor(inputs),[this.poolSize[0],1],[this.strides[0],1],this.padding,"channelsLast");return dist.r2V(output,[2])})}getConfig(){const config={poolSize:this.poolSize,padding:this.padding,strides:this.strides},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}class MaxPooling1D extends Pooling1D{constructor(args){super(args)}poolingFunction(inputs,poolSize,strides,padding,dataFormat){return common_checkDataFormat(dataFormat),checkPaddingMode(padding),pool2d(inputs,poolSize,strides,padding,dataFormat,"max")}}MaxPooling1D.className="MaxPooling1D",dist.JFn.registerClass(MaxPooling1D);class AveragePooling1D extends Pooling1D{constructor(args){super(args)}poolingFunction(inputs,poolSize,strides,padding,dataFormat){return common_checkDataFormat(dataFormat),checkPaddingMode(padding),pool2d(inputs,poolSize,strides,padding,dataFormat,"avg")}}AveragePooling1D.className="AveragePooling1D",dist.JFn.registerClass(AveragePooling1D);class Pooling2D extends Layer{constructor(args){if(null==args.poolSize&&(args.poolSize=[2,2]),super(args),this.poolSize=Array.isArray(args.poolSize)?args.poolSize:[args.poolSize,args.poolSize],null==args.strides)this.strides=this.poolSize;else if(Array.isArray(args.strides)){if(2!==args.strides.length)throw new errors_ValueError(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${args.strides.length}.`);this.strides=args.strides}else this.strides=[args.strides,args.strides];assertPositiveInteger(this.poolSize,"poolSize"),assertPositiveInteger(this.strides,"strides"),this.padding=null==args.padding?"valid":args.padding,this.dataFormat=null==args.dataFormat?"channelsLast":args.dataFormat,common_checkDataFormat(this.dataFormat),checkPaddingMode(this.padding),this.inputSpec=[new InputSpec({ndim:4})]}computeOutputShape(inputShape){inputShape=getExactlyOneShape(inputShape);let rows="channelsFirst"===this.dataFormat?inputShape[2]:inputShape[1],cols="channelsFirst"===this.dataFormat?inputShape[3]:inputShape[2];return rows=convOutputLength(rows,this.poolSize[0],this.padding,this.strides[0]),cols=convOutputLength(cols,this.poolSize[1],this.padding,this.strides[1]),"channelsFirst"===this.dataFormat?[inputShape[0],inputShape[1],rows,cols]:[inputShape[0],rows,cols,inputShape[3]]}call(inputs,kwargs){return(0,dist.DZQ)(()=>(this.invokeCallHook(inputs,kwargs),this.poolingFunction(getExactlyOneTensor(inputs),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const config={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}class MaxPooling2D extends Pooling2D{constructor(args){super(args)}poolingFunction(inputs,poolSize,strides,padding,dataFormat){return common_checkDataFormat(dataFormat),checkPaddingMode(padding),pool2d(inputs,poolSize,strides,padding,dataFormat,"max")}}MaxPooling2D.className="MaxPooling2D",dist.JFn.registerClass(MaxPooling2D);class AveragePooling2D extends Pooling2D{constructor(args){super(args)}poolingFunction(inputs,poolSize,strides,padding,dataFormat){return common_checkDataFormat(dataFormat),checkPaddingMode(padding),pool2d(inputs,poolSize,strides,padding,dataFormat,"avg")}}AveragePooling2D.className="AveragePooling2D",dist.JFn.registerClass(AveragePooling2D);class Pooling3D extends Layer{constructor(args){if(null==args.poolSize&&(args.poolSize=[2,2,2]),super(args),this.poolSize=Array.isArray(args.poolSize)?args.poolSize:[args.poolSize,args.poolSize,args.poolSize],null==args.strides)this.strides=this.poolSize;else if(Array.isArray(args.strides)){if(3!==args.strides.length)throw new errors_ValueError(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${args.strides.length}.`);this.strides=args.strides}else this.strides=[args.strides,args.strides,args.strides];assertPositiveInteger(this.poolSize,"poolSize"),assertPositiveInteger(this.strides,"strides"),this.padding=null==args.padding?"valid":args.padding,this.dataFormat=null==args.dataFormat?"channelsLast":args.dataFormat,common_checkDataFormat(this.dataFormat),checkPaddingMode(this.padding),this.inputSpec=[new InputSpec({ndim:5})]}computeOutputShape(inputShape){inputShape=getExactlyOneShape(inputShape);let depths="channelsFirst"===this.dataFormat?inputShape[2]:inputShape[1],rows="channelsFirst"===this.dataFormat?inputShape[3]:inputShape[2],cols="channelsFirst"===this.dataFormat?inputShape[4]:inputShape[3];return depths=convOutputLength(depths,this.poolSize[0],this.padding,this.strides[0]),rows=convOutputLength(rows,this.poolSize[1],this.padding,this.strides[1]),cols=convOutputLength(cols,this.poolSize[2],this.padding,this.strides[2]),"channelsFirst"===this.dataFormat?[inputShape[0],inputShape[1],depths,rows,cols]:[inputShape[0],depths,rows,cols,inputShape[4]]}call(inputs,kwargs){return(0,dist.DZQ)(()=>(this.invokeCallHook(inputs,kwargs),this.poolingFunction(getExactlyOneTensor(inputs),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const config={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}class MaxPooling3D extends Pooling3D{constructor(args){super(args)}poolingFunction(inputs,poolSize,strides,padding,dataFormat){return common_checkDataFormat(dataFormat),checkPaddingMode(padding),pool3d(inputs,poolSize,strides,padding,dataFormat,"max")}}MaxPooling3D.className="MaxPooling3D",dist.JFn.registerClass(MaxPooling3D);class AveragePooling3D extends Pooling3D{constructor(args){super(args)}poolingFunction(inputs,poolSize,strides,padding,dataFormat){return common_checkDataFormat(dataFormat),checkPaddingMode(padding),pool3d(inputs,poolSize,strides,padding,dataFormat,"avg")}}AveragePooling3D.className="AveragePooling3D",dist.JFn.registerClass(AveragePooling3D);class GlobalPooling1D extends Layer{constructor(args){super(args),this.inputSpec=[new InputSpec({ndim:3})]}computeOutputShape(inputShape){return[inputShape[0],inputShape[2]]}call(inputs,kwargs){throw new errors_NotImplementedError}}class GlobalAveragePooling1D extends GlobalPooling1D{constructor(args){super(args||{})}call(inputs,kwargs){return(0,dist.DZQ)(()=>{const input=getExactlyOneTensor(inputs);return dist.i2o(input,1)})}}GlobalAveragePooling1D.className="GlobalAveragePooling1D",dist.JFn.registerClass(GlobalAveragePooling1D);class GlobalMaxPooling1D extends GlobalPooling1D{constructor(args){super(args||{})}call(inputs,kwargs){return(0,dist.DZQ)(()=>{const input=getExactlyOneTensor(inputs);return dist.T9B(input,1)})}}GlobalMaxPooling1D.className="GlobalMaxPooling1D",dist.JFn.registerClass(GlobalMaxPooling1D);class GlobalPooling2D extends Layer{constructor(args){super(args),this.dataFormat=null==args.dataFormat?"channelsLast":args.dataFormat,common_checkDataFormat(this.dataFormat),this.inputSpec=[new InputSpec({ndim:4})]}computeOutputShape(inputShape){return"channelsLast"===this.dataFormat?[inputShape[0],inputShape[3]]:[inputShape[0],inputShape[1]]}call(inputs,kwargs){throw new errors_NotImplementedError}getConfig(){const config={dataFormat:this.dataFormat},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}class GlobalAveragePooling2D extends GlobalPooling2D{call(inputs,kwargs){return(0,dist.DZQ)(()=>{const input=getExactlyOneTensor(inputs);return"channelsLast"===this.dataFormat?dist.i2o(input,[1,2]):dist.i2o(input,[2,3])})}}GlobalAveragePooling2D.className="GlobalAveragePooling2D",dist.JFn.registerClass(GlobalAveragePooling2D);class GlobalMaxPooling2D extends GlobalPooling2D{call(inputs,kwargs){return(0,dist.DZQ)(()=>{const input=getExactlyOneTensor(inputs);return"channelsLast"===this.dataFormat?dist.T9B(input,[1,2]):dist.T9B(input,[2,3])})}}GlobalMaxPooling2D.className="GlobalMaxPooling2D",dist.JFn.registerClass(GlobalMaxPooling2D);class Wrapper extends Layer{constructor(args){super(args),this.layer=args.layer}build(inputShape){this.built=!0}get trainable(){return null!=this.layer&&this.layer.trainable}set trainable(value){null!=this.layer&&(this.layer.trainable=value)}get trainableWeights(){return this.layer.trainableWeights}get nonTrainableWeights(){return this.layer.nonTrainableWeights}get updates(){return this.layer._updates}get losses(){return this.layer.losses}getWeights(){return this.layer.getWeights()}setWeights(weights){this.layer.setWeights(weights)}getConfig(){const config={layer:{className:this.layer.getClassName(),config:this.layer.getConfig()}},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}setFastWeightInitDuringBuild(value){super.setFastWeightInitDuringBuild(value),null!=this.layer&&this.layer.setFastWeightInitDuringBuild(value)}static fromConfig(cls,config,customObjects={}){const layer=deserialize(config.layer,customObjects);delete config.layer;const newConfig={layer};return Object.assign(newConfig,config),new cls(newConfig)}}class TimeDistributed extends Wrapper{constructor(args){super(args),this.supportsMasking=!0}build(inputShape){if((inputShape=getExactlyOneShape(inputShape)).length<3)throw new errors_ValueError(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(inputShape)}`);this.inputSpec=[{shape:inputShape}];const childInputShape=[inputShape[0]].concat(inputShape.slice(2));this.layer.built||(this.layer.build(childInputShape),this.layer.built=!0),super.build(inputShape)}computeOutputShape(inputShape){const childInputShape=[(inputShape=getExactlyOneShape(inputShape))[0]].concat(inputShape.slice(2)),childOutputShape=this.layer.computeOutputShape(childInputShape),timesteps=inputShape[1];return[childOutputShape[0],timesteps].concat(childOutputShape.slice(1))}call(inputs,kwargs){return(0,dist.DZQ)(()=>rnn((inputs,states)=>[getExactlyOneTensor(this.layer.call(inputs,kwargs)),[]],inputs=getExactlyOneTensor(inputs),[],!1,null,null,!1,!0)[1])}}TimeDistributed.className="TimeDistributed",dist.JFn.registerClass(TimeDistributed);class Bidirectional extends Wrapper{constructor(args){super(args);const layerConfig=args.layer.getConfig(),forwDict={};forwDict.className=args.layer.getClassName(),forwDict.config=layerConfig,this.forwardLayer=deserialize(forwDict),layerConfig.goBackwards=!0!==layerConfig.goBackwards;const backDict={};if(backDict.className=args.layer.getClassName(),backDict.config=layerConfig,this.backwardLayer=deserialize(backDict),this.forwardLayer.name="forward_"+this.forwardLayer.name,this.backwardLayer.name="backward_"+this.backwardLayer.name,this.mergeMode=void 0===args.mergeMode?"concat":args.mergeMode,function checkBidirectionalMergeMode(value){checkStringTypeUnionValue(VALID_BIDIRECTIONAL_MERGE_MODES,"BidirectionalMergeMode",value)}(this.mergeMode),args.weights)throw new errors_NotImplementedError("weights support is not implemented for Bidirectional layer yet.");this._stateful=args.layer.stateful,this.returnSequences=args.layer.returnSequences,this.returnState=args.layer.returnState,this.supportsMasking=!0,this._trainable=!0,this.inputSpec=args.layer.inputSpec,this.numConstants=null}get trainable(){return this._trainable}set trainable(value){this._trainable=value,null!=this.forwardLayer&&(this.forwardLayer.trainable=value),null!=this.backwardLayer&&(this.backwardLayer.trainable=value)}getWeights(){return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights())}setWeights(weights){const numWeights=weights.length,numeightsOver2=Math.floor(numWeights/2);this.forwardLayer.setWeights(weights.slice(0,numeightsOver2)),this.backwardLayer.setWeights(weights.slice(numeightsOver2))}computeOutputShape(inputShape){let outputShape,outputShapes,stateShape,layerShapes=this.forwardLayer.computeOutputShape(inputShape);return Array.isArray(layerShapes)&&Array.isArray(layerShapes[0])||(layerShapes=[layerShapes]),this.returnState?(stateShape=layerShapes.slice(1),outputShape=layerShapes[0]):outputShape=layerShapes[0],"concat"===this.mergeMode?(outputShape[outputShape.length-1]*=2,outputShapes=[outputShape]):outputShapes=null==this.mergeMode?[outputShape,outputShape.slice()]:[outputShape],this.returnState?null==this.mergeMode?outputShapes.concat(stateShape).concat(stateShape.slice()):[outputShape].concat(stateShape).concat(stateShape.slice()):singletonOrArray(outputShapes)}apply(inputs,kwargs){let initialState=null==kwargs?null:kwargs.initialState,constants=null==kwargs?null:kwargs.constants;null==kwargs&&(kwargs={});const standardized=standardizeArgs(inputs,initialState,constants,this.numConstants);if(inputs=standardized.inputs,initialState=standardized.initialState,constants=standardized.constants,Array.isArray(inputs)&&(initialState=inputs.slice(1),inputs=inputs[0]),(null==initialState||0===initialState.length)&&null==constants)return super.apply(inputs,kwargs);const additionalInputs=[],additionalSpecs=[];if(null!=initialState){const numStates=initialState.length;if(numStates%2>0)throw new errors_ValueError("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");kwargs.initialState=initialState,additionalInputs.push(...initialState);const stateSpecs=initialState.map(state=>new InputSpec({shape:state.shape}));this.forwardLayer.stateSpec=stateSpecs.slice(0,numStates/2),this.backwardLayer.stateSpec=stateSpecs.slice(numStates/2),additionalSpecs.push(...stateSpecs)}if(null!=constants)throw new errors_NotImplementedError("Support for constants in Bidirectional layers is not implemented yet.");const isSymbolicTensor=additionalInputs[0]instanceof SymbolicTensor;for(const tensor of additionalInputs)if(tensor instanceof SymbolicTensor!==isSymbolicTensor)throw new errors_ValueError("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");if(isSymbolicTensor){const fullInput=[inputs].concat(additionalInputs),fullInputSpec=this.inputSpec.concat(additionalSpecs),originalInputSpec=this.inputSpec;this.inputSpec=fullInputSpec;const output=super.apply(fullInput,kwargs);return this.inputSpec=originalInputSpec,output}return super.apply(inputs,kwargs)}call(inputs,kwargs){return(0,dist.DZQ)(()=>{const initialState=kwargs.initialState;let y,yRev,states,output;if(null==initialState)y=this.forwardLayer.call(inputs,kwargs),yRev=this.backwardLayer.call(inputs,kwargs);else{const forwardState=initialState.slice(0,initialState.length/2),backwardState=initialState.slice(initialState.length/2);y=this.forwardLayer.call(inputs,Object.assign(kwargs,{initialState:forwardState})),yRev=this.backwardLayer.call(inputs,Object.assign(kwargs,{initialState:backwardState}))}return this.returnState&&(Array.isArray(y)&&(states=y.slice(1).concat(yRev.slice(1))),y=y[0],yRev=yRev[0]),this.returnSequences&&(yRev=dist.BEg(yRev,1)),"concat"===this.mergeMode?output=concatenate([y,yRev]):"sum"===this.mergeMode?output=dist.WQq(y,yRev):"ave"===this.mergeMode?output=dist.lKK(.5,dist.WQq(y,yRev)):"mul"===this.mergeMode?output=dist.lKK(y,yRev):null==this.mergeMode&&(output=[y,yRev]),this.returnState?null==this.mergeMode?output.concat(states):[output].concat(states):output})}resetStates(states){this.forwardLayer.resetStates(),this.backwardLayer.resetStates()}build(inputShape){nameScope(this.forwardLayer.name,()=>{this.forwardLayer.build(inputShape)}),nameScope(this.backwardLayer.name,()=>{this.backwardLayer.build(inputShape)}),this.built=!0}computeMask(inputs,mask){let outputMask;if(Array.isArray(mask)&&(mask=mask[0]),outputMask=this.returnSequences?null==this.mergeMode?[mask,mask]:mask:null==this.mergeMode?[null,null]:null,this.returnState){const stateMask=this.forwardLayer.states.map(state=>null);return Array.isArray(outputMask)?outputMask.concat(stateMask).concat(stateMask):[outputMask].concat(stateMask).concat(stateMask)}return outputMask}get trainableWeights(){return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights)}get nonTrainableWeights(){return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights)}setFastWeightInitDuringBuild(value){super.setFastWeightInitDuringBuild(value),null!=this.forwardLayer&&this.forwardLayer.setFastWeightInitDuringBuild(value),null!=this.backwardLayer&&this.backwardLayer.setFastWeightInitDuringBuild(value)}getConfig(){const config={mergeMode:this.mergeMode},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}static fromConfig(cls,config){const rnnLayer=deserialize(config.layer);if(delete config.layer,null!=config.numConstants)throw new errors_NotImplementedError("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");const newConfig=config;return newConfig.layer=rnnLayer,new cls(newConfig)}}Bidirectional.className="Bidirectional",dist.JFn.registerClass(Bidirectional);class Rescaling extends Layer{constructor(args){super(args),this.scale=args.scale,args.offset?this.offset=args.offset:this.offset=0}getConfig(){const config={scale:this.scale,offset:this.offset},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}call(inputs,kwargs){return(0,dist.DZQ)(()=>("float32"!==(inputs=getExactlyOneTensor(inputs)).dtype&&(inputs=tfjs_backend_cast(inputs,"float32")),(0,dist.WQq)((0,dist.lKK)(inputs,this.scale),this.offset)))}}Rescaling.className="Rescaling",dist.JFn.registerClass(Rescaling);const{resizeBilinear,cropAndResize}=dist.Slp;class CenterCrop extends Layer{constructor(args){super(args),this.height=args.height,this.width=args.width}centerCrop(inputs,hBuffer,wBuffer,height,width,inputHeight,inputWidth,dtype){return(0,dist.DZQ)(()=>{let input,isRank3=!1;const bound=[hBuffer/inputHeight,wBuffer/inputWidth,(height+hBuffer)/inputHeight,(width+wBuffer)/inputWidth],boxesArr=[];3===inputs.rank?(isRank3=!0,input=(0,dist.t$z)([inputs])):input=inputs;for(let i=0;i<input.shape[0];i++)boxesArr.push(bound);const boxes=(0,dist.OEK)(boxesArr,[boxesArr.length,4]),boxInd=(0,dist.y17)(0,boxesArr.length,1,"int32"),cropped=cropAndResize(input,boxes,boxInd,[height,width],"nearest");return tfjs_backend_cast(isRank3?getExactlyOneTensor((0,dist.K$i)(cropped)):cropped,dtype)})}upsize(inputs,height,width,dtype){return(0,dist.DZQ)(()=>tfjs_backend_cast(resizeBilinear(inputs,[height,width]),dtype))}call(inputs,kwargs){return(0,dist.DZQ)(()=>{const rankedInputs=getExactlyOneTensor(inputs),dtype=rankedInputs.dtype,inputShape=rankedInputs.shape,inputHeight=inputShape[inputShape.length-3],inputWidth=inputShape[inputShape.length-2];let hBuffer=0;inputHeight!==this.height&&(hBuffer=Math.floor((inputHeight-this.height)/2));let wBuffer=0;return inputWidth!==this.width&&(wBuffer=Math.floor((inputWidth-this.width)/2),0===wBuffer&&(wBuffer=1)),hBuffer>=0&&wBuffer>=0?this.centerCrop(rankedInputs,hBuffer,wBuffer,this.height,this.width,inputHeight,inputWidth,dtype):this.upsize(inputs,this.height,this.width,dtype)})}getConfig(){const config={height:this.height,width:this.width},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}computeOutputShape(inputShape){const hAxis=(inputShape=getExactlyOneShape(inputShape)).length-3,wAxis=inputShape.length-2;return inputShape[hAxis]=this.height,inputShape[wAxis]=this.width,inputShape}}CenterCrop.className="CenterCrop",dist.JFn.registerClass(CenterCrop);class CategoryEncoding extends Layer{constructor(args){super(args),this.numTokens=args.numTokens,args.outputMode?this.outputMode=args.outputMode:this.outputMode="multiHot"}getConfig(){const config={numTokens:this.numTokens,outputMode:this.outputMode},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}computeOutputShape(inputShape){return null==(inputShape=getExactlyOneShape(inputShape))?[this.numTokens]:"oneHot"===this.outputMode&&1!==inputShape[inputShape.length-1]?(inputShape.push(this.numTokens),inputShape):(inputShape[inputShape.length-1]=this.numTokens,inputShape)}call(inputs,kwargs){return(0,dist.DZQ)(()=>{let countWeights;if("int32"!==(inputs=getExactlyOneTensor(inputs)).dtype&&(inputs=tfjs_backend_cast(inputs,"int32")),void 0!==kwargs.countWeights){if("count"!==this.outputMode)throw new errors_ValueError(`countWeights is not used when outputMode !== count.\n              Received countWeights=${kwargs.countWeights}`);countWeights=getExactlyOneTensor(kwargs.countWeights)}const maxValue=(0,dist.T9B)(inputs),minValue=(0,dist.jkA)(inputs),greaterEqualMax=(0,dist.rhj)(this.numTokens,maxValue).bufferSync().get(0),greaterMin=(0,dist.DQN)(minValue,0).bufferSync().get(0);if(!greaterEqualMax||!greaterMin)throw new errors_ValueError(`Input values must be between 0 < values <= numTokens with numTokens=${this.numTokens}`);return function encodeCategoricalInputs(inputs,outputMode,depth,weights){let input=getExactlyOneTensor(inputs);if("int32"!==input.dtype&&(input=tfjs_backend_cast(input,"int32")),"int"===outputMode)return input;const originalShape=input.shape;if(0===input.rank&&(input=(0,dist.UG6)(input,-1)),"oneHot"===outputMode&&1!==input.shape[input.shape.length-1]&&(input=(0,dist.UG6)(input,-1)),input.rank>2)throw new errors_ValueError(`When outputMode is not int, maximum output rank is 2 Received outputMode ${outputMode} and input shape ${originalShape} which would result in output rank ${input.rank}.`);const binaryOutput=["multiHot","oneHot"].includes(outputMode),denseBincountInput=input;let binCounts;if(binCounts=void 0!==weights&&"count"===outputMode?(0,dist.aOp)(denseBincountInput,weights,depth,binaryOutput):(0,dist.aOp)(denseBincountInput,[],depth,binaryOutput),"tfIdf"!==outputMode)return binCounts;if(weights)return(0,dist.lKK)(binCounts,weights);throw new errors_ValueError("When outputMode is 'tfIdf', weights must be provided.")}(inputs,this.outputMode,this.numTokens,countWeights)})}}CategoryEncoding.className="CategoryEncoding",dist.JFn.registerClass(CategoryEncoding);const INTERPOLATION_METHODS=new Set(["bilinear","nearest"]);class Resizing extends Layer{constructor(args){if(super(args),this.height=args.height,this.width=args.width,args.interpolation){if(!INTERPOLATION_METHODS.has(args.interpolation))throw new errors_ValueError(`Invalid interpolation parameter: ${args.interpolation} is not implemented`);this.interpolation=args.interpolation}else this.interpolation="bilinear";this.cropToAspectRatio=Boolean(args.cropToAspectRatio)}computeOutputShape(inputShape){const numChannels=(inputShape=getExactlyOneShape(inputShape))[2];return[this.height,this.width,numChannels]}getConfig(){const config={height:this.height,width:this.width,interpolation:this.interpolation,cropToAspectRatio:this.cropToAspectRatio},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}call(inputs,kwargs){return(0,dist.DZQ)(()=>{const size=[this.height,this.width];if("bilinear"===this.interpolation)return dist.Slp.resizeBilinear(inputs,size,!this.cropToAspectRatio);if("nearest"===this.interpolation)return dist.Slp.resizeNearestNeighbor(inputs,size,!this.cropToAspectRatio);throw new Error(`Interpolation is ${this.interpolation} but only ${[...INTERPOLATION_METHODS]} are supported`)})}}Resizing.className="Resizing",dist.JFn.registerClass(Resizing);class RandomSeed{constructor(seed){this.seed=seed}next(){if(void 0!==this.seed)return this.seed++}}RandomSeed.className="RandomSeed";class BaseRandomLayer extends Layer{constructor(args){super(args),this.randomGenerator=new RandomSeed(args.seed)}getConfig(){const config={seed:this.randomGenerator.seed},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}}BaseRandomLayer.className="BaseRandomLayer";const random_width_INTERPOLATION_METHODS=new Set(["bilinear","nearest"]);class RandomWidth extends BaseRandomLayer{constructor(args){super(args);const{factor,interpolation="bilinear"}=args;if(this.factor=factor,Array.isArray(this.factor)&&2===this.factor.length)this.widthLower=this.factor[0],this.widthUpper=this.factor[1];else{if(Array.isArray(this.factor)||!(this.factor>0))throw new errors_ValueError(`Invalid factor: ${this.factor}. Must be positive number or tuple of 2 numbers`);this.widthLower=-this.factor,this.widthUpper=this.factor}if(this.widthLower<-1||this.widthUpper<-1)throw new errors_ValueError(`factor must have values larger than -1. Got: ${this.factor}`);if(this.widthUpper<this.widthLower)throw new errors_ValueError(`factor cannot have upper bound less than lower bound.\n        Got upper bound: ${this.widthUpper}.\n        Got lower bound: ${this.widthLower}\n      `);if(interpolation){if(!random_width_INTERPOLATION_METHODS.has(interpolation))throw new errors_ValueError(`Invalid interpolation parameter: ${interpolation} is not implemented`);this.interpolation=interpolation}}getConfig(){const config={factor:this.factor,interpolation:this.interpolation},baseConfig=super.getConfig();return Object.assign(config,baseConfig),config}computeOutputShape(inputShape){const numChannels=(inputShape=getExactlyOneShape(inputShape))[2];return[this.imgHeight,-1,numChannels]}call(inputs,kwargs){return(0,dist.DZQ)(()=>{const input=getExactlyOneTensor(inputs);this.imgHeight=input.shape[input.shape.length-3];const imgWidth=input.shape[input.shape.length-2];this.widthFactor=(0,dist.YeY)([1],1+this.widthLower,1+this.widthUpper,"float32",this.randomGenerator.next());let adjustedWidth=this.widthFactor.dataSync()[0]*imgWidth;adjustedWidth=Math.round(adjustedWidth);const size=[this.imgHeight,adjustedWidth];switch(this.interpolation){case"bilinear":return dist.Slp.resizeBilinear(inputs,size);case"nearest":return dist.Slp.resizeNearestNeighbor(inputs,size);default:throw new Error(`Interpolation is ${this.interpolation}\n          but only ${[...random_width_INTERPOLATION_METHODS]} are supported`)}})}}function inputLayer(args){return new InputLayer(args)}function exports_layers_elu(args){return new ELU(args)}function reLU(args){return new ReLU(args)}function leakyReLU(args){return new LeakyReLU(args)}function exports_layers_prelu(args){return new PReLU(args)}function exports_layers_softmax(args){return new Softmax(args)}function thresholdedReLU(args){return new ThresholdedReLU(args)}function exports_layers_conv1d(args){return new Conv1D(args)}function exports_layers_conv2d(args){return new Conv2D(args)}function conv2dTranspose(args){return new Conv2DTranspose(args)}function exports_layers_conv3d(args){return new Conv3D(args)}function conv3dTranspose(args){return new Conv3DTranspose(args)}function separableConv2d(args){return new SeparableConv2D(args)}function cropping2D(args){return new Cropping2D(args)}function upSampling2d(args){return new UpSampling2D(args)}function exports_layers_depthwiseConv2d(args){return new DepthwiseConv2D(args)}function activation(args){return new core_Activation(args)}function dense(args){return new Dense(args)}function exports_layers_dropout(args){return new Dropout(args)}function spatialDropout1d(args){return new SpatialDropout1D(args)}function exports_layers_flatten(args){return new Flatten(args)}function repeatVector(args){return new RepeatVector(args)}function exports_layers_reshape(args){return new Reshape(args)}function permute(args){return new Permute(args)}function embedding(args){return new Embedding(args)}function exports_layers_add(args){return new Add(args)}function exports_layers_average(args){return new Average(args)}function exports_layers_concatenate(args){return new Concatenate(args)}function exports_layers_maximum(args){return new Maximum(args)}function exports_layers_minimum(args){return new Minimum(args)}function exports_layers_multiply(args){return new Multiply(args)}function exports_layers_dot(args){return new Dot(args)}function exports_layers_batchNormalization(args){return new BatchNormalization(args)}function layerNormalization(args){return new LayerNormalization(args)}function zeroPadding2d(args){return new ZeroPadding2D(args)}function averagePooling1d(args){return new AveragePooling1D(args)}function avgPool1d(args){return averagePooling1d(args)}function avgPooling1d(args){return averagePooling1d(args)}function averagePooling2d(args){return new AveragePooling2D(args)}function avgPool2d(args){return averagePooling2d(args)}function avgPooling2d(args){return averagePooling2d(args)}function averagePooling3d(args){return new AveragePooling3D(args)}function avgPool3d(args){return averagePooling3d(args)}function avgPooling3d(args){return averagePooling3d(args)}function globalAveragePooling1d(args){return new GlobalAveragePooling1D(args)}function globalAveragePooling2d(args){return new GlobalAveragePooling2D(args)}function globalMaxPooling1d(args){return new GlobalMaxPooling1D(args)}function globalMaxPooling2d(args){return new GlobalMaxPooling2D(args)}function maxPooling1d(args){return new MaxPooling1D(args)}function maxPooling2d(args){return new MaxPooling2D(args)}function maxPooling3d(args){return new MaxPooling3D(args)}function gru(args){return new GRU(args)}function gruCell(args){return new GRUCell(args)}function lstm(args){return new LSTM(args)}function lstmCell(args){return new LSTMCell(args)}function simpleRNN(args){return new SimpleRNN(args)}function simpleRNNCell(args){return new SimpleRNNCell(args)}function convLstm2d(args){return new ConvLSTM2D(args)}function convLstm2dCell(args){return new ConvLSTM2DCell(args)}function exports_layers_rnn(args){return new RNN(args)}function stackedRNNCells(args){return new StackedRNNCells(args)}function bidirectional(args){return new Bidirectional(args)}function timeDistributed(args){return new TimeDistributed(args)}RandomWidth.className="RandomWidth",dist.JFn.registerClass(RandomWidth);const globalMaxPool1d=globalMaxPooling1d,globalMaxPool2d=globalMaxPooling2d,maxPool1d=maxPooling1d,maxPool2d=maxPooling2d;function gaussianNoise(args){return new GaussianNoise(args)}function gaussianDropout(args){return new GaussianDropout(args)}function alphaDropout(args){return new AlphaDropout(args)}function masking(args){return new Masking(args)}function rescaling(args){return new Rescaling(args)}function centerCrop(args){return new CenterCrop(args)}function resizing(args){return new Resizing(args)}function categoryEncoding(args){return new CategoryEncoding(args)}function randomWidth(args){return new RandomWidth(args)}function exports_metrics_binaryAccuracy(yTrue,yPred){return binaryAccuracy(yTrue,yPred)}function exports_metrics_binaryCrossentropy(yTrue,yPred){return metrics_binaryCrossentropy(yTrue,yPred)}function exports_metrics_sparseCategoricalAccuracy(yTrue,yPred){return sparseCategoricalAccuracy(yTrue,yPred)}function exports_metrics_categoricalAccuracy(yTrue,yPred){return categoricalAccuracy(yTrue,yPred)}function exports_metrics_categoricalCrossentropy(yTrue,yPred){return metrics_categoricalCrossentropy(yTrue,yPred)}function exports_metrics_precision(yTrue,yPred){return precision(yTrue,yPred)}function exports_metrics_recall(yTrue,yPred){return recall(yTrue,yPred)}function exports_metrics_cosineProximity(yTrue,yPred){return cosineProximity(yTrue,yPred)}function exports_metrics_meanAbsoluteError(yTrue,yPred){return meanAbsoluteError(yTrue,yPred)}function exports_metrics_meanAbsolutePercentageError(yTrue,yPred){return meanAbsolutePercentageError(yTrue,yPred)}function exports_metrics_MAPE(yTrue,yPred){return meanAbsolutePercentageError(yTrue,yPred)}function exports_metrics_mape(yTrue,yPred){return meanAbsolutePercentageError(yTrue,yPred)}function exports_metrics_meanSquaredError(yTrue,yPred){return meanSquaredError(yTrue,yPred)}function exports_metrics_MSE(yTrue,yPred){return meanSquaredError(yTrue,yPred)}function exports_metrics_mse(yTrue,yPred){return meanSquaredError(yTrue,yPred)}function exports_metrics_r2Score(yTrue,yPred){return function r2Score(yTrue,yPred){return(0,dist.DZQ)(()=>{const sumSquaresResiduals=yTrue.sub(yPred).square().sum(),sumSquares=yTrue.sub(yTrue.mean()).square().sum();return dist.d_2(1).sub(sumSquaresResiduals.div(sumSquares))})}(yTrue,yPred)}function l1l2(config){return new L1L2(config)}function exports_regularizers_l1(config){return function l1(args){return assertObjectArgs(args),new L1L2({l1:null!=args?args.l1:null,l2:0})}(config)}function exports_regularizers_l2(config){return function l2(args){return assertObjectArgs(args),new L1L2({l2:null!=args?args.l2:null,l1:0})}(config)}var callbacks_console=__webpack_require__("./node_modules/console-browserify/index.js");class Callback extends BaseCallback{constructor(){super(...arguments),this.model=null}setModel(model){if(!(model instanceof LayersModel))throw new Error("model must be a LayersModel, not some other Container");this.model=model}}function callbacks_less(currVal,prevVal){return currVal<prevVal}function callbacks_greater(currVal,prevVal){return currVal>prevVal}class EarlyStopping extends Callback{constructor(args){if(super(),null==args&&(args={}),args.restoreBestWeights)throw new errors_NotImplementedError("restoreBestWeights = True is not implemented in EarlyStopping yet.");this.monitor=args.monitor||"val_loss",this.minDelta=Math.abs(args.minDelta||0),this.patience=args.patience||0,this.verbose=args.verbose||0,this.mode=args.mode||"auto",this.baseline=args.baseline,-1===["auto","min","max"].indexOf(this.mode)&&(callbacks_console.warn(`EarlyStopping mode '${this.mode}' is invalid. Falling back to mode 'auto'.`),this.mode="auto"),"min"===this.mode?this.monitorFunc=callbacks_less:"max"===this.mode||-1!==this.monitor.indexOf("acc")?this.monitorFunc=callbacks_greater:this.monitorFunc=callbacks_less,this.monitorFunc===callbacks_less&&(this.minDelta*=-1)}async onTrainBegin(logs){this.wait=0,this.stoppedEpoch=0,null!=this.baseline?this.best=this.baseline:this.best=this.monitorFunc===callbacks_less?1/0:-1/0}async onEpochEnd(epoch,logs){await resolveScalarsInLogs(logs);const current=this.getMonitorValue(logs);null!=current&&(this.monitorFunc(current-this.minDelta,this.best)?(this.best=current,this.wait=0):(this.wait++,this.wait>=this.patience&&(this.stoppedEpoch=epoch,this.model.stopTraining=!0)))}async onTrainEnd(logs){this.stoppedEpoch>0&&this.verbose&&callbacks_console.log(`Epoch ${this.stoppedEpoch}: early stopping.`)}getMonitorValue(logs){null==logs&&(logs={});const monitorValue=logs[this.monitor];return null==monitorValue&&callbacks_console.warn(`Metric for EarlyStopping ${this.monitor} is not available. Available metrics are: ${Object.keys(logs)}`),monitorValue}}const callbacks={earlyStopping:function earlyStopping(args){return new EarlyStopping(args)}};var flags_console=__webpack_require__("./node_modules/console-browserify/index.js");var DataType,SaverDef;(0,dist._K2)().registerFlag("KEEP_INTERMEDIATE_TENSORS",()=>!1,debugValue=>{debugValue&&flags_console.warn("Keep intermediate tensors is ON. This will print the values of all intermediate tensors during model inference. Not all models support this mode. For details, check e2e/benchmarks/ model_config.js. This significantly impacts performance.")}),function(DataType){DataType[DataType.DT_INVALID=0]="DT_INVALID",DataType[DataType.DT_FLOAT=1]="DT_FLOAT",DataType[DataType.DT_DOUBLE=2]="DT_DOUBLE",DataType[DataType.DT_INT32=3]="DT_INT32",DataType[DataType.DT_UINT8=4]="DT_UINT8",DataType[DataType.DT_INT16=5]="DT_INT16",DataType[DataType.DT_INT8=6]="DT_INT8",DataType[DataType.DT_STRING=7]="DT_STRING",DataType[DataType.DT_COMPLEX64=8]="DT_COMPLEX64",DataType[DataType.DT_INT64=9]="DT_INT64",DataType[DataType.DT_BOOL=10]="DT_BOOL",DataType[DataType.DT_QINT8=11]="DT_QINT8",DataType[DataType.DT_QUINT8=12]="DT_QUINT8",DataType[DataType.DT_QINT32=13]="DT_QINT32",DataType[DataType.DT_BFLOAT16=14]="DT_BFLOAT16",DataType[DataType.DT_QINT16=15]="DT_QINT16",DataType[DataType.DT_QUINT16=16]="DT_QUINT16",DataType[DataType.DT_UINT16=17]="DT_UINT16",DataType[DataType.DT_COMPLEX128=18]="DT_COMPLEX128",DataType[DataType.DT_HALF=19]="DT_HALF",DataType[DataType.DT_RESOURCE=20]="DT_RESOURCE",DataType[DataType.DT_VARIANT=21]="DT_VARIANT",DataType[DataType.DT_UINT32=22]="DT_UINT32",DataType[DataType.DT_UINT64=23]="DT_UINT64",DataType[DataType.DT_FLOAT_REF=101]="DT_FLOAT_REF",DataType[DataType.DT_DOUBLE_REF=102]="DT_DOUBLE_REF",DataType[DataType.DT_INT32_REF=103]="DT_INT32_REF",DataType[DataType.DT_UINT8_REF=104]="DT_UINT8_REF",DataType[DataType.DT_INT16_REF=105]="DT_INT16_REF",DataType[DataType.DT_INT8_REF=106]="DT_INT8_REF",DataType[DataType.DT_STRING_REF=107]="DT_STRING_REF",DataType[DataType.DT_COMPLEX64_REF=108]="DT_COMPLEX64_REF",DataType[DataType.DT_INT64_REF=109]="DT_INT64_REF",DataType[DataType.DT_BOOL_REF=110]="DT_BOOL_REF",DataType[DataType.DT_QINT8_REF=111]="DT_QINT8_REF",DataType[DataType.DT_QUINT8_REF=112]="DT_QUINT8_REF",DataType[DataType.DT_QINT32_REF=113]="DT_QINT32_REF",DataType[DataType.DT_BFLOAT16_REF=114]="DT_BFLOAT16_REF",DataType[DataType.DT_QINT16_REF=115]="DT_QINT16_REF",DataType[DataType.DT_QUINT16_REF=116]="DT_QUINT16_REF",DataType[DataType.DT_UINT16_REF=117]="DT_UINT16_REF",DataType[DataType.DT_COMPLEX128_REF=118]="DT_COMPLEX128_REF",DataType[DataType.DT_HALF_REF=119]="DT_HALF_REF",DataType[DataType.DT_RESOURCE_REF=120]="DT_RESOURCE_REF",DataType[DataType.DT_VARIANT_REF=121]="DT_VARIANT_REF",DataType[DataType.DT_UINT32_REF=122]="DT_UINT32_REF",DataType[DataType.DT_UINT64_REF=123]="DT_UINT64_REF"}(DataType||(DataType={})),function(SaverDef){let CheckpointFormatVersion;!function(CheckpointFormatVersion){CheckpointFormatVersion[CheckpointFormatVersion.LEGACY=0]="LEGACY",CheckpointFormatVersion[CheckpointFormatVersion.V1=1]="V1",CheckpointFormatVersion[CheckpointFormatVersion.V2=2]="V2"}(CheckpointFormatVersion=SaverDef.CheckpointFormatVersion||(SaverDef.CheckpointFormatVersion={}))}(SaverDef||(SaverDef={}));const CUSTOM_OPS={};function registerOp(name,opFunc){const opMapper={tfOpName:name,category:"custom",inputs:[],attrs:[],customExecutor:opFunc};CUSTOM_OPS[name]=opMapper}function getRegisteredOp(name){return CUSTOM_OPS[name]}function deregisterOp(name){delete CUSTOM_OPS[name]}function getParamValue(paramName,node,tensorMap,context,resourceManager){const inputParam=node.inputParams[paramName];if(inputParam&&void 0!==inputParam.inputIndexStart){const start=inputParam.inputIndexStart,end=0===inputParam.inputIndexEnd?void 0:void 0===inputParam.inputIndexEnd?start+1:inputParam.inputIndexEnd,shiftedStart=start<0?node.inputNames.length+start:start;if("tensor"===inputParam.type)return getTensor(node.inputNames[shiftedStart],tensorMap,context,resourceManager);if("tensors"===inputParam.type){const inputs=node.inputs.slice(start,end);return node.inputNames.slice(start,end).filter((_name,index)=>{var _a;return"NoOp"!==(null===(_a=inputs[index])||void 0===_a?void 0:_a.op)}).map(name=>getTensor(name,tensorMap,context,resourceManager))}const tensor=getTensor(node.inputNames[shiftedStart],tensorMap,context,resourceManager),data=tensor.dataSync();return"number"===inputParam.type?data[0]:dist.ZSL.toNestedArray(tensor.shape,data)}const attrParam=node.attrParams[paramName];return attrParam&&attrParam.value}function getTensor(name,tensorsMap,context,resourceManager){const[nodeName,index]=parseNodeName(name,context);if(null!=resourceManager){const tensor=resourceManager.getHashTableHandleByName(nodeName);if(null!=tensor)return tensor}const contextId=context.currentContextIds.find(contextId=>!!tensorsMap[getNodeNameWithContextId(nodeName,contextId)]);return void 0!==contextId?tensorsMap[getNodeNameWithContextId(nodeName,contextId)][index]:void 0}function getTensorsForCurrentContext(name,tensorsMap,context){return tensorsMap[getNodeNameWithContextId(name,context.currentContextId)]}function getNodeNameAndIndex(inputName,context){const[nodeName,index,outputName]=parseNodeName(inputName,context);return[getNodeNameWithContextId(nodeName,context&&context.currentContextId),index,outputName]}function getNodeNameWithContextId(name,contextId){return contextId?`${name}-${contextId}`:name}function parseNodeName(name,context){if(""===name)return["",0,void 0];const isCacheEnabled=null!=context&&null!=context.parseNodeNameCache;if(isCacheEnabled){const cachedResult=context.parseNodeNameCache.get(name);if(null!=cachedResult)return cachedResult}const parts=name.split(":");let result;if(1===parts.length)result=[name,0,void 0];else{const nodeName=parts[0],outputName=3===parts.length?parts[1]:void 0;result=[nodeName,Number(parts[parts.length-1]),outputName]}return isCacheEnabled&&context.parseNodeNameCache.set(name,result),result}function getPadding(node,tensorMap,context){let pad=getParamValue("pad",node,tensorMap,context);if("explicit"===pad){pad=getParamValue("explicitPaddings",node,tensorMap,context);const explicitPadding=[[0,0],[0,0],[0,0],[0,0]];for(let i=0;i<4;i++)explicitPadding[i][0]=pad[2*i],explicitPadding[i][1]=pad[2*i+1];return explicitPadding}return pad}function cloneTensor(tensor){return tensor.kept?tensor:(0,dist.o8B)(tensor)}const json=[{tfOpName:"Add",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AddV2",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AddN",category:"arithmetic",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"BiasAdd",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"Sub",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"RealDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Div",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"DivNoNan",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"FloorDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Mul",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Maximum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Minimum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Pow",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SquaredDifference",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Mod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"FloorMod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],basic_math_json=[{tfOpName:"Abs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Acos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Asin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atan2",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Ceil",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ClipByValue",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"clipValueMin",type:"number"},{start:2,name:"clipValueMax",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Complex",category:"basic_math",inputs:[{start:0,name:"real",type:"tensor"},{start:1,name:"imag",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ComplexAbs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Cos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Cosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Elu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Exp",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Floor",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Log",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Imag",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:!0}]},{tfOpName:"Neg",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Real",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:!0}]},{tfOpName:"Prelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"alpha",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Relu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Relu6",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Selu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sigmoid",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Rsqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Square",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Tan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Tanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sign",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Round",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Expm1",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Log1p",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Reciprocal",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Softplus",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Asinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Acosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Erf",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LeakyRelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"alpha",name:"alpha",type:"number",defaultValue:.2},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"IsNan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"IsFinite",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"IsInf",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],control_json=[{tfOpName:"EmptyTensorList",category:"control",inputs:[{start:0,name:"elementShape",type:"shape"},{start:1,name:"maxNumElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"LoopCond",category:"control",inputs:[{start:0,name:"pred",type:"tensor"}]},{tfOpName:"Switch",category:"control",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"pred",type:"tensor"}]},{tfOpName:"Merge",category:"control",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"Enter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"frame_name",name:"frameName",type:"string"},{tfName:"is_constant",name:"isConstant",type:"bool"}]},{tfOpName:"Exit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"NextIteration",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayV3",category:"control",inputs:[{start:0,name:"size",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"dynamic_size",name:"dynamicSize",type:"bool"},{tfName:"clear_after_read",name:"clearAfterRead",type:"bool"},{tfName:"identical_element_shapes",name:"identicalElementShapes",type:"bool"},{tfName:"tensor_array_name",name:"name",type:"string"}]},{tfOpName:"TensorArrayWriteV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayReadV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayGatherV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"}]},{tfOpName:"TensorArrayScatterV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArrayConcatV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape_except0",name:"elementShapeExcept0",type:"shape",notSupported:!0}]},{tfOpName:"TensorArraySplitV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"tensor",type:"tensor"},{start:2,name:"lengths",type:"number[]"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArraySizeV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}]},{tfOpName:"TensorArrayCloseV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"}]},{tfOpName:"StatelessIf",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"If",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"StatelessWhile",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"While",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"TensorListScatter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListScatterV2",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"},{start:3,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGather",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListSetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListReserve",category:"control",inputs:[{start:0,name:"elementShape",type:"shape"},{start:1,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListFromTensor",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListStack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"},{tfName:"num_elements",name:"numElements",type:"dtype"}]},{tfOpName:"TensorListSplit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"},{start:2,name:"lengths",type:"number[]"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListConcat",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"}],attrs:[{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListConcatV2",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"}],attrs:[{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPopBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPushBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListLength",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"}]},{tfOpName:"TensorListResize",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"size",type:"number"}]}],convolution_json=[{tfOpName:"AvgPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[],notSupported:!0},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPoolWithArgmax",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"include_batch_in_index",name:"includeBatchInIndex",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AvgPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Conv1D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"stride",name:"stride",type:"number"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NWC"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"dilation",name:"dilation",type:"number",defaultValue:1}]},{tfOpName:"Conv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"useCudnnOnGpu",name:"useCudnnOnGpu",type:"bool"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"_FusedConv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"use_cudnn_on_gpu",name:"useCudnnOnGpu",type:"bool",defaultValue:!0},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4},{tfName:"leakyrelu_alpha",name:"leakyreluAlpha",type:"number",defaultValue:.2}]},{tfOpName:"Conv2DBackpropInput",category:"convolution",inputs:[{start:2,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:0,name:"outputShape",type:"number[]"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]",notSupported:!0}]},{tfOpName:"DepthwiseConv2d",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"DepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"FusedDepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]}]},{tfOpName:"Conv3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"Dilation2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"rates",name:"dilations",type:"number[]"},{tfName:"padding",name:"pad",type:"string"}]}],creation_json=[{tfOpName:"Fill",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"},{start:1,name:"value",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"LinSpace",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"num",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"OneHot",category:"creation",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"depth",type:"number"},{start:2,name:"onValue",type:"number",defaultValue:1},{start:3,name:"offValue",type:"number",defaultValue:0}],attrs:[{tfName:"axis",name:"axis",type:"number",notSupported:!0},{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"Ones",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"OnesLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"RandomStandardNormal",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"seed",name:"seed",type:"number",defaultValue:0},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"RandomUniform",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"minval",name:"minval",type:"number",defaultValue:0},{tfName:"maxval",name:"maxval",type:"number",defaultValue:1},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"seed",name:"seed",type:"number",defaultValue:0},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"RandomUniformInt",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"minval",name:"minval",type:"number"},{tfName:"maxval",name:"maxval",type:"number"},{tfName:"seed",name:"seed",type:"number",defaultValue:0},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0}]},{tfOpName:"Range",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"step",type:"number",defaultValue:0}],attrs:[{tfName:"Tidx",name:"dtype",type:"dtype"}]},{tfOpName:"TruncatedNormal",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"means",name:"mean",type:"number",defaultValue:0},{tfName:"stddev",name:"stdDev",type:"number",defaultValue:1},{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"Zeros",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"ZerosLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"Multinomial",category:"creation",inputs:[{start:0,name:"logits",type:"tensor"},{start:1,name:"numSamples",type:"number"}],attrs:[{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number"},{tfName:"T",name:"dtype",type:"dtype"},{tfName:"output_dtype",name:"output_dtype",type:"dtype"}]}],dynamic_json=[{tfOpName:"NonMaxSuppressionV2",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV3",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV4",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"T_threshold",name:"threshold",type:"dtype",notSupported:!0},{tfName:"pad_to_max_output_size",name:"padToMaxOutputSize",type:"bool"}]},{tfOpName:"NonMaxSuppressionV5",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"},{start:5,name:"softNmsSigma",type:"number"}]},{tfOpName:"Where",category:"dynamic",inputs:[{start:0,name:"condition",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ListDiff",category:"dynamic",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],evaluation_json=[{tfOpName:"LowerBound",category:"evaluation",inputs:[{start:0,name:"sortedSequence",type:"tensor"},{start:1,name:"values",type:"tensor"}]},{tfOpName:"TopKV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"k",type:"number"}],attrs:[{tfName:"sorted",name:"sorted",type:"bool"}]},{tfOpName:"UpperBound",category:"evaluation",inputs:[{start:0,name:"sortedSequence",type:"tensor"},{start:1,name:"values",type:"tensor"}]},{tfOpName:"Unique",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"UniqueV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]}],graph_json=[{tfOpName:"PlaceholderWithDefault",category:"graph",inputs:[{start:0,name:"default",type:"tensor"}],attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Placeholder",category:"graph",attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Const",category:"graph"},{tfOpName:"Identity",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IdentityN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Snapshot",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Rank",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Size",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Shape",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"ShapeN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Print",category:"graph",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"data",type:"tensors"}],attrs:[{tfName:"message",name:"message",type:"string"},{tfName:"first_n",name:"firstN",type:"number",notSupported:!0},{tfName:"summarize",name:"summarize",type:"number",defaultValue:3}]},{tfOpName:"NoOp",category:"graph",inputs:[]},{tfOpName:"StopGradient",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"FakeQuantWithMinMaxVars",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"min",name:"min",type:"number"},{tfName:"max",name:"max",type:"number"}]}],hash_table_json=[{tfOpName:"HashTable",category:"hash_table",inputs:[],attrs:[{tfName:"shared_name",name:"sharedName",type:"string"},{tfName:"use_node_name_sharing",name:"useNodeNameSharing",type:"bool"},{tfName:"key_dtype",name:"keyDType",type:"dtype"},{tfName:"value_dtype",name:"valueDType",type:"dtype"}]},{tfOpName:"HashTableV2",category:"hash_table",inputs:[],attrs:[{tfName:"shared_name",name:"sharedName",type:"string"},{tfName:"use_node_name_sharing",name:"useNodeNameSharing",type:"bool"},{tfName:"key_dtype",name:"keyDType",type:"dtype"},{tfName:"value_dtype",name:"valueDType",type:"dtype"}]},{tfOpName:"LookupTableImport",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableImportV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableFind",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableFindV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableSize",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"}]},{tfOpName:"LookupTableSizeV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"}]},{tfOpName:"InitializeTable",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}]},{tfOpName:"InitializeTableV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}]}],image_json=[{tfOpName:"ResizeBilinear",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"half_pixel_centers",name:"halfPixelCenters",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ResizeNearestNeighbor",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"half_pixel_centers",name:"halfPixelCenters",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"CropAndResize",category:"image",inputs:[{start:0,name:"image",type:"tensor"},{start:1,name:"boxes",type:"tensor"},{start:2,name:"boxInd",type:"tensor"},{start:3,name:"cropSize",type:"number[]"}],attrs:[{tfName:"method",name:"method",type:"string"},{tfName:"extrapolation_value",name:"extrapolationValue",type:"number"}]},{tfOpName:"ImageProjectiveTransformV3",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"transforms",type:"tensor"},{start:2,name:"outputShape",type:"number[]"},{start:3,name:"fillValue",type:"number"}],attrs:[{tfName:"interpolation",name:"interpolation",type:"string"},{tfName:"fill_mode",name:"fillMode",type:"string"}]}],logical_json=[{tfOpName:"Equal",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"NotEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Greater",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"GreaterEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Less",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LessEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalAnd",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalNot",category:"logical",inputs:[{start:0,name:"a",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalOr",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Select",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SelectV2",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"BitwiseAnd",category:"logical",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}]}],matrices_json=[{tfOpName:"_FusedMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4},{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"leakyrelu_alpha",name:"leakyreluAlpha",type:"number",defaultValue:.2},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"BatchMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"BatchMatMulV2",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Transpose",category:"matrices",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"perm",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Einsum",category:"matrices",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}],attrs:[{tfName:"equation",name:"equation",type:"string"},{tfName:"N",name:"n",type:"number",defaultValue:2},{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"MatrixBandPart",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"numLower",type:"tensor"},{start:1,name:"numUpper",type:"tensor"}]}],normalization_json=[{tfOpName:"EuclideanNorm",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool",defaultValue:!1}]},{tfOpName:"FusedBatchNorm",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"FusedBatchNormV2",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"FusedBatchNormV3",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"LRN",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"depth_radius",name:"radius",type:"number",defaultValue:5},{tfName:"bias",name:"bias",type:"number",defaultValue:1},{tfName:"alpha",name:"alpha",type:"number",defaultValue:1},{tfName:"beta",name:"beta",type:"number",defaultValue:.5}]},{tfOpName:"Softmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"LogSoftmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]}],reduction_json=[{tfOpName:"Bincount",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"size",type:"number"},{start:2,name:"weights",type:"tensor"}]},{tfOpName:"DenseBincount",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"size",type:"number"},{start:2,name:"weights",type:"tensor"}],attrs:[{tfName:"binary_output",name:"binaryOutput",type:"bool"}]},{tfOpName:"Max",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Mean",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Min",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Sum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"All",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Any",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"ArgMax",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"ArgMin",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"Prod",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Cumprod",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}],attrs:[{tfName:"exclusive",name:"exclusive",type:"bool"},{tfName:"reverse",name:"reverse",type:"bool"}]},{tfOpName:"Cumsum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}],attrs:[{tfName:"exclusive",name:"exclusive",type:"bool"},{tfName:"reverse",name:"reverse",type:"bool"}]}],slice_join_json=[{tfOpName:"ConcatV2",category:"slice_join",inputs:[{start:0,end:-1,name:"tensors",type:"tensors"},{start:-1,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"Concat",category:"slice_join",inputs:[{start:1,end:0,name:"tensors",type:"tensors"},{start:0,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"GatherV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"axis",type:"number",defaultValue:0}],attrs:[{tfName:"batch_dims",name:"batchDims",type:"number",defaultValue:0}]},{tfOpName:"Gather",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",notSupported:!0}]},{tfOpName:"Reverse",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"dims",type:"bool[]"}]},{tfOpName:"ReverseV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}]},{tfOpName:"Slice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"size",type:"number[]"}]},{tfOpName:"StridedSlice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"end",type:"number[]"},{start:3,name:"strides",type:"number[]"}],attrs:[{tfName:"begin_mask",name:"beginMask",type:"number",defaultValue:0},{tfName:"end_mask",name:"endMask",type:"number",defaultValue:0},{tfName:"new_axis_mask",name:"newAxisMask",type:"number",defaultValue:0},{tfName:"ellipsis_mask",name:"ellipsisMask",type:"number",defaultValue:0},{tfName:"shrink_axis_mask",name:"shrinkAxisMask",type:"number",defaultValue:0}]},{tfOpName:"Pack",category:"slice_join",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0}]},{tfOpName:"Unpack",category:"slice_join",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0},{tfName:"num",name:"num",type:"number",defaultValue:0,notSupported:!0}]},{tfOpName:"Tile",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"reps",type:"number[]"}]},{tfOpName:"Split",category:"slice_join",inputs:[{start:0,name:"axis",type:"number",defaultValue:0},{start:1,name:"x",type:"tensor"}],attrs:[{tfName:"num_split",name:"numOrSizeSplits",type:"number",defaultValue:1}]},{tfOpName:"SplitV",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"numOrSizeSplits",type:"number[]"},{start:2,name:"axis",type:"number",defaultValue:0}]},{tfOpName:"ScatterNd",category:"slice_join",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"values",type:"tensor"},{start:2,name:"shape",type:"number[]"}]},{tfOpName:"GatherNd",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}]},{tfOpName:"SparseToDense",category:"slice_join",inputs:[{start:0,name:"sparseIndices",type:"tensor"},{start:1,name:"outputShape",type:"number[]"},{start:2,name:"sparseValues",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",defaultValue:!1,notSupported:!0}]},{tfOpName:"TensorScatterUpdate",category:"slice_join",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"values",type:"tensor"}]}],sparse_json=[{tfOpName:"SparseFillEmptyRows",category:"sparse",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"values",type:"tensor"},{start:2,name:"denseShape",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}]},{tfOpName:"SparseReshape",category:"sparse",inputs:[{start:0,name:"inputIndices",type:"tensor"},{start:1,name:"inputShape",type:"tensor"},{start:2,name:"newShape",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SparseSegmentMean",category:"sparse",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"segmentIds",type:"tensor"}]},{tfOpName:"SparseSegmentSum",category:"sparse",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"segmentIds",type:"tensor"}]}],spectral_json=[{tfOpName:"FFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"RFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:!0}]},{tfOpName:"IRFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:!0}]}],string_json=[{tfOpName:"StaticRegexReplace",category:"string",inputs:[{start:0,name:"input",type:"tensor"}],attrs:[{tfName:"pattern",name:"pattern",type:"string"},{tfName:"rewrite",name:"rewrite",type:"string"},{tfName:"replace_global",name:"replaceGlobal",type:"bool"}]},{tfOpName:"StringNGrams",category:"string",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"dataSplits",type:"tensor"}],attrs:[{tfName:"separator",name:"separator",type:"string"},{tfName:"ngram_widths",name:"nGramWidths",type:"number[]"},{tfName:"left_pad",name:"leftPad",type:"string"},{tfName:"right_pad",name:"rightPad",type:"string"},{tfName:"pad_width",name:"padWidth",type:"number"},{tfName:"preserve_short_sequences",name:"preserveShortSequences",type:"bool"}],outputs:["ngrams","ngrams_splits"]},{tfOpName:"StringSplit",category:"string",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"delimiter",type:"tensor"}],attrs:[{tfName:"skip_empty",name:"skipEmpty",type:"bool"}],outputs:["indices","values","shape"]},{tfOpName:"StringToHashBucketFast",category:"string",inputs:[{start:0,name:"input",type:"tensor"}],attrs:[{tfName:"num_buckets",name:"numBuckets",type:"number"}]}],transformation_json=[{tfOpName:"Cast",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"SrcT",name:"sdtype",type:"dtype",notSupported:!0},{tfName:"DstT",name:"dtype",type:"dtype"}]},{tfOpName:"ExpandDims",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"MirrorPad",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"}],attrs:[{tfName:"mode",name:"mode",type:"string"}]},{tfOpName:"Pad",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"}],attrs:[{tfName:"constant_value",name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"PadV2",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"},{start:2,name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"Reshape",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}]},{tfOpName:"EnsureShape",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}]},{tfOpName:"Squeeze",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"axis",tfDeprecatedName:"squeeze_dims",name:"axis",type:"number[]"}]},{tfOpName:"SpaceToBatchND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"paddings",type:"number[]"}]},{tfOpName:"BatchToSpaceND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"crops",type:"number[]"}]},{tfOpName:"DepthToSpace",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"block_size",name:"blockSize",type:"number"},{tfName:"data_format",name:"dataFormat",type:"string"}]},{tfOpName:"BroadcastTo",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}],attrs:[]},{tfOpName:"BroadcastArgs",category:"transformation",inputs:[{start:0,name:"s0",type:"tensor"},{start:1,name:"s1",type:"tensor"}],attrs:[]}];var Buffer=__webpack_require__("./node_modules/buffer/index.js").Buffer;class OperationMapper{static get Instance(){return this._instance||(this._instance=new this)}constructor(){const mappersJson=[].concat(...[arithmetic_namespaceObject,basic_math_namespaceObject,control_namespaceObject,convolution_namespaceObject,creation_namespaceObject,dynamic_namespaceObject,evaluation_namespaceObject,graph_namespaceObject,hash_table_namespaceObject,image_namespaceObject,logical_namespaceObject,matrices_namespaceObject,op_list_normalization_namespaceObject,reduction_namespaceObject,slice_join_namespaceObject,sparse_namespaceObject,spectral_namespaceObject,string_namespaceObject,transformation_namespaceObject].map(op=>op.json));this.opMappers=mappersJson.reduce((map,mapper)=>(map[mapper.tfOpName]=mapper,map),{})}transformGraph(graph,signature={}){const tfNodes=graph.node,placeholders=[],weights=[],initNodes=[],nodes=tfNodes.reduce((map,node)=>(map[node.name]=this.mapNode(node),node.op.startsWith("Placeholder")?placeholders.push(map[node.name]):"Const"===node.op?weights.push(map[node.name]):null!=node.input&&0!==node.input.length||initNodes.push(map[node.name]),map),{});let inputs=[];const outputs=[];let inputNodeNameToKey={},outputNodeNameToKey={};null!=signature&&(inputNodeNameToKey=this.mapSignatureEntries(signature.inputs),outputNodeNameToKey=this.mapSignatureEntries(signature.outputs));const allNodes=Object.keys(nodes);allNodes.forEach(key=>{const node=nodes[key];node.inputNames.forEach((name,index)=>{const[nodeName,,outputName]=getNodeNameAndIndex(name),inputNode=nodes[nodeName];if(null!=inputNode.outputs){const outputIndex=inputNode.outputs.indexOf(outputName);if(-1!==outputIndex){const inputName=`${nodeName}:${outputIndex}`;node.inputNames[index]=inputName}}node.inputs.push(inputNode),inputNode.children.push(node)})}),0===Object.keys(outputNodeNameToKey).length?allNodes.forEach(key=>{const node=nodes[key];0===node.children.length&&outputs.push(node)}):Object.keys(outputNodeNameToKey).forEach(name=>{const[nodeName]=getNodeNameAndIndex(name),node=nodes[nodeName];null!=node&&(node.signatureKey=outputNodeNameToKey[name],outputs.push(node))}),Object.keys(inputNodeNameToKey).length>0?Object.keys(inputNodeNameToKey).forEach(name=>{const[nodeName]=getNodeNameAndIndex(name),node=nodes[nodeName];node&&(node.signatureKey=inputNodeNameToKey[name],inputs.push(node))}):inputs=placeholders;let functions={};null!=graph.library&&null!=graph.library.function&&(functions=graph.library.function.reduce((functions,func)=>(functions[func.signature.name]=this.mapFunction(func),functions),{}));const result={nodes,inputs,outputs,weights,placeholders,signature,functions};return initNodes.length>0&&(result.initNodes=initNodes),result}mapSignatureEntries(entries){return Object.keys(entries||{}).reduce((prev,curr)=>(prev[entries[curr].name]=curr,prev),{})}mapNode(node){const mapper=getRegisteredOp(node.op)||this.opMappers[node.op]||{};null==node.attr&&(node.attr={});const newNode={name:node.name,op:node.op,category:mapper.category,inputNames:(node.input||[]).map(input=>input.startsWith("^")?input.slice(1):input),inputs:[],children:[],inputParams:{},attrParams:{},rawAttrs:node.attr,outputs:mapper.outputs};return null!=mapper.inputs&&(newNode.inputParams=mapper.inputs.reduce((map,param)=>(map[param.name]={type:param.type,inputIndexStart:param.start,inputIndexEnd:param.end},map),{})),null!=mapper.attrs&&(newNode.attrParams=mapper.attrs.reduce((map,param)=>{const type=param.type;let value;switch(param.type){case"string":value=getStringParam(node.attr,param.tfName,param.defaultValue),void 0===value&&param.tfDeprecatedName&&(value=getStringParam(node.attr,param.tfDeprecatedName,param.defaultValue));break;case"string[]":value=getStringArrayParam(node.attr,param.tfName,param.defaultValue),void 0===value&&param.tfDeprecatedName&&(value=getStringArrayParam(node.attr,param.tfDeprecatedName,param.defaultValue));break;case"number":value=getNumberParam(node.attr,param.tfName,param.defaultValue||0),void 0===value&&param.tfDeprecatedName&&(value=getNumberParam(node.attr,param.tfDeprecatedName,param.defaultValue));break;case"number[]":value=getNumericArrayParam(node.attr,param.tfName,param.defaultValue),void 0===value&&param.tfDeprecatedName&&(value=getNumericArrayParam(node.attr,param.tfDeprecatedName,param.defaultValue));break;case"bool":value=getBoolParam(node.attr,param.tfName,param.defaultValue),void 0===value&&param.tfDeprecatedName&&(value=getBoolParam(node.attr,param.tfDeprecatedName,param.defaultValue));break;case"bool[]":value=getBoolArrayParam(node.attr,param.tfName,param.defaultValue),void 0===value&&param.tfDeprecatedName&&(value=getBoolArrayParam(node.attr,param.tfDeprecatedName,param.defaultValue));break;case"shape":value=getTensorShapeParam(node.attr,param.tfName,param.defaultValue),void 0===value&&param.tfDeprecatedName&&(value=getTensorShapeParam(node.attr,param.tfDeprecatedName,param.defaultValue));break;case"shape[]":value=getTensorShapeArrayParam(node.attr,param.tfName,param.defaultValue),void 0===value&&param.tfDeprecatedName&&(value=getTensorShapeArrayParam(node.attr,param.tfDeprecatedName,param.defaultValue));break;case"dtype":value=getDtypeParam(node.attr,param.tfName,param.defaultValue),void 0===value&&param.tfDeprecatedName&&(value=getDtypeParam(node.attr,param.tfDeprecatedName,param.defaultValue));break;case"dtype[]":value=getDtypeArrayParam(node.attr,param.tfName,param.defaultValue),void 0===value&&param.tfDeprecatedName&&(value=getDtypeArrayParam(node.attr,param.tfDeprecatedName,param.defaultValue));break;case"func":value=getFuncParam(node.attr,param.tfName,param.defaultValue),void 0===value&&param.tfDeprecatedName&&(value=getFuncParam(node.attr,param.tfDeprecatedName,param.defaultValue));break;case"tensor":case"tensors":break;default:throw new Error(`Unsupported param type: ${param.type} for op: ${node.op}`)}return map[param.name]={value,type},map},{})),newNode}mapFunction(functionDef){const tfNodes=functionDef.nodeDef,weights=[];let nodes={};null!=tfNodes&&(nodes=tfNodes.reduce((map,node)=>(map[node.name]=this.mapNode(node),"Const"===node.op&&weights.push(map[node.name]),map),{}));const inputs=[],outputs=[];functionDef.signature.inputArg.forEach(arg=>{const[nodeName]=getNodeNameAndIndex(arg.name),node={name:nodeName,op:"Placeholder",inputs:[],inputNames:[],category:"graph",inputParams:{},attrParams:{dtype:{value:parseDtypeParam(arg.type),type:"dtype"}},children:[]};node.signatureKey=arg.name,inputs.push(node),nodes[nodeName]=node});Object.keys(nodes).forEach(key=>{const node=nodes[key];node.inputNames.forEach((name,index)=>{const[nodeName,,outputName]=getNodeNameAndIndex(name),inputNode=nodes[nodeName];if(null!=inputNode.outputs){const outputIndex=inputNode.outputs.indexOf(outputName);if(-1!==outputIndex){const inputName=`${nodeName}:${outputIndex}`;node.inputNames[index]=inputName}}node.inputs.push(inputNode),inputNode.children.push(node)})});const returnNodeMap=functionDef.ret;functionDef.signature.outputArg.forEach(output=>{const[nodeName,index]=getNodeNameAndIndex(returnNodeMap[output.name]),node=nodes[nodeName];null!=node&&(node.defaultOutput=index,outputs.push(node))});const signature=this.mapArgsToSignature(functionDef);return{nodes,inputs,outputs,weights,placeholders:[],signature}}mapArgsToSignature(functionDef){return{methodName:functionDef.signature.name,inputs:functionDef.signature.inputArg.reduce((map,arg)=>(map[arg.name]=this.mapArgToTensorInfo(arg),map),{}),outputs:functionDef.signature.outputArg.reduce((map,arg)=>(map[arg.name]=this.mapArgToTensorInfo(arg,functionDef.ret),map),{})}}mapArgToTensorInfo(arg,nameMap){let name=arg.name;return null!=nameMap&&(name=nameMap[name]),{name,dtype:arg.type}}}function parseStringParam(s,keepCase){const value=Array.isArray(s)?String.fromCharCode.apply(null,s):function decodeBase64(text){const global=(0,dist._K2)().global;if(void 0!==global.atob)return global.atob(text);if(void 0!==Buffer)return new Buffer(text,"base64").toString();throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()")}(s);return keepCase?value:value.toLowerCase()}function getStringParam(attrs,name,def,keepCase=!1){const param=attrs[name];return null!=param?parseStringParam(param.s,keepCase):def}function getBoolParam(attrs,name,def){const param=attrs[name];return param?param.b:def}function getNumberParam(attrs,name,def){const param=attrs[name]||{},value=null!=param.i?param.i:null!=param.f?param.f:def;return"number"==typeof value?value:parseInt(value,10)}function parseDtypeParam(value){switch("string"==typeof value&&(value=DataType[value]),value){case DataType.DT_FLOAT:case DataType.DT_HALF:return"float32";case DataType.DT_INT32:case DataType.DT_INT64:case DataType.DT_INT8:case DataType.DT_UINT8:return"int32";case DataType.DT_BOOL:return"bool";case DataType.DT_DOUBLE:return"float32";case DataType.DT_STRING:return"string";case DataType.DT_COMPLEX64:case DataType.DT_COMPLEX128:return"complex64";default:return null}}function getFuncParam(attrs,name,def){const param=attrs[name];return param&&param.func?param.func.name:def}function getDtypeParam(attrs,name,def){const param=attrs[name];return param&&param.type?parseDtypeParam(param.type):def}function getDtypeArrayParam(attrs,name,def){const param=attrs[name];return param&&param.list&&param.list.type?param.list.type.map(v=>parseDtypeParam(v)):def}function parseTensorShapeParam(shape){if(!shape.unknownRank)return null!=shape.dim?shape.dim.map(dim=>"number"==typeof dim.size?dim.size:parseInt(dim.size,10)):[]}function getTensorShapeParam(attrs,name,def){const param=attrs[name];return param&&param.shape?parseTensorShapeParam(param.shape):def}function getNumericArrayParam(attrs,name,def){const param=attrs[name];return param?((param.list.f&&param.list.f.length?param.list.f:param.list.i)||[]).map(v=>"number"==typeof v?v:parseInt(v,10)):def}function getStringArrayParam(attrs,name,def,keepCase=!1){const param=attrs[name];return param&&param.list&&param.list.s?param.list.s.map(v=>parseStringParam(v,keepCase)):def}function getTensorShapeArrayParam(attrs,name,def){const param=attrs[name];return param&&param.list&&param.list.shape?param.list.shape.map(v=>parseTensorShapeParam(v)):def}function getBoolArrayParam(attrs,name,def){const param=attrs[name];return param&&param.list&&param.list.b?param.list.b:def}class NodeValueImpl{constructor(node,tensorMap,context){this.node=node,this.tensorMap=tensorMap,this.context=context,this.inputs=[],this.attrs={},this.inputs=node.inputNames.map(name=>this.getInput(name)),null!=node.rawAttrs&&(this.attrs=Object.keys(node.rawAttrs).reduce((attrs,key)=>(attrs[key]=this.getAttr(key),attrs),{}))}getInput(name){return getTensor(name,this.tensorMap,this.context)}getAttr(name,defaultValue){const value=this.node.rawAttrs[name];if(null!=value.tensor)return getTensor(name,this.tensorMap,this.context);if(null!=value.i||null!=value.f)return getNumberParam(this.node.rawAttrs,name,defaultValue);if(null!=value.s)return getStringParam(this.node.rawAttrs,name,defaultValue);if(null!=value.b)return getBoolParam(this.node.rawAttrs,name,defaultValue);if(null!=value.shape)return getTensorShapeParam(this.node.rawAttrs,name,defaultValue);if(null!=value.type)return getDtypeParam(this.node.rawAttrs,name,defaultValue);if(null!=value.list){if(null!=value.list.i||null!=value.list.f)return getNumericArrayParam(this.node.rawAttrs,name,defaultValue);if(null!=value.list.s)return getStringArrayParam(this.node.rawAttrs,name,defaultValue);if(null!=value.list.shape)return getTensorShapeArrayParam(this.node.rawAttrs,name,defaultValue);if(null!=value.list.b)return getBoolArrayParam(this.node.rawAttrs,name,defaultValue);if(null!=value.list.type)return getDtypeArrayParam(this.node.rawAttrs,name,defaultValue)}return defaultValue}}var ops=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js");function assertShapesMatchAllowUndefinedSize(shapeA,shapeB,errorMessagePrefix=""){if("number"!=typeof shapeA&&"number"!=typeof shapeB){dist.ZSL.assert(shapeA.length===shapeB.length,()=>errorMessagePrefix+` Shapes ${shapeA} and ${shapeB} must match`);for(let i=0;i<shapeA.length;i++){const dim0=shapeA[i],dim1=shapeB[i];dist.ZSL.assert(dim0<0||dim1<0||dim0===dim1,()=>errorMessagePrefix+` Shapes ${shapeA} and ${shapeB} must match`)}}}function fullDefinedShape(elementShape){return"number"!=typeof elementShape&&!elementShape.some(dim=>dim<0)}function inferElementShape(listElementShape,tensors,elementShape){let partialShape=mergeElementShape(listElementShape,elementShape);const notfullDefinedShape=!fullDefinedShape(partialShape);if(notfullDefinedShape&&0===tensors.length)throw new Error(`Tried to calculate elements of an empty list with non-fully-defined elementShape: ${partialShape}`);if(notfullDefinedShape&&tensors.forEach(tensor=>{partialShape=mergeElementShape(tensor.shape,partialShape)}),!fullDefinedShape(partialShape))throw new Error(`Non-fully-defined elementShape: ${partialShape}`);return partialShape}function mergeElementShape(elementShapeA,elementShapeB){if("number"==typeof elementShapeA)return elementShapeB;if("number"==typeof elementShapeB)return elementShapeA;if(elementShapeA.length!==elementShapeB.length)throw new Error(`Incompatible ranks during merge: ${elementShapeA} vs. ${elementShapeB}`);const result=[];for(let i=0;i<elementShapeA.length;++i){const dim0=elementShapeA[i],dim1=elementShapeB[i];if(dim0>=0&&dim1>=0&&dim0!==dim1)throw new Error(`Incompatible shape during merge: ${elementShapeA} vs. ${elementShapeB}`);result[i]=dim0>=0?dim0:dim1}return result}class TensorArray{constructor(name,dtype,maxSize,elementShape,identicalElementShapes,dynamicSize,clearAfterRead){this.name=name,this.dtype=dtype,this.maxSize=maxSize,this.elementShape=elementShape,this.identicalElementShapes=identicalElementShapes,this.dynamicSize=dynamicSize,this.clearAfterRead=clearAfterRead,this.tensors=[],this.closed_=!1,this.idTensor=(0,dist.d_2)(0),(0,dist.aCs)(this.idTensor)}get id(){return this.idTensor.id}get closed(){return this.closed_}clearAndClose(keepIds){this.tensors.forEach(tensor=>{null!=keepIds&&keepIds.has(tensor.tensor.id)||tensor.tensor.dispose()}),this.tensors=[],this.closed_=!0,this.idTensor.dispose()}size(){return this.tensors.length}read(index){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(index<0||index>=this.size())throw new Error(`Tried to read from index ${index}, but array size is: ${this.size()}`);const tensorWithState=this.tensors[index];if(tensorWithState.cleared)throw new Error(`TensorArray ${this.name}: Could not read index ${index} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);return this.clearAfterRead&&(tensorWithState.cleared=!0),tensorWithState.read=!0,tensorWithState.tensor}readMany(indices){return indices.map(index=>this.read(index))}write(index,tensor){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(index<0||!this.dynamicSize&&index>=this.maxSize)throw new Error(`Tried to write to index ${index}, but array is not resizeable and size is: ${this.maxSize}`);const t=this.tensors[index]||{};if(tensor.dtype!==this.dtype)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index},\n          because the value dtype is ${tensor.dtype}, but TensorArray dtype is ${this.dtype}.`);if(0!==this.size()||null!=this.elementShape&&0!==this.elementShape.length||(this.elementShape=tensor.shape),assertShapesMatchAllowUndefinedSize(this.elementShape,tensor.shape,`TensorArray ${this.name}: Could not write to TensorArray index ${index}.`),t.read)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index}, because it has already been read.`);if(t.written)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index}, because it has already been written.`);t.tensor=tensor,(0,dist.aCs)(tensor),t.written=!0,this.tensors[index]=t}writeMany(indices,tensors){if(indices.length!==tensors.length)throw new Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${indices.length} is not the same as tensors size: ${tensors.length}.`);indices.forEach((i,index)=>this.write(i,tensors[index]))}gather(indices,dtype){if(dtype&&dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${dtype}`);if(indices)indices=indices.slice(0,this.size());else{indices=[];for(let i=0;i<this.size();i++)indices.push(i)}if(0===indices.length)return(0,dist.OEK)([],[0].concat(this.elementShape));const tensors=this.readMany(indices);return assertShapesMatchAllowUndefinedSize(this.elementShape,tensors[0].shape,"TensorArray shape mismatch: "),(0,dist.t$z)(tensors,0)}concat(dtype){if(dtype&&dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${dtype}`);if(0===this.size())return(0,dist.OEK)([],[0].concat(this.elementShape));const indices=[];for(let i=0;i<this.size();i++)indices.push(i);const tensors=this.readMany(indices);return assertShapesMatchAllowUndefinedSize(this.elementShape,tensors[0].shape,`TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${tensors[0].shape})`),(0,dist.xWs)(tensors,0)}scatter(indices,tensor){if(tensor.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${tensor.dtype}`);if(indices.length!==tensor.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${indices.length} vs. ${tensor.shape[0]}`);const maxIndex=Math.max(...indices);if(!this.dynamicSize&&maxIndex>=this.maxSize)throw new Error(`Max index must be < array size (${maxIndex}  vs. ${this.maxSize})`);this.writeMany(indices,(0,dist.K$i)(tensor,0))}split(length,tensor){if(tensor.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${tensor.dtype}`);let totalLength=0;const cumulativeLengths=length.map(len=>(totalLength+=len,totalLength));if(totalLength!==tensor.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);if(!this.dynamicSize&&length.length!==this.maxSize)throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${length.length}), and the TensorArray is not marked as dynamically resizeable`);const elementPerRow=0===totalLength?0:tensor.size/totalLength,tensors=[];(0,dist.DZQ)(()=>{tensor=(0,dist.tQQ)(tensor,[1,totalLength,elementPerRow]);for(let i=0;i<length.length;++i){const indices=[0,0===i?0:cumulativeLengths[i-1],0],sizes=[1,length[i],elementPerRow];tensors[i]=(0,dist.tQQ)((0,dist.dik)(tensor,indices,sizes),this.elementShape)}return tensors});const indices=[];for(let i=0;i<length.length;i++)indices[i]=i;this.writeMany(indices,tensors)}}class TensorList{get id(){return this.idTensor.id}constructor(tensors,elementShape,elementDtype,maxNumElements=-1){this.tensors=tensors,this.elementShape=elementShape,this.elementDtype=elementDtype,null!=tensors&&tensors.forEach(tensor=>{if(elementDtype!==tensor.dtype)throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${tensor.dtype}`);assertShapesMatchAllowUndefinedSize(elementShape,tensor.shape,"TensorList shape mismatch: "),(0,dist.aCs)(tensor)}),this.idTensor=(0,dist.d_2)(0),this.maxNumElements=maxNumElements,(0,dist.aCs)(this.idTensor)}copy(){return new TensorList([...this.tensors],this.elementShape,this.elementDtype)}clearAndClose(keepIds){this.tensors.forEach(tensor=>{null!=keepIds&&keepIds.has(tensor.id)||tensor.dispose()}),this.tensors.length=0,this.idTensor.dispose()}size(){return this.tensors.length}stack(elementShape,elementDtype,numElements=-1){if(elementDtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);if(-1!==numElements&&this.tensors.length!==numElements)throw new Error(`Operation expected a list with ${numElements} elements but got a list with ${this.tensors.length} elements.`);assertShapesMatchAllowUndefinedSize(elementShape,this.elementShape,"TensorList shape mismatch: ");const outputElementShape=inferElementShape(this.elementShape,this.tensors,elementShape);return(0,dist.DZQ)(()=>{const reshapedTensors=this.tensors.map(tensor=>(0,dist.tQQ)(tensor,outputElementShape));return(0,dist.t$z)(reshapedTensors,0)})}popBack(elementShape,elementDtype){if(elementDtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);if(0===this.size())throw new Error("Trying to pop from an empty list.");const outputElementShape=inferElementShape(this.elementShape,this.tensors,elementShape),tensor=this.tensors.pop();return tensor.kept=!1,assertShapesMatchAllowUndefinedSize(tensor.shape,elementShape,"TensorList shape mismatch: "),(0,dist.tQQ)(tensor,outputElementShape)}pushBack(tensor){if(tensor.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${tensor.dtype}, but list elements ${this.elementDtype}`);if(assertShapesMatchAllowUndefinedSize(tensor.shape,this.elementShape,"TensorList shape mismatch: "),this.maxNumElements===this.size())throw new Error("Trying to push element into a full list.");(0,dist.aCs)(tensor),this.tensors.push(tensor)}resize(size){if(size<0)throw new Error(`TensorListResize expects size to be non-negative. Got: ${size}`);if(-1!==this.maxNumElements&&size>this.maxNumElements)throw new Error(`TensorListResize input size ${size} is greater maxNumElement ${this.maxNumElements}.`);const destTensorList=new TensorList([],this.elementShape,this.elementDtype,this.maxNumElements);destTensorList.tensors.length=size;for(let i=0;i<Math.min(this.tensors.length,size);++i)destTensorList.tensors[i]=this.tensors[i];return destTensorList}getItem(elementIndex,elementShape,elementDtype){if(elementDtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);if(elementIndex<0||elementIndex>this.tensors.length)throw new Error(`Trying to access element ${elementIndex} in a list with ${this.tensors.length} elements.`);if(null==this.tensors[elementIndex])throw new Error(`element at index ${elementIndex} is null.`);assertShapesMatchAllowUndefinedSize(this.tensors[elementIndex].shape,elementShape,"TensorList shape mismatch: ");const outputElementShape=inferElementShape(this.elementShape,this.tensors,elementShape);return(0,dist.tQQ)(this.tensors[elementIndex],outputElementShape)}setItem(elementIndex,tensor){if(tensor.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${tensor.dtype}, but list elements ${this.elementDtype}`);if(elementIndex<0||-1!==this.maxNumElements&&elementIndex>=this.maxNumElements)throw new Error(`Trying to set element ${elementIndex} in a list with max ${this.maxNumElements} elements.`);assertShapesMatchAllowUndefinedSize(this.elementShape,tensor.shape,"TensorList shape mismatch: "),(0,dist.aCs)(tensor),null!=this.tensors[elementIndex]&&(this.tensors[elementIndex].kept=!1),this.tensors[elementIndex]=tensor}gather(indices,elementDtype,elementShape){if(elementDtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);assertShapesMatchAllowUndefinedSize(this.elementShape,elementShape,"TensorList shape mismatch: "),indices=indices.slice(0,this.size());const outputElementShape=inferElementShape(this.elementShape,this.tensors,elementShape);return 0===indices.length?(0,dist.OEK)([],[0].concat(outputElementShape)):(0,dist.DZQ)(()=>{const tensors=indices.map(i=>(0,dist.tQQ)(this.tensors[i],outputElementShape));return(0,dist.t$z)(tensors,0)})}concat(elementDtype,elementShape){if(elementDtype&&elementDtype!==this.elementDtype)throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${elementDtype}`);assertShapesMatchAllowUndefinedSize(this.elementShape,elementShape,"TensorList shape mismatch: ");const outputElementShape=inferElementShape(this.elementShape,this.tensors,elementShape);return 0===this.size()?(0,dist.OEK)([],[0].concat(outputElementShape)):(0,dist.DZQ)(()=>{const tensors=this.tensors.map(t=>(0,dist.tQQ)(t,outputElementShape));return(0,dist.xWs)(tensors,0)})}}const control_executor_executeOp=async(node,tensorMap,context)=>{switch(node.op){case"If":case"StatelessIf":{const thenFunc=getParamValue("thenBranch",node,tensorMap,context),elseFunc=getParamValue("elseBranch",node,tensorMap,context),cond=getParamValue("cond",node,tensorMap,context),args=getParamValue("args",node,tensorMap,context);return(await cond.data())[0]?context.functionMap[thenFunc].executeFunctionAsync(args,context.tensorArrayMap,context.tensorListMap):context.functionMap[elseFunc].executeFunctionAsync(args,context.tensorArrayMap,context.tensorListMap)}case"While":case"StatelessWhile":{const bodyFunc=getParamValue("body",node,tensorMap,context),condFunc=getParamValue("cond",node,tensorMap,context),args=getParamValue("args",node,tensorMap,context),condResult=await context.functionMap[condFunc].executeFunctionAsync(args,context.tensorArrayMap,context.tensorListMap),argIds=args.map(tensor=>tensor.id);let condValue=await condResult[0].data();condResult.forEach(tensor=>{tensor.kept||-1!==argIds.indexOf(tensor.id)||tensor.dispose()});let result=args;for(;condValue[0];){const origResult=result;result=await context.functionMap[bodyFunc].executeFunctionAsync(result,context.tensorArrayMap,context.tensorListMap);const resultIds=result.map(tensor=>tensor.id);origResult.forEach(tensor=>{tensor.kept||-1!==argIds.indexOf(tensor.id)||-1!==resultIds.indexOf(tensor.id)||tensor.dispose()});const condResult=await context.functionMap[condFunc].executeFunctionAsync(result,context.tensorArrayMap,context.tensorListMap);condValue=await condResult[0].data(),condResult.forEach(tensor=>{tensor.kept||-1!==argIds.indexOf(tensor.id)||-1!==resultIds.indexOf(tensor.id)||tensor.dispose()})}return result}case"LoopCond":return[cloneTensor(getParamValue("pred",node,tensorMap,context))];case"Switch":{const pred=getParamValue("pred",node,tensorMap,context);let data=getParamValue("data",node,tensorMap,context);return data.kept||(data=cloneTensor(data)),(await pred.data())[0]?[void 0,data]:[data,void 0]}case"Merge":{const inputName=node.inputNames.find(name=>void 0!==getTensor(name,tensorMap,context));if(inputName){return[cloneTensor(getTensor(inputName,tensorMap,context))]}return}case"Enter":{const frameId=getParamValue("frameName",node,tensorMap,context),data=getParamValue("tensor",node,tensorMap,context);return context.enterFrame(frameId),[cloneTensor(data)]}case"Exit":{const data=getParamValue("tensor",node,tensorMap,context);return context.exitFrame(),[cloneTensor(data)]}case"NextIteration":{const data=getParamValue("tensor",node,tensorMap,context);return context.nextIteration(),[cloneTensor(data)]}case"TensorArrayV3":{const size=getParamValue("size",node,tensorMap,context),dtype=getParamValue("dtype",node,tensorMap,context),elementShape=getParamValue("elementShape",node,tensorMap,context),dynamicSize=getParamValue("dynamicSize",node,tensorMap,context),clearAfterRead=getParamValue("clearAfterRead",node,tensorMap,context),identicalElementShapes=getParamValue("identicalElementShapes",node,tensorMap,context),name=getParamValue("name",node,tensorMap,context),tensorArray=new TensorArray(name,dtype,size,elementShape,identicalElementShapes,dynamicSize,clearAfterRead);return context.addTensorArray(tensorArray),[tensorArray.idTensor,(0,dist.d_2)(1)]}case"TensorArrayWriteV3":{const id=getParamValue("tensorArrayId",node,tensorMap,context),index=getParamValue("index",node,tensorMap,context),writeTensor=getParamValue("tensor",node,tensorMap,context),writeTensorArray=context.getTensorArray(id.id);return writeTensorArray.write(index,writeTensor),[writeTensorArray.idTensor]}case"TensorArrayReadV3":{const readId=getParamValue("tensorArrayId",node,tensorMap,context),readIndex=getParamValue("index",node,tensorMap,context);return[context.getTensorArray(readId.id).read(readIndex)]}case"TensorArrayGatherV3":{const gatherId=getParamValue("tensorArrayId",node,tensorMap,context),gatherIndices=getParamValue("indices",node,tensorMap,context),gatherDtype=getParamValue("dtype",node,tensorMap,context);return[context.getTensorArray(gatherId.id).gather(gatherIndices,gatherDtype)]}case"TensorArrayScatterV3":{const scatterId=getParamValue("tensorArrayId",node,tensorMap,context),scatterIndices=getParamValue("indices",node,tensorMap,context),scatterTensor=getParamValue("tensor",node,tensorMap,context),scatterTensorArray=context.getTensorArray(scatterId.id);return scatterTensorArray.scatter(scatterIndices,scatterTensor),[scatterTensorArray.idTensor]}case"TensorArrayConcatV3":{const concatId=getParamValue("tensorArrayId",node,tensorMap,context),concatTensorArray=context.getTensorArray(concatId.id),concatDtype=getParamValue("dtype",node,tensorMap,context);return[concatTensorArray.concat(concatDtype)]}case"TensorArraySplitV3":{const splitId=getParamValue("tensorArrayId",node,tensorMap,context),splitTensor=getParamValue("tensor",node,tensorMap,context),lengths=getParamValue("lengths",node,tensorMap,context),splitTensorArray=context.getTensorArray(splitId.id);return splitTensorArray.split(lengths,splitTensor),[splitTensorArray.idTensor]}case"TensorArraySizeV3":{const sizeId=getParamValue("tensorArrayId",node,tensorMap,context),sizeTensorArray=context.getTensorArray(sizeId.id);return[(0,dist.d_2)(sizeTensorArray.size(),"int32")]}case"TensorArrayCloseV3":{const closeId=getParamValue("tensorArrayId",node,tensorMap,context),closeTensorArray=context.getTensorArray(closeId.id);return closeTensorArray.clearAndClose(),[closeTensorArray.idTensor]}case"TensorListSetItem":{const idTensor=getParamValue("tensorListId",node,tensorMap,context),index=getParamValue("index",node,tensorMap,context),writeTensor=getParamValue("tensor",node,tensorMap,context),tensorList=context.getTensorList(idTensor.id);return tensorList.setItem(index,writeTensor),[tensorList.idTensor]}case"TensorListGetItem":{const idTensor=getParamValue("tensorListId",node,tensorMap,context),readIndex=getParamValue("index",node,tensorMap,context),elementShape=getParamValue("elementShape",node,tensorMap,context),elementDType=getParamValue("elementDType",node,tensorMap,context);return[context.getTensorList(idTensor.id).getItem(readIndex,elementShape,elementDType)]}case"TensorListScatterV2":case"TensorListScatter":{const scatterIndices=getParamValue("indices",node,tensorMap,context),tensorList=function scatter(tensor,indices,elementShape,numElements){if(indices.length!==tensor.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${indices.length} vs. ${tensor.shape[0]}`);const maxIndex=Math.max(...indices);if(null!=numElements&&-1!==numElements&&maxIndex>=numElements)throw new Error(`Max index must be < array size (${maxIndex}  vs. ${numElements})`);const list=new TensorList([],elementShape,tensor.dtype,numElements),tensors=(0,dist.K$i)(tensor,0);return indices.forEach((value,index)=>{list.setItem(value,tensors[index])}),list}(getParamValue("tensor",node,tensorMap,context),scatterIndices,getParamValue("elementShape",node,tensorMap,context),getParamValue("numElements",node,tensorMap,context));return context.addTensorList(tensorList),[tensorList.idTensor]}case"TensorListReserve":case"EmptyTensorList":{const elementShape=getParamValue("elementShape",node,tensorMap,context),elementDtype=getParamValue("elementDType",node,tensorMap,context);let numElementsParam;numElementsParam="TensorListReserve"===node.op?"numElements":"maxNumElements";const numElements=getParamValue(numElementsParam,node,tensorMap,context),tensorList=function reserve(elementShape,elementDtype,numElements,maxNumElements){return new TensorList([],elementShape,elementDtype,maxNumElements)}(elementShape,elementDtype,0,"TensorListReserve"===node.op?-1:numElements);return context.addTensorList(tensorList),[tensorList.idTensor]}case"TensorListGather":{const gatherId=getParamValue("tensorListId",node,tensorMap,context),gatherIndices=getParamValue("indices",node,tensorMap,context),elementShape=getParamValue("elementShape",node,tensorMap,context),elementDtype=getParamValue("elementDType",node,tensorMap,context);return[context.getTensorList(gatherId.id).gather(gatherIndices,elementDtype,elementShape)]}case"TensorListStack":{const idTensor=getParamValue("tensorListId",node,tensorMap,context),elementShape=getParamValue("elementShape",node,tensorMap,context),elementDtype=getParamValue("elementDType",node,tensorMap,context),numElements=getParamValue("numElements",node,tensorMap,context);return[context.getTensorList(idTensor.id).stack(elementShape,elementDtype,numElements)]}case"TensorListFromTensor":{const tensorList=function fromTensor(tensor,elementShape,elementDtype){const dtype=tensor.dtype;if(tensor.shape.length<1)throw new Error(`Tensor must be at least a vector, but saw shape: ${tensor.shape}`);if(tensor.dtype!==elementDtype)throw new Error(`Invalid data types; op elements ${tensor.dtype}, but list elements ${elementDtype}`);assertShapesMatchAllowUndefinedSize(tensor.shape.slice(1),elementShape,"TensorList shape mismatch: ");const tensorList=(0,dist.K$i)(tensor);return new TensorList(tensorList,elementShape,dtype)}(getParamValue("tensor",node,tensorMap,context),getParamValue("elementShape",node,tensorMap,context),getParamValue("elementDType",node,tensorMap,context));return context.addTensorList(tensorList),[tensorList.idTensor]}case"TensorListConcat":case"TensorListConcatV2":{const concatId=getParamValue("tensorListId",node,tensorMap,context),tensorList=context.getTensorList(concatId.id),concatDtype=getParamValue("dtype",node,tensorMap,context),elementShape=getParamValue("elementShape",node,tensorMap,context);return[tensorList.concat(concatDtype,elementShape)]}case"TensorListPushBack":{const idTensor=getParamValue("tensorListId",node,tensorMap,context),writeTensor=getParamValue("tensor",node,tensorMap,context),tensorList=context.getTensorList(idTensor.id);return tensorList.pushBack(writeTensor),[tensorList.idTensor]}case"TensorListPopBack":{const idTensor=getParamValue("tensorListId",node,tensorMap,context),elementShape=getParamValue("elementShape",node,tensorMap,context),elementDType=getParamValue("elementDType",node,tensorMap,context);return[context.getTensorList(idTensor.id).popBack(elementShape,elementDType)]}case"TensorListSplit":{const splitTensor=getParamValue("tensor",node,tensorMap,context),elementShape=getParamValue("elementShape",node,tensorMap,context),tensorList=function tensor_list_split(tensor,length,elementShape){let totalLength=0;const cumulativeLengths=length.map(len=>(totalLength+=len,totalLength));if(totalLength!==tensor.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);const outputElementShape=mergeElementShape(tensor.shape.slice(1),elementShape),elementPerRow=0===totalLength?0:tensor.size/totalLength,tensors=(0,dist.DZQ)(()=>{const tensors=[];tensor=(0,dist.tQQ)(tensor,[1,totalLength,elementPerRow]);for(let i=0;i<length.length;++i){const indices=[0,0===i?0:cumulativeLengths[i-1],0],sizes=[1,length[i],elementPerRow];tensors[i]=(0,dist.tQQ)((0,dist.dik)(tensor,indices,sizes),outputElementShape)}return tensor.dispose(),tensors}),list=new TensorList([],elementShape,tensor.dtype,length.length);for(let i=0;i<tensors.length;i++)list.setItem(i,tensors[i]);return list}(splitTensor,getParamValue("lengths",node,tensorMap,context),elementShape);return context.addTensorList(tensorList),[tensorList.idTensor]}case"TensorListLength":{const idTensor=getParamValue("tensorListId",node,tensorMap,context),tensorList=context.getTensorList(idTensor.id);return[(0,dist.d_2)(tensorList.size(),"int32")]}case"TensorListResize":{const idTensor=getParamValue("tensorListId",node,tensorMap,context),size=getParamValue("size",node,tensorMap,context),destTensorList=context.getTensorList(idTensor.id).resize(size);return context.addTensorList(destTensorList),[destTensorList.idTensor]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};function fusedConvAndDepthWiseParams(node,tensorMap,context){const[extraOp,activationFunc]=getParamValue("fusedOps",node,tensorMap,context),isBiasAdd="biasadd"===extraOp,noBiasAdd=!isBiasAdd,isPrelu="prelu"===activationFunc,isBatchNorm="fusedbatchnorm"===extraOp,numArgs=getParamValue("numArgs",node,tensorMap,context);if(isBiasAdd){if(isPrelu&&2!==numArgs)throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");if(!isPrelu&&isBiasAdd&&1!==numArgs)throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.")}if(isBatchNorm)throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported");const stride=getParamValue("strides",node,tensorMap,context),pad=getPadding(node,tensorMap,context),dataFormat=getParamValue("dataFormat",node,tensorMap,context).toUpperCase(),dilations=getParamValue("dilations",node,tensorMap,context);let[biasArg,preluArg]=getParamValue("args",node,tensorMap,context);noBiasAdd&&(preluArg=biasArg,biasArg=void 0);return{stride,pad,dataFormat,dilations,biasArg,preluArg,activationFunc,leakyreluAlpha:getParamValue("leakyreluAlpha",node,tensorMap,context)}}function nmsParams(node,tensorMap,context){return{boxes:getParamValue("boxes",node,tensorMap,context),scores:getParamValue("scores",node,tensorMap,context),maxOutputSize:getParamValue("maxOutputSize",node,tensorMap,context),iouThreshold:getParamValue("iouThreshold",node,tensorMap,context),scoreThreshold:getParamValue("scoreThreshold",node,tensorMap,context),softNmsSigma:getParamValue("softNmsSigma",node,tensorMap,context)}}var graph_executor_console=__webpack_require__("./node_modules/console-browserify/index.js");class HashTable{get id(){return this.handle.id}constructor(keyDType,valueDType){this.keyDType=keyDType,this.valueDType=valueDType,this.handle=(0,dist.d_2)(0),this.tensorMap=new Map,(0,dist.aCs)(this.handle)}clearAndClose(){this.tensorMap.forEach(value=>value.dispose()),this.tensorMap.clear(),this.handle.dispose()}size(){return this.tensorMap.size}tensorSize(){return ops_scalar.d(this.size(),"int32")}async import(keys,values){this.checkKeyAndValueTensor(keys,values);const $keys=await keys.data();return this.tensorMap.forEach(value=>value.dispose()),this.tensorMap.clear(),(0,dist.DZQ)(()=>{const $values=(0,dist.K$i)(values),keysLength=$keys.length,valuesLength=$values.length;dist.ZSL.assert(keysLength===valuesLength,()=>`The number of elements doesn't match, keys has ${keysLength} elements, the values has ${valuesLength} elements.`);for(let i=0;i<keysLength;i++){const key=$keys[i],value=$values[i];(0,dist.aCs)(value),this.tensorMap.set(key,value)}return this.handle})}async find(keys,defaultValue){this.checkKeyAndValueTensor(keys,defaultValue);const $keys=await keys.data();return(0,dist.DZQ)(()=>{const result=[];for(let i=0;i<$keys.length;i++){const key=$keys[i],value=this.findWithDefault(key,defaultValue);result.push(value)}return(0,dist.t$z)(result)})}findWithDefault(key,defaultValue){const result=this.tensorMap.get(key);return null!=result?result:defaultValue}checkKeyAndValueTensor(key,value){if(key.dtype!==this.keyDType)throw new Error(`Expect key dtype ${this.keyDType}, but got ${key.dtype}`);if(value.dtype!==this.valueDType)throw new Error(`Expect value dtype ${this.valueDType}, but got ${value.dtype}`)}}function operation_executor_executeOp(node,tensorMap,context,resourceManager,tidy=dist.DZQ){const value=((node,tensorMap,context)=>{switch(node.category){case"arithmetic":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"BiasAdd":case"AddV2":case"Add":return[ops.add(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"AddN":return[ops.addN(getParamValue("tensors",node,tensorMap,context))];case"FloorMod":case"Mod":return[ops.mod(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"Mul":return[ops.mul(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"RealDiv":case"Div":return[ops.div(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"DivNoNan":return[ops.divNoNan(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"FloorDiv":return[ops.floorDiv(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"Sub":return[ops.sub(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"Minimum":return[ops.minimum(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"Maximum":return[ops.maximum(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"Pow":return[ops.pow(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"SquaredDifference":return[ops.squaredDifference(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"basic_math":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"Abs":case"ComplexAbs":return[ops.abs(getParamValue("x",node,tensorMap,context))];case"Acos":return[ops.acos(getParamValue("x",node,tensorMap,context))];case"Acosh":return[ops.acosh(getParamValue("x",node,tensorMap,context))];case"Asin":return[ops.asin(getParamValue("x",node,tensorMap,context))];case"Asinh":return[ops.asinh(getParamValue("x",node,tensorMap,context))];case"Atan":return[ops.atan(getParamValue("x",node,tensorMap,context))];case"Atan2":return[ops.atan2(getParamValue("x",node,tensorMap,context),getParamValue("y",node,tensorMap,context))];case"Atanh":return[ops.atanh(getParamValue("x",node,tensorMap,context))];case"Ceil":return[ops.ceil(getParamValue("x",node,tensorMap,context))];case"Complex":return[ops.complex(getParamValue("real",node,tensorMap,context),getParamValue("imag",node,tensorMap,context))];case"Cos":return[ops.cos(getParamValue("x",node,tensorMap,context))];case"Cosh":return[ops.cosh(getParamValue("x",node,tensorMap,context))];case"Elu":return[ops.elu(getParamValue("x",node,tensorMap,context))];case"Erf":return[ops.erf(getParamValue("x",node,tensorMap,context))];case"Exp":return[ops.exp(getParamValue("x",node,tensorMap,context))];case"Expm1":return[ops.expm1(getParamValue("x",node,tensorMap,context))];case"Floor":return[ops.floor(getParamValue("x",node,tensorMap,context))];case"Log":return[ops.log(getParamValue("x",node,tensorMap,context))];case"Log1p":return[ops.log1p(getParamValue("x",node,tensorMap,context))];case"Imag":return[ops.imag(getParamValue("x",node,tensorMap,context))];case"Neg":return[ops.neg(getParamValue("x",node,tensorMap,context))];case"Reciprocal":return[ops.reciprocal(getParamValue("x",node,tensorMap,context))];case"Real":return[ops.real(getParamValue("x",node,tensorMap,context))];case"Relu":return[ops.relu(getParamValue("x",node,tensorMap,context))];case"Round":return[ops.round(getParamValue("x",node,tensorMap,context))];case"Selu":return[ops.selu(getParamValue("x",node,tensorMap,context))];case"Sigmoid":return[ops.sigmoid(getParamValue("x",node,tensorMap,context))];case"Sin":return[ops.sin(getParamValue("x",node,tensorMap,context))];case"Sign":return[ops.sign(getParamValue("x",node,tensorMap,context))];case"Sinh":return[ops.sinh(getParamValue("x",node,tensorMap,context))];case"Softplus":return[ops.softplus(getParamValue("x",node,tensorMap,context))];case"Sqrt":return[ops.sqrt(getParamValue("x",node,tensorMap,context))];case"Square":return[ops.square(getParamValue("x",node,tensorMap,context))];case"Tanh":return[ops.tanh(getParamValue("x",node,tensorMap,context))];case"Tan":return[ops.tan(getParamValue("x",node,tensorMap,context))];case"ClipByValue":return[ops.clipByValue(getParamValue("x",node,tensorMap,context),getParamValue("clipValueMin",node,tensorMap,context),getParamValue("clipValueMax",node,tensorMap,context))];case"Relu6":return[ops.relu6(getParamValue("x",node,tensorMap,context))];case"Rsqrt":return[ops.rsqrt(getTensor(node.inputNames[0],tensorMap,context))];case"LeakyRelu":return[ops.leakyRelu(getParamValue("x",node,tensorMap,context),getParamValue("alpha",node,tensorMap,context))];case"Prelu":return[ops.prelu(getParamValue("x",node,tensorMap,context),getParamValue("alpha",node,tensorMap,context))];case"IsNan":return[ops.isNaN(getTensor(node.inputNames[0],tensorMap,context))];case"IsInf":return[ops.isInf(getTensor(node.inputNames[0],tensorMap,context))];case"IsFinite":return[ops.isFinite(getTensor(node.inputNames[0],tensorMap,context))];default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"control":return control_executor_executeOp(node,tensorMap,context);case"convolution":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"Conv1D":{const stride=getParamValue("stride",node,tensorMap,context),pad=getParamValue("pad",node,tensorMap,context),dataFormat=getParamValue("dataFormat",node,tensorMap,context).toUpperCase(),dilation=getParamValue("dilation",node,tensorMap,context);return[ops.conv1d(getParamValue("x",node,tensorMap,context),getParamValue("filter",node,tensorMap,context),stride,pad,dataFormat,dilation)]}case"Conv2D":{const stride=getParamValue("strides",node,tensorMap,context),pad=getPadding(node,tensorMap,context),dataFormat=getParamValue("dataFormat",node,tensorMap,context).toUpperCase(),dilations=getParamValue("dilations",node,tensorMap,context);return[ops.conv2d(getParamValue("x",node,tensorMap,context),getParamValue("filter",node,tensorMap,context),[stride[1],stride[2]],pad,dataFormat,[dilations[1],dilations[2]])]}case"_FusedConv2D":{const{stride,pad,dataFormat,dilations,biasArg,preluArg,activationFunc,leakyreluAlpha}=fusedConvAndDepthWiseParams(node,tensorMap,context);return[ops.fused.conv2d({x:getParamValue("x",node,tensorMap,context),filter:getParamValue("filter",node,tensorMap,context),strides:[stride[1],stride[2]],pad,dataFormat,dilations:[dilations[1],dilations[2]],bias:biasArg,activation:activationFunc,preluActivationWeights:preluArg,leakyreluAlpha})]}case"FusedDepthwiseConv2dNative":{const{stride,pad,dataFormat,dilations,biasArg,preluArg,activationFunc,leakyreluAlpha}=fusedConvAndDepthWiseParams(node,tensorMap,context);return[ops.fused.depthwiseConv2d({x:getParamValue("x",node,tensorMap,context),filter:getParamValue("filter",node,tensorMap,context),strides:[stride[1],stride[2]],pad,dataFormat,dilations:[dilations[1],dilations[2]],bias:biasArg,activation:activationFunc,preluActivationWeights:preluArg,leakyreluAlpha})]}case"Conv2DBackpropInput":case"Conv2dTranspose":{const shape=getParamValue("outputShape",node,tensorMap,context),stride=getParamValue("strides",node,tensorMap,context),pad=getPadding(node,tensorMap,context);return[ops.conv2dTranspose(getParamValue("x",node,tensorMap,context),getParamValue("filter",node,tensorMap,context),shape,[stride[1],stride[2]],pad)]}case"DepthwiseConv2dNative":case"DepthwiseConv2d":{const stride=getParamValue("strides",node,tensorMap,context),pad=getPadding(node,tensorMap,context),dilations=getParamValue("dilations",node,tensorMap,context),dataFormat=getParamValue("dataFormat",node,tensorMap,context).toUpperCase();return[ops.depthwiseConv2d(getParamValue("input",node,tensorMap,context),getParamValue("filter",node,tensorMap,context),[stride[1],stride[2]],pad,dataFormat,[dilations[1],dilations[2]])]}case"Conv3D":{const stride=getParamValue("strides",node,tensorMap,context),pad=getParamValue("pad",node,tensorMap,context),dataFormat=getParamValue("dataFormat",node,tensorMap,context).toUpperCase(),dilations=getParamValue("dilations",node,tensorMap,context);return[ops.conv3d(getParamValue("x",node,tensorMap,context),getParamValue("filter",node,tensorMap,context),[stride[1],stride[2],stride[3]],pad,dataFormat,[dilations[1],dilations[2],dilations[3]])]}case"AvgPool":{const stride=getParamValue("strides",node,tensorMap,context),pad=getParamValue("pad",node,tensorMap,context),kernelSize=getParamValue("kernelSize",node,tensorMap,context);return[ops.avgPool(getParamValue("x",node,tensorMap,context),[kernelSize[1],kernelSize[2]],[stride[1],stride[2]],pad)]}case"MaxPool":{const stride=getParamValue("strides",node,tensorMap,context),pad=getParamValue("pad",node,tensorMap,context),kernelSize=getParamValue("kernelSize",node,tensorMap,context);return[ops.maxPool(getParamValue("x",node,tensorMap,context),[kernelSize[1],kernelSize[2]],[stride[1],stride[2]],pad)]}case"MaxPoolWithArgmax":{const stride=getParamValue("strides",node,tensorMap,context),pad=getParamValue("pad",node,tensorMap,context),kernelSize=getParamValue("kernelSize",node,tensorMap,context),includeBatchInIndex=getParamValue("includeBatchInIndex",node,tensorMap,context),{result,indexes}=ops.maxPoolWithArgmax(getParamValue("x",node,tensorMap,context),[kernelSize[1],kernelSize[2]],[stride[1],stride[2]],pad,includeBatchInIndex);return[result,indexes]}case"AvgPool3D":{const stride=getParamValue("strides",node,tensorMap,context),pad=getParamValue("pad",node,tensorMap,context),kernelSize=getParamValue("kernelSize",node,tensorMap,context);return[ops.avgPool3d(getParamValue("x",node,tensorMap,context),[kernelSize[1],kernelSize[2],kernelSize[3]],[stride[1],stride[2],stride[3]],pad)]}case"MaxPool3D":{const stride=getParamValue("strides",node,tensorMap,context),pad=getParamValue("pad",node,tensorMap,context),kernelSize=getParamValue("kernelSize",node,tensorMap,context);return[ops.maxPool3d(getParamValue("x",node,tensorMap,context),[kernelSize[1],kernelSize[2],kernelSize[3]],[stride[1],stride[2],stride[3]],pad)]}case"Dilation2D":{const strides=getParamValue("strides",node,tensorMap,context),pad=getParamValue("pad",node,tensorMap,context),dilations=getParamValue("dilations",node,tensorMap,context),strideHeight=strides[1],strideWidth=strides[2],dilationHeight=dilations[1],dilationWidth=dilations[2];return[ops.dilation2d(getParamValue("x",node,tensorMap,context),getParamValue("filter",node,tensorMap,context),[strideHeight,strideWidth],pad,[dilationHeight,dilationWidth],"NHWC")]}default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"creation":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"Fill":{const shape=getParamValue("shape",node,tensorMap,context),dtype=getParamValue("dtype",node,tensorMap,context),value=getParamValue("value",node,tensorMap,context);return[ops.fill(shape,value,dtype)]}case"LinSpace":{const start=getParamValue("start",node,tensorMap,context),stop=getParamValue("stop",node,tensorMap,context),num=getParamValue("num",node,tensorMap,context);return[ops.linspace(start,stop,num)]}case"Multinomial":{const logits=getParamValue("logits",node,tensorMap,context),numSamples=getParamValue("numSamples",node,tensorMap,context),seed=getParamValue("seed",node,tensorMap,context);return[ops.multinomial(logits,numSamples,seed)]}case"OneHot":{const indices=getParamValue("indices",node,tensorMap,context),depth=getParamValue("depth",node,tensorMap,context),onValue=getParamValue("onValue",node,tensorMap,context),offValue=getParamValue("offValue",node,tensorMap,context),dtype=getParamValue("dtype",node,tensorMap,context);return[ops.oneHot(indices,depth,onValue,offValue,dtype)]}case"Ones":return[ops.ones(getParamValue("shape",node,tensorMap,context),getParamValue("dtype",node,tensorMap,context))];case"OnesLike":return[ops.onesLike(getParamValue("x",node,tensorMap,context))];case"RandomStandardNormal":return[ops.randomStandardNormal(getParamValue("shape",node,tensorMap,context),getParamValue("dtype",node,tensorMap,context),getParamValue("seed",node,tensorMap,context))];case"RandomUniform":return[ops.randomUniform(getParamValue("shape",node,tensorMap,context),getParamValue("minval",node,tensorMap,context),getParamValue("maxval",node,tensorMap,context),getParamValue("dtype",node,tensorMap,context))];case"RandomUniformInt":return[ops.randomUniformInt(getParamValue("shape",node,tensorMap,context),getParamValue("minval",node,tensorMap,context),getParamValue("maxval",node,tensorMap,context),getParamValue("seed",node,tensorMap,context))];case"Range":{const start=getParamValue("start",node,tensorMap,context),stop=getParamValue("stop",node,tensorMap,context),step=getParamValue("step",node,tensorMap,context);return[ops.range(start,stop,step,getParamValue("dtype",node,tensorMap,context))]}case"TruncatedNormal":{const shape=getParamValue("shape",node,tensorMap,context),mean=getParamValue("mean",node,tensorMap,context),stdDev=getParamValue("stdDev",node,tensorMap,context),seed=getParamValue("seed",node,tensorMap,context);return[ops.truncatedNormal(shape,mean,stdDev,getParamValue("dtype",node,tensorMap,context),seed)]}case"Zeros":return[ops.zeros(getParamValue("shape",node,tensorMap,context),getParamValue("dtype",node,tensorMap,context))];case"ZerosLike":return[ops.zerosLike(getParamValue("x",node,tensorMap,context))];default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"dynamic":return(async(node,tensorMap,context,resourceManager,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"NonMaxSuppressionV5":{const{boxes,scores,maxOutputSize,iouThreshold,scoreThreshold,softNmsSigma}=nmsParams(node,tensorMap,context),result=await ops.image.nonMaxSuppressionWithScoreAsync(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold,softNmsSigma);return[result.selectedIndices,result.selectedScores]}case"NonMaxSuppressionV4":{const{boxes,scores,maxOutputSize,iouThreshold,scoreThreshold}=nmsParams(node,tensorMap,context),padToMaxOutputSize=getParamValue("padToMaxOutputSize",node,tensorMap,context),result=await ops.image.nonMaxSuppressionPaddedAsync(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold,padToMaxOutputSize);return[result.selectedIndices,result.validOutputs]}case"NonMaxSuppressionV3":case"NonMaxSuppressionV2":{const{boxes,scores,maxOutputSize,iouThreshold,scoreThreshold}=nmsParams(node,tensorMap,context);return[await ops.image.nonMaxSuppressionAsync(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold)]}case"Where":{const condition=ops.cast(getParamValue("condition",node,tensorMap,context),"bool"),result=[await ops.whereAsync(condition)];return condition.dispose(),result}case"ListDiff":return ops.setdiff1dAsync(getParamValue("x",node,tensorMap,context),getParamValue("y",node,tensorMap,context));default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context);case"evaluation":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"LowerBound":{const sortedSequence=getParamValue("sortedSequence",node,tensorMap,context),values=getParamValue("values",node,tensorMap,context);return[ops.lowerBound(sortedSequence,values)]}case"TopKV2":{const x=getParamValue("x",node,tensorMap,context),k=getParamValue("k",node,tensorMap,context),sorted=getParamValue("sorted",node,tensorMap,context),result=ops.topk(x,k,sorted);return[result.values,result.indices]}case"UpperBound":{const sortedSequence=getParamValue("sortedSequence",node,tensorMap,context),values=getParamValue("values",node,tensorMap,context);return[ops.upperBound(sortedSequence,values)]}case"Unique":{const x=getParamValue("x",node,tensorMap,context),result=ops.unique(x);return[result.values,result.indices]}case"UniqueV2":{const x=getParamValue("x",node,tensorMap,context),axis=getParamValue("axis",node,tensorMap,context),result=ops.unique(x,axis);return[result.values,result.indices]}default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"image":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"ResizeBilinear":{const images=getParamValue("images",node,tensorMap,context),size=getParamValue("size",node,tensorMap,context),alignCorners=getParamValue("alignCorners",node,tensorMap,context),halfPixelCenters=getParamValue("halfPixelCenters",node,tensorMap,context);return[ops.image.resizeBilinear(images,[size[0],size[1]],alignCorners,halfPixelCenters)]}case"ResizeNearestNeighbor":{const images=getParamValue("images",node,tensorMap,context),size=getParamValue("size",node,tensorMap,context),alignCorners=getParamValue("alignCorners",node,tensorMap,context),halfPixelCenters=getParamValue("halfPixelCenters",node,tensorMap,context);return[ops.image.resizeNearestNeighbor(images,[size[0],size[1]],alignCorners,halfPixelCenters)]}case"CropAndResize":{const image=getParamValue("image",node,tensorMap,context),boxes=getParamValue("boxes",node,tensorMap,context),boxInd=getParamValue("boxInd",node,tensorMap,context),cropSize=getParamValue("cropSize",node,tensorMap,context),method=getParamValue("method",node,tensorMap,context),extrapolationValue=getParamValue("extrapolationValue",node,tensorMap,context);return[ops.image.cropAndResize(image,boxes,boxInd,cropSize,method,extrapolationValue)]}case"ImageProjectiveTransformV3":{const images=getParamValue("images",node,tensorMap,context),transforms=getParamValue("transforms",node,tensorMap,context),outputShape=getParamValue("outputShape",node,tensorMap,context),fillValue=getParamValue("fillValue",node,tensorMap,context),interpolation=getParamValue("interpolation",node,tensorMap,context),fillMode=getParamValue("fillMode",node,tensorMap,context);return[ops.image.transform(images,transforms,interpolation.toLowerCase(),fillMode.toLowerCase(),fillValue,outputShape)]}default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"graph":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"Const":return tensorMap[node.name];case"PlaceholderWithDefault":const def=getParamValue("default",node,tensorMap,context);return[getTensor(node.name,tensorMap,context)||def];case"Placeholder":return[getTensor(node.name,tensorMap,context)];case"Identity":case"StopGradient":case"FakeQuantWithMinMaxVars":case"Snapshot":return[cloneTensor(getParamValue("x",node,tensorMap,context))];case"IdentityN":return getParamValue("x",node,tensorMap,context).map(t=>cloneTensor(t));case"Shape":return[ops.tensor1d(getParamValue("x",node,tensorMap,context).shape,"int32")];case"ShapeN":return getParamValue("x",node,tensorMap,context).map(t=>ops.tensor1d(t.shape));case"Size":return[ops.scalar(getParamValue("x",node,tensorMap,context).size,"int32")];case"Rank":return[ops.scalar(getParamValue("x",node,tensorMap,context).rank,"int32")];case"NoOp":return[ops.scalar(1)];case"Print":const input=getParamValue("x",node,tensorMap,context),data=getParamValue("data",node,tensorMap,context),message=getParamValue("message",node,tensorMap,context),summarize=getParamValue("summarize",node,tensorMap,context);graph_executor_console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance."),graph_executor_console.log(message);for(let i=0;i<data.length;i++)graph_executor_console.log(Array.prototype.slice.call(data[i].dataSync()).slice(0,summarize));return[input];default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"logical":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"Equal":return[ops.equal(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"NotEqual":return[ops.notEqual(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"Greater":return[ops.greater(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"GreaterEqual":return[ops.greaterEqual(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"Less":return[ops.less(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"LessEqual":return[ops.lessEqual(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"LogicalAnd":return[ops.logicalAnd(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"LogicalNot":return[ops.logicalNot(getParamValue("a",node,tensorMap,context))];case"LogicalOr":return[ops.logicalOr(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"Select":case"SelectV2":return[ops.where(getParamValue("condition",node,tensorMap,context),getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"BitwiseAnd":return[ops.bitwiseAnd(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"matrices":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"BatchMatMul":case"BatchMatMulV2":case"MatMul":return[ops.matMul(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context),getParamValue("transposeA",node,tensorMap,context),getParamValue("transposeB",node,tensorMap,context))];case"Einsum":return[ops.einsum(getParamValue("equation",node,tensorMap,context),...getParamValue("tensors",node,tensorMap,context))];case"Transpose":return[ops.transpose(getParamValue("x",node,tensorMap,context),getParamValue("perm",node,tensorMap,context))];case"_FusedMatMul":const[extraOp,activationFunc]=getParamValue("fusedOps",node,tensorMap,context),isBiasAdd="biasadd"===extraOp,isPrelu="prelu"===activationFunc,numArgs=getParamValue("numArgs",node,tensorMap,context),leakyreluAlpha=getParamValue("leakyreluAlpha",node,tensorMap,context);if(isBiasAdd){if(isPrelu&&2!==numArgs)throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");if(!isPrelu&&1!==numArgs)throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.")}const[biasArg,preluArg]=getParamValue("args",node,tensorMap,context);return[ops.fused.matMul({a:getParamValue("a",node,tensorMap,context),b:getParamValue("b",node,tensorMap,context),transposeA:getParamValue("transposeA",node,tensorMap,context),transposeB:getParamValue("transposeB",node,tensorMap,context),bias:biasArg,activation:activationFunc,preluActivationWeights:preluArg,leakyreluAlpha})];case"MatrixBandPart":return[ops.linalg.bandPart(getParamValue("a",node,tensorMap,context),getParamValue("numLower",node,tensorMap,context),getParamValue("numUpper",node,tensorMap,context))];default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"normalization":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"EuclideanNorm":return[ops.euclideanNorm(getParamValue("x",node,tensorMap,context),getParamValue("axis",node,tensorMap,context),getParamValue("keepDims",node,tensorMap,context))];case"FusedBatchNorm":case"FusedBatchNormV2":case"FusedBatchNormV3":return[ops.batchNorm(getParamValue("x",node,tensorMap,context),getParamValue("mean",node,tensorMap,context),getParamValue("variance",node,tensorMap,context),getParamValue("offset",node,tensorMap,context),getParamValue("scale",node,tensorMap,context),getParamValue("epsilon",node,tensorMap,context))];case"LRN":return[ops.localResponseNormalization(getParamValue("x",node,tensorMap,context),getParamValue("radius",node,tensorMap,context),getParamValue("bias",node,tensorMap,context),getParamValue("alpha",node,tensorMap,context),getParamValue("beta",node,tensorMap,context))];case"Softmax":return[ops.softmax(getParamValue("x",node,tensorMap,context))];case"LogSoftmax":return[ops.logSoftmax(getParamValue("x",node,tensorMap,context))];default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"ragged":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"RaggedGather":{const{outputNestedSplits,outputDenseValues}=ops.raggedGather(getParamValue("paramsNestedSplits",node,tensorMap,context),getParamValue("paramsDenseValues",node,tensorMap,context),getParamValue("indices",node,tensorMap,context),getParamValue("outputRaggedRank",node,tensorMap,context));return outputNestedSplits.concat(outputDenseValues)}case"RaggedRange":{const{rtNestedSplits,rtDenseValues}=ops.raggedRange(getParamValue("starts",node,tensorMap,context),getParamValue("limits",node,tensorMap,context),getParamValue("splits",node,tensorMap,context));return[rtNestedSplits,rtDenseValues]}case"RaggedTensorToTensor":return[ops.raggedTensorToTensor(getParamValue("shape",node,tensorMap,context),getParamValue("values",node,tensorMap,context),getParamValue("defaultValue",node,tensorMap,context),getParamValue("rowPartitionTensors",node,tensorMap,context),getParamValue("rowPartitionTypes",node,tensorMap,context))];default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"reduction":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"Max":{const axis=getParamValue("axis",node,tensorMap,context),keepDims=getParamValue("keepDims",node,tensorMap,context);return[ops.max(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"Mean":{const axis=getParamValue("axis",node,tensorMap,context),keepDims=getParamValue("keepDims",node,tensorMap,context);return[ops.mean(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"Min":{const axis=getParamValue("axis",node,tensorMap,context),keepDims=getParamValue("keepDims",node,tensorMap,context);return[ops.min(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"Sum":{const axis=getParamValue("axis",node,tensorMap,context),keepDims=getParamValue("keepDims",node,tensorMap,context);return[ops.sum(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"All":{const axis=getParamValue("axis",node,tensorMap,context),keepDims=getParamValue("keepDims",node,tensorMap,context);return[ops.all(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"Any":{const axis=getParamValue("axis",node,tensorMap,context),keepDims=getParamValue("keepDims",node,tensorMap,context);return[ops.any(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"ArgMax":{const axis=getParamValue("axis",node,tensorMap,context);return[ops.argMax(getParamValue("x",node,tensorMap,context),axis)]}case"ArgMin":{const axis=getParamValue("axis",node,tensorMap,context);return[ops.argMin(getParamValue("x",node,tensorMap,context),axis)]}case"Prod":{const axis=getParamValue("axis",node,tensorMap,context),keepDims=getParamValue("keepDims",node,tensorMap,context);return[ops.prod(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"Cumprod":{const axis=getParamValue("axis",node,tensorMap,context),exclusive=getParamValue("exclusive",node,tensorMap,context),reverse=getParamValue("reverse",node,tensorMap,context);return[ops.cumprod(getParamValue("x",node,tensorMap,context),axis,exclusive,reverse)]}case"Cumsum":{const axis=getParamValue("axis",node,tensorMap,context),exclusive=getParamValue("exclusive",node,tensorMap,context),reverse=getParamValue("reverse",node,tensorMap,context);return[ops.cumsum(getParamValue("x",node,tensorMap,context),axis,exclusive,reverse)]}case"Bincount":const x=getParamValue("x",node,tensorMap,context),weights=getParamValue("weights",node,tensorMap,context),size=getParamValue("size",node,tensorMap,context);return[ops.bincount(x,weights,size)];case"DenseBincount":{const x=getParamValue("x",node,tensorMap,context),weights=getParamValue("weights",node,tensorMap,context),size=getParamValue("size",node,tensorMap,context),binaryOutput=getParamValue("binaryOutput",node,tensorMap,context);return[ops.denseBincount(x,weights,size,binaryOutput)]}default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"slice_join":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"ConcatV2":case"Concat":{const n=getParamValue("n",node,tensorMap,context),axis=getParamValue("axis",node,tensorMap,context);let inputs=getParamValue("tensors",node,tensorMap,context);return inputs=inputs.slice(0,n),[ops.concat(inputs,axis)]}case"Gather":{const input=getParamValue("x",node,tensorMap,context),indices=getParamValue("indices",node,tensorMap,context);return[ops.gather(input,ops.cast(indices,"int32"),0)]}case"GatherV2":{const axis=getParamValue("axis",node,tensorMap,context),batchDims=getParamValue("batchDims",node,tensorMap,context),input=getParamValue("x",node,tensorMap,context),indices=getParamValue("indices",node,tensorMap,context);return[ops.gather(input,ops.cast(indices,"int32"),axis,batchDims)]}case"Reverse":{const dims=getParamValue("dims",node,tensorMap,context),axis=[];for(let i=0;i<dims.length;i++)dims[i]&&axis.push(i);const input=getParamValue("x",node,tensorMap,context);return[ops.reverse(input,axis)]}case"ReverseV2":{const axis=getParamValue("axis",node,tensorMap,context),input=getParamValue("x",node,tensorMap,context);return[ops.reverse(input,axis)]}case"Slice":{const begin=getParamValue("begin",node,tensorMap,context),size=getParamValue("size",node,tensorMap,context);return[ops.slice(getParamValue("x",node,tensorMap,context),begin,size)]}case"StridedSlice":{const begin=getParamValue("begin",node,tensorMap,context),end=getParamValue("end",node,tensorMap,context),strides=getParamValue("strides",node,tensorMap,context),beginMask=getParamValue("beginMask",node,tensorMap,context),endMask=getParamValue("endMask",node,tensorMap,context),ellipsisMask=getParamValue("ellipsisMask",node,tensorMap,context),newAxisMask=getParamValue("newAxisMask",node,tensorMap,context),shrinkAxisMask=getParamValue("shrinkAxisMask",node,tensorMap,context),tensor=getParamValue("x",node,tensorMap,context);return[ops.stridedSlice(tensor,begin,end,strides,beginMask,endMask,ellipsisMask,newAxisMask,shrinkAxisMask)]}case"Pack":return(0,dist.DZQ)(()=>{const axis=getParamValue("axis",node,tensorMap,context),tensors=getParamValue("tensors",node,tensorMap,context),shape=tensors[0].shape,squeezedShape=ops.squeeze(tensors[0]).shape,mapped=tensors.map(tensor=>{const sameShape=dist.ZSL.arraysEqual(tensor.shape,shape);if(!sameShape&&!dist.ZSL.arraysEqual(ops.squeeze(tensor).shape,squeezedShape))throw new Error("the input tensors shape does not match");return sameShape?tensor:ops.reshape(tensor,shape)});return[ops.stack(mapped,axis)]});case"Unpack":{const axis=getParamValue("axis",node,tensorMap,context),tensor=getParamValue("tensor",node,tensorMap,context);return ops.unstack(tensor,axis)}case"Tile":{const reps=getParamValue("reps",node,tensorMap,context);return[ops.tile(getParamValue("x",node,tensorMap,context),reps)]}case"Split":case"SplitV":{const axis=getParamValue("axis",node,tensorMap,context),numOrSizeSplits=getParamValue("numOrSizeSplits",node,tensorMap,context),tensor=getParamValue("x",node,tensorMap,context);return ops.split(tensor,numOrSizeSplits,axis)}case"ScatterNd":{const indices=getParamValue("indices",node,tensorMap,context),values=getParamValue("values",node,tensorMap,context),shape=getParamValue("shape",node,tensorMap,context);return[ops.scatterND(indices,values,shape)]}case"GatherNd":{const x=getParamValue("x",node,tensorMap,context),indices=getParamValue("indices",node,tensorMap,context);return[ops.gatherND(x,indices)]}case"SparseToDense":{const indices=getParamValue("sparseIndices",node,tensorMap,context),shape=getParamValue("outputShape",node,tensorMap,context),sparseValues=getParamValue("sparseValues",node,tensorMap,context),defaultValue=getParamValue("defaultValue",node,tensorMap,context);return[ops.sparseToDense(indices,sparseValues,shape,sparseValues.dtype===defaultValue.dtype?defaultValue:ops.cast(defaultValue,sparseValues.dtype))]}case"TensorScatterUpdate":{const indices=getParamValue("indices",node,tensorMap,context),values=getParamValue("values",node,tensorMap,context),tensor=getParamValue("tensor",node,tensorMap,context);return[ops.tensorScatterUpdate(tensor,indices,values)]}default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"sparse":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"SparseFillEmptyRows":{const{outputIndices,outputValues,emptyRowIndicator,reverseIndexMap}=ops.sparse.sparseFillEmptyRows(getParamValue("indices",node,tensorMap,context),getParamValue("values",node,tensorMap,context),getParamValue("denseShape",node,tensorMap,context),getParamValue("defaultValue",node,tensorMap,context));return[outputIndices,outputValues,emptyRowIndicator,reverseIndexMap]}case"SparseReshape":{const{outputIndices,outputShape}=ops.sparse.sparseReshape(getParamValue("inputIndices",node,tensorMap,context),getParamValue("inputShape",node,tensorMap,context),getParamValue("newShape",node,tensorMap,context));return[outputIndices,outputShape]}case"SparseSegmentMean":return[ops.sparse.sparseSegmentMean(getParamValue("data",node,tensorMap,context),getParamValue("indices",node,tensorMap,context),getParamValue("segmentIds",node,tensorMap,context))];case"SparseSegmentSum":return[ops.sparse.sparseSegmentSum(getParamValue("data",node,tensorMap,context),getParamValue("indices",node,tensorMap,context),getParamValue("segmentIds",node,tensorMap,context))];default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"spectral":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"FFT":return[ops.fft(getParamValue("x",node,tensorMap,context))];case"IFFT":return[ops.ifft(getParamValue("x",node,tensorMap,context))];case"RFFT":return[ops.rfft(getParamValue("x",node,tensorMap,context))];case"IRFFT":return[ops.irfft(getParamValue("x",node,tensorMap,context))];default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"string":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"StaticRegexReplace":return[ops.string.staticRegexReplace(getParamValue("input",node,tensorMap,context),getParamValue("pattern",node,tensorMap,context),getParamValue("rewrite",node,tensorMap,context),getParamValue("replaceGlobal",node,tensorMap,context))];case"StringNGrams":{const{nGrams,nGramsSplits}=ops.string.stringNGrams(getParamValue("data",node,tensorMap,context),getParamValue("dataSplits",node,tensorMap,context),getParamValue("separator",node,tensorMap,context),getParamValue("nGramWidths",node,tensorMap,context),getParamValue("leftPad",node,tensorMap,context),getParamValue("rightPad",node,tensorMap,context),getParamValue("padWidth",node,tensorMap,context),getParamValue("preserveShortSequences",node,tensorMap,context));return[nGrams,nGramsSplits]}case"StringSplit":{const{indices,values,shape}=ops.string.stringSplit(getParamValue("input",node,tensorMap,context),getParamValue("delimiter",node,tensorMap,context),getParamValue("skipEmpty",node,tensorMap,context));return[indices,values,shape]}case"StringToHashBucketFast":return[ops.string.stringToHashBucketFast(getParamValue("input",node,tensorMap,context),getParamValue("numBuckets",node,tensorMap,context))];default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"transformation":return tidy(()=>((node,tensorMap,context,ops=ops_for_converter_namespaceObject)=>{switch(node.op){case"Cast":return[ops.cast(getParamValue("x",node,tensorMap,context),getParamValue("dtype",node,tensorMap,context))];case"ExpandDims":{const axis=getParamValue("axis",node,tensorMap,context);return[ops.expandDims(getParamValue("x",node,tensorMap,context),axis)]}case"Squeeze":{const axis=getParamValue("axis",node,tensorMap,context);return[ops.squeeze(getParamValue("x",node,tensorMap,context),axis)]}case"Reshape":return[ops.reshape(getParamValue("x",node,tensorMap,context),getParamValue("shape",node,tensorMap,context))];case"EnsureShape":return[ops.ensureShape(getParamValue("x",node,tensorMap,context),getParamValue("shape",node,tensorMap,context))];case"MirrorPad":return[ops.mirrorPad(getParamValue("x",node,tensorMap,context),getParamValue("padding",node,tensorMap,context),getParamValue("mode",node,tensorMap,context))];case"PadV2":case"Pad":return[ops.pad(getParamValue("x",node,tensorMap,context),getParamValue("padding",node,tensorMap,context),getParamValue("constantValue",node,tensorMap,context))];case"SpaceToBatchND":{const blockShape=getParamValue("blockShape",node,tensorMap,context),paddings=getParamValue("paddings",node,tensorMap,context);return[ops.spaceToBatchND(getParamValue("x",node,tensorMap,context),blockShape,paddings)]}case"BatchToSpaceND":{const blockShape=getParamValue("blockShape",node,tensorMap,context),crops=getParamValue("crops",node,tensorMap,context);return[ops.batchToSpaceND(getParamValue("x",node,tensorMap,context),blockShape,crops)]}case"DepthToSpace":{const blockSize=getParamValue("blockSize",node,tensorMap,context),dataFormat=getParamValue("dataFormat",node,tensorMap,context).toUpperCase();return[ops.depthToSpace(getParamValue("x",node,tensorMap,context),blockSize,dataFormat)]}case"BroadcastTo":return[ops.broadcastTo(getParamValue("x",node,tensorMap,context),getParamValue("shape",node,tensorMap,context))];case"BroadcastArgs":return[ops.broadcastArgs(getParamValue("s0",node,tensorMap,context),getParamValue("s1",node,tensorMap,context))];default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context));case"hash_table":return(async(node,tensorMap,context,resourceManager)=>{switch(node.op){case"HashTable":case"HashTableV2":{const existingTableHandle=resourceManager.getHashTableHandleByName(node.name);if(null!=existingTableHandle)return[existingTableHandle];{const keyDType=getParamValue("keyDType",node,tensorMap,context),valueDType=getParamValue("valueDType",node,tensorMap,context),hashTable=new HashTable(keyDType,valueDType);return resourceManager.addHashTable(node.name,hashTable),[hashTable.handle]}}case"InitializeTable":case"InitializeTableV2":case"LookupTableImport":case"LookupTableImportV2":{const handle=getParamValue("tableHandle",node,tensorMap,context,resourceManager),keys=getParamValue("keys",node,tensorMap,context),values=getParamValue("values",node,tensorMap,context),hashTable=resourceManager.getHashTableById(handle.id);return[await hashTable.import(keys,values)]}case"LookupTableFind":case"LookupTableFindV2":{const handle=getParamValue("tableHandle",node,tensorMap,context,resourceManager),keys=getParamValue("keys",node,tensorMap,context),defaultValue=getParamValue("defaultValue",node,tensorMap,context),hashTable=resourceManager.getHashTableById(handle.id);return[await hashTable.find(keys,defaultValue)]}case"LookupTableSize":case"LookupTableSizeV2":{const handle=getParamValue("tableHandle",node,tensorMap,context,resourceManager);return[resourceManager.getHashTableById(handle.id).tensorSize()]}default:throw TypeError(`Node type ${node.op} is not implemented`)}})(node,tensorMap,context,resourceManager);case"custom":const opMapper=getRegisteredOp(node.op);if(opMapper&&opMapper.customExecutor)return opMapper.customExecutor(new NodeValueImpl(node,tensorMap,context));throw TypeError(`Custom op ${node.op} is not registered.`);default:throw TypeError(`Unknown op '${node.op}'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()`)}})(node,tensorMap,context);return dist.ZSL.isPromise(value)?value.then(data=>[].concat(data)):[].concat(value)}class ExecutionContext{constructor(weightMap={},tensorArrayMap={},tensorListMap={},functionMap={},parseNodeNameCache){this.weightMap=weightMap,this.tensorArrayMap=tensorArrayMap,this.tensorListMap=tensorListMap,this.functionMap=functionMap,this.parseNodeNameCache=parseNodeNameCache,this.rootContext={id:0,frameName:"",iterationId:0},this.contexts=[this.rootContext],this.lastId=0,this.generateCurrentContextIds()}newFrame(id,frameName){return{id,frameName,iterationId:0}}set currentContext(contexts){this.contexts!==contexts&&(this.contexts=contexts,this.generateCurrentContextIds())}get currentContext(){return this.contexts}get currentContextId(){return this._currentContextIds[0]}get currentContextIds(){return this._currentContextIds}generateCurrentContextIds(){const names=[];for(let i=0;i<this.contexts.length-1;i++){const contexts=this.contexts.slice(0,this.contexts.length-i);names.push(this.contextIdforContexts(contexts))}names.push(""),this._currentContextIds=names}contextIdforContexts(contexts){return contexts?contexts.map(context=>0===context.id&&0===context.iterationId?"":`${context.frameName}-${context.iterationId}`).join("/"):""}enterFrame(frameId){this.contexts&&(this.lastId++,this.contexts=this.contexts.slice(),this.contexts.push(this.newFrame(this.lastId,frameId)),this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)))}exitFrame(){if(!(this.contexts&&this.contexts.length>1))throw new Error("Cannot exit frame, the context is empty");this.contexts=this.contexts.slice(),this.contexts.splice(-1),this.currentContextIds.shift()}nextIteration(){if(!(this.contexts&&this.contexts.length>0))throw new Error("Cannot increase frame iteration, the context is empty");{this.contexts=this.contexts.slice(),this.lastId++;const context=Object.assign({},this.contexts[this.contexts.length-1]);context.iterationId+=1,context.id=this.lastId,this.contexts.splice(-1,1,context),this._currentContextIds.splice(0,1,this.contextIdforContexts(this.contexts))}}getWeight(name){return this.weightMap[name]}addTensorArray(tensorArray){this.tensorArrayMap[tensorArray.id]=tensorArray}getTensorArray(id){return this.tensorArrayMap[id]}addTensorList(tensorList){this.tensorListMap[tensorList.id]=tensorList}getTensorList(id){return this.tensorListMap[id]}dispose(keepIds){for(const key in this.tensorArrayMap)this.tensorArrayMap[key].clearAndClose(keepIds);for(const key in this.tensorListMap)this.tensorListMap[key].clearAndClose(keepIds)}}function getExecutionSubgraph(inputs,outputs,weightMap,initNodes){const usedNodes=new Set,missingInputs=[];let dynamicNode=null,syncInputs=null;const seen=new Set,inputNodeNames=new Set(Object.keys(inputs).map(name=>parseNodeName(name)[0]));initNodes=initNodes||[];const initNodeNames=new Set(initNodes.map(node=>parseNodeName(node.name)[0])),frontier=[...outputs];for(;frontier.length>0;){const node=frontier.pop();(isControlFlow(node)||isDynamicShape(node)||isHashTable(node))&&null==dynamicNode&&(dynamicNode=node,syncInputs=dynamicNode.children.map(child=>child.name).filter(name=>usedNodes.has(name))),usedNodes.add(node.name),null==weightMap[node.name]&&(inputNodeNames.has(node.name)||initNodeNames.has(node.name)||(0!==node.inputs.length?node.inputs.forEach(input=>{seen.has(input.name)||(seen.add(input.name),frontier.push(input))}):missingInputs.push(node.name)))}return{inputs,outputs,usedNodes,missingInputs,dynamicNode,syncInputs}}function getNodesInTopologicalOrder(graph,executionInfo){const{usedNodes,inputs}=executionInfo,inputNodes=Object.keys(inputs).map(name=>parseNodeName(name)[0]).map(name=>graph.nodes[name]),initNodes=graph.initNodes||[],isUsed=node=>usedNodes.has("string"==typeof node?node:node.name);function unique(nodes){return[...new Map(nodes.map(node=>[node.name,node])).values()]}const predefinedNodes=unique([...inputNodes,...graph.weights,...initNodes]).filter(isUsed),allNodes=unique([...predefinedNodes,...Object.values(graph.nodes)]).filter(isUsed),nameToNode=new Map(allNodes.map(node=>[node.name,node])),inCounts={};for(const node of allNodes){inCounts[node.name]=inCounts[node.name]||0;for(const child of node.children)isUsed(child)||(inCounts[child.name]=Number.POSITIVE_INFINITY),inCounts[child.name]=(inCounts[child.name]||0)+1}const frontier=Object.entries(inCounts).filter(([,inCount])=>0===inCount).map(([name])=>name),orderedNodeNames=[...frontier];for(;frontier.length>0;){const nodeName=frontier.pop(),node=nameToNode.get(nodeName);for(const child of node.children.filter(isUsed))0===--inCounts[child.name]&&(orderedNodeNames.push(child.name),frontier.push(child.name))}const filteredOrderedNodes=function filterPredefinedReachableNodes(orderedNodes,predefinedNodes){const nameToNode=new Map(orderedNodes.map(node=>[node.name,node])),stack=predefinedNodes.map(node=>node.name),predefinedReachableNodeNames=new Set(stack);for(;stack.length>0;){const nodeName=stack.pop(),node=nameToNode.get(nodeName);for(const child of node.children)nameToNode.has(child.name)&&!predefinedReachableNodeNames.has(child.name)&&(predefinedReachableNodeNames.add(child.name),stack.push(child.name))}const filteredOrderedNodes=orderedNodes.filter(node=>predefinedReachableNodeNames.has(node.name));return filteredOrderedNodes}(orderedNodeNames.map(name=>nameToNode.get(name)),predefinedNodes);return function validateNodesExecutionOrder(orderedNodes,predefinedNodes){const nodeNameToOrder=new Map(orderedNodes.map((node,order)=>[node.name,order])),predefinedNodeNames=new Set(predefinedNodes.map(node=>node.name)),isPredefined=node=>predefinedNodeNames.has("string"==typeof node?node:node.name),willBeExecutedNodeNames=new Set(orderedNodes.map(node=>node.name)),willBeExecuted=node=>willBeExecutedNodeNames.has("string"==typeof node?node:node.name);for(const node of orderedNodes){for(const child of node.children.filter(willBeExecuted)){if(!nodeNameToOrder.has(child.name))throw new NodesExecutionOrderError(`Child ${child.name} of node ${node.name} is unreachable.`);if(nodeNameToOrder.get(node.name)>nodeNameToOrder.get(child.name))throw new NodesExecutionOrderError(`Node ${node.name} is scheduled to run after its child ${child.name}.`)}if(!isPredefined(node))for(const input of node.inputs){if(!nodeNameToOrder.has(input.name))throw new NodesExecutionOrderError(`Input ${input.name} of node ${node.name} is unreachable.`);if(nodeNameToOrder.get(input.name)>nodeNameToOrder.get(node.name))throw new NodesExecutionOrderError(`Node ${node.name} is scheduled to run before its input ${input.name}.`)}}}(filteredOrderedNodes,predefinedNodes),filteredOrderedNodes}class NodesExecutionOrderError extends Error{constructor(message){super(`NodesExecutionOrderError: ${message}`)}}const CONTROL_FLOW_OPS=new Set(["Switch","Merge","Enter","Exit","NextIteration","StatelessIf","StatelessWhile","if","While"]),DYNAMIC_SHAPE_OPS=new Set(["NonMaxSuppressionV2","NonMaxSuppressionV3","NonMaxSuppressionV5","Where"]),HASH_TABLE_OPS=new Set(["HashTable","HashTableV2","LookupTableImport","LookupTableImportV2","LookupTableFind","LookupTableFindV2","LookupTableSize","LookupTableSizeV2"]);function isControlFlow(node){return CONTROL_FLOW_OPS.has(node.op)}function isDynamicShape(node){return DYNAMIC_SHAPE_OPS.has(node.op)}function isHashTable(node){return HASH_TABLE_OPS.has(node.op)}var executor_graph_executor_console=__webpack_require__("./node_modules/console-browserify/index.js");class GraphExecutor{get weightIds(){return this.parent?this.parent.weightIds:this._weightIds}get functionExecutorMap(){return this.parent?this.parent.functionExecutorMap:this._functionExecutorMap}get weightMap(){return this.parent?this.parent.weightMap:this._weightMap}set weightMap(weightMap){const weightIds=Object.keys(weightMap).map(key=>weightMap[key].map(tensor=>tensor.id));this._weightIds=[].concat(...weightIds),this._weightMap=weightMap}set resourceManager(resourceManager){this._resourceManager=resourceManager}get inputs(){return this._inputs.map(node=>({name:node.name,shape:node.attrParams.shape?node.attrParams.shape.value:void 0,dtype:node.attrParams.dtype?node.attrParams.dtype.value:void 0}))}get outputs(){return this._outputs.map(node=>({name:node.name,shape:node.attrParams.shape?node.attrParams.shape.value:void 0,dtype:node.attrParams.dtype?node.attrParams.dtype.value:void 0}))}get inputNodes(){return this._inputs.map(node=>node.signatureKey||node.name)}get outputNodes(){return this._outputs.map(node=>{const name=node.signatureKey||node.name;return node.defaultOutput?`${name}:${node.defaultOutput}`:name})}get functions(){return Object.keys(this._functions).reduce((map,key)=>(map[key]=this._functions[key].signature,map),{})}constructor(graph,parent){this.graph=graph,this.parent=parent,this.compiledMap=new Map,this.parseNodeNameCache=new Map,this._weightMap={},this.SEPARATOR=",",this._functions={},this._functionExecutorMap={},this.keepIntermediateTensors=!1,this._outputs=graph.outputs,this._inputs=graph.inputs,this._initNodes=graph.initNodes,this._signature=graph.signature,this._functions=graph.functions,null!=graph.functions&&Object.keys(graph.functions).forEach(name=>{this._functionExecutorMap[name]=new GraphExecutor(graph.functions[name],this)})}getCompilationKey(inputs,outputs){const sortedInputs=inputs.map(node=>node.name).sort(),sortedOutputs=outputs.map(node=>node.name).sort();return sortedInputs.join(this.SEPARATOR)+"--"+sortedOutputs.join(this.SEPARATOR)}compile(inputs,outputs){const executionInfo=getExecutionSubgraph(inputs,outputs,this.weightMap,this._initNodes),{missingInputs,dynamicNode,syncInputs}=executionInfo;if(null!=dynamicNode)throw new Error(`This execution contains the node '${dynamicNode.name}', which has the dynamic op '${dynamicNode.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${syncInputs}]`);if(missingInputs.length>0){const outNames=outputs.map(n=>n.name),inNames=Object.keys(inputs);throw new Error(`Cannot compute the outputs [${outNames}] from the provided inputs [${inNames}]. Missing the following inputs: [${missingInputs}]`)}const orderedNodes=getNodesInTopologicalOrder(this.graph,executionInfo),nodeLiveUntilMap=function getNodeLiveUntilMap(orderedNodes){const nodeNameToOrder=new Map(orderedNodes.map((node,order)=>[node.name,order])),INF_LIFE=Number.MAX_SAFE_INTEGER,selfLifespans=orderedNodes.map((node,nodeOrder)=>isControlFlow(node)?INF_LIFE:nodeOrder),getSelfLifeSpan=node=>{const selfLife=selfLifespans[nodeNameToOrder.get(node.name)];return null==selfLife?-1:selfLife},liveUntilOrders=orderedNodes.map((node,nodeOrder)=>node.children.map(getSelfLifeSpan).reduce((a,b)=>Math.max(a,b),selfLifespans[nodeOrder])),liveUntilMap=new Map;for(let nodeOrder=0;nodeOrder<orderedNodes.length;++nodeOrder){const liveUntilOrder=liveUntilOrders[nodeOrder];if(liveUntilOrder===INF_LIFE)continue;const node=orderedNodes[nodeOrder],liveUntilNode=orderedNodes[liveUntilOrder];liveUntilMap.has(liveUntilNode.name)||liveUntilMap.set(liveUntilNode.name,[]),liveUntilMap.get(liveUntilNode.name).push(node)}return liveUntilMap}(orderedNodes);return{orderedNodes,nodeLiveUntilMap}}cloneAndKeepTensor(tensor){if(null==tensor)return null;const clone=tensor.clone();return(0,dist.aCs)(clone),clone}cloneTensorList(tensors){if(!tensors)return null;const clonedTensor=tensors.map(tensor=>this.cloneAndKeepTensor(tensor));return clonedTensor}cloneTensorMap(tensorsMap){return Object.fromEntries(Object.entries(tensorsMap).map(([name,tensorsList])=>[name,this.cloneTensorList(tensorsList)]))}execute(inputs,outputs){this.disposeIntermediateTensors(),inputs=this.mapInputs(inputs);const names=Object.keys(inputs).sort();this.checkInputs(inputs),this.checkInputShapeAndType(inputs),outputs=this.mapOutputs(outputs),this.checkOutputs(outputs);const inputNodes=names.map(name=>this.graph.nodes[parseNodeName(name)[0]]),outputNodeNames=outputs.map(name=>parseNodeName(name)[0]),outputNodeNameSet=new Set(outputNodeNames);let outputNodes=outputNodeNames.map(name=>this.graph.nodes[name]);0===outputNodes.length&&(outputNodes=this._outputs);const compilationKey=this.getCompilationKey(inputNodes,outputNodes);let compilation=this.compiledMap.get(compilationKey);null==compilation&&(compilation=this.compile(inputs,outputNodes),this.compiledMap.set(compilationKey,compilation));try{this.keepIntermediateTensors=(0,dist._K2)().getBool("KEEP_INTERMEDIATE_TENSORS")}catch(e){this.keepIntermediateTensors=!1,executor_graph_executor_console.warn(e.message)}const tensorArrayMap={},tensorListMap={};return(0,dist.DZQ)(()=>{const context=new ExecutionContext(this.weightMap,tensorArrayMap,tensorListMap,this.functionExecutorMap,this.parseNodeNameCache),tensorsMap=Object.assign({},this.weightMap);this.keepIntermediateTensors&&(this.clonedTensorsMap=this.cloneTensorMap(this.weightMap)),Object.keys(inputs).forEach(name=>{const[nodeName,index]=parseNodeName(name,context),tensors=[];tensors[index]=inputs[name],tensorsMap[nodeName]=tensors,this.keepIntermediateTensors&&(this.clonedTensorsMap[nodeName]=this.cloneTensorList(tensors))});const tensorsToKeep=this.getFrozenTensorIds(tensorsMap),{orderedNodes,nodeLiveUntilMap}=compilation;for(const node of orderedNodes){if(tensorsMap[node.name])continue;const tensors=operation_executor_executeOp(node,tensorsMap,context,this._resourceManager);if(dist.ZSL.isPromise(tensors))throw new Error(`The execution of the op '${node.op}' returned a promise. Please use model.executeAsync() instead.`);tensorsMap[node.name]=tensors,this.keepIntermediateTensors&&(this.clonedTensorsMap[node.name]=this.cloneTensorList(tensors)),this.checkTensorForDisposalWithNodeLiveUntilInfo(node,tensorsMap,context,tensorsToKeep,outputNodeNameSet,nodeLiveUntilMap.get(node.name))}return null==this.parent&&context.dispose(tensorsToKeep),outputs.map(name=>getTensor(name,tensorsMap,context))})}getFrozenTensorIds(tensorMap){const ids=[].concat.apply([],Object.keys(tensorMap).map(key=>tensorMap[key]).map(tensors=>tensors.map(tensor=>tensor.id)));return new Set(ids)}checkTensorForDisposal(nodeName,node,tensorMap,context,tensorsToKeep,outputNodeNameSet,intermediateTensorConsumerCount){if(!isControlFlow(node)&&!outputNodeNameSet.has(nodeName)){for(const tensor of tensorMap[nodeName])null!=tensor&&(intermediateTensorConsumerCount[tensor.id]=(intermediateTensorConsumerCount[tensor.id]||0)+node.children.length);for(const input of node.inputs){if(isControlFlow(input))continue;const tensors=getTensorsForCurrentContext(input.name,tensorMap,context);if(null!=tensors)for(const tensor of tensors){if(!tensor||tensor.kept||tensorsToKeep.has(tensor.id))continue;const count=intermediateTensorConsumerCount[tensor.id];1===count?(tensor.dispose(),delete intermediateTensorConsumerCount[tensor.id]):null!=count&&intermediateTensorConsumerCount[tensor.id]--}}}}checkTensorForDisposalWithNodeLiveUntilInfo(node,tensorMap,context,tensorsToKeep,outputNodeNameSet,liveUntilNodes){function isNonDisposableNode(node){return isControlFlow(node)||outputNodeNameSet.has(node.name)}if(!isControlFlow(node)&&null!=liveUntilNodes)for(const nodeToDispose of liveUntilNodes){if(isNonDisposableNode(nodeToDispose))continue;const tensors=getTensorsForCurrentContext(nodeToDispose.name,tensorMap,context);for(const tensor of tensors)!tensor||tensor.kept||tensorsToKeep.has(tensor.id)||tensor.dispose()}}async executeAsync(inputs,outputs){return this._executeAsync(inputs,outputs)}disposeIntermediateTensors(){this.clonedTensorsMap&&(Object.values(this.clonedTensorsMap).forEach(tensorsList=>{for(const tensor of tensorsList)tensor&&!tensor.isDisposed&&tensor.dispose()}),this.clonedTensorsMap=null)}getIntermediateTensors(){return this.clonedTensorsMap}async _executeAsync(inputs,outputs,isFunctionExecution=!1,tensorArrayMap={},tensorListMap={}){this.disposeIntermediateTensors(),isFunctionExecution||(inputs=this.mapInputs(inputs),this.checkInputs(inputs),this.checkInputShapeAndType(inputs),outputs=this.mapOutputs(outputs),this.checkOutputs(outputs));try{this.keepIntermediateTensors=(0,dist._K2)().getBool("KEEP_INTERMEDIATE_TENSORS")}catch(e){this.keepIntermediateTensors=!1,executor_graph_executor_console.warn(e.message)}const context=new ExecutionContext(this.weightMap,tensorArrayMap,tensorListMap,this.functionExecutorMap,this.parseNodeNameCache);this.keepIntermediateTensors&&(this.clonedTensorsMap=this.cloneTensorMap(this.weightMap));const tensorsMap=await this.executeWithControlFlow(inputs,context,outputs,isFunctionExecution),results=outputs.map(name=>getTensor(name,tensorsMap,context)),outputIds=results.map(t=>t.id),inputIds=Object.keys(inputs).map(name=>inputs[name].id),keepIds=new Set([...outputIds,...inputIds,...this.weightIds]);return Object.values(tensorsMap).forEach(tensorsList=>{tensorsList.forEach(tensor=>{!tensor||tensor.isDisposed||keepIds.has(tensor.id)||tensor.dispose()})}),null==this.parent&&context.dispose(keepIds),results}async executeFunctionAsync(inputs,tensorArrayMap,tensorListMap){const mappedInputs=inputs.reduce((map,tensor,index)=>(map[this.inputs[index].name]=tensor,map),{});return this._executeAsync(mappedInputs,this.outputNodes,!0,tensorArrayMap,tensorListMap)}async executeWithControlFlow(inputs,context,outputNames,isFunctionExecution){const names=Object.keys(inputs),inputNodes=names.map(name=>this.graph.nodes[parseNodeName(name)[0]]),outputNodeNames=outputNames.map(name=>parseNodeName(name)[0]),outputNodeNameSet=new Set(outputNodeNames);let outputNodes=outputNodeNames.map(name=>this.graph.nodes[name]);0===outputNodes.length&&(outputNodes=this._outputs);const{usedNodes,missingInputs,dynamicNode,syncInputs}=getExecutionSubgraph(inputs,outputNodes,this.weightMap,this._initNodes),stack=[...inputNodes,...this.graph.weights,...this._initNodes||[]].map(node=>({node,contexts:context.currentContext})),tensorsMap=Object.assign({},this.weightMap);Object.keys(inputs).forEach(name=>{const[nodeName,index]=parseNodeName(name),tensors=[];tensors[index]=inputs[name],tensorsMap[nodeName]=tensors});const intermediateTensorConsumerCount={},tensorsToKeep=this.getFrozenTensorIds(tensorsMap),added={};for(;stack.length>0;){const promises=this.processStack(inputNodes,stack,context,tensorsMap,added,tensorsToKeep,outputNodeNameSet,intermediateTensorConsumerCount,usedNodes);await Promise.all(promises)}null!=dynamicNode||isFunctionExecution||executor_graph_executor_console.warn("This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.");const missingOutputs=outputNodes.filter(node=>!isControlFlow(node)&&!getTensor(node.name,tensorsMap,context)).map(node=>node.name);if(missingOutputs.length>0){let alternativeMsg="";throw null!=dynamicNode&&(alternativeMsg=`Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${syncInputs}]`),new Error(`Cannot compute the outputs [${missingOutputs}] from the provided inputs [${names}]. Consider providing the following inputs: [${missingInputs}]. ${alternativeMsg}`)}return tensorsMap}processStack(inputNodes,stack,context,tensorMap,added,tensorsToKeep,outputNodeNameSet,intermediateTensorConsumerCount,usedNodes){const promises=[];for(;stack.length>0;){const item=stack.pop();context.currentContext=item.contexts;let nodeName="";if("Enter"===item.node.op&&getParamValue("isConstant",item.node,tensorMap,context)&&([nodeName]=getNodeNameAndIndex(item.node.name,context)),null==tensorMap[item.node.name]){const tensors=operation_executor_executeOp(item.node,tensorMap,context,this._resourceManager);nodeName||([nodeName]=getNodeNameAndIndex(item.node.name,context));const currentContext=context.currentContext;dist.ZSL.isPromise(tensors)?promises.push(tensors.then(t=>(tensorMap[nodeName]=t,this.keepIntermediateTensors&&(this.clonedTensorsMap[nodeName]=this.cloneTensorList(t)),context.currentContext=currentContext,this.checkTensorForDisposal(nodeName,item.node,tensorMap,context,tensorsToKeep,outputNodeNameSet,intermediateTensorConsumerCount),this.processChildNodes(item.node,stack,context,tensorMap,added,usedNodes),t))):(tensorMap[nodeName]=tensors,this.keepIntermediateTensors&&(this.clonedTensorsMap[nodeName]=this.cloneTensorList(tensors)),this.checkTensorForDisposal(nodeName,item.node,tensorMap,context,tensorsToKeep,outputNodeNameSet,intermediateTensorConsumerCount),this.processChildNodes(item.node,stack,context,tensorMap,added,usedNodes))}else this.processChildNodes(item.node,stack,context,tensorMap,added,usedNodes)}return promises}processChildNodes(node,stack,context,tensorMap,added,usedNodes){node.children.forEach(childNode=>{const[nodeName]=getNodeNameAndIndex(childNode.name,context);!added[nodeName]&&usedNodes.has(childNode.name)&&("Merge"===childNode.op?childNode.inputNames.some(name=>!!getTensor(name,tensorMap,context))&&(added[nodeName]=!0,stack.push({contexts:context.currentContext,node:childNode})):childNode.inputNames.every(name=>!!getTensor(name,tensorMap,context))&&(added[nodeName]=!0,stack.push({contexts:context.currentContext,node:childNode})))})}dispose(){Object.keys(this.weightMap).forEach(key=>this.weightMap[key].forEach(tensor=>tensor.dispose()))}checkInputShapeAndType(inputs){Object.keys(inputs).forEach(name=>{const input=inputs[name],[nodeName]=parseNodeName(name),node=this.graph.nodes[nodeName];if(node.attrParams.shape&&node.attrParams.shape.value){const shape=node.attrParams.shape.value,match=shape.length===input.shape.length&&input.shape.every((dim,index)=>-1===shape[index]||shape[index]===dim);dist.ZSL.assert(match,()=>`The shape of dict['${node.name}'] provided in model.execute(dict) must be [${shape}], but was [${input.shape}]`)}node.attrParams.dtype&&node.attrParams.dtype.value&&dist.ZSL.assert(input.dtype===node.attrParams.dtype.value,()=>`The dtype of dict['${node.name}'] provided in model.execute(dict) must be ${node.attrParams.dtype.value}, but was ${input.dtype}`)})}mapInputs(inputs){var _a,_b;const result={};for(const inputName in inputs){const tensor=null===(_b=null===(_a=this._signature)||void 0===_a?void 0:_a.inputs)||void 0===_b?void 0:_b[inputName];null!=tensor?result[tensor.name]=inputs[inputName]:result[inputName]=inputs[inputName]}return result}checkInputs(inputs){const notInGraph=Object.keys(inputs).filter(name=>{const[nodeName]=parseNodeName(name);return null==this.graph.nodes[nodeName]});if(notInGraph.length>0)throw new Error(`The dict provided in model.execute(dict) has keys: [${notInGraph}] that are not part of graph`)}mapOutputs(outputs){return outputs.map(name=>{var _a,_b;const tensor=null===(_b=null===(_a=this._signature)||void 0===_a?void 0:_a.outputs)||void 0===_b?void 0:_b[name];return null!=tensor?tensor.name:name},{})}checkOutputs(outputs){outputs.forEach(name=>{const[normalizedName]=parseNodeName(name);if(!this.graph.nodes[normalizedName])throw new Error(`The output '${name}' is not found in the graph`)})}}class ResourceManager{constructor(hashTableNameToHandle={},hashTableMap={}){this.hashTableNameToHandle=hashTableNameToHandle,this.hashTableMap=hashTableMap}addHashTable(name,hashTable){this.hashTableNameToHandle[name]=hashTable.handle,this.hashTableMap[hashTable.id]=hashTable}getHashTableHandleByName(name){return this.hashTableNameToHandle[name]}getHashTableById(id){return this.hashTableMap[id]}dispose(){for(const key in this.hashTableMap)this.hashTableMap[key].clearAndClose(),delete this.hashTableMap[key];for(const name in this.hashTableNameToHandle)this.hashTableNameToHandle[name].dispose(),delete this.hashTableNameToHandle[name]}}var io_utils=__webpack_require__("./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js");const TFHUB_SEARCH_PARAM="?tfjs-format=file",DEFAULT_MODEL_NAME="model.json";class GraphModel{get modelVersion(){return this.version}get inputNodes(){return this.executor.inputNodes}get outputNodes(){return this.executor.outputNodes}get inputs(){return this.executor.inputs}get outputs(){return this.executor.outputs}get weights(){return this.executor.weightMap}get metadata(){return this.artifacts.userDefinedMetadata}get modelSignature(){return this.signature}get modelStructuredOutputKeys(){return this.structuredOutputKeys}constructor(modelUrl,loadOptions={},tfio=dist.io){this.modelUrl=modelUrl,this.loadOptions=loadOptions,this.version="n/a",this.io=tfio,null==loadOptions&&(this.loadOptions={}),this.resourceManager=new ResourceManager}findIOHandler(){const path=this.modelUrl;if(null!=path.load)this.handler=path;else if(null!=this.loadOptions.requestInit)this.handler=this.io.browserHTTPRequest(path,this.loadOptions);else{const handlers=this.io.getLoadHandlers(path,this.loadOptions);if(0===handlers.length)handlers.push(this.io.browserHTTPRequest(path,this.loadOptions));else if(handlers.length>1)throw new Error(`Found more than one (${handlers.length}) load handlers for URL '${[path]}'`);this.handler=handlers[0]}}load(){if(this.findIOHandler(),null==this.handler.load)throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const loadResult=this.handler.load();return dist.ZSL.isPromise(loadResult)?loadResult.then(artifacts=>null==artifacts.getWeightStream?this.loadSync(artifacts):this.loadStreaming(artifacts)):this.loadSync(loadResult)}loadSync(artifacts){const weightMap=this.io.decodeWeights(artifacts.weightData,artifacts.weightSpecs);return this.loadWithWeightMap(artifacts,weightMap)}async loadStreaming(artifacts){if(null==artifacts.getWeightStream)throw new Error("Model artifacts missing streamWeights function");const weightMap=await(0,io_utils.s5)(artifacts.getWeightStream(),artifacts.weightSpecs);return this.loadWithWeightMap(artifacts,weightMap)}loadWithWeightMap(artifacts,weightMap){this.artifacts=artifacts;const graph=this.artifacts.modelTopology;let signature=this.artifacts.signature;if(null!=this.artifacts.userDefinedMetadata){const metadata=this.artifacts.userDefinedMetadata;null!=metadata.signature&&(signature=metadata.signature),null!=metadata.structuredOutputKeys&&(this.structuredOutputKeys=metadata.structuredOutputKeys)}if(this.signature=signature,this.version=`${graph.versions.producer}.${graph.versions.minConsumer}`,this.executor=new GraphExecutor(OperationMapper.Instance.transformGraph(graph,this.signature)),this.executor.weightMap=this.convertTensorMapToTensorsMap(weightMap),this.executor.resourceManager=this.resourceManager,null!=artifacts.modelInitializer&&null!=artifacts.modelInitializer.node){const initializer=OperationMapper.Instance.transformGraph(artifacts.modelInitializer);this.initializer=new GraphExecutor(initializer),this.initializer.weightMap=this.executor.weightMap,this.initializer.resourceManager=this.resourceManager,this.initializerSignature=artifacts.initializerSignature}return!0}async save(handlerOrURL,config){if("string"==typeof handlerOrURL){const handlers=this.io.getSaveHandlers(handlerOrURL);if(0===handlers.length)throw new Error(`Cannot find any save handlers for URL '${handlerOrURL}'`);if(handlers.length>1)throw new Error(`Found more than one (${handlers.length}) save handlers for URL '${handlerOrURL}'`);handlerOrURL=handlers[0]}if(null==handlerOrURL.save)throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");return handlerOrURL.save(this.artifacts)}addStructuredOutputNames(outputTensors){if(this.structuredOutputKeys){const outputTensorsArray=outputTensors instanceof dist.qYS?[outputTensors]:outputTensors,outputTensorMap={};return outputTensorsArray.forEach((outputTensor,i)=>outputTensorMap[this.structuredOutputKeys[i]]=outputTensor),outputTensorMap}return outputTensors}predict(inputs,config){const outputTensors=this.execute(inputs,this.outputNodes);return this.addStructuredOutputNames(outputTensors)}async predictAsync(inputs,config){const outputTensors=await this.executeAsync(inputs,this.outputNodes);return this.addStructuredOutputNames(outputTensors)}normalizeInputs(inputs){var _a;if(!(inputs instanceof dist.qYS||Array.isArray(inputs))){const signatureInputs=null===(_a=this.signature)||void 0===_a?void 0:_a.inputs;if(null!=signatureInputs)for(const input in signatureInputs){const tensor=signatureInputs[input];null!=tensor.resourceId&&(inputs[input]=this.resourceIdToCapturedInput[tensor.resourceId])}return inputs}inputs=Array.isArray(inputs)?inputs:[inputs];const numCapturedInputs=Object.keys(this.resourceIdToCapturedInput).length;if(inputs.length+numCapturedInputs!==this.inputNodes.length)throw new Error(`Input tensor count mismatch, the graph model has ${this.inputNodes.length-numCapturedInputs} non-resource placeholders, while there are ${inputs.length} input tensors provided.`);let inputIndex=0;return this.inputNodes.reduce((map,inputName)=>{var _a,_b,_c;const resourceId=null===(_c=null===(_b=null===(_a=this.signature)||void 0===_a?void 0:_a.inputs)||void 0===_b?void 0:_b[inputName])||void 0===_c?void 0:_c.resourceId;return map[inputName]=null!=resourceId?this.resourceIdToCapturedInput[resourceId]:inputs[inputIndex++],map},{})}normalizeOutputs(outputs){return outputs=outputs||this.outputNodes,Array.isArray(outputs)?outputs:[outputs]}executeInitializerGraph(){return null==this.initializer?[]:null==this.initializerSignature?this.initializer.execute({},[]):this.initializer.execute({},Object.keys(this.initializerSignature.outputs))}async executeInitializerGraphAsync(){return null==this.initializer?[]:null==this.initializerSignature?this.initializer.executeAsync({},[]):this.initializer.executeAsync({},Object.keys(this.initializerSignature.outputs))}setResourceIdToCapturedInput(outputs){if(this.resourceIdToCapturedInput={},this.initializerSignature){const signatureOutputs=this.initializerSignature.outputs,outputNames=Object.keys(signatureOutputs);for(let i=0;i<outputNames.length;i++){const tensorInfo=signatureOutputs[outputNames[i]];this.resourceIdToCapturedInput[tensorInfo.resourceId]=outputs[i]}}}execute(inputs,outputs){null==this.resourceIdToCapturedInput&&this.setResourceIdToCapturedInput(this.executeInitializerGraph()),inputs=this.normalizeInputs(inputs),outputs=this.normalizeOutputs(outputs);const result=this.executor.execute(inputs,outputs);return result.length>1?result:result[0]}async executeAsync(inputs,outputs){null==this.resourceIdToCapturedInput&&this.setResourceIdToCapturedInput(await this.executeInitializerGraphAsync()),inputs=this.normalizeInputs(inputs),outputs=this.normalizeOutputs(outputs);const result=await this.executor.executeAsync(inputs,outputs);return result.length>1?result:result[0]}getIntermediateTensors(){return this.executor.getIntermediateTensors()}disposeIntermediateTensors(){this.executor.disposeIntermediateTensors()}convertTensorMapToTensorsMap(map){return Object.keys(map).reduce((newMap,key)=>(newMap[key]=[map[key]],newMap),{})}dispose(){this.executor.dispose(),this.initializer&&(this.initializer.dispose(),this.resourceIdToCapturedInput&&(0,dist.ASo)(this.resourceIdToCapturedInput)),this.resourceManager.dispose()}}async function loadGraphModel(modelUrl,options={},tfio=dist.io){if(null==modelUrl)throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");null==options&&(options={}),options.fromTFHub&&"string"==typeof modelUrl&&(modelUrl=function getTFHubUrl(modelUrl){modelUrl.endsWith("/")||(modelUrl+="/");return`${modelUrl}${DEFAULT_MODEL_NAME}${TFHUB_SEARCH_PARAM}`}(modelUrl));const model=new GraphModel(modelUrl,options,tfio);return await model.load(),model}function loadGraphModelSync(modelSource){if(null==modelSource)throw new Error("modelUrl in loadGraphModelSync() cannot be null. Please provide model artifacts or an IOHandler that loads the model");let ioHandler;if(modelSource instanceof Array){const[modelJSON,weights]=modelSource;if(!modelJSON)throw new Error("modelJSON must be the first element of the array");if(!(weights&&weights instanceof ArrayBuffer))throw new Error("An ArrayBuffer of weights must be the second element of the array");if(!("modelTopology"in modelJSON))throw new Error("Model JSON is missing 'modelTopology'");if(!("weightsManifest"in modelJSON))throw new Error("Model JSON is missing 'weightsManifest'");const weightSpecs=dist.io.getWeightSpecs(modelJSON.weightsManifest),modelArtifacts=dist.io.getModelArtifactsForJSONSync(modelJSON,weightSpecs,weights);ioHandler=dist.io.fromMemorySync(modelArtifacts)}else if("load"in modelSource)ioHandler=modelSource;else{if(!("modelTopology"in modelSource&&"weightSpecs"in modelSource&&"weightData"in modelSource))throw new Error("Unknown model format");ioHandler=dist.io.fromMemorySync(modelSource)}const model=new GraphModel(ioHandler);return model.load(),model}const version_version="4.22.0";var ZipMismatchMode,seedrandom=__webpack_require__("./node_modules/seedrandom/index.js");function deepMapInternal(input,mapFn,seen=new Map,containedIn=new Set){if(null==input)return null;if("function"==typeof Blob&&input instanceof Blob)return input.slice();if(containedIn.has(input))throw new Error("Circular references are not supported.");if(seen.has(input))return seen.get(input);const result=mapFn(input);if(result.recurse&&null!==result.value)throw new Error("A deep map function may not return both a value and recurse=true.");if(result.recurse){if(isIterable(input)){const mappedIterable=Array.isArray(input)?[]:{};containedIn.add(input);for(const k in input){const childResult=deepMapInternal(input[k],mapFn,seen,containedIn);mappedIterable[k]=childResult}return containedIn.delete(input),input.__proto__&&(mappedIterable.__proto__=input.__proto__),mappedIterable}throw new Error(`Can't recurse into non-iterable type: ${input}`)}return seen.set(input,result.value),result.value}function deepZip(inputs,zipFn=zipToList){return deepZipInternal(inputs,zipFn)}function deepZipInternal(inputs,zipFn,containedIn=new Set){const input=inputs[0];if(containedIn.has(input))throw new Error("Circular references are not supported.");const result=zipFn(inputs);if(result.recurse&&null!==result.value)throw new Error("A deep zip function may not return both a value and recurse=true.");if(result.recurse){if(isIterable(input)){const mappedIterable=Array.isArray(input)?[]:{};containedIn.add(input);for(const k in input){const childResult=deepZipInternal(inputs.map(x=>x[k]),zipFn,containedIn);mappedIterable[k]=childResult}return containedIn.delete(input),mappedIterable}throw new Error(`Can't recurse into non-iterable type: ${input}`)}return result.value}function zipToList(x){return null===x?null:isIterable(x[0])?{value:null,recurse:!0}:{value:x,recurse:!1}}async function deepMapAndAwaitAll(input,mapFn){const seen=new Map;deepMapInternal(input,mapFn,seen);for(const key of Array.from(seen.keys())){const value=seen.get(key);if(dist.ZSL.isPromise(value)){const mappedValue=await value;seen.set(key,mappedValue)}}return deepMapInternal(input,mapFn,seen)}function isIterable(obj){let isTextDecoder=!1;if(dist._K2().get("IS_BROWSER"))isTextDecoder=obj instanceof TextDecoder;else{const{StringDecoder}=__webpack_require__("?9f49");isTextDecoder=obj instanceof StringDecoder}return null!=obj&&!ArrayBuffer.isView(obj)&&(Array.isArray(obj)||"object"==typeof obj&&!(obj instanceof dist.qYS)&&!(obj instanceof Promise)&&!isTextDecoder)}function deepClone(container){return function deepMap(input,mapFn){return deepMapInternal(input,mapFn)}(container,cloneIfTensor)}function cloneIfTensor(item){return item instanceof dist.qYS?{value:item.clone(),recurse:!1}:isIterable(item)?{value:null,recurse:!0}:{value:item,recurse:!1}}class RingBuffer{constructor(capacity){if(this.capacity=capacity,this.begin=0,this.end=0,null==capacity)throw new RangeError("Can't create a ring buffer of unknown capacity.");if(capacity<1)throw new RangeError("Can't create ring buffer of capacity < 1.");this.data=new Array(capacity),this.doubledCapacity=2*capacity}wrap(index){for(;index<0;)index+=this.doubledCapacity;return index%this.doubledCapacity}get(index){if(index<0)throw new RangeError("Can't get item at a negative index.");return this.data[index%this.capacity]}set(index,value){if(index<0)throw new RangeError("Can't set item at a negative index.");this.data[index%this.capacity]=value}length(){let length=this.end-this.begin;return length<0&&(length=this.doubledCapacity+length),length}isFull(){return this.length()===this.capacity}isEmpty(){return 0===this.length()}push(value){if(this.isFull())throw new RangeError("Ring buffer is full.");this.set(this.end,value),this.end=this.wrap(this.end+1)}pushAll(values){for(const value of values)this.push(value)}pop(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");this.end=this.wrap(this.end-1);const result=this.get(this.end);return this.set(this.end,void 0),result}unshift(value){if(this.isFull())throw new RangeError("Ring buffer is full.");this.begin=this.wrap(this.begin-1),this.set(this.begin,value)}shift(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const result=this.get(this.begin);return this.set(this.begin,void 0),this.begin=this.wrap(this.begin+1),result}shuffleExcise(relativeIndex){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const index=this.wrap(this.begin+relativeIndex),result=this.get(index);return this.set(index,this.pop()),result}}class GrowingRingBuffer extends RingBuffer{constructor(){super(GrowingRingBuffer.INITIAL_CAPACITY)}isFull(){return!1}push(value){super.isFull()&&this.expand(),super.push(value)}unshift(value){super.isFull()&&this.expand(),super.unshift(value)}expand(){const newCapacity=2*this.capacity,newData=new Array(newCapacity),len=this.length();for(let i=0;i<len;i++)newData[i]=this.get(this.wrap(this.begin+i));this.data=newData,this.capacity=newCapacity,this.doubledCapacity=2*this.capacity,this.begin=0,this.end=len}}function iteratorFromItems(items){return new ArrayIterator(items)}function iteratorFromFunction(func){return new FunctionCallIterator(func)}function iteratorFromConcatenated(baseIterators,baseErrorHandler){return new ChainedIterator(baseIterators,baseErrorHandler)}GrowingRingBuffer.INITIAL_CAPACITY=32;class LazyIterator{async toArray(){const result=[];let x=await this.next();for(;!x.done;)result.push(x.value),x=await this.next();return result}async toArrayForTest(){const stream=this.prefetch(100),result=[];let x=await stream.next();for(;!x.done;)result.push(x.value),x=await stream.next();return result}async resolveFully(){let x=await this.next();for(;!x.done;)x=await this.next()}async resolveWhile(predicate){let x=await this.next(),shouldContinue=predicate(x.value);for(;!x.done&&shouldContinue;)x=await this.next(),shouldContinue=predicate(x.value)}handleErrors(handler){return new ErrorHandlingLazyIterator(this,handler)}filter(predicate){return new FilterIterator(this,predicate)}map(transform){return new MapIterator(this,transform)}mapAsync(transform){return new AsyncMapIterator(this,transform)}serialMapAsync(transform){return new AsyncMapIterator(this,transform).serial()}flatmap(transform){return new FlatmapIterator(this,transform)}async forEachAsync(f){return this.map(f).resolveFully()}async serialForEach(f){return this.serialMapAsync(f).resolveWhile(x=>!0===x)}rowMajorBatch(batchSize,smallLastBatch=!0){return new RowMajorBatchIterator(this,batchSize,smallLastBatch)}columnMajorBatch(batchSize,smallLastBatch=!0,zipFn=zipToList){return this.rowMajorBatch(batchSize,smallLastBatch).map(x=>deepZip(x,zipFn))}concatenate(iterator,baseErrorHandler){return new ChainedIterator(iteratorFromItems([this,iterator]),baseErrorHandler)}take(count){return count<0||null==count?this:new TakeIterator(this,count)}skip(count){return count<0||null==count?this:new SkipIterator(this,count)}prefetch(bufferSize){return new PrefetchIterator(this,bufferSize)}shuffle(windowSize,seed){return new ShuffleIterator(this,windowSize,seed)}serial(){return new SerialIterator(this)}}class ArrayIterator extends LazyIterator{constructor(items){super(),this.items=items,this.trav=0}summary(){return`Array of ${this.items.length} items`}async next(){if(this.trav>=this.items.length)return{value:null,done:!0};const item=this.items[this.trav];return this.trav++,{value:deepClone(item),done:!1}}}class FunctionCallIterator extends LazyIterator{constructor(nextFn){super(),this.nextFn=nextFn}summary(){return"Function call"}async next(){try{return this.nextFn()}catch(e){throw e.message=`Error thrown while iterating through a dataset: ${e.message}`,e}}}class SerialIterator extends LazyIterator{constructor(upstream){super(),this.upstream=upstream,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Serial`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){return this.upstream.next()}}class SkipIterator extends LazyIterator{constructor(upstream,maxCount){super(),this.upstream=upstream,this.maxCount=maxCount,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Skip`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;this.count++<this.maxCount;){const skipped=await this.upstream.next();if(skipped.done)return skipped;dist.ASo(skipped.value)}return this.upstream.next()}}class TakeIterator extends LazyIterator{constructor(upstream,maxCount){super(),this.upstream=upstream,this.maxCount=maxCount,this.count=0}summary(){return`${this.upstream.summary()} -> Take`}async next(){return this.count++>=this.maxCount?{value:null,done:!0}:this.upstream.next()}}class RowMajorBatchIterator extends LazyIterator{constructor(upstream,batchSize,enableSmallLastBatch=!0){super(),this.upstream=upstream,this.batchSize=batchSize,this.enableSmallLastBatch=enableSmallLastBatch,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> RowMajorBatch`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){const batch=[];for(;batch.length<this.batchSize;){const item=await this.upstream.next();if(item.done)return this.enableSmallLastBatch&&batch.length>0?{value:batch,done:!1}:{value:null,done:!0};batch.push(item.value)}return{value:batch,done:!1}}}class FilterIterator extends LazyIterator{constructor(upstream,predicate){super(),this.upstream=upstream,this.predicate=predicate,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Filter`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;;){const item=await this.upstream.next();if(item.done||this.predicate(item.value))return item;dist.ASo(item.value)}}}class MapIterator extends LazyIterator{constructor(upstream,transform){super(),this.upstream=upstream,this.transform=transform}summary(){return`${this.upstream.summary()} -> Map`}async next(){const item=await this.upstream.next();if(item.done)return{value:null,done:!0};const inputTensors=dist.d_S.getTensorsInContainer(item.value),mapped=this.transform(item.value),outputTensors=dist.d_S.getTensorsInContainer(mapped);for(const t of inputTensors)dist.d_S.isTensorInList(t,outputTensors)||t.dispose();return{value:mapped,done:!1}}}class ErrorHandlingLazyIterator extends LazyIterator{constructor(upstream,handler){super(),this.upstream=upstream,this.handler=handler,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> handleErrors`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;;)try{return await this.upstream.next()}catch(e){if(!this.handler(e))return{value:null,done:!0}}}}class AsyncMapIterator extends LazyIterator{constructor(upstream,transform){super(),this.upstream=upstream,this.transform=transform}summary(){return`${this.upstream.summary()} -> AsyncMap`}async next(){const item=await this.upstream.next();if(item.done)return{value:null,done:!0};const inputTensors=dist.d_S.getTensorsInContainer(item.value),mapped=await this.transform(item.value),outputTensors=dist.d_S.getTensorsInContainer(mapped);for(const t of inputTensors)dist.d_S.isTensorInList(t,outputTensors)||t.dispose();return{value:mapped,done:!1}}}class OneToManyIterator extends LazyIterator{constructor(){super(),this.outputQueue=new GrowingRingBuffer,this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;0===this.outputQueue.length();)if(!await this.pump())return{value:null,done:!0};return{value:this.outputQueue.shift(),done:!1}}}class FlatmapIterator extends OneToManyIterator{constructor(upstream,transform){super(),this.upstream=upstream,this.transform=transform}summary(){return`${this.upstream.summary()} -> Flatmap`}async pump(){const item=await this.upstream.next();if(item.done)return!1;const inputTensors=dist.d_S.getTensorsInContainer(item.value),mappedArray=this.transform(item.value),outputTensors=dist.d_S.getTensorsInContainer(mappedArray);this.outputQueue.pushAll(mappedArray);for(const t of inputTensors)dist.d_S.isTensorInList(t,outputTensors)||t.dispose();return!0}}class ChainedIterator extends LazyIterator{constructor(iterators,baseErrorHandler){super(),this.baseErrorHandler=baseErrorHandler,this.lastRead=null,this.iterator=null,this.moreIterators=iterators}summary(){return"TODO: fill in upstream of chained summaries -> Chained"}async next(){return this.lastRead=this.readFromChain(this.lastRead),this.lastRead}async readFromChain(lastRead){if(await lastRead,null==this.iterator){const iteratorResult=await this.moreIterators.next();if(iteratorResult.done)return{value:null,done:!0};this.iterator=iteratorResult.value,null!=this.baseErrorHandler&&(this.iterator=this.iterator.handleErrors(this.baseErrorHandler))}const itemResult=await this.iterator.next();return itemResult.done?(this.iterator=null,this.readFromChain(lastRead)):itemResult}}!function(ZipMismatchMode){ZipMismatchMode[ZipMismatchMode.FAIL=0]="FAIL",ZipMismatchMode[ZipMismatchMode.SHORTEST=1]="SHORTEST",ZipMismatchMode[ZipMismatchMode.LONGEST=2]="LONGEST"}(ZipMismatchMode||(ZipMismatchMode={}));class ZipIterator extends LazyIterator{constructor(iterators,mismatchMode=ZipMismatchMode.FAIL){super(),this.iterators=iterators,this.mismatchMode=mismatchMode,this.count=0,this.currentPromise=null}summary(){return"{TODO: fill in upstream of zip summaries} -> Zip"}async nextState(afterState){await afterState;let numIterators=0,iteratorsDone=0;const mapped=await deepMapAndAwaitAll(this.iterators,function getNext(container){if(container instanceof LazyIterator){return{value:container.next().then(x=>(numIterators++,x.done&&iteratorsDone++,x.value)),recurse:!1}}return{value:null,recurse:!0}});if(numIterators===iteratorsDone)return{value:null,done:!0};if(iteratorsDone>0)switch(this.mismatchMode){case ZipMismatchMode.FAIL:throw new Error(`Zipped streams should have the same length. Mismatched at element ${this.count}.`);case ZipMismatchMode.SHORTEST:return{value:null,done:!0};case ZipMismatchMode.LONGEST:}return this.count++,{value:mapped,done:!1}}async next(){return this.currentPromise=this.nextState(this.currentPromise),this.currentPromise}}class PrefetchIterator extends LazyIterator{constructor(upstream,bufferSize){super(),this.upstream=upstream,this.bufferSize=bufferSize,this.buffer=new RingBuffer(bufferSize)}summary(){return`${this.upstream.summary()} -> Prefetch`}refill(){for(;!this.buffer.isFull();){const v=this.upstream.next();this.buffer.push(v)}}next(){return this.refill(),this.buffer.shift()}}class ShuffleIterator extends PrefetchIterator{constructor(upstream,windowSize,seed){super(upstream,windowSize),this.upstream=upstream,this.windowSize=windowSize,this.upstreamExhausted=!1,this.random=seedrandom.alea(seed||dist.ZSL.now().toString()),this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}randomInt(max){return Math.floor(this.random()*max)}chooseIndex(){return this.randomInt(this.buffer.length())}async serialNext(){for(this.upstreamExhausted||this.refill();!this.buffer.isEmpty();){const chosenIndex=this.chooseIndex(),result=await this.buffer.shuffleExcise(chosenIndex);if(!result.done)return this.refill(),result;this.upstreamExhausted=!0}return{value:null,done:!0}}}class Dataset{constructor(){this.size=null}batch(batchSize,smallLastBatch=!0){const base=this;let size;return dist.ZSL.assert(batchSize>0,()=>`batchSize needs to be positive, but it is\n      ${batchSize}`),size=this.size===1/0||null==this.size?this.size:smallLastBatch?Math.ceil(this.size/batchSize):Math.floor(this.size/batchSize),datasetFromIteratorFn(async()=>(await base.iterator()).columnMajorBatch(batchSize,smallLastBatch,deepBatchConcat),size)}concatenate(dataset){const base=this;let size;return size=this.size===1/0||dataset.size===1/0?1/0:null!=this.size&&null!=dataset.size?this.size+dataset.size:null,datasetFromIteratorFn(async()=>(await base.iterator()).concatenate(await dataset.iterator()),size)}filter(predicate){const base=this;let size;return size=this.size===1/0?1/0:null,datasetFromIteratorFn(async()=>(await base.iterator()).filter(x=>dist.DZQ(()=>predicate(x))),size)}async forEachAsync(f){return(await this.iterator()).forEachAsync(f)}map(transform){const base=this;return datasetFromIteratorFn(async()=>(await base.iterator()).map(x=>dist.DZQ(()=>transform(x))),this.size)}mapAsync(transform){const base=this;return datasetFromIteratorFn(async()=>(await base.iterator()).mapAsync(transform),this.size)}prefetch(bufferSize){if(null==bufferSize)throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");const base=this;return datasetFromIteratorFn(async()=>(await base.iterator()).prefetch(bufferSize),this.size)}repeat(count){const base=this;let size;return size=null!=this.size&&count>0?this.size*count:0===count?0:null!=this.size&&(void 0===count||count<0)?1/0:null,datasetFromIteratorFn(async()=>iteratorFromConcatenated(iteratorFromFunction(async()=>({value:await base.iterator(),done:!1})).take(count)),size)}skip(count){const base=this;let size;return size=null!=this.size&&count>=0&&this.size>=count?this.size-count:null!=this.size&&(this.size<count||void 0===count||count<0)?0:null,datasetFromIteratorFn(async()=>(await base.iterator()).skip(count),size)}shuffle(bufferSize,seed,reshuffleEachIteration=!0){if(null==bufferSize||bufferSize<0)throw null==this.size?new RangeError("`Dataset.shuffle()` requires bufferSize to be specified."):new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);const base=this,random=seedrandom.alea(seed||dist.ZSL.now().toString());return datasetFromIteratorFn(async()=>{let seed2=random.int32();return reshuffleEachIteration&&(seed2+=random.int32()),(await base.iterator()).shuffle(bufferSize,seed2.toString())},this.size)}take(count){const base=this;let size;return size=null!=this.size&&this.size>count?count:null!=this.size&&this.size<=count?this.size:null,datasetFromIteratorFn(async()=>(await base.iterator()).take(count),size)}async toArray(){if(this.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArray()}async toArrayForTest(){if(this.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArrayForTest()}}function datasetFromIteratorFn(iteratorFn,size=null){return new class extends Dataset{constructor(){super(...arguments),this.size=size}async iterator(){return iteratorFn()}}}function array(items){return datasetFromIteratorFn(async()=>iteratorFromItems(items),items.length)}function zip(datasets){if(!isIterable(datasets))throw new Error("The argument to zip() must be an object or array.");let size;if(Array.isArray(datasets))for(let i=0;i<datasets.length;i++)size=null==size?datasets[i].size:Math.min(size,datasets[i].size);else if(datasets instanceof Object)for(const ds in datasets)size=null==size?datasets[ds].size:Math.min(size,datasets[ds].size);return datasetFromIteratorFn(async()=>function iteratorFromZipped(iterators,mismatchMode=ZipMismatchMode.FAIL){return new ZipIterator(iterators,mismatchMode)}(await deepMapAndAwaitAll(datasets,d=>{if(d instanceof Dataset)return{value:d.iterator(),recurse:!1};if(isIterable(d))return{value:null,recurse:!0};throw new Error("Leaves of the structure passed to zip() must be Datasets, not primitives.")}),ZipMismatchMode.SHORTEST),size)}function deepBatchConcat(rows){if(null===rows)return null;if(function canTensorify(obj){return null==obj||function isPrimitive(value){return null===value||"object"!=typeof value&&"function"!=typeof value}(obj)||Array.isArray(obj)||"object"==typeof obj&&obj instanceof dist.qYS||dist.ZSL.isTypedArray(obj)}(rows[0])){return{value:function batchConcat(arrays){if(0===arrays.length)throw new Error("Can't make a batch of zero elements.");return arrays[0]instanceof dist.qYS?dist.t$z(arrays):dist.OEK(arrays)}(rows),recurse:!1}}return{value:null,recurse:!0}}Dataset.MAX_BUFFER_SIZE=1e4;class TextLineDataset extends Dataset{constructor(input){super(),this.input=input}async iterator(){return(await this.input.iterator()).decodeUTF8().split("\n").map(line=>(line.endsWith("\r")&&(line=line.slice(0,-1)),line))}}const STATE_OUT=Symbol("out"),STATE_FIELD=Symbol("field"),STATE_QUOTE=Symbol("quote"),STATE_QUOTE_AFTER_QUOTE=Symbol("quoteafterquote"),STATE_WITHIN_QUOTE_IN_QUOTE=Symbol("quoteinquote");class CSVDataset extends Dataset{async columnNames(){return this.columnNamesValidated||await this.setColumnNames(),this.configuredColumnsOnly?Object.keys(this.columnConfigs):this.fullColumnNames}async setColumnNames(){const columnNamesFromFile=await this.maybeReadHeaderLine();if(!this.fullColumnNames&&!columnNamesFromFile)throw new Error("Column names must be provided if there is no header line.");this.fullColumnNames&&columnNamesFromFile&&dist.ZSL.assert(columnNamesFromFile.length===this.fullColumnNames.length,()=>"The length of provided columnNames ("+this.fullColumnNames.length.toString()+") does not match the length of the header line read from file ("+columnNamesFromFile.length.toString()+")."),this.fullColumnNames||(this.fullColumnNames=columnNamesFromFile);const counts=this.fullColumnNames.reduce((countAcc,name)=>(countAcc[name]=countAcc[name]+1||1,countAcc),{}),duplicateNames=Object.keys(counts).filter(name=>counts[name]>1);if(dist.ZSL.assert(0===duplicateNames.length,()=>"Duplicate column names found: "+duplicateNames.toString()),this.columnConfigs)for(const key of Object.keys(this.columnConfigs)){if(-1===this.fullColumnNames.indexOf(key))throw new Error('The key "'+key+'" provided in columnConfigs does not match any of the column names ('+this.fullColumnNames.toString()+").")}this.columnNamesValidated=!0}async maybeReadHeaderLine(){if(this.hasHeader){const iter=await this.base.iterator(),firstElement=await iter.next();if(firstElement.done)throw new Error("No data was found for CSV parsing.");const firstLine=firstElement.value;return this.parseRow(firstLine,!1)}return null}constructor(input,csvConfig){super(),this.input=input,this.hasHeader=!0,this.fullColumnNames=null,this.columnNamesValidated=!1,this.columnConfigs=null,this.configuredColumnsOnly=!1,this.delimiter=",",this.delimWhitespace=!1,this.base=new TextLineDataset(input),csvConfig||(csvConfig={}),this.hasHeader=!1!==csvConfig.hasHeader,this.fullColumnNames=csvConfig.columnNames,this.columnConfigs=csvConfig.columnConfigs,this.configuredColumnsOnly=csvConfig.configuredColumnsOnly,csvConfig.delimWhitespace?(dist.ZSL.assert(null==csvConfig.delimiter,()=>"Delimiter should not be provided when delimWhitespace is true."),this.delimWhitespace=!0,this.delimiter=" "):this.delimiter=csvConfig.delimiter?csvConfig.delimiter:","}async iterator(){this.columnNamesValidated||await this.setColumnNames();let lines=await this.base.iterator();return this.hasHeader&&(lines=lines.skip(1)),lines.map(x=>this.makeDataElement(x))}makeDataElement(line){const values=this.parseRow(line),features={},labels={};for(let i=0;i<this.fullColumnNames.length;i++){const key=this.fullColumnNames[i],config=this.columnConfigs?this.columnConfigs[key]:null;if(!this.configuredColumnsOnly||config){const value=values[i];let parsedValue=null;if(""===value)if(config&&void 0!==config.default)parsedValue=config.default;else{if(config&&(config.required||config.isLabel))throw new Error(`Required column ${key} is empty in this line: ${line}`);parsedValue=void 0}else{const valueAsNum=Number(value);if(isNaN(valueAsNum))parsedValue=config&&"bool"===config.dtype?this.getBoolean(value):value;else if(config&&config.dtype)switch(config.dtype){case"float32":default:parsedValue=valueAsNum;break;case"int32":parsedValue=Math.floor(valueAsNum);break;case"bool":parsedValue=this.getBoolean(value)}else parsedValue=valueAsNum}config&&config.isLabel?labels[key]=parsedValue:features[key]=parsedValue}}return 0===Object.keys(labels).length?features:{xs:features,ys:labels}}getBoolean(value){return"1"===value||"true"===value.toLowerCase()?1:0}parseRow(line,validateElementCount=!0){const result=[];let readOffset=0;const readLength=line.length;let currentState=STATE_OUT;for(let i=0;i<readLength;i++)switch(currentState){case STATE_OUT:switch(line.charAt(i)){case'"':readOffset=i+1,currentState=STATE_QUOTE;break;case this.delimiter:if(readOffset=i+1," "===this.delimiter&&this.delimWhitespace)break;result.push(""),currentState=STATE_OUT;break;default:currentState=STATE_FIELD,readOffset=i}break;case STATE_FIELD:if(line.charAt(i)===this.delimiter)result.push(line.substring(readOffset,i)),currentState=STATE_OUT,readOffset=i+1;break;case STATE_QUOTE:if('"'===line.charAt(i))currentState=STATE_QUOTE_AFTER_QUOTE;break;case STATE_QUOTE_AFTER_QUOTE:switch(line.charAt(i)){case this.delimiter:result.push(line.substring(readOffset,i-1)),currentState=STATE_OUT,readOffset=i+1;break;case'"':currentState=STATE_QUOTE;break;default:currentState=STATE_WITHIN_QUOTE_IN_QUOTE}break;case STATE_WITHIN_QUOTE_IN_QUOTE:if('"'===line.charAt(i))currentState=STATE_QUOTE}if(currentState===STATE_QUOTE_AFTER_QUOTE?result.push(line.substring(readOffset,readLength-1)):result.push(line.substring(readOffset)),validateElementCount&&result.length!==this.fullColumnNames.length)throw new Error(`Invalid row in csv file. Should have ${this.fullColumnNames.length} elements in a row, but got ${result}`);return result}}class MicrophoneIterator extends LazyIterator{constructor(microphoneConfig){super(),this.microphoneConfig=microphoneConfig,this.isClosed=!1,this.fftSize=microphoneConfig.fftSize||1024;const fftSizeLog2=Math.log2(this.fftSize);if(this.fftSize<0||fftSizeLog2<4||fftSizeLog2>14||!Number.isInteger(fftSizeLog2))throw new Error(`Invalid fftSize: it must be a power of 2 between 2 to 4 and 2 to 14, but got ${this.fftSize}`);if(this.numFrames=microphoneConfig.numFramesPerSpectrogram||43,this.sampleRateHz=microphoneConfig.sampleRateHz,this.columnTruncateLength=microphoneConfig.columnTruncateLength||this.fftSize,this.audioTrackConstraints=microphoneConfig.audioTrackConstraints,this.smoothingTimeConstant=microphoneConfig.smoothingTimeConstant||0,this.includeSpectrogram=!1!==microphoneConfig.includeSpectrogram,this.includeWaveform=!0===microphoneConfig.includeWaveform,!this.includeSpectrogram&&!this.includeWaveform)throw new Error("Both includeSpectrogram and includeWaveform are false. At least one type of data should be returned.")}summary(){return"microphone"}static async create(microphoneConfig={}){if(!(0,dist._K2)().get("IS_BROWSER"))throw new Error("microphone API is only supported in browser environment.");const microphoneIterator=new MicrophoneIterator(microphoneConfig);return await microphoneIterator.start(),microphoneIterator}async start(){try{this.stream=await navigator.mediaDevices.getUserMedia({audio:null==this.audioTrackConstraints||this.audioTrackConstraints,video:!1})}catch(e){throw new Error(`Error thrown while initializing video stream: ${e.message}`)}if(!this.stream)throw new Error("Could not obtain audio from microphone.");const ctxConstructor=window.AudioContext||window.webkitAudioContext;if(this.audioContext=new ctxConstructor,this.sampleRateHz){if(this.audioContext.sampleRate!==this.sampleRateHz)throw new Error(`Mismatch in sampling rate: Expected: ${this.sampleRateHz}; Actual: ${this.audioContext.sampleRate}`)}else this.sampleRateHz=this.audioContext.sampleRate;const streamSource=this.audioContext.createMediaStreamSource(this.stream);this.analyser=this.audioContext.createAnalyser(),this.analyser.fftSize=2*this.fftSize,this.analyser.smoothingTimeConstant=this.smoothingTimeConstant,streamSource.connect(this.analyser),this.freqData=new Float32Array(this.fftSize),this.timeData=new Float32Array(this.fftSize)}async next(){if(this.isClosed)return{value:null,done:!0};let spectrogramTensor,waveformTensor;const audioDataQueue=await this.getAudioData();if(this.includeSpectrogram){const freqData=this.flattenQueue(audioDataQueue.freqDataQueue);spectrogramTensor=this.getTensorFromAudioDataArray(freqData,[this.numFrames,this.columnTruncateLength,1])}if(this.includeWaveform){const timeData=this.flattenQueue(audioDataQueue.timeDataQueue);waveformTensor=this.getTensorFromAudioDataArray(timeData,[this.numFrames*this.fftSize,1])}return{value:{spectrogram:spectrogramTensor,waveform:waveformTensor},done:!1}}async capture(){return(await this.next()).value}async getAudioData(){const freqDataQueue=[],timeDataQueue=[];let currentFrames=0;return new Promise(resolve=>{const intervalID=setInterval(()=>{this.includeSpectrogram&&(this.analyser.getFloatFrequencyData(this.freqData),this.freqData[0]===-1/0&&resolve({freqDataQueue,timeDataQueue}),freqDataQueue.push(this.freqData.slice(0,this.columnTruncateLength))),this.includeWaveform&&(this.analyser.getFloatTimeDomainData(this.timeData),timeDataQueue.push(this.timeData.slice())),++currentFrames===this.numFrames&&(clearInterval(intervalID),resolve({freqDataQueue,timeDataQueue}))},this.fftSize/this.sampleRateHz*1e3)})}stop(){this.isClosed||(this.isClosed=!0,this.analyser.disconnect(),this.audioContext.close(),null!=this.stream&&this.stream.getTracks().length>0&&this.stream.getTracks()[0].stop())}toArray(){throw new Error("Can not convert infinite audio stream to array.")}getSampleRate(){return this.sampleRateHz}flattenQueue(queue){const frameSize=queue[0].length,freqData=new Float32Array(queue.length*frameSize);return queue.forEach((data,i)=>freqData.set(data,i*frameSize)),freqData}getTensorFromAudioDataArray(freqData,shape){const vals=new Float32Array(dist.ZSL.sizeFromShape(shape));return vals.set(freqData,vals.length-freqData.length),(0,dist.OEK)(vals,shape)}}var webcam_iterator_console=__webpack_require__("./node_modules/console-browserify/index.js");class WebcamIterator extends LazyIterator{constructor(webcamVideoElement,webcamConfig){if(super(),this.webcamVideoElement=webcamVideoElement,this.webcamConfig=webcamConfig,this.isClosed=!0,this.resize=!1,this.needToResize())if(this.resize=!0,this.cropSize=[this.webcamConfig.resizeHeight,this.webcamConfig.resizeWidth],this.cropBoxInd=(0,dist.tGX)([0],"int32"),this.webcamConfig.centerCrop){const widthCroppingRatio=1*this.webcamConfig.resizeWidth/this.webcamVideoElement.width,heightCroppingRatio=1*this.webcamConfig.resizeHeight/this.webcamVideoElement.height,widthCropStart=(1-widthCroppingRatio)/2,heightCropStart=(1-heightCroppingRatio)/2,widthCropEnd=widthCropStart+widthCroppingRatio,heightCropEnd=heightCroppingRatio+heightCropStart;this.cropBox=(0,dist.KtR)([heightCropStart,widthCropStart,heightCropEnd,widthCropEnd],[1,4])}else this.cropBox=(0,dist.KtR)([0,0,1,1],[1,4])}summary(){return"webcam"}static async create(webcamVideoElement,webcamConfig={}){if(!(0,dist._K2)().get("IS_BROWSER"))throw new Error("tf.data.webcam is only supported in browser environment.");if(!webcamVideoElement){if(webcamVideoElement=document.createElement("video"),!webcamConfig.resizeWidth||!webcamConfig.resizeHeight)throw new Error("Please provide webcam video element, or resizeWidth and resizeHeight to create a hidden video element.");webcamVideoElement.width=webcamConfig.resizeWidth,webcamVideoElement.height=webcamConfig.resizeHeight}const webcamIterator=new WebcamIterator(webcamVideoElement,webcamConfig);return await webcamIterator.start(),webcamIterator}async start(){this.webcamConfig.facingMode&&dist.ZSL.assert("user"===this.webcamConfig.facingMode||"environment"===this.webcamConfig.facingMode,()=>`Invalid webcam facing mode: ${this.webcamConfig.facingMode}. Please provide 'user' or 'environment'`);try{this.stream=await navigator.mediaDevices.getUserMedia({video:{deviceId:this.webcamConfig.deviceId,facingMode:this.webcamConfig.facingMode?this.webcamConfig.facingMode:"user",width:this.webcamVideoElement.width,height:this.webcamVideoElement.height}})}catch(e){throw e.message=`Error thrown while initializing video stream: ${e.message}`,e}if(!this.stream)throw new Error("Could not obtain video from webcam.");try{this.webcamVideoElement.srcObject=this.stream}catch(error){webcam_iterator_console.log(error),this.webcamVideoElement.src=window.URL.createObjectURL(this.stream)}return this.webcamVideoElement.play(),this.isClosed=!1,new Promise(resolve=>{this.webcamVideoElement.onloadedmetadata=()=>{resolve()}})}async next(){if(this.isClosed)return{value:null,done:!0};let img;try{img=dist.TaL.fromPixels(this.webcamVideoElement)}catch(e){throw new Error(`Error thrown converting video to pixels: ${JSON.stringify(e)}`)}if(!this.resize)return{value:img,done:!1};try{return{value:this.cropAndResizeFrame(img),done:!1}}catch(e){throw new Error(`Error thrown cropping the video: ${e.message}`)}finally{img.dispose()}}needToResize(){return!(!this.webcamConfig.resizeWidth||!this.webcamConfig.resizeHeight||this.webcamVideoElement.width===this.webcamConfig.resizeWidth&&this.webcamVideoElement.height===this.webcamConfig.resizeHeight)}cropAndResizeFrame(img){return(0,dist.DZQ)(()=>{const expandedImage=(0,dist.UG6)((0,dist.wgE)(img,"float32"),0);let resizedImage;resizedImage=dist.Slp.cropAndResize(expandedImage,this.cropBox,this.cropBoxInd,this.cropSize,"bilinear");const shape=resizedImage.shape;return(0,dist.tQQ)(resizedImage,shape.slice(1))})}async capture(){return(await this.next()).value}stop(){this.stream.getTracks().forEach(track=>track.stop());try{this.webcamVideoElement.srcObject=null}catch(error){webcam_iterator_console.log(error),this.webcamVideoElement.src=null}this.isClosed=!0}toArray(){throw new Error("Can not convert infinite video stream to array.")}}class DataSource{}class StringIterator extends LazyIterator{split(separator){return new SplitIterator(this,separator)}}class SplitIterator extends StringIterator{constructor(upstream,separator){super(),this.upstream=upstream,this.impl=new SplitIteratorImpl(upstream,separator)}summary(){return this.impl.summary()}async next(){return this.impl.next()}}class SplitIteratorImpl extends OneToManyIterator{constructor(upstream,separator){super(),this.upstream=upstream,this.separator=separator,this.carryover=""}summary(){return`${this.upstream.summary()} -> Split('${this.separator}')`}async pump(){const chunkResult=await this.upstream.next();if(chunkResult.done)return""!==this.carryover&&(this.outputQueue.push(this.carryover),this.carryover="",!0);const lines=chunkResult.value.split(this.separator);lines[0]=this.carryover+lines[0];for(const line of lines.slice(0,-1))this.outputQueue.push(line);return this.carryover=lines[lines.length-1],!0}}var byte_chunk_iterator_Buffer=__webpack_require__("./node_modules/buffer/index.js").Buffer;class ByteChunkIterator extends LazyIterator{decodeUTF8(){return new Utf8Iterator(this)}}class Utf8Iterator extends StringIterator{constructor(upstream){super(),this.upstream=upstream,this.impl=new Utf8IteratorImpl(upstream)}summary(){return this.impl.summary()}async next(){return this.impl.next()}}class Utf8IteratorImpl extends OneToManyIterator{constructor(upstream){if(super(),this.upstream=upstream,(0,dist._K2)().get("IS_BROWSER"))this.decoder=new TextDecoder("utf-8");else{const{StringDecoder}=__webpack_require__("?defc");this.decoder=new StringDecoder("utf8")}}summary(){return`${this.upstream.summary()} -> Utf8`}async pump(){const chunkResult=await this.upstream.next();let chunk,text;return!chunkResult.done&&(chunk=chunkResult.value,text=(0,dist._K2)().get("IS_BROWSER")?this.decoder.decode(chunk,{stream:!0}):this.decoder.write(byte_chunk_iterator_Buffer.from(chunk.buffer)),this.outputQueue.push(text),!0)}}class FileChunkIterator extends ByteChunkIterator{constructor(file,options={}){super(),this.file=file,this.options=options,dist.ZSL.assert(file instanceof Uint8Array||!!(0,dist._K2)().get("IS_BROWSER")&&(file instanceof File||file instanceof Blob),()=>"FileChunkIterator only supports File, Blob and Uint8Array right now."),this.offset=options.offset||0,this.chunkSize=options.chunkSize||1048576}summary(){return`FileChunks ${this.file}`}async next(){if(this.offset>=(this.file instanceof Uint8Array?this.file.byteLength:this.file.size))return{value:null,done:!0};const chunk=new Promise((resolve,reject)=>{const end=this.offset+this.chunkSize;if(this.file instanceof Uint8Array)resolve(new Uint8Array(this.file.slice(this.offset,end)));else{const fileReader=new FileReader;fileReader.onload=event=>{let data=fileReader.result;if(data instanceof ArrayBuffer&&(data=new Uint8Array(data)),!(data instanceof Uint8Array))return reject(new TypeError("FileReader returned unknown type."));resolve(data)},fileReader.onabort=event=>reject(new Error("Aborted")),fileReader.onerror=event=>reject(new Error(event.type));const slice=this.file.slice(this.offset,end);fileReader.readAsArrayBuffer(slice)}this.offset=end});return{value:await chunk,done:!1}}}const getRequestInitFromRequest=request=>({method:request.method,headers:request.headers,body:request.body,mode:request.mode,credentials:request.credentials,cache:request.cache,redirect:request.redirect,referrer:request.referrer,integrity:request.integrity});function isLocalPath(source){return"string"==typeof source&&"file://"===source.slice(0,7)}class FileDataSource extends DataSource{constructor(input,options={}){super(),this.input=input,this.options=options}async iterator(){if(isLocalPath(this.input)&&(0,dist._K2)().get("IS_NODE")){const fs=__webpack_require__("?fdcf");this.input=fs.readFileSync(this.input.slice(7))}return new FileChunkIterator(this.input,this.options)}}class URLDataSource extends DataSource{constructor(url,fileOptions={}){super(),this.url=url,this.fileOptions=fileOptions}async iterator(){return isLocalPath(this.url)?new FileDataSource(this.url,this.fileOptions).iterator():async function urlChunkIterator(url,options={},fetchFunc){let urlString,requestInit;"string"==typeof url?urlString=url:(urlString=url.url,requestInit=getRequestInitFromRequest(url));const response=await(fetchFunc||dist.ZSL.fetch)(urlString,requestInit);if(response.ok){const uint8Array=new Uint8Array(await response.arrayBuffer());return new FileChunkIterator(uint8Array,options)}throw new Error(response.statusText)}(this.url,this.fileOptions)}}function csv(source,csvConfig={}){return new CSVDataset(new URLDataSource(source),csvConfig)}function func(f){const iter=iteratorFromFunction(f);return datasetFromIteratorFn(async()=>iter)}function generator(generator){return datasetFromIteratorFn(async()=>{const gen=await generator();return iteratorFromFunction(()=>gen.next())})}async function webcam(webcamVideoElement,webcamConfig){return WebcamIterator.create(webcamVideoElement,webcamConfig)}async function microphone(microphoneConfig){return MicrophoneIterator.create(microphoneConfig)}const dist_version_version="4.22.0";var cpu_util=__webpack_require__("./node_modules/@tensorflow/tfjs-backend-cpu/dist/cpu_util.js");const whereImpl=dist.kpo.whereImpl;class MathBackendCPU extends dist.uI_{nextDataId(){return MathBackendCPU.nextDataId++}constructor(){super(),this.blockSize=48,this.firstUse=!0,this.data=new dist.GJx(this,(0,dist.Hi9)())}write(values,shape,dtype){this.firstUse&&(this.firstUse=!1,(0,dist._K2)().get("IS_NODE")&&dist.C0T.warn("\n============================\nHi, looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, visit https://github.com/tensorflow/tfjs-node for more details. \n============================"));const dataId={id:this.nextDataId()};return this.data.set(dataId,{values,dtype,refCount:1}),dataId}makeTensorInfo(shape,dtype,values){let outId;if("string"===dtype&&null!=values&&values.length>0&&dist.ZSL.isString(values[0])){const encodedValues=values.map(d=>dist.ZSL.encodeString(d));outId=this.write(encodedValues,shape,dtype)}else outId=this.write(values,shape,dtype);return{dataId:outId,shape,dtype}}refCount(dataId){if(this.data.has(dataId)){return this.data.get(dataId).refCount}return 0}incRef(dataId){this.data.get(dataId).refCount++}decRef(dataId){if(this.data.has(dataId)){this.data.get(dataId).refCount--}}move(dataId,values,shape,dtype,refCount){this.data.set(dataId,{values,dtype,refCount})}numDataIds(){return this.data.numDataIds()}async read(dataId){return this.readSync(dataId)}readSync(dataId){const{dtype,complexTensorInfos}=this.data.get(dataId);if("complex64"===dtype){const realValues=this.readSync(complexTensorInfos.real.dataId),imagValues=this.readSync(complexTensorInfos.imag.dataId);return dist.C0T.mergeRealAndImagArrays(realValues,imagValues)}return dist.ZSL.convertBackendValuesAndArrayBuffer(this.data.get(dataId).values,dtype)}bufferSync(t){const data=this.readSync(t.dataId);if("string"===t.dtype)try{const strings=data.map(d=>dist.ZSL.decodeString(d));return(0,dist.ra8)(t.shape,t.dtype,strings)}catch(_a){throw new Error("Failed to decode encoded string bytes into utf-8")}return(0,dist.ra8)(t.shape,t.dtype,data)}makeOutput(values,shape,dtype){return(0,dist.Hi9)().makeTensorFromTensorInfo(this.makeTensorInfo(shape,dtype,values),this)}disposeData(dataId,force=!1){if(this.data.has(dataId)){if(this.data.get(dataId).refCount--,!force&&this.data.get(dataId).refCount>0)return!1;const{complexTensorInfos}=this.data.get(dataId);null!=complexTensorInfos&&(this.disposeData(complexTensorInfos.real.dataId,!0),this.disposeData(complexTensorInfos.imag.dataId,!0)),this.data.delete(dataId)}return!0}disposeIntermediateTensorInfo(tensorInfo){this.disposeData(tensorInfo.dataId)}async time(f){const start=dist.ZSL.now();f();return{kernelMs:dist.ZSL.now()-start}}memory(){return{unreliable:!0,reasons:["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]}}where(condition){(0,cpu_util.C)([condition],"where");const condVals=this.readSync(condition.dataId);return whereImpl(condition.shape,condVals)}dispose(){}floatPrecision(){return 32}epsilon(){return super.epsilon()}}function simpleAbsImpl(vals){const resultValues=new Float32Array(vals.length);for(let i=0;i<vals.length;++i)resultValues[i]=Math.abs(vals[i]);return resultValues}MathBackendCPU.nextDataId=0;const absConfig={kernelName:dist.ljI,backendName:"cpu",kernelFunc:args=>{const{x}=args.inputs,cpuBackend=args.backend;(0,cpu_util.C)(x,"abs");let resultValues=new Float32Array(dist.ZSL.sizeFromShape(x.shape));return resultValues=simpleAbsImpl(cpuBackend.data.get(x.dataId).values),cpuBackend.makeOutput(resultValues,x.shape,x.dtype)}};function createSimpleBinaryKernelImpl(op){return(aShape,bShape,aVals,bVals,dtype)=>{const newShape=dist.C0T.assertAndGetBroadcastShape(aShape,bShape),resultRank=newShape.length,resultStrides=dist.ZSL.computeStrides(newShape),resultSize=dist.ZSL.sizeFromShape(newShape),result=dist.ZSL.getTypedArrayFromDType(dtype,resultSize),aRank=aShape.length,bRank=bShape.length,aStrides=dist.ZSL.computeStrides(aShape),bStrides=dist.ZSL.computeStrides(bShape),aBroadcastDims=dist.C0T.getBroadcastDims(aShape,newShape),bBroadcastDims=dist.C0T.getBroadcastDims(bShape,newShape);if(aBroadcastDims.length+bBroadcastDims.length===0)for(let i=0;i<result.length;++i)result[i]=op(aVals[i%aVals.length],bVals[i%bVals.length]);else for(let i=0;i<result.length;++i){const loc=dist.ZSL.indexToLoc(i,resultRank,resultStrides),aLoc=loc.slice(-aRank);aBroadcastDims.forEach(d=>aLoc[d]=0);const aIndex=dist.ZSL.locToIndex(aLoc,aRank,aStrides),bLoc=loc.slice(-bRank);bBroadcastDims.forEach(d=>bLoc[d]=0);const bIndex=dist.ZSL.locToIndex(bLoc,bRank,bStrides);result[i]=op(aVals[aIndex],bVals[bIndex])}return[result,newShape]}}function complex(args){const{inputs,backend}=args,{real,imag}=inputs,realVals=backend.data.get(real.dataId).values,imagVals=backend.data.get(imag.dataId).values,complexInfo=backend.makeTensorInfo(real.shape,"complex64");return backend.data.get(complexInfo.dataId).complexTensorInfos={real:backend.makeTensorInfo(real.shape,"float32",realVals),imag:backend.makeTensorInfo(imag.shape,"float32",imagVals)},complexInfo}const complexConfig={kernelName:dist.pr3,backendName:"cpu",kernelFunc:complex};function zeros_impl_zeros(backend,shape,dtype="float32"){if("complex64"===dtype){return complex({inputs:{real:zeros_impl_zeros(backend,shape,"float32"),imag:zeros_impl_zeros(backend,shape,"float32")},backend})}const values=dist.ZSL.makeZerosTypedArray(dist.ZSL.sizeFromShape(shape),dtype);return backend.makeTensorInfo(shape,dtype,values)}function Identity_identity(args){const{inputs,backend}=args,{x}=inputs;return backend.incRef(x.dataId),{dataId:x.dataId,shape:x.shape,dtype:x.dtype}}const identityConfig={kernelName:dist.lzr,backendName:"cpu",kernelFunc:Identity_identity};function real(args){const{inputs,backend}=args,{input}=inputs,real=backend.data.get(input.dataId).complexTensorInfos.real,realVal=backend.data.get(real.dataId).values;return backend.makeTensorInfo(real.shape,real.dtype,realVal)}const realConfig={kernelName:dist.LRy,backendName:"cpu",kernelFunc:real};function castImpl(values,shape,inputType,dtype){if("int32"===dtype){return[shape,"int32",Int32Array.from(values)]}if("bool"===dtype){const zero=dist.ZSL.toTypedArray([0],inputType),[resultData,resultShape]=createSimpleBinaryKernelImpl((a,b)=>a!==b?1:0)(shape,[],values,zero,"bool");return[resultShape,"bool",resultData]}throw new Error(`Error in Cast: failed to cast ${inputType} to ${dtype}`)}function Cast_cast(args){const{inputs,backend,attrs}=args,{x}=inputs,{dtype}=attrs;if("complex64"===dtype){if("complex64"===x.dtype)return Identity_identity({inputs:{x},backend});const zerosTensorInfo=zeros_impl_zeros(backend,x.shape,x.dtype),floatX=Cast_cast({inputs:{x},backend,attrs:{dtype:"float32"}}),result=complex({inputs:{real:floatX,imag:zerosTensorInfo},backend});return backend.disposeIntermediateTensorInfo(zerosTensorInfo),backend.disposeIntermediateTensorInfo(floatX),result}if("complex64"===x.dtype){const realPart=real({inputs:{input:x},backend}),result=Cast_cast({inputs:{x:realPart},backend,attrs:{dtype}});return backend.disposeIntermediateTensorInfo(realPart),result}if(!dist.ZSL.hasEncodingLoss(x.dtype,dtype)){const result=Identity_identity({inputs:{x},backend});return{dataId:result.dataId,shape:result.shape,dtype}}const values=backend.data.get(x.dataId).values,[resultShape,resultType,resultData]=castImpl(values,x.shape,x.dtype,dtype);return backend.makeTensorInfo(resultShape,resultType,resultData)}const castConfig={kernelName:dist.KXH,backendName:"cpu",kernelFunc:Cast_cast};function binaryKernelFunc(name,simpleImpl,complexImpl,dtype){return null==complexImpl?({inputs,backend})=>{const{a,b}=inputs,cpuBackend=backend;(0,cpu_util.C)([a,b],name);const aVals=cpuBackend.data.get(a.dataId).values,bVals=cpuBackend.data.get(b.dataId).values,decodedAVals="string"===a.dtype?dist.C0T.fromUint8ToStringArray(aVals):aVals,decodedBVals="string"===a.dtype?dist.C0T.fromUint8ToStringArray(bVals):bVals,$dtype=dtype||a.dtype,[resultData,resultShape]=simpleImpl(a.shape,b.shape,decodedAVals,decodedBVals,$dtype);return cpuBackend.makeTensorInfo(resultShape,$dtype,resultData)}:({inputs,backend})=>{const{a,b}=inputs,cpuBackend=backend;if("complex64"===a.dtype||"complex64"===b.dtype){const $aComplex=Cast_cast({inputs:{x:a},backend:cpuBackend,attrs:{dtype:"complex64"}}),$aComplexVals=cpuBackend.data.get($aComplex.dataId),aReal=$aComplexVals.complexTensorInfos.real,aImag=$aComplexVals.complexTensorInfos.imag,aRealVals=cpuBackend.data.get(aReal.dataId).values,aImagVals=cpuBackend.data.get(aImag.dataId).values,$bComplex=Cast_cast({inputs:{x:b},backend:cpuBackend,attrs:{dtype:"complex64"}}),$bComplexVals=cpuBackend.data.get($bComplex.dataId),bReal=$bComplexVals.complexTensorInfos.real,bImag=$bComplexVals.complexTensorInfos.imag,bRealVals=cpuBackend.data.get(bReal.dataId).values,bImagVals=cpuBackend.data.get(bImag.dataId).values,[resultRealData,resultImagData,resultShape]=complexImpl(a.shape,b.shape,aRealVals,aImagVals,bRealVals,bImagVals),resultReal=cpuBackend.makeTensorInfo(resultShape,"float32",resultRealData),resultImag=cpuBackend.makeTensorInfo(resultShape,"float32",resultImagData),result=complex({inputs:{real:resultReal,imag:resultImag},backend:cpuBackend});return cpuBackend.disposeIntermediateTensorInfo($aComplex),cpuBackend.disposeIntermediateTensorInfo($bComplex),cpuBackend.disposeIntermediateTensorInfo(resultReal),cpuBackend.disposeIntermediateTensorInfo(resultImag),result}{const aVals=cpuBackend.data.get(a.dataId).values,bVals=cpuBackend.data.get(b.dataId).values,$dtype=dtype||a.dtype,[resultData,resultShape]=simpleImpl(a.shape,b.shape,aVals,bVals,$dtype);return cpuBackend.makeTensorInfo(resultShape,$dtype,resultData)}}}function createComplexBinaryKernelImpl(op){return(aShape,bShape,aRealVals,aImagVals,bRealVals,bImagVals)=>{const resultShape=dist.C0T.assertAndGetBroadcastShape(aShape,bShape),resultSize=dist.ZSL.sizeFromShape(resultShape),resultRank=resultShape.length,resultStrides=dist.ZSL.computeStrides(resultShape),resultRealVals=dist.ZSL.getTypedArrayFromDType("float32",resultSize),resultImagVals=dist.ZSL.getTypedArrayFromDType("float32",resultSize),aBroadcastDims=dist.C0T.getBroadcastDims(aShape,resultShape),bBroadcastDims=dist.C0T.getBroadcastDims(bShape,resultShape),aVals=dist.C0T.mergeRealAndImagArrays(aRealVals,aImagVals),bVals=dist.C0T.mergeRealAndImagArrays(bRealVals,bImagVals),aRank=aShape.length,aStrides=dist.ZSL.computeStrides(aShape),bRank=bShape.length,bStrides=dist.ZSL.computeStrides(bShape);if(aBroadcastDims.length+bBroadcastDims.length===0)for(let i=0;i<resultRealVals.length;i++){const aIdx=i%aVals.length,bIdx=i%bVals.length,result=op(aVals[2*aIdx],aVals[2*aIdx+1],bVals[2*bIdx],bVals[2*bIdx+1]);resultRealVals[i]=result.real,resultImagVals[i]=result.imag}else for(let i=0;i<resultRealVals.length;i++){const loc=dist.ZSL.indexToLoc(i,resultRank,resultStrides),aLoc=loc.slice(-aRank);aBroadcastDims.forEach(d=>aLoc[d]=0);const aIndex=dist.ZSL.locToIndex(aLoc,aRank,aStrides),bLoc=loc.slice(-bRank);bBroadcastDims.forEach(d=>bLoc[d]=0);const bIndex=dist.ZSL.locToIndex(bLoc,bRank,bStrides),opResult=op(aVals[2*aIndex],aVals[2*aIndex+1],bVals[2*bIndex],bVals[2*bIndex+1]);resultRealVals[i]=opResult.real,resultImagVals[i]=opResult.imag}return[resultRealVals,resultImagVals,resultShape]}}const addImpl=createSimpleBinaryKernelImpl((a,b)=>a+b),addComplexImpl=createComplexBinaryKernelImpl((aReal,aImag,bReal,bImag)=>({real:aReal+bReal,imag:aImag+bImag})),Add_add=binaryKernelFunc(dist.OMN,addImpl,addComplexImpl),addConfig={kernelName:dist.OMN,backendName:"cpu",kernelFunc:Add_add};function bincountImpl(xVals,weightsVals,weightsDtype,weightsShape,size){const weightsSize=dist.ZSL.sizeFromShape(weightsShape),outVals=dist.ZSL.makeZerosTypedArray(size,weightsDtype);for(let i=0;i<xVals.length;i++){const value=xVals[i];if(value<0)throw new Error("Input x must be non-negative!");value>=size||(outVals[value]+=weightsSize>0?weightsVals[i]:1)}return outVals}function bincountReduceImpl(xBuf,weightsBuf,size,binaryOutput=!1){const numRows=xBuf.shape[0],numCols=xBuf.shape[1],outBuf=(0,dist.ra8)([numRows,size],weightsBuf.dtype);for(let i=0;i<numRows;i++)for(let j=0;j<numCols;j++){const value=xBuf.get(i,j);if(value<0)throw new Error("Input x must be non-negative!");value>=size||(binaryOutput?outBuf.set(1,i,value):weightsBuf.size>0?outBuf.set(outBuf.get(i,value)+weightsBuf.get(i,j),i,value):outBuf.set(outBuf.get(i,value)+1,i,value))}return outBuf}const bitwiseAndImpl=createSimpleBinaryKernelImpl((a,b)=>a&b),bitwiseAnd=binaryKernelFunc(dist.HNs,bitwiseAndImpl),bitwiseAndConfig={kernelName:dist.HNs,backendName:"cpu",kernelFunc:bitwiseAnd};function createSimpleUnaryImpl(op){return(values,dtype,attrs)=>{const newValues=dist.ZSL.getArrayFromDType(dtype,values.length);for(let i=0;i<values.length;++i)newValues[i]=op(values[i],attrs);return newValues}}function unaryKernelFunc(name,op,dtype){return unaryKernelFuncFromImpl(name,createSimpleUnaryImpl(op),dtype)}function unaryKernelFuncFromImpl(name,unaryImpl,dtype){return({inputs,attrs,backend})=>{const{x}=inputs;(0,cpu_util.C)(x,name);const cpuBackend=backend,values=cpuBackend.data.get(x.dataId).values;let decoded;if("string"===x.dtype){if(!Array.isArray(values))throw new Error("String tensor's value was not an instance of Array");decoded=dist.C0T.fromUint8ToStringArray(values)}else decoded=values;const $dtype=dtype||x.dtype,newValues=unaryImpl(decoded,$dtype,attrs);return cpuBackend.makeTensorInfo(x.shape,$dtype,newValues)}}const ceilImpl=createSimpleUnaryImpl(xi=>Math.ceil(xi)),Ceil_ceil=unaryKernelFuncFromImpl(dist.QDP,ceilImpl),ceilConfig={kernelName:dist.QDP,backendName:"cpu",kernelFunc:Ceil_ceil};var Concat_impl=__webpack_require__("./node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Concat_impl.js");const equalImpl=createSimpleBinaryKernelImpl((a,b)=>a===b?1:0),Equal_equal=binaryKernelFunc(dist.BRl,equalImpl,null,"bool"),equalConfig={kernelName:dist.BRl,backendName:"cpu",kernelFunc:Equal_equal},expImpl=createSimpleUnaryImpl(xi=>Math.exp(xi)),Exp_exp=unaryKernelFuncFromImpl(dist.ox3,expImpl,"float32"),expConfig={kernelName:dist.ox3,backendName:"cpu",kernelFunc:Exp_exp},expm1Impl=createSimpleUnaryImpl(xi=>Math.expm1(xi)),Expm1_expm1=unaryKernelFuncFromImpl(dist.ybj,expm1Impl),expm1Config={kernelName:dist.ybj,backendName:"cpu",kernelFunc:Expm1_expm1},floorImpl=createSimpleUnaryImpl(xi=>Math.floor(xi)),Floor_floor=unaryKernelFuncFromImpl(dist.ZgB,floorImpl),floorConfig={kernelName:dist.ZgB,backendName:"cpu",kernelFunc:Floor_floor},floorDivImpl=createSimpleBinaryKernelImpl((a,b)=>Math.floor(a/b)),FloorDiv_floorDiv=binaryKernelFunc(dist.ElG,floorDivImpl,null,"int32"),floorDivConfig={kernelName:dist.ElG,backendName:"cpu",kernelFunc:FloorDiv_floorDiv};function gatherNdImpl(indicesData,paramsBuf,dtype,numSlices,sliceRank,sliceSize,strides,paramsShape,paramsSize){const outBuf=(0,dist.ra8)([numSlices,sliceSize],dtype);for(let i=0;i<numSlices;i++){const index=[];let flattenIndex=0;for(let j=0;j<sliceRank;j++){const dim=indicesData[i*sliceRank+j];flattenIndex+=dim*strides[j],index.push(dim)}if(flattenIndex<0||flattenIndex>=paramsSize/sliceSize)throw new Error(`Invalid indices: ${index} does not index into ${paramsShape}`);for(let k=0;k<sliceSize;k++)outBuf.values[i*sliceSize+k]=paramsBuf.get(...paramsBuf.indexToLoc(flattenIndex*sliceSize+k))}return outBuf}function gatherV2Impl(xBuf,indicesBuf,flattenOutputShape){const outBuf=(0,dist.ra8)(flattenOutputShape,xBuf.dtype);for(let i=0;i<outBuf.size;++i){const originalLoc=outBuf.indexToLoc(i).slice(),batchIdx=originalLoc[0],indicesIdx=originalLoc[2],indicesIndex=indicesBuf.locToIndex([batchIdx,indicesIdx]);originalLoc[2]=indicesBuf.values[indicesIndex];const originalIndex=xBuf.locToIndex(originalLoc);0<=originalIndex&&originalIndex<xBuf.values.length&&(outBuf.values[i]=xBuf.values[originalIndex])}return outBuf}const greaterImpl=createSimpleBinaryKernelImpl((a,b)=>a>b?1:0),Greater_greater=binaryKernelFunc(dist.XhZ,greaterImpl,null,"bool"),greaterConfig={kernelName:dist.XhZ,backendName:"cpu",kernelFunc:Greater_greater},greaterEqualImpl=createSimpleBinaryKernelImpl((a,b)=>a>=b?1:0),greaterEqual=binaryKernelFunc(dist.lLS,greaterEqualImpl,null,"bool"),greaterEqualConfig={kernelName:dist.lLS,backendName:"cpu",kernelFunc:greaterEqual},lessImpl=createSimpleBinaryKernelImpl((a,b)=>a<b?1:0),Less_less=binaryKernelFunc(dist.mIA,lessImpl,null,"bool"),lessConfig={kernelName:dist.mIA,backendName:"cpu",kernelFunc:Less_less},lessEqualImpl=createSimpleBinaryKernelImpl((a,b)=>a<=b?1:0),lessEqual=binaryKernelFunc(dist.CwD,lessEqualImpl,null,"bool"),lessEqualConfig={kernelName:dist.CwD,backendName:"cpu",kernelFunc:lessEqual};function linSpaceImpl(start,stop,num){const step=(stop-start)/(num-1),values=dist.ZSL.makeZerosTypedArray(num,"float32");values[0]=start;for(let i=1;i<values.length;i++)values[i]=values[i-1]+step;return values}const logImpl=createSimpleUnaryImpl(xi=>Math.log(xi)),Log_log=unaryKernelFuncFromImpl(dist.tG8,logImpl),logConfig={kernelName:dist.tG8,backendName:"cpu",kernelFunc:Log_log};function maxImpl(aVals,reduceSize,outShape,dtype){const vals=dist.ZSL.getTypedArrayFromDType(dtype,dist.ZSL.sizeFromShape(outShape));for(let i=0;i<vals.length;++i){const offset=i*reduceSize;let max=aVals[offset];for(let j=0;j<reduceSize;++j){const value=aVals[offset+j];(Number.isNaN(value)||value>max)&&(max=value)}vals[i]=max}return vals}const maximumImpl=createSimpleBinaryKernelImpl((aValue,bValue)=>Math.max(aValue,bValue)),Maximum_maximum=binaryKernelFunc(dist.LDN,maximumImpl),maximumConfig={kernelName:dist.LDN,backendName:"cpu",kernelFunc:Maximum_maximum},minimumImpl=createSimpleBinaryKernelImpl((aValue,bValue)=>Math.min(aValue,bValue)),Minimum_minimum=binaryKernelFunc(dist.LG0,minimumImpl),minimumConfig={kernelName:dist.LG0,backendName:"cpu",kernelFunc:Minimum_minimum},multiplyImpl=createSimpleBinaryKernelImpl((aValue,bValue)=>aValue*bValue),multiplyComplexImpl=createComplexBinaryKernelImpl((aReal,aImag,bReal,bImag)=>({real:aReal*bReal-aImag*bImag,imag:aReal*bImag+aImag*bReal})),Multiply_multiply=binaryKernelFunc(dist.xu7,multiplyImpl,multiplyComplexImpl),multiplyConfig={kernelName:dist.xu7,backendName:"cpu",kernelFunc:Multiply_multiply};function negImpl(xVals,xShape,xDtype){const minusOne=dist.ZSL.createScalarValue(-1,xDtype);return multiplyImpl([],xShape,minusOne,xVals,xDtype)}const negConfig={kernelName:dist.l0G,backendName:"cpu",kernelFunc:function Neg_neg(args){const{inputs,backend}=args,{x}=inputs;(0,cpu_util.C)(x,"neg");const xVals=backend.data.get(x.dataId).values,[res,newShape]=negImpl(xVals,x.shape,x.dtype);return backend.makeTensorInfo(newShape,x.dtype,res)}},notEqualImpl=createSimpleBinaryKernelImpl((a,b)=>a!==b?1:0),notEqual=binaryKernelFunc(dist.ylV,notEqualImpl,null,"bool"),notEqualConfig={kernelName:dist.ylV,backendName:"cpu",kernelFunc:notEqual};function transposeImpl(xVals,xShape,dtype,perm,newShape){const xRank=xShape.length,xSize=dist.ZSL.sizeFromShape(xShape),xStrides=dist.ZSL.computeStrides(xShape),newStrides=dist.ZSL.computeStrides(newShape),result=dist.ZSL.getTypedArrayFromDType(dtype,dist.ZSL.sizeFromShape(newShape));for(let i=0;i<xSize;++i){const loc=dist.ZSL.indexToLoc(i,xRank,xStrides),newLoc=new Array(loc.length);for(let i=0;i<newLoc.length;i++)newLoc[i]=loc[perm[i]];result[dist.ZSL.locToIndex(newLoc,xRank,newStrides)]=xVals[i]}return result}function Transpose_transpose(args){const{inputs,attrs,backend}=args,{x}=inputs,{perm}=attrs;(0,cpu_util.C)(x,"transpose");const xRank=x.shape.length,newShape=new Array(xRank);for(let i=0;i<newShape.length;i++)newShape[i]=x.shape[perm[i]];const result=transposeImpl(backend.data.get(x.dataId).values,x.shape,x.dtype,perm,newShape);return{dataId:backend.write(result,newShape,x.dtype),shape:newShape,dtype:x.dtype}}const transposeConfig={kernelName:dist.wx0,backendName:"cpu",kernelFunc:Transpose_transpose};function prodImpl(xShape,xDtype,xVals,reductionAxes){const[outShape,reduceShape]=dist.C0T.computeOutAndReduceShapes(xShape,reductionAxes),outDtype=(0,dist.TuY)(xDtype,"int32"),outVals=dist.ZSL.makeZerosTypedArray(dist.ZSL.sizeFromShape(outShape),outDtype),reduceSize=dist.ZSL.sizeFromShape(reduceShape);for(let i=0;i<outVals.length;++i){const offset=i*reduceSize;let prod=1;for(let j=0;j<reduceSize;++j)prod*=xVals[offset+j];outVals[i]=prod}return{outVals,outShape,outDtype}}const prodConfig={kernelName:dist.kdj,backendName:"cpu",kernelFunc:function Prod_prod(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,keepDims}=attrs;(0,cpu_util.C)(x,"prod");const xRank=x.shape.length,axes=dist.ZSL.parseAxisParam(axis,x.shape),permutation=dist.C0T.getAxesPermutation(axes,xRank);let reductionAxes=axes,permutedX=x;const intermediateTensorInfos=[];null!=permutation&&(permutedX=Transpose_transpose({inputs:{x},backend,attrs:{perm:permutation}}),intermediateTensorInfos.push(permutedX),reductionAxes=dist.C0T.getInnerMostAxes(reductionAxes.length,xRank));const xVals=backend.data.get(permutedX.dataId).values,{outVals,outShape,outDtype}=prodImpl(permutedX.shape,permutedX.dtype,xVals,reductionAxes);let resultShape=outShape;return keepDims&&(resultShape=dist.C0T.expandShapeToKeepDim(outShape,axes)),intermediateTensorInfos.forEach(t=>backend.disposeIntermediateTensorInfo(t)),backend.makeTensorInfo(resultShape,outDtype,outVals)}};function makeSplits(indices,indicesShape,paramsNestedSplits,numParamsDenseValues){const valueSlices=[];let numValues=0;const numSplits=indicesShape.length-1+paramsNestedSplits.length,outSplits=new Array(numSplits).fill(null).map(()=>[0]);!function validateSplits(paramsNestedSplits,numParamsDenseValues){for(let dim=0;dim<paramsNestedSplits.length;++dim){const splits=paramsNestedSplits[dim],lastSplit=dim===paramsNestedSplits.length-1?numParamsDenseValues:paramsNestedSplits[dim+1].length;if(0===splits.length)throw new Error("Ragged splits may not be empty");if(splits[0]<0)throw new Error("Ragged splits must be non-negative");if(splits[splits.length-1]>lastSplit)throw new Error("Ragged splits must not point past values");for(let i=1;i<splits.length;++i)if(splits[i-1]>splits[i])throw new Error("Ragged splits must be sorted in ascending order")}}(paramsNestedSplits,numParamsDenseValues);let nrows=1;for(let dim=0;dim<indicesShape.length-1;++dim){nrows*=indicesShape[dim];const rowLength=indicesShape[dim+1];for(let i=1;i<nrows+1;++i)outSplits[dim].push(i*rowLength)}for(let i=0;i<indices.length;++i){let start=indices[i],limit=indices[i]+1;for(let dim=0;dim<paramsNestedSplits.length;++dim){const splits=paramsNestedSplits[dim],outDim=dim+indicesShape.length-1;if(outDim>=0){const outSplitsOutDim=outSplits[outDim],delta=outSplitsOutDim[outSplitsOutDim.length-1]-splits[start];for(let j=start;j<limit;++j)outSplits[outDim].push(splits[j+1]+delta)}start=splits[start],limit=splits[limit]}limit!==start&&(valueSlices.push([start,limit]),numValues+=limit-start)}return{outSplits,valueSlices,numValues}}function computeFlatOuterDims(orig,numOutDims){const outDims=orig.slice(0,numOutDims);for(;outDims.length<numOutDims;)outDims.push(1);for(let inDim=numOutDims;inDim<orig.length;inDim++)outDims[numOutDims-1]*=orig[inDim];return outDims}function getValues(paramsDenseValues,paramsDenseValuesShape,paramsDenseValuesDType,valueSlices,numValues){const valuesShape=paramsDenseValuesShape.slice();valuesShape[0]=numValues;const valuesOut=dist.ZSL.getArrayFromDType(paramsDenseValuesDType,dist.ZSL.sizeFromShape(valuesShape)),numElements=paramsDenseValues.length;return function writeValueSlices(paramsDenseValues,paramsDenseValuesShape,valueSlices,valueSize,values,valuesShape){const denseM=computeFlatOuterDims(paramsDenseValuesShape,2)[1],valuesM=computeFlatOuterDims(valuesShape,2)[1];let outPos=0;for(const slice of valueSlices)for(let i=slice[0];i<slice[1];++i){for(let j=0;j<valueSize;++j)values[outPos*valuesM+j]=paramsDenseValues[i*denseM+j];++outPos}}(paramsDenseValues,paramsDenseValuesShape,valueSlices,0===numElements?0:numElements/paramsDenseValuesShape[0],valuesOut,valuesShape),[valuesOut,valuesShape]}function raggedGatherImpl(paramsNestedSplits,paramsNestedSplitsShapes,paramsDenseValues,paramsDenseValuesShape,paramsDenseValuesDType,indices,indicesShape,outputRaggedRank){if(0===paramsNestedSplits.length)throw new Error("paramsNestedSplits must be non empty");if(0===paramsNestedSplitsShapes[0].length)throw new Error("Split tensors must not be scalars");if(function validateIndices(indices,indicesShape,numParams){indices.forEach((index,i)=>{if(index<0||index>=numParams){const locString=dist.ZSL.indexToLoc(i,indicesShape.length,dist.ZSL.computeStrides(indicesShape)).join(",");throw new Error(`indices[${locString}] = ${index} is not in [0, ${numParams})`)}})}(indices,indicesShape,paramsNestedSplitsShapes[0][0]-1),0===paramsDenseValuesShape.length)throw new Error("params.rank must be nonzero");const numParamsDenseValues=paramsDenseValuesShape[0],{outSplits,valueSlices,numValues}=makeSplits(indices,indicesShape,paramsNestedSplits,numParamsDenseValues),outputNestedSplits=function getSplits(outSplits){const splitsOut=[];for(let i=0;i<outSplits.length;++i){const numSplits=outSplits[i].length,splits=dist.ZSL.getArrayFromDType("int32",numSplits);splitsOut.push(splits),outSplits[i].forEach((value,j)=>splits[j]=value)}return splitsOut}(outSplits),outputDenseValues=getValues(paramsDenseValues,paramsDenseValuesShape,paramsDenseValuesDType,valueSlices,numValues);return[outputNestedSplits,outputDenseValues[0],outputDenseValues[1]]}const INT32_MAX=2147483647;function raggedRangeImpl(starts,startsShape,startsDType,limits,limitsShape,deltas,deltasShape){if(startsShape.length>1)throw new Error("starts must be a scalar or vector");if(limitsShape.length>1)throw new Error("limits must be a scalar or vector");if(deltasShape.length>1)throw new Error("deltas must be a scalar or vector");const broadcastStarts=0===startsShape.length,broadcastLimits=0===limitsShape.length,broadcastDeltas=0===deltasShape.length,inSizes=[];broadcastStarts||inSizes.push(startsShape[0]),broadcastLimits||inSizes.push(limitsShape[0]),broadcastDeltas||inSizes.push(deltasShape[0]);for(let i=1;i<inSizes.length;++i)if(inSizes[i]!==inSizes[i-1])throw new Error("starts, limits, and deltas must have the same shape");const nRows=0===inSizes.length?1:inSizes[0],rtNestedSplits=dist.ZSL.getArrayFromDType("int32",nRows+1);rtNestedSplits[0]=0;for(let row=0;row<nRows;++row){const start=broadcastStarts?starts[0]:starts[row],limit=broadcastLimits?limits[0]:limits[row],delta=broadcastDeltas?deltas[0]:deltas[row];if(0===delta)throw new Error("Requires delta != 0");let size;if(delta>0&&limit<start||delta<0&&limit>start)size=0;else if(size=Math.ceil(Math.abs((limit-start)/delta)),size>INT32_MAX)throw new Error(`Requires ((limit - start) / delta) <= ${INT32_MAX}`);rtNestedSplits[row+1]=rtNestedSplits[row]+size}const nVals=rtNestedSplits[nRows],rtDenseValues=dist.ZSL.getArrayFromDType(startsDType,nVals);let valueIndex=0;for(let row=0;row<nRows;++row){const rowSize=rtNestedSplits[row+1]-rtNestedSplits[row];let value=broadcastStarts?starts[0]:starts[row];const delta=broadcastDeltas?deltas[0]:deltas[row];for(let i=0;i<rowSize;++i)rtDenseValues[valueIndex++]=value,value+=delta}return[rtNestedSplits,rtDenseValues]}var RowPartitionType=dist.C0T.RowPartitionType;class RaggedTensorToTensorOp{constructor(shape,shapeShape,values,valuesShape,valuesDType,defaultValue,defaultValueShape,rowPartitionValues,rowPartitionValuesShapes,rowPartitionTypeStrings){this.shape=shape,this.shapeShape=shapeShape,this.values=values,this.valuesShape=valuesShape,this.valuesDType=valuesDType,this.defaultValue=defaultValue,this.defaultValueShape=defaultValueShape,this.rowPartitionValues=rowPartitionValues,this.rowPartitionValuesShapes=rowPartitionValuesShapes,this.rowPartitionTypes=dist.C0T.getRowPartitionTypesHelper(rowPartitionTypeStrings),this.raggedRank=dist.C0T.getRaggedRank(this.rowPartitionTypes)}getRowPartitionTypeByDimension(dimension){return this.rowPartitionTypes[0]===RowPartitionType.FIRST_DIM_SIZE?this.rowPartitionTypes[dimension+1]:this.rowPartitionTypes[dimension]}getRowPartitionTensor(dimension){return this.rowPartitionTypes[0]===RowPartitionType.FIRST_DIM_SIZE?this.rowPartitionValues[dimension+1]:this.rowPartitionValues[dimension]}getMaxWidth(dimension){const rowPartitionTensor=this.getRowPartitionTensor(dimension-1);switch(this.getRowPartitionTypeByDimension(dimension-1)){case RowPartitionType.VALUE_ROWIDS:return RaggedTensorToTensorOp.getMaxWidthValueRowID(rowPartitionTensor);case RowPartitionType.ROW_SPLITS:return RaggedTensorToTensorOp.getMaxWidthRowSplit(rowPartitionTensor);default:throw new Error(`Cannot handle partition type ${RowPartitionType[this.getRowPartitionTypeByDimension(dimension-1)]}`)}}static getMaxWidthRowSplit(rowSplit){const tensorLength=rowSplit.length;if(0===tensorLength||1===tensorLength)return 0;let maxWidth=0;for(let i=0;i<tensorLength-1;++i){const currentWidth=rowSplit[i+1]-rowSplit[i];currentWidth>maxWidth&&(maxWidth=currentWidth)}return maxWidth}static getMaxWidthValueRowID(valueRowIds){const indexLength=valueRowIds.length;if(0===indexLength)return 0;let firstEqualIndex=0,firstEqualIndexValue=valueRowIds[0],maxWidth=0;for(let i=1;i<indexLength;++i){const value=valueRowIds[i];value!==firstEqualIndexValue&&(firstEqualIndexValue=value,maxWidth=Math.max(i-firstEqualIndex,maxWidth),firstEqualIndex=i)}return Math.max(indexLength-firstEqualIndex,maxWidth)}tensorShapeFromTensor(t,tShape,isPartial=!0){if(0===tShape.length){if(-1===t[0])return[];throw new Error("The only valid scalar shape tensor is the fully unknown shape specified as -1.")}return makeShape(t,isPartial)}calculateOutputSize(firstDim){const valueShape=this.valuesShape,defaultValueShape=this.defaultValueShape;dist.C0T.validateDefaultValueShape(defaultValueShape,valueShape);const shape=this.tensorShapeFromTensor(this.shape,this.shapeShape),result=dist.C0T.combineRaggedTensorToTensorShapes(this.raggedRank,shape,valueShape);result[0]<0&&(result[0]=firstDim);for(let i=1;i<=this.raggedRank;++i)result[i]<0&&(result[i]=this.getMaxWidth(i));return result}calculateFirstParentOutputIndex(firstDimension,outputIndexMultiplier,firstDimensionOutput){const minDimension=Math.min(firstDimension,firstDimensionOutput),result=[];let currentOutputIndex=0;for(let i=0;i<minDimension;++i,currentOutputIndex+=outputIndexMultiplier)result.push(currentOutputIndex);for(let i=minDimension;i<firstDimension;++i)result.push(-1);return dist.ZSL.assert(result.length===firstDimension,()=>"Final length of result must be equal to firstDimension."),result}calculateOutputIndexRowSplit(rowSplit,parentOutputIndex,outputIndexMultiplier,outputSize){const rowSplitSize=rowSplit.length,result=[];for(let i=0;i<rowSplitSize-1;++i){const rowLength=rowSplit[i+1]-rowSplit[i];let realLength=Math.min(outputSize,rowLength),parentOutputIndexCurrent=parentOutputIndex[i];-1===parentOutputIndexCurrent&&(realLength=0);for(let j=0;j<realLength;++j)result.push(parentOutputIndexCurrent),parentOutputIndexCurrent+=outputIndexMultiplier;for(let j=0;j<rowLength-realLength;++j)result.push(-1)}if(rowSplitSize>0&&result.length!==rowSplit[rowSplitSize-1])throw new Error("Invalid row split size.");return result}calculateOutputIndexValueRowID(valueRowIds,parentOutputIndex,outputIndexMultiplier,outputSize){const indexSize=valueRowIds.length,result=[];if(0===indexSize)return[];let currentOutputColumn=0,currentValueRowId=valueRowIds[0];if(currentValueRowId>=parentOutputIndex.length)throw new Error(`Got currentValueRowId=${currentValueRowId}, which is not less than ${parentOutputIndex.length}`);let currentOutputIndex=parentOutputIndex[currentValueRowId];result.push(currentOutputIndex);for(let i=1;i<indexSize;++i){const nextValueRowId=valueRowIds[i];if(nextValueRowId===currentValueRowId)currentOutputIndex>=0&&(++currentOutputColumn,currentOutputColumn<outputSize?currentOutputIndex+=outputIndexMultiplier:currentOutputIndex=-1);else{if(currentOutputColumn=0,currentValueRowId=nextValueRowId,nextValueRowId>=parentOutputIndex.length)throw new Error(`Got nextValueRowId=${nextValueRowId} which is not less than ${parentOutputIndex.length}`);currentOutputIndex=parentOutputIndex[nextValueRowId]}result.push(currentOutputIndex)}if(result.length!==valueRowIds.length)throw new Error("Invalid row ids.");return result}calculateOutputIndex(dimension,parentOutputIndex,outputIndexMultiplier,outputSize){const rowPartitionTensor=this.getRowPartitionTensor(dimension),partitionType=this.getRowPartitionTypeByDimension(dimension);switch(partitionType){case RowPartitionType.VALUE_ROWIDS:return this.calculateOutputIndexValueRowID(rowPartitionTensor,parentOutputIndex,outputIndexMultiplier,outputSize);case RowPartitionType.ROW_SPLITS:if(rowPartitionTensor.length-1>parentOutputIndex.length)throw new Error(`Row partition size is greater than output size: ${rowPartitionTensor.length-1} > ${parentOutputIndex.length}`);return this.calculateOutputIndexRowSplit(rowPartitionTensor,parentOutputIndex,outputIndexMultiplier,outputSize);default:throw new Error(`Unsupported partition type: ${RowPartitionType[partitionType]}`)}}getFirstDimensionSize(){const firstPartitionTensor=this.rowPartitionValues[0];if(0===this.rowPartitionTypes.length)throw new Error("No row_partition_types given.");const firstPartitionType=this.rowPartitionTypes[0];switch(firstPartitionType){case RowPartitionType.FIRST_DIM_SIZE:return firstPartitionTensor[0];case RowPartitionType.VALUE_ROWIDS:throw new Error("Cannot handle VALUE_ROWIDS in first dimension.");case RowPartitionType.ROW_SPLITS:return this.rowPartitionValuesShapes[0][0]-1;default:throw new Error(`Cannot handle type ${RowPartitionType[firstPartitionType]}`)}}compute(){if(this.rowPartitionValues[0].length<=0)throw new Error("Invalid first partition input. Tensor requires at least one element.");const firstDimension=this.getFirstDimensionSize(),outputSize=this.calculateOutputSize(firstDimension),multiplier=new Array(this.raggedRank+1);multiplier[multiplier.length-1]=1;for(let i=multiplier.length-2;i>=0;--i)multiplier[i]=multiplier[i+1]*outputSize[i+1];const outputShape=makeShape(outputSize,!1),outputTensor=dist.ZSL.getArrayFromDType(this.valuesDType,dist.ZSL.sizeFromShape(outputShape));if(multiplier[0]*outputSize[0]>0){let outputIndex=this.calculateFirstParentOutputIndex(firstDimension,multiplier[0],outputSize[0]);for(let i=1;i<=this.raggedRank;++i){outputIndex=this.calculateOutputIndex(i-1,outputIndex,multiplier[i],outputSize[i])}this.setOutput(this.raggedRank,outputIndex,outputTensor,outputShape)}return[outputShape,outputTensor]}setOutput(raggedRank,outputIndex,outputTensor,outputShape){if(0===outputTensor.length)return;const valuesBase=this.values,outputBase=outputTensor;let elementShape=outputShape.slice();elementShape=elementShape.slice(raggedRank+1);const valueElementSize=dist.ZSL.sizeFromShape(elementShape),outputIndexSize=outputIndex.length;let defaultValue=this.defaultValue;if(defaultValue.length!==valueElementSize&&1!==defaultValue.length){const srcShape=this.defaultValueShape;(0,dist.DZQ)(()=>{const defaultValueTensor=(0,dist.tQQ)(defaultValue,srcShape),bCastDefault=(0,dist.hOW)(defaultValueTensor,elementShape);defaultValue=bCastDefault.dataSync()})}let srcStart=0,dstStart=0,dstEnd=0;for(let srcI=0;srcI<=outputIndexSize;++srcI){let dstI=srcI<outputIndexSize?outputIndex[srcI]:-1;if(dstI!==dstEnd){if(dstStart<dstEnd){const src=valuesBase.subarray(srcStart*valueElementSize);copyArray(outputBase.subarray(dstStart*valueElementSize),src,(dstEnd-dstStart)*valueElementSize)}if(srcI>=outputIndexSize){const outputSize=outputTensor.length;dstI=Math.floor(outputSize/valueElementSize)}if(dstI>dstEnd)if(1===this.defaultValue.length)outputBase.subarray(dstEnd*valueElementSize,dstI*valueElementSize).fill(this.defaultValue[0]),dstEnd=dstI;else for(;dstI>dstEnd;){copyArray(outputBase.slice(dstEnd*valueElementSize),defaultValue,valueElementSize),++dstEnd}dstI<0?(srcStart=srcI+1,dstStart=dstEnd):(srcStart=srcI,dstStart=dstEnd,dstEnd=dstStart+1)}else++dstEnd}}}function copyArray(dst,src,size){for(let i=0;i<size;i++)dst[i]=src[i]}function makeShape(shape,isPartial){const out=[];for(let dim of shape){if(dim<0){if(!isPartial)throw new Error(`Dimension ${dim} must be >= 0`);if(dim<-1)throw new Error(`Dimension ${dim} must be >= -1`);dim=-1}out.push(dim)}return out}function raggedTensorToTensorImpl(shape,shapesShape,values,valuesShape,valuesDType,defaultValue,defaultValueShape,rowPartitionValues,rowPartitionValuesShapes,rowPartitionTypes){return new RaggedTensorToTensorOp(shape,shapesShape,values,valuesShape,valuesDType,defaultValue,defaultValueShape,rowPartitionValues,rowPartitionValuesShapes,rowPartitionTypes).compute()}var Range_impl=__webpack_require__("./node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Range_impl.js");const rsqrtImpl=createSimpleUnaryImpl(xi=>1/Math.sqrt(xi)),Rsqrt_rsqrt=unaryKernelFuncFromImpl(dist.TOR,rsqrtImpl),rsqrtConfig={kernelName:dist.TOR,backendName:"cpu",kernelFunc:Rsqrt_rsqrt};function scatterImpl(indices,updates,shape,outputSize,sliceSize,numUpdates,sliceRank,strides,defaultValue,sumDupeIndices){const flattenShape=[outputSize/sliceSize,sliceSize],indicesData=indices.values,updatesData=updates.values;if(0===outputSize)return(0,dist.ra8)(shape,updates.dtype);const outBuf=defaultValue instanceof dist.ylz?defaultValue:(0,dist.ra8)(flattenShape,updates.dtype);"string"==typeof defaultValue||"number"==typeof defaultValue?outBuf.values.fill(defaultValue):"boolean"==typeof defaultValue&&outBuf.values.fill(+defaultValue);for(let i=0;i<numUpdates;i++){const index=[];let flattenIndex=0;for(let j=0;j<sliceRank;j++){const dim=indicesData[i*sliceRank+j];index.push(dim),flattenIndex+=dim*strides[j]}if(flattenIndex<0||flattenIndex>=outputSize/sliceSize)throw new Error(`Invalid indices: ${index} does not index into ${shape}`);for(let k=0;k<sliceSize;k++)sumDupeIndices?outBuf.values[flattenIndex*sliceSize+k]+=updatesData[i*sliceSize+k]:outBuf.values[flattenIndex*sliceSize+k]=0===updates.rank?updatesData[0]:updatesData[i*sliceSize+k]}return outBuf}const sigmoidImpl=createSimpleUnaryImpl(xi=>1/(1+Math.exp(-xi))),Sigmoid_sigmoid=unaryKernelFunc(dist.vI1,xi=>1/(1+Math.exp(-xi))),sigmoidConfig={kernelName:dist.vI1,backendName:"cpu",kernelFunc:Sigmoid_sigmoid};var Slice=__webpack_require__("./node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Slice.js");function sparseFillEmptyRowsImpl(indices,indicesShape,indicesDType,values,valuesDType,denseShape,defaultValue){const indicesCount=indicesShape[0],denseRows=denseShape[0],emptyRowIndicator=new Array(denseRows),reverseIndexMap=new Array(indicesCount),rank=indicesShape[1];if(0===denseRows){if(0!==indicesCount)throw new Error(dist.C0T.getSparseFillEmptyRowsIndicesDenseShapeMismatch(indicesCount));return[dist.ZSL.getArrayFromDType(indicesDType,0),[0,rank],dist.ZSL.getArrayFromDType(valuesDType,0),emptyRowIndicator,reverseIndexMap]}let rowsAreOrdered=!0,lastIndicesRow=0;const csrOffset=new Array(denseRows).fill(0);for(let i=0;i<indicesCount;++i){const row=indices[i*rank];if(row<0)throw new Error(dist.C0T.getSparseFillEmptyRowsNegativeIndexErrorMessage(i,row));if(row>=denseRows)throw new Error(dist.C0T.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(i,row,denseRows));++csrOffset[row],rowsAreOrdered=rowsAreOrdered&&row>=lastIndicesRow,lastIndicesRow=row}let allRowsFull=!0;for(let row=0;row<denseRows;++row){const rowEmpty=0===csrOffset[row];emptyRowIndicator[row]=rowEmpty,allRowsFull=allRowsFull&&!rowEmpty,csrOffset[row]=Math.max(csrOffset[row],1),row>0&&(csrOffset[row]+=csrOffset[row-1])}if(allRowsFull&&rowsAreOrdered){const outputIndices=indices,outputValues=values;for(let i=0;i<indicesCount;++i)reverseIndexMap[i]=i;return[outputIndices,[indicesCount,rank],outputValues,emptyRowIndicator,reverseIndexMap]}{const fullIndicesCount=csrOffset[denseRows-1],outputIndices=dist.ZSL.getArrayFromDType(indicesDType,fullIndicesCount*rank),outputValues=dist.ZSL.getArrayFromDType(valuesDType,fullIndicesCount),filledCount=new Array(denseRows).fill(0);for(let i=0;i<indicesCount;++i){const row=indices[i*rank],offset=filledCount[row],outputI=(0===row?0:csrOffset[row-1])+offset;filledCount[row]++;for(let j=0;j<rank;++j)outputIndices[outputI*rank+j]=indices[i*rank+j];outputValues[outputI]=values[i],reverseIndexMap[i]=outputI}for(let row=0;row<denseRows;++row){if(0===filledCount[row]){const startingIndex=0===row?0:csrOffset[row-1];outputIndices[startingIndex*rank+0]=row;for(let col=1;col<rank;++col)outputIndices[startingIndex*rank+col]=0;outputValues[startingIndex]=defaultValue}}return[outputIndices,[fullIndicesCount,rank],outputValues,emptyRowIndicator,reverseIndexMap]}}function sparseReshapeImpl(inputIndices,inputIndicesShape,inputDType,inputShape,targetShape){const denseSize=dist.ZSL.sizeFromShape(inputShape),nnz=inputIndicesShape[0],outputRank=targetShape.length,outputShape=[];let product=1,unknownIndex=-1;for(let d=0;d<outputRank;++d){const size=targetShape[d];if(-1===size){if(-1!==unknownIndex)throw new Error(dist.C0T.getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(unknownIndex,d));unknownIndex=d,outputShape.push(1)}else{if(size<0)throw new Error(dist.C0T.getSparseReshapeNegativeOutputDimErrorMessage(d,size));product*=size,outputShape.push(size)}}if(-1!==unknownIndex){if(product<=0)throw new Error(dist.C0T.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());const missing=Math.trunc(denseSize/product);if(product*missing!==denseSize)throw new Error(dist.C0T.getSparseReshapeInputOutputMultipleErrorMessage(inputShape,outputShape));outputShape[unknownIndex]=missing}if(dist.ZSL.sizeFromShape(outputShape)!==denseSize)throw new Error(dist.C0T.getSparseReshapeInputOutputMismatchErrorMessage(inputShape,outputShape));const inputRank=inputShape.length,inputStrides=[];if(inputRank>0){inputStrides[inputRank-1]=1;for(let d=inputRank-2;d>=0;--d)inputStrides[d]=inputStrides[d+1]*inputShape[d+1]}const outputStrides=[];if(outputRank>0){outputStrides[outputRank-1]=1;for(let d=outputRank-2;d>=0;--d)outputStrides[d]=outputStrides[d+1]*outputShape[d+1]}const newIndices=dist.ZSL.getArrayFromDType(inputDType,nnz*outputRank);for(let i=0;i<nnz;++i){let id=0;for(let j=0;j<inputRank;++j)id+=inputIndices[i*inputRank+j]*inputStrides[j];for(let j=0;j<outputRank;++j)newIndices[i*outputRank+j]=Math.trunc(id/outputStrides[j]),id%=outputStrides[j]}return[newIndices,[nnz,outputRank],outputShape]}function sparseSegmentReductionImpl(input,inputShape,inputDType,indices,segmentIds,isMean=!1,defaultValue=0){const numIndices=indices.length,inputFlat=[inputShape[0],input.length/inputShape[0]],numCol=inputFlat[1],outputRows=numIndices>0?segmentIds[numIndices-1]+1:0;if(outputRows<0)throw new Error(dist.C0T.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());const outputShape=inputShape.slice();outputShape[0]=outputRows;const outputLength=outputShape.reduce((product,value)=>product*value,1),output=dist.ZSL.getArrayFromDType(inputDType,outputLength);if(0===numIndices)return outputRows>0&&output.fill(defaultValue),[output,outputShape];if(outputRows<=0)throw new Error(dist.C0T.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());let start=0,end=1,uninitializedIndex=0,outIndex=segmentIds[start];for(;;){let nextIndex=0;if(end<numIndices){if(nextIndex=segmentIds[end],outIndex===nextIndex){++end;continue}if(outIndex>=nextIndex)throw new Error(dist.C0T.getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage())}if(outIndex<0||outIndex>=outputRows)throw new Error(dist.C0T.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(outIndex,outputRows));outIndex>uninitializedIndex&&output.fill(defaultValue,uninitializedIndex*numCol,outIndex*numCol);for(let i=start;i<end;++i){const index=indices[i];if(index<0||index>=inputFlat[0])throw new Error(dist.C0T.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(i,indices[i],inputFlat[0]));for(let j=0;j<numCol;j++)output[outIndex*numCol+j]+=input[index*numCol+j]}if(isMean)for(let j=0;j<numCol;j++)output[outIndex*numCol+j]/=end-start;if(start=end,++end,uninitializedIndex=outIndex+1,outIndex=nextIndex,end>numIndices)break}return uninitializedIndex<outputRows&&output.fill(defaultValue,uninitializedIndex*numCol,outputRows*numCol),[output,outputShape]}const sqrtImpl=createSimpleUnaryImpl(xi=>Math.sqrt(xi)),Sqrt_sqrt=unaryKernelFunc(dist.dFH,xi=>Math.sqrt(xi)),sqrtConfig={kernelName:dist.dFH,backendName:"cpu",kernelFunc:Sqrt_sqrt},squaredDifferenceImpl=createSimpleBinaryKernelImpl((a,b)=>{const diff=a-b;return diff*diff}),squaredDifference=binaryKernelFunc(dist.Ddj,squaredDifferenceImpl),squaredDifferenceConfig={kernelName:dist.Ddj,backendName:"cpu",kernelFunc:squaredDifference},staticRegexReplaceImpl=createSimpleUnaryImpl((x,attrs)=>{const{pattern,replaceGlobal,rewrite}=attrs;return x.replace(new RegExp(pattern,replaceGlobal?"g":""),rewrite)}),staticRegexReplace=unaryKernelFuncFromImpl(dist.GZp,staticRegexReplaceImpl),staticRegexReplaceConfig={kernelName:dist.GZp,backendName:"cpu",kernelFunc:staticRegexReplace};function stridedSliceImpl(outShape,xBuf,strides,begin){const outBuf=(0,dist.ra8)(outShape,xBuf.dtype);for(let i=0;i<outBuf.size;i++){const loc=outBuf.indexToLoc(i),newLoc=new Array(loc.length);for(let j=0;j<newLoc.length;j++)newLoc[j]=loc[j]*strides[j]+begin[j];outBuf.set(xBuf.get(...newLoc),...loc)}return outBuf}var StringNGrams_impl=__webpack_require__("./node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams_impl.js"),StringSplit_impl=__webpack_require__("./node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit_impl.js"),StringToHashBucketFast_impl=__webpack_require__("./node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast_impl.js");const subImpl=createSimpleBinaryKernelImpl((aValue,bValue)=>aValue-bValue),subComplexImpl=createComplexBinaryKernelImpl((aReal,aImag,bReal,bImag)=>({real:aReal-bReal,imag:aImag-bImag})),Sub_sub=binaryKernelFunc(dist.PbM,subImpl,subComplexImpl),subConfig={kernelName:dist.PbM,backendName:"cpu",kernelFunc:Sub_sub};function tileImpl(xBuf,reps){const newShape=new Array(xBuf.rank);for(let i=0;i<newShape.length;i++)newShape[i]=xBuf.shape[i]*reps[i];const result=(0,dist.ra8)(newShape,xBuf.dtype);for(let i=0;i<result.values.length;++i){const newLoc=result.indexToLoc(i),originalLoc=new Array(xBuf.rank);for(let j=0;j<originalLoc.length;j++)originalLoc[j]=newLoc[j]%xBuf.shape[j];const originalIndex=xBuf.locToIndex(originalLoc);result.values[i]=xBuf.values[originalIndex]}return result}const comparePair=(a,b)=>{const valueDiff=b.value-a.value;return 0===valueDiff?a.index-b.index:valueDiff};function TopK_impl_select(array,k,left=0,right=array.length-1){for(;right>left;){if(right-left>600){const n=right-left+1,i=k-left+1,z=Math.log(n),s=.5*Math.exp(2*z/3),sd=.5*Math.sqrt(z*s*(n-s)/n)*Math.sign(i-n/2);TopK_impl_select(array,k,Math.max(left,Math.floor(k-i*s/n+sd)),Math.min(right,Math.floor(k+(n-i)*s/n+sd)))}const t=array[k];let i=left,j=right;for(dist.ZSL.swap(array,left,k),comparePair(array[right],t)>0&&dist.ZSL.swap(array,left,right);i<j;){for(dist.ZSL.swap(array,i,j),i++,j--;comparePair(array[i],t)<0;)i+=1;for(;comparePair(array[j],t)>0;)j-=1}0===comparePair(array[left],t)?dist.ZSL.swap(array,left,j):(j+=1,dist.ZSL.swap(array,j,right)),j<=k&&(left=j+1),k<=j&&(right=j-1)}}function topKImpl(x,xShape,xDtype,k,sorted){const lastDim=xShape[xShape.length-1],[batch,size]=[x.length/lastDim,lastDim],allTopKVals=dist.ZSL.getTypedArrayFromDType(xDtype,batch*k),allTopKIndices=dist.ZSL.getTypedArrayFromDType("int32",batch*k);for(let b=0;b<batch;b++){const offset=b*size,vals=x.subarray(offset,offset+size);let valAndInd=new Array(vals.length);vals.forEach((value,index)=>valAndInd[index]={value,index}),k<valAndInd.length&&(TopK_impl_select(valAndInd,k),valAndInd=valAndInd.slice(0,k)),sorted&&valAndInd.sort(comparePair);const outOffset=b*k,topKVals=allTopKVals.subarray(outOffset,outOffset+k),topKIndices=allTopKIndices.subarray(outOffset,outOffset+k);for(let i=0;i<k;i++)topKVals[i]=valAndInd[i].value,topKIndices[i]=valAndInd[i].index}const outputShape=xShape.slice();return outputShape[outputShape.length-1]=k,[(0,dist.ra8)(outputShape,xDtype,allTopKVals),(0,dist.ra8)(outputShape,"int32",allTopKIndices)]}var Unique_impl=__webpack_require__("./node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unique_impl.js");const tfjs_backend_cpu_dist_version_version="4.22.0";(0,dist.gJX)("cpu",()=>new MathBackendCPU,1);const Elu_elu=unaryKernelFunc(dist.Pah,xi=>xi>=0?xi:Math.exp(xi)-1),eluConfig={kernelName:dist.Pah,backendName:"cpu",kernelFunc:Elu_elu};function leakyRelu(args){const{inputs,backend,attrs}=args,{x}=inputs,{alpha}=attrs;(0,cpu_util.C)([x],"leakyRelu");const xSize=dist.ZSL.sizeFromShape(x.shape),xVals=backend.data.get(x.dataId).values,outVals=dist.ZSL.getTypedArrayFromDType("float32",xSize);for(let i=0;i<xVals.length;i++)outVals[i]=xVals[i]<0?alpha*xVals[i]:xVals[i];return backend.makeTensorInfo(x.shape,"float32",outVals)}const leakyReluConfig={kernelName:dist.X0$,backendName:"cpu",kernelFunc:leakyRelu},preluImpl=createSimpleBinaryKernelImpl((xValue,aValue)=>xValue<0?aValue*xValue:xValue);function Prelu_prelu(args){const{inputs,backend}=args,{x,alpha}=inputs;(0,cpu_util.C)([x,alpha],"prelu");const aVals=backend.data.get(x.dataId).values,bVals=backend.data.get(alpha.dataId).values,[resultData,resultShape]=preluImpl(x.shape,alpha.shape,aVals,bVals,"float32");return backend.makeTensorInfo(resultShape,"float32",resultData)}const preluConfig={kernelName:dist.Ncv,backendName:"cpu",kernelFunc:Prelu_prelu},Relu_relu=unaryKernelFunc(dist.fUj,xi=>Math.max(0,xi)),reluConfig={kernelName:dist.fUj,backendName:"cpu",kernelFunc:Relu_relu},Relu6_relu6=unaryKernelFunc(dist.P_L,xi=>Math.min(Math.max(0,xi),6)),relu6Config={kernelName:dist.P_L,backendName:"cpu",kernelFunc:Relu6_relu6};function applyActivation(backend,x,activation,preluActivationWeights,leakyreluAlpha){if("linear"===activation)return Identity_identity({inputs:{x},backend});if("relu"===activation)return Relu_relu({inputs:{x},backend});if("elu"===activation)return Elu_elu({inputs:{x},backend});if("relu6"===activation)return Relu6_relu6({inputs:{x},backend});if("prelu"===activation)return Prelu_prelu({inputs:{x,alpha:preluActivationWeights},backend});if("leakyrelu"===activation)return leakyRelu({inputs:{x},backend,attrs:{alpha:leakyreluAlpha}});if("sigmoid"===activation)return Sigmoid_sigmoid({inputs:{x},backend});throw new Error(`Activation ${activation} has not been implemented for the CPU backend.`)}function Reshape_reshape(args){const{inputs,backend,attrs}=args,{x}=inputs,{shape}=attrs,xSize=dist.ZSL.sizeFromShape(x.shape),$shape=dist.ZSL.inferFromImplicitShape(shape,xSize),$xSize=dist.ZSL.sizeFromShape($shape);dist.ZSL.assert(xSize===$xSize,()=>`The new shape (${$shape}) has ${$xSize} elements and the old shape (${x.shape}) has ${xSize} elements. The new shape and old shape must have the same number of elements.`),backend.incRef(x.dataId);const xData=backend.data.get(x.dataId);if(null!=xData.complexTensorInfos){const real=xData.complexTensorInfos.real,imag=xData.complexTensorInfos.imag;real.shape=$shape,imag.shape=$shape}return{dataId:x.dataId,shape:$shape,dtype:x.dtype}}const reshapeConfig={kernelName:dist.R23,backendName:"cpu",kernelFunc:Reshape_reshape};function batchMatMul(args){const{inputs,backend,attrs}=args,{a,b}=inputs,{transposeA,transposeB}=attrs;(0,cpu_util.C)([a,b],"matMul");const aRank=a.shape.length,bRank=b.shape.length,innerShapeA=transposeA?a.shape[aRank-2]:a.shape[aRank-1],innerShapeB=transposeB?b.shape[bRank-1]:b.shape[bRank-2],outerShapeA=transposeA?a.shape[aRank-1]:a.shape[aRank-2],outerShapeB=transposeB?b.shape[bRank-2]:b.shape[bRank-1],outerDimsA=a.shape.slice(0,-2),outerDimsB=b.shape.slice(0,-2),batchDimA=dist.ZSL.sizeFromShape(outerDimsA),batchDimB=dist.ZSL.sizeFromShape(outerDimsB),outShape=dist.ZEY.assertAndGetBroadcastShape(a.shape.slice(0,-2),b.shape.slice(0,-2)).concat([outerShapeA,outerShapeB]);dist.ZSL.assert(innerShapeA===innerShapeB,()=>`Error in matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${a.shape} and ${b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);const b3dShape=transposeB?[batchDimB,outerShapeB,innerShapeB]:[batchDimB,innerShapeB,outerShapeB],a3d=Reshape_reshape({inputs:{x:a},backend,attrs:{shape:transposeA?[batchDimA,innerShapeA,outerShapeA]:[batchDimA,outerShapeA,innerShapeA]}}),b3d=Reshape_reshape({inputs:{x:b},backend,attrs:{shape:b3dShape}}),sharedDim=transposeA?a3d.shape[1]:a3d.shape[2],leftDim=transposeA?a3d.shape[2]:a3d.shape[1],rightDim=transposeB?b3d.shape[1]:b3d.shape[2],batchDim=Math.max(batchDimA,batchDimB),a3dValues=backend.data.get(a3d.dataId).values,b3dValues=backend.data.get(b3d.dataId).values,a3dStrides=dist.ZSL.computeStrides(a3d.shape),b3dStrides=dist.ZSL.computeStrides(b3d.shape),[aBatch,aOuterStep,aInnerStep]=transposeA?[a3dStrides[0],1,a3dStrides[1]]:[a3dStrides[0],a3dStrides[1],1],[bInnerStep,bOuterStep,bBatch]=transposeB?[1,b3dStrides[1],b3dStrides[0]]:[b3dStrides[1],1,b3dStrides[0]],size=leftDim*rightDim,result=(0,dist.ra8)([batchDim,leftDim,rightDim],a3d.dtype),resVals=result.values,blockSize=backend.blockSize;for(let bi=0;bi<batchDim;bi++){const batchIndexA=bi%batchDimA,batchIndexB=bi%batchDimB;for(let i0=0;i0<leftDim;i0+=blockSize){const iBlock=Math.min(i0+blockSize,leftDim);for(let j0=0;j0<rightDim;j0+=blockSize){const jBlock=Math.min(j0+blockSize,rightDim);for(let k0=0;k0<sharedDim;k0+=blockSize){const kBlock=Math.min(k0+blockSize,sharedDim);for(let i=i0;i<iBlock;i++)for(let j=j0;j<jBlock;j++){let sum=0;for(let k=k0;k<kBlock;k++){sum+=a3dValues[batchIndexA*aBatch+i*aOuterStep+k*aInnerStep]*b3dValues[k*bInnerStep+j*bOuterStep+batchIndexB*bBatch]}resVals[bi*size+(i*rightDim+j)]+=sum}}}}}return backend.disposeIntermediateTensorInfo(a3d),backend.disposeIntermediateTensorInfo(b3d),backend.makeTensorInfo(outShape,result.dtype,result.values)}const batchMatMulConfig={kernelName:dist.jAQ,backendName:"cpu",kernelFunc:batchMatMul};const _fusedMatMulConfig={kernelName:dist.Dr,backendName:"cpu",kernelFunc:function _fusedMatMul(args){const{inputs,backend,attrs}=args,{a,b,bias,preluActivationWeights}=inputs,{transposeA,transposeB,activation,leakyreluAlpha}=attrs;let current,addRes,activationRes;const intermediates=[];current=batchMatMul({inputs:{a,b},attrs:{transposeA,transposeB},backend}),bias&&(addRes=Add_add({inputs:{a:current,b:bias},backend}),intermediates.push(current),current=addRes),activation&&(activationRes=applyActivation(backend,current,activation,preluActivationWeights,leakyreluAlpha),intermediates.push(current),current=activationRes);for(const i of intermediates)backend.disposeIntermediateTensorInfo(i);return current}},Acos_acos=unaryKernelFunc(dist.Vvy,xi=>Math.acos(xi)),acosConfig={kernelName:dist.Vvy,backendName:"cpu",kernelFunc:Acos_acos},Acosh_acosh=unaryKernelFunc(dist.PH8,xi=>Math.acosh(xi)),acoshConfig={kernelName:dist.PH8,backendName:"cpu",kernelFunc:Acosh_acosh};const addNConfig={kernelName:dist.EkD,backendName:"cpu",kernelFunc:function addN(args){const{inputs,backend}=args,tensors=inputs;(0,cpu_util.C)(inputs,"addN");const vals=tensors.map(t=>backend.data.get(t.dataId).values),outBuf=(0,dist.ra8)(tensors[0].shape,tensors[0].dtype),outVals=outBuf.values;for(let i=0;i<tensors.length;i++){const currVals=vals[i];for(let j=0;j<outVals.length;j++)outVals[j]+=currVals[j]}return backend.makeTensorInfo(outBuf.shape,outBuf.dtype,outBuf.values)}};const allConfig={kernelName:dist.u8Z,backendName:"cpu",kernelFunc:function All_all(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,keepDims}=attrs;(0,cpu_util.C)(x,"all");const origAxes=dist.ZSL.parseAxisParam(axis,x.shape);let axes=origAxes;const permutedAxes=dist.C0T.getAxesPermutation(axes,x.shape.length);let $x=x;null!=permutedAxes&&($x=Transpose_transpose({inputs:{x},backend,attrs:{perm:permutedAxes}}),axes=dist.C0T.getInnerMostAxes(axes.length,x.shape.length)),dist.C0T.assertAxesAreInnerMostDims("all",axes,$x.shape.length);const[outShape,reduceShape]=dist.C0T.computeOutAndReduceShapes($x.shape,axes),reduceSize=dist.ZSL.sizeFromShape(reduceShape),vals=dist.ZSL.makeZerosTypedArray(dist.ZSL.sizeFromShape(outShape),$x.dtype),aVals=backend.data.get($x.dataId).values;for(let i=0;i<vals.length;++i){const offset=i*reduceSize;let all=aVals[offset];for(let j=0;j<reduceSize;++j){const value=aVals[offset+j];all=all&&value}vals[i]=all}null!=permutedAxes&&backend.disposeIntermediateTensorInfo($x);const result=backend.makeTensorInfo(outShape,$x.dtype,vals);if(keepDims){const reshapedResult=Reshape_reshape({inputs:{x:result},backend,attrs:{shape:dist.C0T.expandShapeToKeepDim(outShape,origAxes)}});return backend.disposeIntermediateTensorInfo(result),reshapedResult}return result}};const anyConfig={kernelName:dist.FSt,backendName:"cpu",kernelFunc:function Any_any(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,keepDims}=attrs;(0,cpu_util.C)(x,"any");const origAxes=dist.ZSL.parseAxisParam(axis,x.shape);let axes=origAxes;const permutedAxes=dist.C0T.getAxesPermutation(axes,x.shape.length);let $x=x;null!=permutedAxes&&($x=Transpose_transpose({inputs:{x},backend,attrs:{perm:permutedAxes}}),axes=dist.C0T.getInnerMostAxes(axes.length,x.shape.length)),dist.C0T.assertAxesAreInnerMostDims("any",axes,$x.shape.length);const[outShape,reduceShape]=dist.C0T.computeOutAndReduceShapes($x.shape,axes),reduceSize=dist.ZSL.sizeFromShape(reduceShape),vals=dist.ZSL.makeZerosTypedArray(dist.ZSL.sizeFromShape(outShape),$x.dtype),aVals=backend.data.get($x.dataId).values;for(let i=0;i<vals.length;++i){const offset=i*reduceSize;let anyVal=aVals[offset];for(let j=0;j<reduceSize;++j){const value=aVals[offset+j];anyVal=anyVal||value}vals[i]=anyVal}null!=permutedAxes&&backend.disposeIntermediateTensorInfo($x);const result=backend.makeTensorInfo(outShape,$x.dtype,vals);if(keepDims){const reshapedResult=Reshape_reshape({inputs:{x:result},backend,attrs:{shape:dist.C0T.expandShapeToKeepDim(outShape,origAxes)}});return backend.disposeIntermediateTensorInfo(result),reshapedResult}return result}};const argMaxConfig={kernelName:dist.Jp_,backendName:"cpu",kernelFunc:function argMax(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis}=attrs;(0,cpu_util.C)(x,"argMax");let axes=dist.ZSL.parseAxisParam(axis,x.shape);const permutedAxes=dist.C0T.getAxesPermutation(axes,x.shape.length);let $x=x;const intermediateTensorInfos=[];null!=permutedAxes&&($x=Transpose_transpose({inputs:{x},backend,attrs:{perm:permutedAxes}}),intermediateTensorInfos.push($x),axes=dist.C0T.getInnerMostAxes(axes.length,$x.shape.length)),axes=[axes[0]],dist.C0T.assertAxesAreInnerMostDims("argMax",axes,$x.shape.length);const[outShape,reduceShape]=dist.C0T.computeOutAndReduceShapes($x.shape,axes),outSize=dist.ZSL.sizeFromShape(outShape),vals=dist.ZSL.makeZerosTypedArray(outSize,"int32"),reduceSize=dist.ZSL.sizeFromShape(reduceShape),aVals=backend.data.get($x.dataId).values;for(let i=0;i<vals.length;++i){const offset=i*reduceSize;let max=aVals[offset],maxIndex=0;for(let j=0;j<reduceSize;++j){const value=aVals[offset+j];value>max&&(max=value,maxIndex=j)}vals[i]=maxIndex}return intermediateTensorInfos.forEach(t=>backend.disposeIntermediateTensorInfo(t)),backend.makeTensorInfo(outShape,"int32",vals)}};const argMinConfig={kernelName:dist.p_m,backendName:"cpu",kernelFunc:function argMin(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis}=attrs;(0,cpu_util.C)(x,"argMin");let axes=dist.ZSL.parseAxisParam(axis,x.shape);const permutedAxes=dist.C0T.getAxesPermutation(axes,x.shape.length);let $x=x;const intermediateTensorInfos=[];null!=permutedAxes&&($x=Transpose_transpose({inputs:{x},backend,attrs:{perm:permutedAxes}}),intermediateTensorInfos.push($x),axes=dist.C0T.getInnerMostAxes(axes.length,$x.shape.length)),axes=[axes[0]],dist.C0T.assertAxesAreInnerMostDims("argMin",axes,$x.shape.length);const[outShape,reduceShape]=dist.C0T.computeOutAndReduceShapes($x.shape,axes),outSize=dist.ZSL.sizeFromShape(outShape),vals=dist.ZSL.makeZerosTypedArray(outSize,"int32"),reduceSize=dist.ZSL.sizeFromShape(reduceShape),aVals=backend.data.get($x.dataId).values;for(let i=0;i<vals.length;++i){const offset=i*reduceSize;let min=aVals[offset],minIndex=0;for(let j=0;j<reduceSize;++j){const value=aVals[offset+j];value<min&&(min=value,minIndex=j)}vals[i]=minIndex}return intermediateTensorInfos.forEach(t=>backend.disposeIntermediateTensorInfo(t)),backend.makeTensorInfo(outShape,"int32",vals)}},Asin_asin=unaryKernelFunc(dist.QKF,xi=>Math.asin(xi)),asinConfig={kernelName:dist.QKF,backendName:"cpu",kernelFunc:Asin_asin},Asinh_asinh=unaryKernelFunc(dist.epO,xi=>Math.asinh(xi)),asinhConfig={kernelName:dist.epO,backendName:"cpu",kernelFunc:Asinh_asinh},Atan_atan=unaryKernelFunc(dist.TyE,xi=>Math.atan(xi)),atanConfig={kernelName:dist.TyE,backendName:"cpu",kernelFunc:Atan_atan},atan2Impl=createSimpleBinaryKernelImpl((aValue,bValue)=>Math.atan2(aValue,bValue)),Atan2_atan2=binaryKernelFunc(dist.lxb,atan2Impl),atan2Config={kernelName:dist.lxb,backendName:"cpu",kernelFunc:Atan2_atan2},Atanh_atanh=unaryKernelFunc(dist.zP9,xi=>Math.atanh(xi)),atanhConfig={kernelName:dist.zP9,backendName:"cpu",kernelFunc:Atanh_atanh};function pool_utils_pool(xValues,xShape,dtype,strides,convInfo,poolType){const strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padTop=convInfo.padInfo.top,padLeft=convInfo.padInfo.left,initialValue="max"===poolType?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,output=(0,dist.ra8)(convInfo.outShape,dtype),outputVals=output.values,outputBatchStrides=convInfo.outShape[1]*convInfo.outShape[2]*convInfo.outShape[3],outputRowStrides=convInfo.outShape[2]*convInfo.outShape[3],outputColStrides=convInfo.outShape[3];for(let b=0;b<convInfo.batchSize;++b){const outputBatchOffset=b*outputBatchStrides,inputBatchOffset=b*strides[0];for(let d=0;d<convInfo.inChannels;++d)for(let yR=0;yR<convInfo.outHeight;++yR){const xRCorner=yR*strideHeight-padTop,xRMin=Math.max(0,xRCorner),xRMax=Math.min(convInfo.inHeight,effectiveFilterHeight+xRCorner),outputRowOffset=outputBatchOffset+yR*outputRowStrides;for(let yC=0;yC<convInfo.outWidth;++yC){const xCCorner=yC*strideWidth-padLeft,xCMin=Math.max(0,xCCorner),xCMax=Math.min(convInfo.inWidth,effectiveFilterWidth+xCCorner);let minMaxValue=initialValue,avgValue=0,count=0;for(let xR=xRMin;xR<xRMax;xR+=dilationHeight){const xROffset=inputBatchOffset+xR*strides[1];for(let xC=xCMin;xC<xCMax;xC+=dilationWidth){const pixel=xValues[xROffset+xC*strides[2]+d];"max"===poolType&&pixel>minMaxValue?minMaxValue=pixel:"avg"===poolType&&(avgValue+=pixel,count++)}if(isNaN(minMaxValue))break}outputVals[outputRowOffset+yC*outputColStrides+d]="avg"===poolType?avgValue/count:minMaxValue}}}return output}function maxPoolPositions(xValues,xShape,dtype,convInfo,flattenPositions=!1,includeBatchInIndex=!1){const maxPositions=(0,dist.ra8)(convInfo.outShape,"int32"),strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padTop=convInfo.padInfo.top,padLeft=convInfo.padInfo.left,xBuf=(0,dist.ra8)(xShape,dtype,xValues);for(let b=0;b<convInfo.batchSize;++b)for(let d=0;d<convInfo.inChannels;++d)for(let yR=0;yR<convInfo.outHeight;++yR){const xRCorner=yR*strideHeight-padTop;let xRMin=xRCorner;for(;xRMin<0;)xRMin+=dilationHeight;const xRMax=Math.min(convInfo.inHeight,effectiveFilterHeight+xRCorner);for(let yC=0;yC<convInfo.outWidth;++yC){const xCCorner=yC*strideWidth-padLeft;let xCMin=xCCorner;for(;xCMin<0;)xCMin+=dilationWidth;const xCMax=Math.min(convInfo.inWidth,effectiveFilterWidth+xCCorner);let maxValue=Number.NEGATIVE_INFINITY,maxPosition=-1;for(let xR=xRMin;xR<xRMax;xR+=dilationHeight){const wR=xR-xRCorner;for(let xC=xCMin;xC<xCMax;xC+=dilationWidth){const wC=xC-xCCorner,pixel=xBuf.get(b,xR,xC,d);pixel>maxValue&&(maxValue=pixel,maxPosition=flattenPositions?includeBatchInIndex?((b*convInfo.inHeight+xR)*convInfo.inWidth+xC)*convInfo.inChannels+d:(xR*convInfo.inWidth+xC)*convInfo.inChannels+d:wR*effectiveFilterWidth+wC)}}maxPositions.set(maxPosition,b,yR,yC,d)}}return maxPositions}function pool_utils_pool3d(xValues,xShape,dtype,strides,convInfo,poolType){const strideDepth=convInfo.strideDepth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationDepth=convInfo.dilationDepth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,effectiveFilterDepth=convInfo.effectiveFilterDepth,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padFront=convInfo.padInfo.front,padTop=convInfo.padInfo.top,padLeft=convInfo.padInfo.left,initialValue="max"===poolType?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,output=(0,dist.ra8)(convInfo.outShape,dtype),outputVals=output.values,outputBatchStrides=convInfo.outShape[1]*convInfo.outShape[2]*convInfo.outShape[3]*convInfo.outShape[4],outputDepthStrides=convInfo.outShape[2]*convInfo.outShape[3]*convInfo.outShape[4],outputRowStrides=convInfo.outShape[3]*convInfo.outShape[4],outputColStrides=convInfo.outShape[4];for(let batch=0;batch<convInfo.batchSize;++batch){const outputBatchOffset=batch*outputBatchStrides,inputBatchOffset=batch*strides[0];for(let channel=0;channel<convInfo.inChannels;++channel)for(let yDepth=0;yDepth<convInfo.outDepth;++yDepth){const xDepthCorner=yDepth*strideDepth-padFront;let xDepthMin=xDepthCorner;for(;xDepthMin<0;)xDepthMin+=dilationDepth;const xDepthMax=Math.min(convInfo.inDepth,effectiveFilterDepth+xDepthCorner),outputDepthOffset=outputBatchOffset+yDepth*outputDepthStrides;for(let yRow=0;yRow<convInfo.outHeight;++yRow){const xRowCorner=yRow*strideHeight-padTop;let xRowMin=xRowCorner;for(;xRowMin<0;)xRowMin+=dilationHeight;const xRowMax=Math.min(convInfo.inHeight,effectiveFilterHeight+xRowCorner),outputRowOffset=outputDepthOffset+yRow*outputRowStrides;for(let yCol=0;yCol<convInfo.outWidth;++yCol){const xColCorner=yCol*strideWidth-padLeft;let xColMin=xColCorner;for(;xColMin<0;)xColMin+=dilationWidth;const xColMax=Math.min(convInfo.inWidth,effectiveFilterWidth+xColCorner),outputColOffset=outputRowOffset+yCol*outputColStrides;let minMaxValue=initialValue,avgValue=0,count=0;for(let xDepth=xDepthMin;xDepth<xDepthMax;xDepth+=dilationDepth){const xDepthOffset=inputBatchOffset+xDepth*strides[1];for(let xRow=xRowMin;xRow<xRowMax;xRow+=dilationHeight){const xRowOffset=xDepthOffset+xRow*strides[2];for(let xCol=xColMin;xCol<xColMax;xCol+=dilationWidth){const pixel=xValues[xRowOffset+xCol*strides[3]+channel];if("max"===poolType&&pixel>minMaxValue?minMaxValue=pixel:"avg"===poolType&&(avgValue+=pixel,count++),isNaN(minMaxValue))break}if(isNaN(minMaxValue))break}if(isNaN(minMaxValue))break}outputVals[outputColOffset+channel]="avg"===poolType?avgValue/Math.max(count,1):minMaxValue}}}}return output}const avgPoolConfig={kernelName:dist.ho8,backendName:"cpu",kernelFunc:function avgPool(args){const{inputs,backend,attrs}=args,{x}=inputs;(0,cpu_util.C)(x,"avgPool");const{filterSize,strides,pad,dimRoundingMode}=attrs;dist.ZSL.assert(dist.C0T.eitherStridesOrDilationsAreOne(strides,1),()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '1'`);const convInfo=dist.C0T.computePool2DInfo(x.shape,filterSize,strides,1,pad,dimRoundingMode);let res;if(1===convInfo.filterWidth&&1===convInfo.filterHeight&&dist.ZSL.arraysEqual(convInfo.inShape,convInfo.outShape))res=Identity_identity({inputs:{x},backend});else{const xValues=backend.data.get(x.dataId).values,strides=dist.ZSL.computeStrides(x.shape),buffer=pool_utils_pool(xValues,x.shape,x.dtype,strides,convInfo,"avg");res=backend.makeTensorInfo(convInfo.outShape,x.dtype,buffer.values)}return res}};const avgPool3DConfig={kernelName:dist.cS,backendName:"cpu",kernelFunc:function avgPool3D(args){const{inputs,backend,attrs}=args,{x}=inputs,{filterSize,strides,pad,dimRoundingMode,dataFormat}=attrs;(0,cpu_util.C)(x,"avgPool3d");const convInfo=dist.C0T.computePool3DInfo(x.shape,filterSize,strides,1,pad,dimRoundingMode,dataFormat),outBuf=pool_utils_pool3d(backend.data.get(x.dataId).values,x.shape,x.dtype,dist.ZSL.computeStrides(x.shape),convInfo,"avg");return backend.makeTensorInfo(outBuf.shape,"float32",outBuf.values)}};const AvgPool3DGrad_avgPool3DGradConfig={kernelName:dist.wwC,backendName:"cpu",kernelFunc:function avgPool3DGrad(args){const{inputs,backend,attrs}=args,{dy,input}=inputs,{filterSize,strides,pad,dimRoundingMode}=attrs;(0,cpu_util.C)([dy,input],"avgPool3DGrad");const convInfo=dist.C0T.computePool3DInfo(input.shape,filterSize,strides,1,pad,dimRoundingMode),strideDepth=convInfo.strideDepth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,filterDepth=convInfo.filterDepth,filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,dilationDepth=convInfo.dilationDepth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,effectiveFilterDepth=convInfo.effectiveFilterDepth,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padFront=effectiveFilterDepth-1-convInfo.padInfo.front,padLeft=effectiveFilterWidth-1-convInfo.padInfo.left,padTop=effectiveFilterHeight-1-convInfo.padInfo.top,dx=(0,dist.ra8)(input.shape,"float32"),avgMultiplier=1/(filterDepth*filterHeight*filterWidth),dyBuf=backend.bufferSync(dy);for(let batch=0;batch<convInfo.batchSize;++batch)for(let channel=0;channel<convInfo.inChannels;++channel)for(let dxDepth=0;dxDepth<convInfo.inDepth;++dxDepth)for(let dxRow=0;dxRow<convInfo.inHeight;++dxRow)for(let dxCol=0;dxCol<convInfo.inWidth;++dxCol){const dyDepthCorner=dxDepth-padFront,dyRowCorner=dxRow-padTop,dyColCorner=dxCol-padLeft;let dotProd=0;for(let wDepth=0;wDepth<effectiveFilterDepth;wDepth+=dilationDepth){const dyDepth=(dyDepthCorner+wDepth)/strideDepth;if(!(dyDepth<0||dyDepth>=convInfo.outDepth||Math.floor(dyDepth)!==dyDepth))for(let wRow=0;wRow<effectiveFilterHeight;wRow+=dilationHeight){const dyRow=(dyRowCorner+wRow)/strideHeight;if(!(dyRow<0||dyRow>=convInfo.outHeight||Math.floor(dyRow)!==dyRow))for(let wCol=0;wCol<effectiveFilterWidth;wCol+=dilationWidth){const dyCol=(dyColCorner+wCol)/strideWidth;if(dyCol<0||dyCol>=convInfo.outWidth||Math.floor(dyCol)!==dyCol)continue;dotProd+=dyBuf.get(batch,dyDepth,dyRow,dyCol,channel)}}}dx.set(dotProd*avgMultiplier,batch,dxDepth,dxRow,dxCol,channel)}return backend.makeTensorInfo(dx.shape,dx.dtype,dx.values)}};const AvgPoolGrad_avgPoolGradConfig={kernelName:dist.VCH,backendName:"cpu",kernelFunc:function AvgPoolGrad_avgPoolGrad(args){const{inputs,backend,attrs}=args,{dy,input}=inputs,x=input;(0,cpu_util.C)([dy,input],"avgPoolGrad");const{filterSize,strides,pad}=attrs,convInfo=dist.C0T.computePool2DInfo(x.shape,filterSize,strides,1,pad),strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padLeft=effectiveFilterWidth-1-convInfo.padInfo.left,padTop=effectiveFilterHeight-1-convInfo.padInfo.top,dx=(0,dist.ra8)(x.shape,"float32"),avgMultiplier=1/(filterHeight*filterWidth),dyData=backend.data.get(dy.dataId).values,dyBuf=(0,dist.ra8)(dy.shape,"float32",dyData);for(let b=0;b<convInfo.batchSize;++b)for(let d=0;d<convInfo.inChannels;++d)for(let dxR=0;dxR<convInfo.inHeight;++dxR)for(let dxC=0;dxC<convInfo.inWidth;++dxC){const dyRCorner=dxR-padTop,dyCCorner=dxC-padLeft;let dotProd=0;for(let wR=0;wR<effectiveFilterHeight;wR+=dilationHeight){const dyR=(dyRCorner+wR)/strideHeight;if(!(dyR<0||dyR>=convInfo.outHeight||Math.floor(dyR)!==dyR))for(let wC=0;wC<effectiveFilterWidth;wC+=dilationWidth){const dyC=(dyCCorner+wC)/strideWidth;if(dyC<0||dyC>=convInfo.outWidth||Math.floor(dyC)!==dyC)continue;dotProd+=dyBuf.get(b,dyR,dyC,d)}}dx.set(dotProd*avgMultiplier,b,dxR,dxC,d)}return backend.makeTensorInfo(dx.shape,dx.dtype,dx.values)}};const batchNormConfig={kernelName:dist.i5R,backendName:"cpu",kernelFunc:function batchNorm(args){const{inputs,backend,attrs}=args,{x,scale,offset,mean,variance}=inputs;dist.ZSL.assert(mean.shape.length===variance.shape.length,()=>"Batch normalization gradient requires mean and variance to have equal ranks."),dist.ZSL.assert(null==offset||mean.shape.length===offset.shape.length,()=>"Batch normalization gradient requires mean and offset to have equal ranks."),dist.ZSL.assert(null==scale||mean.shape.length===scale.shape.length,()=>"Batch normalization gradient requires mean and scale to have equal ranks."),(0,cpu_util.C)([x,mean,variance,scale,offset],"batchNorm");let{varianceEpsilon}=attrs;null==varianceEpsilon&&(varianceEpsilon=.001);const xVals=backend.data.get(x.dataId).values,mVals=backend.data.get(mean.dataId).values,varVals=backend.data.get(variance.dataId).values,sVals=scale?backend.data.get(scale.dataId).values:new Float32Array([1]),offVals=offset?backend.data.get(offset.dataId).values:new Float32Array([0]),outVals=new Float32Array(xVals.length),offValsLength=offVals.length,sValsLength=sVals.length,varValsLength=varVals.length,mValsLength=mVals.length;let offi=0,mi=0,si=0,vi=0;for(let i=0;i<xVals.length;++i)outVals[i]=offVals[offi++]+(xVals[i]-mVals[mi++])*sVals[si++]/Math.sqrt(varVals[vi++]+varianceEpsilon),offi>=offValsLength&&(offi=0),mi>=mValsLength&&(mi=0),si>=sValsLength&&(si=0),vi>=varValsLength&&(vi=0);return backend.makeTensorInfo(x.shape,x.dtype,outVals)}};const batchToSpaceNDConfig={kernelName:dist.Ik2,backendName:"cpu",kernelFunc:function batchToSpaceND(args){const{inputs,backend,attrs}=args,{x}=inputs,{blockShape,crops}=attrs;(0,cpu_util.C)([x],"batchToSpaceND");const prod=blockShape.reduce((a,b)=>a*b),reshaped=dist.C0T.getReshaped(x.shape,blockShape,prod),permuted=dist.C0T.getPermuted(reshaped.length,blockShape.length),reshapedPermuted=dist.C0T.getReshapedPermuted(x.shape,blockShape,prod),sliceBeginCoords=dist.C0T.getSliceBeginCoords(crops,blockShape.length),sliceSize=dist.C0T.getSliceSize(reshapedPermuted,crops,blockShape.length),xReshaped=Reshape_reshape({inputs:{x},backend,attrs:{shape:reshaped}}),xTransposed=Transpose_transpose({inputs:{x:xReshaped},backend,attrs:{perm:permuted}}),xTransposedReshaped=Reshape_reshape({inputs:{x:xTransposed},backend,attrs:{shape:reshapedPermuted}}),result=(0,Slice.di)({inputs:{x:xTransposedReshaped},backend,attrs:{begin:sliceBeginCoords,size:sliceSize}});return backend.disposeIntermediateTensorInfo(xReshaped),backend.disposeIntermediateTensorInfo(xTransposed),backend.disposeIntermediateTensorInfo(xTransposedReshaped),result}};const bincountConfig={kernelName:dist.N4F,backendName:"cpu",kernelFunc:function bincount(args){const{inputs,backend,attrs}=args,{x,weights}=inputs,{size}=attrs,outVals=bincountImpl(backend.data.get(x.dataId).values,backend.data.get(weights.dataId).values,weights.dtype,weights.shape,size);return backend.makeTensorInfo([size],weights.dtype,outVals)}};const broadcastArgsConfig={kernelName:dist.vj7,backendName:"cpu",kernelFunc:function broadcastArgs(args){const{inputs,backend}=args,{s0,s1}=inputs,s0Vals=backend.data.get(s0.dataId).values,s1Vals=backend.data.get(s1.dataId).values,broadcastShape=dist.C0T.assertAndGetBroadcastShape(Array.from(s0Vals),Array.from(s1Vals));return backend.makeTensorInfo([broadcastShape.length],"int32",Int32Array.from(broadcastShape))}},clipByValue=unaryKernelFunc(dist.vaV,(xi,attrs)=>{const clipAttrs=attrs;return xi>clipAttrs.clipValueMax?clipAttrs.clipValueMax:xi<clipAttrs.clipValueMin?clipAttrs.clipValueMin:xi}),clipByValueConfig={kernelName:dist.vaV,backendName:"cpu",kernelFunc:clipByValue},complexAbsConfig={kernelName:dist.$zE,backendName:"cpu",kernelFunc:args=>{const{x}=args.inputs,cpuBackend=args.backend,resultValues=new Float32Array(dist.ZSL.sizeFromShape(x.shape)),complexVals=cpuBackend.data.get(x.dataId),real=complexVals.complexTensorInfos.real,imag=complexVals.complexTensorInfos.imag,realVals=cpuBackend.data.get(real.dataId).values,imagVals=cpuBackend.data.get(imag.dataId).values;for(let i=0;i<realVals.length;i++){const real=realVals[i],imag=imagVals[i];resultValues[i]=Math.hypot(real,imag)}return cpuBackend.makeOutput(resultValues,x.shape,"float32")}};function imag(args){const{inputs,backend}=args,{input}=inputs,imag=backend.data.get(input.dataId).complexTensorInfos.imag,imagVal=backend.data.get(imag.dataId).values;return backend.makeTensorInfo(imag.shape,imag.dtype,imagVal)}const imagConfig={kernelName:dist.dv8,backendName:"cpu",kernelFunc:imag};function Concat_concat(args){const{inputs,backend,attrs}=args,{axis}=attrs,$axis=dist.ZSL.parseAxisParam(axis,inputs[0].shape)[0],shapes=inputs.map(t=>t.shape);dist.C0T.assertParamsConsistent(shapes,$axis);let outShape=dist.C0T.computeOutShape(inputs.map(t=>t.shape),$axis);if(0===dist.ZSL.sizeFromShape(outShape))return backend.makeTensorInfo(outShape,inputs[0].dtype,[]);const $inputs=inputs.filter(t=>dist.ZSL.sizeFromShape(t.shape)>0);if(1===$inputs.length)return Identity_identity({inputs:{x:$inputs[0]},backend});if("complex64"===$inputs[0].dtype){const reals=$inputs.map(t=>real({inputs:{input:t},backend})),imags=$inputs.map(t=>imag({inputs:{input:t},backend})),realConcated=Concat_concat({inputs:reals,backend,attrs:{axis:$axis}}),imagConcated=Concat_concat({inputs:imags,backend,attrs:{axis:$axis}}),result=complex({inputs:{real:realConcated,imag:imagConcated},backend});return reals.forEach(r=>backend.disposeIntermediateTensorInfo(r)),imags.forEach(i=>backend.disposeIntermediateTensorInfo(i)),backend.disposeIntermediateTensorInfo(realConcated),backend.disposeIntermediateTensorInfo(imagConcated),result}const inputs2D=$inputs.map(t=>{const innerSize=dist.ZSL.sizeFromShape(t.shape.slice($axis));return Reshape_reshape({inputs:{x:t},backend,attrs:{shape:[-1,innerSize]}})}),inputsValShapes=inputs2D.map(t=>({vals:backend.data.get(t.dataId).values,shape:t.shape}));outShape=dist.C0T.computeOutShape(inputs2D.map(t=>t.shape),1);const simplyConcat=1===inputs2D[0].shape[0],outVals=(0,Concat_impl.h)(inputsValShapes,outShape,inputs[0].dtype,simplyConcat),finalOutShape=dist.C0T.computeOutShape($inputs.map(t=>t.shape),$axis),outInfo=backend.makeTensorInfo(finalOutShape,inputs[0].dtype,outVals);return inputs2D.forEach(t=>backend.disposeIntermediateTensorInfo(t)),outInfo}const concatConfig={kernelName:dist.$dB,backendName:"cpu",kernelFunc:Concat_concat};function conv2D(args){const{inputs,backend,attrs}=args,{x,filter}=inputs,{strides,pad,dataFormat,dilations,dimRoundingMode}=attrs;(0,cpu_util.C)([x,filter],"conv2d");const $dataFormat=dist.C0T.convertConv2DDataFormat(dataFormat),convInfo=dist.C0T.computeConv2DInfo(x.shape,filter.shape,strides,dilations,pad,dimRoundingMode,!1,$dataFormat),filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,padLeft=convInfo.padInfo.left,padTop=convInfo.padInfo.top,isChannelsLast="channelsLast"===convInfo.dataFormat,y=new dist.ylz(convInfo.outShape,x.dtype),xStrides=dist.ZSL.computeStrides(x.shape),filterStrides=dist.ZSL.computeStrides(filter.shape),xBatchStride=xStrides[0],xRowStride=isChannelsLast?xStrides[1]:xStrides[2],xColStride=isChannelsLast?xStrides[2]:1,xChannelStride=isChannelsLast?1:xStrides[1],yBatchStride=y.strides[0],yRowStride=isChannelsLast?y.strides[1]:y.strides[2],yColStride=isChannelsLast?y.strides[2]:1,yChannelStride=isChannelsLast?1:y.strides[1],xVals=backend.data.get(x.dataId).values,wVals=backend.data.get(filter.dataId).values,yVals=y.values;for(let b=0;b<convInfo.batchSize;++b){const xOffset1=b*xBatchStride,yOffset1=b*yBatchStride;for(let yR=0;yR<convInfo.outHeight;++yR){const yOffset2=yOffset1+yR*yRowStride,xRCorner=yR*convInfo.strideHeight-padTop;for(let wR=0;wR<filterHeight;++wR){const xR=xRCorner+wR*dilationHeight;if(xR<0||xR>=convInfo.inHeight)continue;const wOffset1=wR*filterStrides[0],xOffset2=xOffset1+xR*xRowStride;for(let yC=0;yC<convInfo.outWidth;++yC){const yOffset3=yOffset2+yC*yColStride,xCCorner=yC*convInfo.strideWidth-padLeft;for(let wC=0;wC<filterWidth;++wC){const xC=xCCorner+wC*dilationWidth;if(xC<0||xC>=convInfo.inWidth)continue;const xOffset3=xOffset2+xC*xColStride;let wOffset3=wOffset1+wC*filterStrides[1];for(let d1=0;d1<convInfo.inChannels;++d1){const xVal=xVals[xOffset3+d1*xChannelStride];for(let d2=0;d2<convInfo.outChannels;++d2)yVals[yOffset3+d2*yChannelStride]+=xVal*wVals[wOffset3+d2];wOffset3+=convInfo.outChannels}}}}}}return backend.makeTensorInfo(y.shape,y.dtype,yVals)}const conv2DConfig={kernelName:dist.p2J,backendName:"cpu",kernelFunc:conv2D};const conv2DBackpropFilterConfig={kernelName:dist.rFm,backendName:"cpu",kernelFunc:function conv2DBackpropFilter(args){const{inputs,backend,attrs}=args,{x,dy}=inputs,{strides,pad,dataFormat,dimRoundingMode,filterShape}=attrs;(0,cpu_util.C)([x,dy],"conv2dBackpropFilter");const $dataFormat=dist.C0T.convertConv2DDataFormat(dataFormat),convInfo=dist.C0T.computeConv2DInfo(x.shape,filterShape,strides,1,pad,dimRoundingMode,!1,$dataFormat),{strideHeight,strideWidth,filterHeight,filterWidth}=convInfo,isChannelsLast="channelsLast"===convInfo.dataFormat,dW=new dist.ylz(convInfo.filterShape,"float32"),leftPad=convInfo.padInfo.left,topPad=convInfo.padInfo.top,xVals=backend.data.get(x.dataId).values,dyVals=backend.data.get(dy.dataId).values,xBuf=new dist.ylz(x.shape,x.dtype,xVals),dyBuf=new dist.ylz(dy.shape,dy.dtype,dyVals);for(let wR=0;wR<filterHeight;++wR){const yRMin=Math.max(0,Math.ceil((topPad-wR)/strideHeight)),yRMax=Math.min(convInfo.outHeight,(convInfo.inHeight+topPad-wR)/strideHeight);for(let wC=0;wC<filterWidth;++wC){const yCMin=Math.max(0,Math.ceil((leftPad-wC)/strideWidth)),yCMax=Math.min(convInfo.outWidth,(convInfo.inWidth+leftPad-wC)/strideWidth);for(let d1=0;d1<convInfo.inChannels;++d1)for(let d2=0;d2<convInfo.outChannels;++d2){let dotProd=0;for(let b=0;b<convInfo.batchSize;++b)for(let yR=yRMin;yR<yRMax;++yR){const xR=wR+yR*strideHeight-topPad;for(let yC=yCMin;yC<yCMax;++yC){const xC=wC+yC*strideWidth-leftPad;dotProd+=isChannelsLast?xBuf.get(b,xR,xC,d1)*dyBuf.get(b,yR,yC,d2):xBuf.get(b,d1,xR,xC)*dyBuf.get(b,d2,yR,yC)}}dW.set(dotProd,wR,wC,d1,d2)}}}return backend.makeTensorInfo(dW.shape,dW.dtype,dW.values)}};const conv2DBackpropInputConfig={kernelName:dist.jfg,backendName:"cpu",kernelFunc:function conv2DBackpropInput(args){const{inputs,backend,attrs}=args,{dy,filter}=inputs,{inputShape,strides,pad,dataFormat,dimRoundingMode}=attrs;(0,cpu_util.C)([dy,filter],"conv2dBackpropInput");const filterStrides=dist.ZSL.computeStrides(filter.shape),dyStrides=dist.ZSL.computeStrides(dy.shape);let $dataFormat=dist.C0T.convertConv2DDataFormat(dataFormat);const convInfo=dist.C0T.computeConv2DInfo(inputShape,filter.shape,strides,1,pad,dimRoundingMode,!1,$dataFormat),dx=new dist.ylz(convInfo.inShape,"float32"),dxValues=dx.values,dyValues=backend.data.get(dy.dataId).values,fltValues=backend.data.get(filter.dataId).values,[fltS0,fltS1,fltS2]=filterStrides,{batchSize,filterHeight,filterWidth,inChannels,inHeight,inWidth,outChannels,outHeight,outWidth,strideHeight,strideWidth}=convInfo;$dataFormat=convInfo.dataFormat;const topPad=filterHeight-1-convInfo.padInfo.top,leftPad=filterWidth-1-convInfo.padInfo.left,isChannelsLast="channelsLast"===$dataFormat,xBatchStride=dx.strides[0],xRowStride=isChannelsLast?dx.strides[1]:dx.strides[2],xColStride=isChannelsLast?dx.strides[2]:1,xChannelStride=isChannelsLast?1:dx.strides[1],yBatchStride=dyStrides[0],yRowStride=isChannelsLast?dyStrides[1]:dyStrides[2],yColStride=isChannelsLast?dyStrides[2]:1,yChannelStride=isChannelsLast?1:dyStrides[1];for(let b=0;b<batchSize;++b)for(let d1=0;d1<inChannels;++d1)for(let xR=0;xR<inHeight;++xR){const xRCorner=xR-topPad,xRMin=Math.max(0,Math.ceil(xRCorner/strideHeight)),yRMax=Math.min(outHeight,(filterHeight+xRCorner)/strideHeight);for(let xC=0;xC<inWidth;++xC){const xCCorner=xC-leftPad,xCMin=Math.max(0,Math.ceil(xCCorner/strideWidth)),yCMax=Math.min(outWidth,(filterWidth+xCCorner)/strideWidth);let dotProd=0;for(let yR=xRMin;yR<yRMax;++yR){const wR=yR*strideHeight-xRCorner;for(let yC=xCMin;yC<yCMax;++yC){const dyOffset=yBatchStride*b+yRowStride*yR+yColStride*yC,fltOffset=fltS0*(filterHeight-1-wR)+fltS1*(filterWidth-1-(yC*strideWidth-xCCorner))+fltS2*d1;for(let d2=0;d2<outChannels;++d2){dotProd+=dyValues[dyOffset+yChannelStride*d2]*fltValues[fltOffset+d2]}}}dxValues[xBatchStride*b+xRowStride*xR+xColStride*xC+xChannelStride*d1]=dotProd}}return backend.makeTensorInfo(dx.shape,dx.dtype,dx.values)}};const conv3DConfig={kernelName:dist.A1h,backendName:"cpu",kernelFunc:function conv3D(args){const{inputs,backend,attrs}=args,{x,filter}=inputs,{strides,pad,dilations}=attrs;(0,cpu_util.C)([x,filter],"conv3d");const convInfo=dist.C0T.computeConv3DInfo(x.shape,filter.shape,strides,dilations,pad),{filterDepth,filterHeight,filterWidth,dilationDepth,dilationHeight,dilationWidth,padInfo}=convInfo,padFront=padInfo.front,padLeft=padInfo.left,padTop=padInfo.top,y=new dist.ylz(convInfo.outShape,x.dtype),xVals=backend.data.get(x.dataId).values,wVals=backend.data.get(filter.dataId).values,yVals=y.values,xStrides=dist.ZSL.computeStrides(x.shape),filterStrides=dist.ZSL.computeStrides(filter.shape);for(let b=0;b<convInfo.batchSize;++b){const xOffset1=b*xStrides[0],yOffset1=b*y.strides[0];for(let yF=0;yF<convInfo.outDepth;++yF){const yOffset2=yOffset1+yF*y.strides[1],xFCorner=yF*convInfo.strideDepth-padFront;for(let wF=0;wF<filterDepth;++wF){const xF=xFCorner+wF*dilationDepth;if(xF<0||xF>=convInfo.inDepth)continue;const wOffset1=wF*filterStrides[0],xOffset2=xOffset1+xF*xStrides[1];for(let yR=0;yR<convInfo.outHeight;++yR){const yOffset3=yOffset2+yR*y.strides[2],xRCorner=yR*convInfo.strideHeight-padTop;for(let wR=0;wR<filterHeight;++wR){const xR=xRCorner+wR*dilationHeight;if(xR<0||xR>=convInfo.inHeight)continue;const wOffset2=wOffset1+wR*filterStrides[1],xOffset3=xOffset2+xR*xStrides[2];for(let yC=0;yC<convInfo.outWidth;++yC){const yOffset4=yOffset3+yC*convInfo.outChannels,xCCorner=yC*convInfo.strideWidth-padLeft;for(let wC=0;wC<filterWidth;++wC){const xC=xCCorner+wC*dilationWidth;if(xC<0||xC>=convInfo.inWidth)continue;const wOffset3=wOffset2+wC*filterStrides[2],xOffset4=xOffset3+xC*convInfo.inChannels;let wOffset4=wOffset3;for(let d1=0;d1<convInfo.inChannels;++d1){const xVal=xVals[xOffset4+d1];for(let d2=0;d2<convInfo.outChannels;++d2)yVals[yOffset4+d2]+=xVal*wVals[wOffset4+d2];wOffset4+=convInfo.outChannels}}}}}}}}return backend.makeTensorInfo(y.shape,y.dtype,y.values)}};const conv3DBackpropFilterV2Config={kernelName:dist.iGz,backendName:"cpu",kernelFunc:function conv3DBackpropFilterV2(args){const{inputs,backend,attrs}=args,{x,dy}=inputs,{strides,pad,filterShape}=attrs;(0,cpu_util.C)([x,dy],"conv3dBackpropFilterV2");const xStrides=dist.ZSL.computeStrides(x.shape),dyStrides=dist.ZSL.computeStrides(dy.shape),convInfo=dist.C0T.computeConv3DInfo(x.shape,filterShape,strides,1,pad),strideDepth=convInfo.strideDepth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,filterDepth=convInfo.filterDepth,filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,dw=new dist.ylz(convInfo.filterShape,"float32"),dwValues=dw.values,[dwS0,dwS1,dwS2,dwS3]=dw.strides,dyValues=backend.data.get(dy.dataId).values,[dyS0,dyS1,dyS2,dyS3]=dyStrides,xValues=backend.data.get(x.dataId).values,[xS0,xS1,xS2,xS3]=xStrides,frontPad=convInfo.padInfo.front,leftPad=convInfo.padInfo.left,topPad=convInfo.padInfo.top;for(let wF=0;wF<filterDepth;++wF){const yFMin=Math.max(0,Math.ceil((frontPad-wF)/strideDepth)),yFMax=Math.min(convInfo.outDepth,(convInfo.inDepth+frontPad-wF)/strideDepth),wOffset1=wF*dwS0;for(let wR=0;wR<filterHeight;++wR){const yRMin=Math.max(0,Math.ceil((topPad-wR)/strideHeight)),yRMax=Math.min(convInfo.outHeight,(convInfo.inHeight+topPad-wR)/strideHeight),wOffset2=wR*dwS1+wOffset1;for(let wC=0;wC<filterWidth;++wC){const yCMin=Math.max(0,Math.ceil((leftPad-wC)/strideWidth)),yCMax=Math.min(convInfo.outWidth,(convInfo.inWidth+leftPad-wC)/strideWidth),wOffset3=wC*dwS2+wOffset2;for(let d1=0;d1<convInfo.inChannels;++d1){const wOffset4=d1*dwS3+wOffset3;for(let d2=0;d2<convInfo.outChannels;++d2){let dotProd=0;for(let b=0;b<convInfo.batchSize;++b){const xOffset1=b*xS0,yOffset1=b*dyS0;for(let yF=yFMin;yF<yFMax;++yF){const xOffset2=(wF+yF*strideDepth-frontPad)*xS1+xOffset1,yOffset2=yF*dyS1+yOffset1;for(let yR=yRMin;yR<yRMax;++yR){const xOffset3=(wR+yR*strideHeight-topPad)*xS2+xOffset2,yOffset3=yR*dyS2+yOffset2;for(let yC=yCMin;yC<yCMax;++yC){const yOffset4=yC*dyS3+yOffset3;dotProd+=xValues[(wC+yC*strideWidth-leftPad)*xS3+xOffset3+d1]*dyValues[yOffset4+d2]}}}}dwValues[wOffset4+d2]=dotProd}}}}}return backend.makeTensorInfo(dw.shape,dw.dtype,dw.values)}};const conv3DBackpropInputV2Config={kernelName:dist.gC7,backendName:"cpu",kernelFunc:function conv3DBackpropInputV2(args){const{inputs,backend,attrs}=args,{dy,filter}=inputs,{pad,strides,inputShape}=attrs;(0,cpu_util.C)([dy],"conv3dBackpropInputV2");const dyStrides=dist.ZSL.computeStrides(dy.shape),filterStrides=dist.ZSL.computeStrides(filter.shape),convInfo=dist.C0T.computeConv3DInfo(inputShape,filter.shape,strides,1,pad),dx=new dist.ylz(convInfo.inShape,"float32"),dxValues=dx.values,[dxS0,dxS1,dxS2,dxS3]=dx.strides,dyValues=backend.data.get(dy.dataId).values,[dyS0,dyS1,dyS2,dyS3]=dyStrides,fltValues=backend.data.get(filter.dataId).values,[fltS0,fltS1,fltS2,fltS3]=filterStrides,{batchSize,filterDepth,filterHeight,filterWidth,inChannels,inDepth,inHeight,inWidth,outChannels,outDepth,outHeight,outWidth,strideDepth,strideHeight,strideWidth}=convInfo,frontPad=filterDepth-1-convInfo.padInfo.front,topPad=filterHeight-1-convInfo.padInfo.top,leftPad=filterWidth-1-convInfo.padInfo.left;for(let b=0;b<batchSize;++b)for(let d1=0;d1<inChannels;++d1)for(let xF=0;xF<inDepth;++xF){const xFCorner=xF-frontPad,xFMin=Math.max(0,Math.ceil(xFCorner/strideDepth)),yFMax=Math.min(outDepth,(filterDepth+xFCorner)/strideDepth);for(let xR=0;xR<inHeight;++xR){const xRCorner=xR-topPad,xRMin=Math.max(0,Math.ceil(xRCorner/strideHeight)),yRMax=Math.min(outHeight,(filterHeight+xRCorner)/strideHeight);for(let xC=0;xC<inWidth;++xC){const xCCorner=xC-leftPad,xCMin=Math.max(0,Math.ceil(xCCorner/strideWidth)),yCMax=Math.min(outWidth,(filterWidth+xCCorner)/strideWidth);let dotProd=0;for(let yF=xFMin;yF<yFMax;++yF){const wF=yF*strideDepth-xFCorner;for(let yR=xRMin;yR<yRMax;++yR){const wR=yR*strideHeight-xRCorner;for(let yC=xCMin;yC<yCMax;++yC){const dyOffset=dyS0*b+dyS1*yF+dyS2*yR+dyS3*yC,fltOffset=fltS0*(filterDepth-1-wF)+fltS1*(filterHeight-1-wR)+fltS2*(filterWidth-1-(yC*strideWidth-xCCorner))+fltS3*d1;for(let d2=0;d2<outChannels;++d2){dotProd+=dyValues[dyOffset+d2]*fltValues[fltOffset+d2]}}}}dxValues[dxS0*b+dxS1*xF+dxS2*xR+dxS3*xC+d1]=dotProd}}}return backend.makeTensorInfo(dx.shape,dx.dtype,dx.values)}},Cos_cos=unaryKernelFunc(dist.Mn0,xi=>Math.cos(xi)),cosConfig={kernelName:dist.Mn0,backendName:"cpu",kernelFunc:Cos_cos},Cosh_cosh=unaryKernelFunc(dist.MnK,xi=>Math.cosh(xi)),coshConfig={kernelName:dist.MnK,backendName:"cpu",kernelFunc:Cosh_cosh};const cropAndResizeConfig={kernelName:dist.MRQ,backendName:"cpu",kernelFunc:function CropAndResize_cropAndResize(args){const{inputs,backend,attrs}=args,{image,boxes,boxInd}=inputs,{cropSize,method,extrapolationValue}=attrs,[batch,imageHeight,imageWidth,numChannels]=image.shape,numBoxes=boxes.shape[0],[cropHeight,cropWidth]=cropSize,output=(0,dist.ra8)([numBoxes,cropHeight,cropWidth,numChannels],"float32"),boxVals=backend.data.get(boxes.dataId).values,boxIndVals=backend.data.get(boxInd.dataId).values,imageVals=backend.data.get(image.dataId).values,inStride=dist.ZSL.computeStrides(image.shape),outStride=dist.ZSL.computeStrides(output.shape);for(let b=0;b<numBoxes;b++){const startInd=4*b,y1=boxVals[startInd],x1=boxVals[startInd+1],y2=boxVals[startInd+2],x2=boxVals[startInd+3],bInd=boxIndVals[b];if(bInd>=batch)continue;const heightScale=cropHeight>1?(y2-y1)*(imageHeight-1)/(cropHeight-1):0,widthScale=cropWidth>1?(x2-x1)*(imageWidth-1)/(cropWidth-1):0;for(let y=0;y<cropHeight;y++){const yInd=cropHeight>1?y1*(imageHeight-1)+y*heightScale:.5*(y1+y2)*(imageHeight-1);if(yInd<0||yInd>imageHeight-1)for(let x=0;x<cropWidth;x++)for(let c=0;c<numChannels;c++){const ind=c+x*outStride[2]+y*outStride[1]+b*outStride[0];output.values[ind]=extrapolationValue}else if("bilinear"===method){const topInd=Math.floor(yInd),bottomInd=Math.ceil(yInd),yLerp=yInd-topInd;for(let x=0;x<cropWidth;x++){const xInd=cropWidth>1?x1*(imageWidth-1)+x*widthScale:.5*(x1+x2)*(imageWidth-1);if(xInd<0||xInd>imageWidth-1){for(let c=0;c<numChannels;c++){const ind=c+x*outStride[2]+y*outStride[1]+b*outStride[0];output.values[ind]=extrapolationValue}continue}const leftInd=Math.floor(xInd),rightInd=Math.ceil(xInd),xLerp=xInd-leftInd;for(let c=0;c<numChannels;c++){let ind=c+leftInd*inStride[2]+topInd*inStride[1]+bInd*inStride[0];const topLeft=imageVals[ind];ind=c+rightInd*inStride[2]+topInd*inStride[1]+bInd*inStride[0];const topRight=imageVals[ind];ind=c+leftInd*inStride[2]+bottomInd*inStride[1]+bInd*inStride[0];const bottomLeft=imageVals[ind];ind=c+rightInd*inStride[2]+bottomInd*inStride[1]+bInd*inStride[0];const top=topLeft+(topRight-topLeft)*xLerp,bottom=bottomLeft+(imageVals[ind]-bottomLeft)*xLerp;ind=c+x*outStride[2]+y*outStride[1]+b*outStride[0],output.values[ind]=top+(bottom-top)*yLerp}}}else for(let x=0;x<cropWidth;++x){const xInd=cropWidth>1?x1*(imageWidth-1)+x*widthScale:.5*(x1+x2)*(imageWidth-1);if(xInd<0||xInd>imageWidth-1){for(let c=0;c<numChannels;c++){const ind=c+x*outStride[2]+y*outStride[1]+b*outStride[0];output.values[ind]=extrapolationValue}continue}const closestX=Math.round(xInd),closestY=Math.round(yInd);for(let c=0;c<numChannels;c++){const inInd=c+closestX*inStride[2]+closestY*inStride[1]+bInd*inStride[0],outInd=c+x*outStride[2]+y*outStride[1]+b*outStride[0];output.values[outInd]=imageVals[inInd]}}}}return backend.makeTensorInfo(output.shape,output.dtype,output.values)}};const cumprodConfig={kernelName:dist.jj_,backendName:"cpu",kernelFunc:function Cumprod_cumprod(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,exclusive,reverse}=attrs;(0,cpu_util.C)(x,"cumprod");const permutation=dist.C0T.getAxesPermutation([axis],x.shape.length);let $x=x;null!=permutation&&($x=Transpose_transpose({inputs:{x},backend,attrs:{perm:permutation}}));const permutedAxis=dist.C0T.getInnerMostAxes(1,x.shape.length)[0];if(permutedAxis!==$x.shape.length-1)throw new Error(`backend.cumprod in CPU expects an inner-most axis=${$x.shape.length-1} but got axis=${permutedAxis}`);const resultDtype=(0,dist.TuY)($x.dtype,"int32"),vals=dist.ZSL.makeOnesTypedArray(dist.ZSL.sizeFromShape($x.shape),resultDtype),aVals=backend.data.get($x.dataId).values,finalDim=$x.shape[$x.shape.length-1],indexAdjuster=reverse?(i,j)=>i+finalDim-j-1:(i,j)=>i+j;for(let i=0;i<aVals.length;i+=finalDim)for(let j=0;j<finalDim;j++){const idx=indexAdjuster(i,j);if(0===j)vals[idx]=exclusive?1:aVals[idx];else{const prevIdx=indexAdjuster(i,j-1);vals[idx]=exclusive?aVals[prevIdx]*vals[prevIdx]:aVals[idx]*vals[prevIdx]}}const result=backend.makeTensorInfo($x.shape,resultDtype,vals);if(null!=permutation){const reverseTransposedResult=Transpose_transpose({inputs:{x:result},backend,attrs:{perm:dist.C0T.getUndoAxesPermutation(permutation)}});return backend.disposeIntermediateTensorInfo(result),backend.disposeIntermediateTensorInfo($x),reverseTransposedResult}return result}};const cumsumConfig={kernelName:dist.nY8,backendName:"cpu",kernelFunc:function Cumsum_cumsum(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,exclusive,reverse}=attrs;(0,cpu_util.C)(x,"cumsum");const permutation=dist.C0T.getAxesPermutation([axis],x.shape.length);let $x=x;null!=permutation&&($x=Transpose_transpose({inputs:{x},backend,attrs:{perm:permutation}}));const permutedAxis=dist.C0T.getInnerMostAxes(1,x.shape.length)[0];if(permutedAxis!==$x.shape.length-1)throw new Error(`backend.cumsum in CPU expects an inner-most axis=${$x.shape.length-1} but got axis=${permutedAxis}`);const resultDtype=(0,dist.TuY)($x.dtype,"int32"),vals=dist.ZSL.makeZerosTypedArray(dist.ZSL.sizeFromShape($x.shape),resultDtype),aVals=backend.data.get($x.dataId).values,finalDim=$x.shape[$x.shape.length-1],indexAdjuster=reverse?(i,j)=>i+finalDim-j-1:(i,j)=>i+j;for(let i=0;i<aVals.length;i+=finalDim)for(let j=0;j<finalDim;j++){const idx=indexAdjuster(i,j);if(0===j)vals[idx]=exclusive?0:aVals[idx];else{const prevIdx=indexAdjuster(i,j-1);vals[idx]=exclusive?aVals[prevIdx]+vals[prevIdx]:aVals[idx]+vals[prevIdx]}}const result=backend.makeTensorInfo($x.shape,resultDtype,vals);if(null!=permutation){const reverseTransposedResult=Transpose_transpose({inputs:{x:result},backend,attrs:{perm:dist.C0T.getUndoAxesPermutation(permutation)}});return backend.disposeIntermediateTensorInfo(result),backend.disposeIntermediateTensorInfo($x),reverseTransposedResult}return result}};const denseBincountConfig={kernelName:dist.wNW,backendName:"cpu",kernelFunc:function denseBincount(args){const{inputs,backend,attrs}=args,{x,weights}=inputs,{size,binaryOutput}=attrs;if(1===x.shape.length){const outVals=bincountImpl(backend.data.get(x.dataId).values,backend.data.get(weights.dataId).values,weights.dtype,weights.shape,size);return backend.makeTensorInfo([size],weights.dtype,outVals)}if(2===x.shape.length){const outBuf=bincountReduceImpl(backend.bufferSync(x),backend.bufferSync(weights),size,binaryOutput);return backend.makeTensorInfo(outBuf.shape,weights.dtype,outBuf.values)}throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${x.shape.length}.`)}};const depthToSpaceConfig={kernelName:dist.TMz,backendName:"cpu",kernelFunc:function depthToSpace(args){const{inputs,backend,attrs}=args,{x}=inputs,{blockSize,dataFormat}=attrs;dist.ZSL.assert("NHWC"===dataFormat,()=>`Only NHWC dataFormat supported on CPU for depthToSpace. Got ${dataFormat}`);const batchSize=x.shape[0],inputHeight=x.shape[1],inputWidth=x.shape[2],inputDepth=x.shape[3],outputHeight=inputHeight*blockSize,outputWidth=inputWidth*blockSize,outputDepth=inputDepth/(blockSize*blockSize),xValues=backend.data.get(x.dataId).values,result=new Float32Array(batchSize*outputHeight*outputWidth*outputDepth);let outputIdx=0;for(let b=0;b<batchSize;++b)for(let h=0;h<outputHeight;++h){const inH=Math.floor(h/blockSize),offsetH=h%blockSize;for(let w=0;w<outputWidth;++w){const inW=Math.floor(w/blockSize),offsetD=(offsetH*blockSize+w%blockSize)*outputDepth;for(let d=0;d<outputDepth;++d){const inputIdx=d+offsetD+inputDepth*(inW+inputWidth*(inH+inputHeight*b));result[outputIdx++]=xValues[inputIdx]}}}return backend.makeTensorInfo([batchSize,outputHeight,outputWidth,outputDepth],x.dtype,result)}};function depthwiseConv2dNative(args){const{inputs,backend,attrs}=args,{x,filter}=inputs,{strides,pad,dilations,dimRoundingMode}=attrs;(0,cpu_util.C)([x,filter],"depthwiseConv2DNative");const xStrides=dist.ZSL.computeStrides(x.shape),filterStrides=dist.ZSL.computeStrides(filter.shape);let $dilations=dilations;null==$dilations&&($dilations=[1,1]),dist.ZSL.assert(dist.C0T.eitherStridesOrDilationsAreOne(strides,$dilations),()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);const convInfo=dist.C0T.computeConv2DInfo(x.shape,filter.shape,strides,$dilations,pad,dimRoundingMode,!0),{filterHeight,filterWidth,dilationHeight,dilationWidth,padInfo}=convInfo,padLeft=padInfo.left,padTop=padInfo.top,chMul=convInfo.outChannels/convInfo.inChannels,y=new dist.ylz(convInfo.outShape,x.dtype),xVals=backend.data.get(x.dataId).values,wVals=backend.data.get(filter.dataId).values,yVals=y.values;for(let b=0;b<convInfo.batchSize;++b){const xOffset1=b*xStrides[0],yOffset1=b*y.strides[0];for(let yR=0;yR<convInfo.outHeight;++yR){const yOffset2=yOffset1+yR*y.strides[1],xRCorner=yR*convInfo.strideHeight-padTop;for(let wR=0;wR<filterHeight;++wR){const xR=xRCorner+wR*dilationHeight;if(xR<0||xR>=convInfo.inHeight)continue;const wOffset1=wR*filterStrides[0],xOffset2=xOffset1+xR*xStrides[1];for(let yC=0;yC<convInfo.outWidth;++yC){const yOffset3=yOffset2+yC*y.strides[2],xCCorner=yC*convInfo.strideWidth-padLeft;for(let wC=0;wC<filterWidth;++wC){const xC=xCCorner+wC*dilationWidth;if(xC<0||xC>=convInfo.inWidth)continue;const wOffset2=wOffset1+wC*filterStrides[1],xOffset3=xOffset2+xC*convInfo.inChannels;let yOffset4=yOffset3,wOffset3=wOffset2;for(let d1=0;d1<convInfo.inChannels;++d1){const xVal=xVals[xOffset3+d1];for(let q=0;q<chMul;++q)yVals[yOffset4+q]+=xVal*wVals[wOffset3+q];yOffset4+=chMul,wOffset3+=chMul}}}}}}return backend.makeTensorInfo(y.shape,y.dtype,y.values)}const depthwiseConv2dNativeConfig={kernelName:dist.tGH,backendName:"cpu",kernelFunc:depthwiseConv2dNative};const depthwiseConv2dNativeBackpropFilterConfig={kernelName:dist.X$8,backendName:"cpu",kernelFunc:function depthwiseConv2dNativeBackpropFilter(args){const{inputs,backend,attrs}=args,{x,dy}=inputs,{strides,dilations,pad,dimRoundingMode,filterShape}=attrs;(0,cpu_util.C)([x,dy],"depthwiseConv2dNativeBackpropFilter");const convInfo=dist.C0T.computeConv2DInfo(x.shape,filterShape,strides,dilations,pad,dimRoundingMode,!0),{strideHeight,strideWidth,filterHeight,filterWidth}=convInfo,dW=new dist.ylz(convInfo.filterShape,"float32"),leftPad=convInfo.padInfo.left,topPad=convInfo.padInfo.top,chMul=convInfo.outChannels/convInfo.inChannels,xVals=backend.data.get(x.dataId).values,xBuf=new dist.ylz(x.shape,x.dtype,xVals),dyVals=backend.data.get(dy.dataId).values,dyBuf=new dist.ylz(dy.shape,dy.dtype,dyVals);for(let wR=0;wR<filterHeight;++wR){const yRMin=Math.max(0,Math.ceil((topPad-wR)/strideHeight)),yRMax=Math.min(convInfo.outHeight,(convInfo.inHeight+topPad-wR)/strideHeight);for(let wC=0;wC<filterWidth;++wC){const yCMin=Math.max(0,Math.ceil((leftPad-wC)/strideWidth)),yCMax=Math.min(convInfo.outWidth,(convInfo.inWidth+leftPad-wC)/strideWidth);for(let d2=0;d2<convInfo.outChannels;++d2){const d1=Math.trunc(d2/chMul),dm=d2%chMul;let dotProd=0;for(let b=0;b<convInfo.batchSize;++b)for(let yR=yRMin;yR<yRMax;++yR){const xR=wR+yR*strideHeight-topPad;for(let yC=yCMin;yC<yCMax;++yC){const xC=wC+yC*strideWidth-leftPad;dotProd+=xBuf.get(b,xR,xC,d1)*dyBuf.get(b,yR,yC,d2)}}dW.set(dotProd,wR,wC,d1,dm)}}}return backend.makeTensorInfo(dW.shape,dW.dtype,dW.values)}};const depthwiseConv2dNativeBackpropInputConfig={kernelName:dist.nVu,backendName:"cpu",kernelFunc:function depthwiseConv2dNativeBackpropInput(args){const{inputs,backend,attrs}=args,{dy,filter}=inputs,{strides,dilations,pad,dimRoundingMode,inputShape}=attrs;(0,cpu_util.C)([dy,filter],"depthwiseConv2DNativeBackpropInput");const dyStrides=dist.ZSL.computeStrides(dy.shape),filterStrides=dist.ZSL.computeStrides(filter.shape),convInfo=dist.C0T.computeConv2DInfo(inputShape,filter.shape,strides,dilations,pad,dimRoundingMode,!0),dx=new dist.ylz(convInfo.inShape,"float32"),dxValues=dx.values,[dxS0,dxS1,dxS2]=dx.strides,dyValues=backend.data.get(dy.dataId).values,[dyS0,dyS1,dyS2]=dyStrides,fltValues=backend.data.get(filter.dataId).values,[fltS0,fltS1,fltS2]=filterStrides,{batchSize,filterHeight,filterWidth,inChannels,inHeight,inWidth,outChannels,outHeight,outWidth,strideHeight,strideWidth}=convInfo,topPad=filterHeight-1-convInfo.padInfo.top,leftPad=filterWidth-1-convInfo.padInfo.left,chMul=outChannels/inChannels;for(let b=0;b<batchSize;++b)for(let d1=0;d1<inChannels;++d1)for(let xR=0;xR<inHeight;++xR){const xRCorner=xR-topPad,xRMin=Math.max(0,Math.ceil(xRCorner/strideHeight)),yRMax=Math.min(outHeight,(filterHeight+xRCorner)/strideHeight);for(let xC=0;xC<inWidth;++xC){const xCCorner=xC-leftPad,xCMin=Math.max(0,Math.ceil(xCCorner/strideWidth)),yCMax=Math.min(outWidth,(filterWidth+xCCorner)/strideWidth);let dotProd=0;for(let yR=xRMin;yR<yRMax;++yR){const wR=yR*strideHeight-xRCorner;for(let yC=xCMin;yC<yCMax;++yC){const dyOffset=dyS0*b+dyS1*yR+dyS2*yC,fltOffset=fltS0*(filterHeight-1-wR)+fltS1*(filterWidth-1-(yC*strideWidth-xCCorner))+fltS2*d1;for(let dm=0;dm<chMul;++dm){dotProd+=dyValues[dyOffset+(d1*chMul+dm)]*fltValues[fltOffset+dm]}}}dxValues[dxS0*b+dxS1*xR+dxS2*xC+d1]=dotProd}}return backend.makeTensorInfo(dx.shape,dx.dtype,dx.values)}};const diagConfig={kernelName:dist.ORI,backendName:"cpu",kernelFunc:function diag(args){const{inputs,backend}=args,{x}=inputs,xSize=dist.ZSL.sizeFromShape(x.shape),xVals=backend.data.get(x.dataId).values,outBuf=(0,dist.ra8)([xSize,xSize],x.dtype),vals=outBuf.values;for(let i=0;i<xVals.length;i++)vals[i*xSize+i]=xVals[i];const outShape=[...x.shape,...x.shape];return backend.makeTensorInfo(outShape,outBuf.dtype,outBuf.values)}},dilation2DConfig={kernelName:dist.jxD,backendName:"cpu",kernelFunc:({inputs,backend,attrs})=>{const{x,filter}=inputs,{strides,pad,dilations}=attrs,cpuBackend=backend,xVals=cpuBackend.data.get(x.dataId).values,xRank=x.shape.length,filterVals=cpuBackend.data.get(filter.dataId).values,filterRank=filter.shape.length,{batchSize,inHeight,inWidth,inChannels,outHeight,outWidth,padInfo,strideHeight,strideWidth,filterHeight,filterWidth,dilationHeight,dilationWidth,outShape}=dist.C0T.computeDilation2DInfo(x.shape,filter.shape,strides,pad,"NHWC",dilations),outSize=dist.ZSL.sizeFromShape(outShape),outRank=outShape.length,outputVals=dist.ZSL.getArrayFromDType(x.dtype,outSize);for(let b=0;b<batchSize;++b)for(let hOut=0;hOut<outHeight;++hOut){const hBeg=hOut*strideHeight-padInfo.top;for(let wOut=0;wOut<outWidth;++wOut){const wBeg=wOut*strideWidth-padInfo.left;for(let d=0;d<inChannels;++d){let curVal=Number.MIN_SAFE_INTEGER;for(let h=0;h<filterHeight;++h){const hIn=hBeg+h*dilationHeight;if(hIn>=0&&hIn<inHeight)for(let w=0;w<filterWidth;++w){const wIn=wBeg+w*dilationWidth;if(wIn>=0&&wIn<inWidth){const xIndex=dist.ZSL.locToIndex([b,hIn,wIn,d],xRank,dist.ZSL.computeStrides(x.shape)),filterIndex=dist.ZSL.locToIndex([h,w,d],filterRank,dist.ZSL.computeStrides(filter.shape)),val=xVals[xIndex]+filterVals[filterIndex];val>curVal&&(curVal=val)}}}outputVals[dist.ZSL.locToIndex([b,hOut,wOut,d],outRank,dist.ZSL.computeStrides(outShape))]=curVal}}}return{dataId:cpuBackend.write(dist.ZSL.toTypedArray(outputVals,x.dtype),outShape,x.dtype),shape:outShape,dtype:x.dtype}}},dilation2DBackpropFilterConfig={kernelName:dist.pk0,backendName:"cpu",kernelFunc:({inputs,backend,attrs})=>{const{x,filter,dy}=inputs,{strides,pad,dilations}=attrs,cpuBackend=backend,$x=dist.ZSL.toNestedArray(x.shape,cpuBackend.data.get(x.dataId).values),$filter=dist.ZSL.toNestedArray(filter.shape,cpuBackend.data.get(filter.dataId).values),{batchSize,inHeight,inWidth,inChannels,outHeight,outWidth,padInfo,strideHeight,strideWidth,filterHeight,filterWidth,dilationHeight,dilationWidth,outShape}=dist.C0T.computeDilation2DInfo(x.shape,filter.shape,strides,pad,"NHWC",dilations);dist.ZSL.assert(dy.rank===outShape.length,()=>`Error in ${dist.pk0}, dy must have the same rank as output ${outShape.length}, but got ${dy.rank}`);const $dy=dist.ZSL.toNestedArray(outShape,cpuBackend.data.get(dy.dataId).values),gradients=dist.ZSL.makeZerosNestedTypedArray(filter.shape,filter.dtype);for(let b=0;b<batchSize;++b)for(let hOut=0;hOut<outHeight;++hOut){const hBeg=hOut*strideHeight-padInfo.top;for(let wOut=0;wOut<outWidth;++wOut){const wBeg=wOut*strideWidth-padInfo.left;for(let d=0;d<inChannels;++d){let curVal=Number.MIN_SAFE_INTEGER,hMax=0,wMax=0;for(let h=0;h<filterHeight;++h){const hIn=hBeg+h*dilationHeight;if(hIn>=0&&hIn<inHeight)for(let w=0;w<filterWidth;++w){const wIn=wBeg+w*dilationWidth;if(wIn>=0&&wIn<inWidth){const val=$x[b][hIn][wIn][d]+$filter[h][w][d];val>curVal&&(curVal=val,hMax=h,wMax=w)}}}gradients[hMax][wMax][d]+=$dy[b][hOut][wOut][d]}}}return{dataId:cpuBackend.write(dist.ZSL.toTypedArray(gradients,x.dtype),filter.shape,filter.dtype),shape:filter.shape,dtype:filter.dtype}}},dilation2DBackpropInputConfig={kernelName:dist.bP9,backendName:"cpu",kernelFunc:({inputs,backend,attrs})=>{const{x,filter,dy}=inputs,{strides,pad,dilations}=attrs,cpuBackend=backend,$x=dist.ZSL.toNestedArray(x.shape,cpuBackend.data.get(x.dataId).values),$filter=dist.ZSL.toNestedArray(filter.shape,cpuBackend.data.get(filter.dataId).values),{batchSize,inHeight,inWidth,inChannels,outHeight,outWidth,padInfo,strideHeight,strideWidth,filterHeight,filterWidth,dilationHeight,dilationWidth,outShape}=dist.C0T.computeDilation2DInfo(x.shape,filter.shape,strides,pad,"NHWC",dilations);dist.ZSL.assert(dy.rank===outShape.length,()=>`Error in ${dist.bP9}, dy must have the same rank as output ${outShape.length}, but got ${dy.rank}`);const $dy=dist.ZSL.toNestedArray(outShape,cpuBackend.data.get(dy.dataId).values),gradients=dist.ZSL.makeZerosNestedTypedArray(x.shape,x.dtype);for(let b=0;b<batchSize;++b)for(let hOut=0;hOut<outHeight;++hOut){const hBeg=hOut*strideHeight-padInfo.top;for(let wOut=0;wOut<outWidth;++wOut){const wBeg=wOut*strideWidth-padInfo.left;for(let d=0;d<inChannels;++d){let curVal=Number.MIN_SAFE_INTEGER,hInMax=hBeg<0?0:hBeg,wInMax=wBeg<0?0:wBeg;for(let h=0;h<filterHeight;++h){const hIn=hBeg+h*dilationHeight;if(hIn>=0&&hIn<inHeight)for(let w=0;w<filterWidth;++w){const wIn=wBeg+w*dilationWidth;if(wIn>=0&&wIn<inWidth){const val=$x[b][hIn][wIn][d]+$filter[h][w][d];val>curVal&&(curVal=val,hInMax=hIn,wInMax=wIn)}}}gradients[b][hInMax][wInMax][d]+=$dy[b][hOut][wOut][d]}}}return{dataId:cpuBackend.write(dist.ZSL.toTypedArray(gradients,x.dtype),x.shape,x.dtype),shape:x.shape,dtype:x.dtype}}};const drawConfig={kernelName:dist.XmO,backendName:"cpu",kernelFunc:function draw(args){const{inputs,backend,attrs}=args,{image}=inputs,{canvas,options}=attrs,{contextOptions,imageOptions}=options||{},alpha=(null==imageOptions?void 0:imageOptions.alpha)||1,contextType=(null==contextOptions?void 0:contextOptions.contextType)||"2d";if("2d"!==contextType)throw new Error(`Context type ${contextOptions.contextType} is not supported by the CPU backend.`);const ctx=canvas.getContext(contextType,(null==contextOptions?void 0:contextOptions.contextAttributes)||{});if(null==ctx)throw new Error(`Could not get the context with ${contextType} type.`);const[height,width]=image.shape.slice(0,2),depth=2===image.shape.length?1:image.shape[2],data=backend.data.get(image.dataId).values,multiplier="float32"===image.dtype?255:1,bytes=new Uint8ClampedArray(width*height*4);for(let i=0;i<height*width;++i){const rgba=[0,0,0,255*alpha];for(let d=0;d<depth;d++){const value=data[i*depth+d];if("float32"===image.dtype){if(value<0||value>1)throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${value}.`)}else if("int32"===image.dtype&&(value<0||value>255))throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${value}.`);1===depth?(rgba[0]=value*multiplier,rgba[1]=value*multiplier,rgba[2]=value*multiplier):rgba[d]=value*multiplier}const j=4*i;bytes[j+0]=Math.round(rgba[0]),bytes[j+1]=Math.round(rgba[1]),bytes[j+2]=Math.round(rgba[2]),bytes[j+3]=Math.round(rgba[3])}canvas.width=width,canvas.height=height;const imageData=new ImageData(bytes,width,height);return ctx.putImageData(imageData,0,0),image}};function Sum_sum(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,keepDims}=attrs;let $x;(0,cpu_util.C)(x,"sum"),$x="bool"===x.dtype?Cast_cast({inputs:{x},backend,attrs:{dtype:"int32"}}):Identity_identity({inputs:{x},backend});const xRank=$x.shape.length,axes=dist.ZSL.parseAxisParam(axis,$x.shape),permutation=dist.C0T.getAxesPermutation(axes,xRank);let reductionAxes=axes,permutedX=$x;null!=permutation&&(permutedX=Transpose_transpose({inputs:{x:$x},backend,attrs:{perm:permutation}}),reductionAxes=dist.C0T.getInnerMostAxes(reductionAxes.length,xRank)),dist.C0T.assertAxesAreInnerMostDims("sum",reductionAxes,permutedX.shape.length);const[outShape,reduceShape]=dist.C0T.computeOutAndReduceShapes(permutedX.shape,reductionAxes);let result=zeros_impl_zeros(backend,outShape,dist.C0T.upcastType(permutedX.dtype,"int32"));const reduceSize=dist.ZSL.sizeFromShape(reduceShape),vals=backend.data.get(result.dataId).values,aVals=backend.data.get(permutedX.dataId).values;for(let i=0;i<vals.length;++i){const offset=i*reduceSize;let sum=0;for(let j=0;j<reduceSize;++j)sum+=aVals[offset+j];vals[i]=sum}if(keepDims){const oldResult=result;result=Reshape_reshape({inputs:{x:result},backend,attrs:{shape:dist.C0T.expandShapeToKeepDim(result.shape,axes)}}),backend.disposeIntermediateTensorInfo(oldResult)}return backend.disposeIntermediateTensorInfo($x),null!=permutation&&backend.disposeIntermediateTensorInfo(permutedX),result}const sumConfig={kernelName:dist.WuN,backendName:"cpu",kernelFunc:Sum_sum};const einsumConfig={kernelName:dist.Qgm,backendName:"cpu",kernelFunc:function einsum(args){const{inputs,backend,attrs}=args,{equation}=attrs,tensors=inputs,{allDims,summedDims,idDims}=dist.C0T.decodeEinsumEquation(equation,tensors.length);dist.C0T.checkEinsumDimSizes(allDims.length,idDims,tensors);const{path,steps}=dist.C0T.getEinsumComputePath(summedDims,idDims),nSteps=steps.length;let out=null,numDimsRemaining=allDims.length;const tensorsToDispose=[];for(let i=0;i<nSteps;++i){for(const idTerm of steps[i]){const{permutationIndices:perm,expandDims:dimsToExpand}=dist.C0T.getEinsumPermutation(numDimsRemaining,idDims[idTerm]);let x;dist.C0T.isIdentityPermutation(perm)?x=tensors[idTerm]:(x=Transpose_transpose({inputs:{x:tensors[idTerm]},backend,attrs:{perm}}),tensorsToDispose.push(x));const targetShape=x.shape.slice();for(let k=0;k<dimsToExpand.length;++k)targetShape.splice(dimsToExpand[k],0,1);dist.ZSL.arraysEqual(x.shape,targetShape)||(x=Reshape_reshape({inputs:{x},backend,attrs:{shape:targetShape}}),tensorsToDispose.push(x)),null===out?out=x:(out=Multiply_multiply({inputs:{a:x,b:out},backend}),tensorsToDispose.push(out))}i<nSteps-1&&(path[i]>=0&&(out=Sum_sum({inputs:{x:out},backend,attrs:{axis:path[i]-(allDims.length-numDimsRemaining),keepDims:!1}}),tensorsToDispose.push(out)),numDimsRemaining--)}for(const tensorInfo of tensorsToDispose)tensorInfo!==out&&backend.disposeIntermediateTensorInfo(tensorInfo);return out}};const EluGrad_eluGradConfig={kernelName:dist.rsH,backendName:"cpu",kernelFunc:function eluGrad(args){const{inputs,backend}=args,{dy,y}=inputs;(0,cpu_util.C)([dy,y],"eluGrad");const resultValues=new Float32Array(dist.ZSL.sizeFromShape(y.shape)),values=backend.data.get(y.dataId).values,dyValues=backend.data.get(dy.dataId).values;for(let i=0;i<values.length;++i){const v=values[i];resultValues[i]=v>=0?dyValues[i]:dyValues[i]*(v+1)}return backend.makeTensorInfo(y.shape,"float32",resultValues)}},p=dist.C0T.ERF_P,a1=dist.C0T.ERF_A1,a2=dist.C0T.ERF_A2,a3=dist.C0T.ERF_A3,a4=dist.C0T.ERF_A4,a5=dist.C0T.ERF_A5,Erf_erf=unaryKernelFunc(dist._s9,xi=>{const sign=Math.sign(xi),v=Math.abs(xi),t=1/(1+p*v);return sign*(1-((((a5*t+a4)*t+a3)*t+a2)*t+a1)*t*Math.exp(-v*v))}),erfConfig={kernelName:dist._s9,backendName:"cpu",kernelFunc:Erf_erf};function ExpandDims_expandDims(args){const{inputs,backend,attrs}=args,{input}=inputs,{dim}=attrs,inputRank=input.shape.length,newShape=input.shape.slice();let $dim=dim;return dim<0&&(dist.ZSL.assert(-(inputRank+1)<=dim,()=>`Axis must be in the interval [${-(inputRank+1)}, ${inputRank}]`),$dim=inputRank+dim+1),newShape.splice($dim,0,1),Reshape_reshape({inputs:{x:input},backend,attrs:{shape:newShape}})}const expandDimsConfig={kernelName:dist.ybN,backendName:"cpu",kernelFunc:ExpandDims_expandDims},realDivImpl=createSimpleBinaryKernelImpl((a,b)=>a/b),RealDiv_div=binaryKernelFunc(dist.sDr,realDivImpl),realDivConfig={kernelName:dist.sDr,backendName:"cpu",kernelFunc:RealDiv_div};function fftBatch(input,inverse,cpuBackend){const inputShape=input.shape,batch=inputShape[0],innerDim=inputShape[1],inputVals=cpuBackend.data.get(input.dataId),real2D=inputVals.complexTensorInfos.real,imag2D=inputVals.complexTensorInfos.imag,resultShape=[batch,innerDim],resultSize=dist.ZSL.sizeFromShape(resultShape),resultReal=dist.ZSL.getTypedArrayFromDType("float32",resultSize),resultImag=dist.ZSL.getTypedArrayFromDType("float32",resultSize);for(let b=0;b<batch;b++){const r=(0,Slice.di)({inputs:{x:real2D},backend:cpuBackend,attrs:{begin:[b,0],size:[1,innerDim]}}),i=(0,Slice.di)({inputs:{x:imag2D},backend:cpuBackend,attrs:{begin:[b,0],size:[1,innerDim]}}),input=complex({inputs:{real:r,imag:i},backend:cpuBackend}),{real,imag}=fftImpl(input,inverse,cpuBackend),res=dist.C0T.mergeRealAndImagArrays(real,imag);for(let d=0;d<innerDim;d++){const c=dist.C0T.getComplexWithIndex(res,d);resultReal[b*innerDim+d]=c.real,resultImag[b*innerDim+d]=c.imag}cpuBackend.disposeIntermediateTensorInfo(r),cpuBackend.disposeIntermediateTensorInfo(i),cpuBackend.disposeIntermediateTensorInfo(input)}const $realInfo=cpuBackend.makeTensorInfo(resultShape,"float32",resultReal),$imagInfo=cpuBackend.makeTensorInfo(resultShape,"float32",resultImag),result=complex({inputs:{real:$realInfo,imag:$imagInfo},backend:cpuBackend});return cpuBackend.disposeIntermediateTensorInfo($realInfo),cpuBackend.disposeIntermediateTensorInfo($imagInfo),result}function fftImpl(input,inverse,cpuBackend){const inputSize=dist.ZSL.sizeFromShape(input.shape),inputVals=cpuBackend.data.get(input.dataId),realVals=cpuBackend.data.get(inputVals.complexTensorInfos.real.dataId).values,imagVals=cpuBackend.data.get(inputVals.complexTensorInfos.imag.dataId).values;if(function isExponentOf2(size){return!(size&size-1)}(inputSize)){const result=fftRadix2(realVals,imagVals,inputSize,inverse,cpuBackend),resultShape=[input.shape[0],input.shape[1]];if(inverse){const realInfo=cpuBackend.makeTensorInfo(resultShape,"float32",result.real),imagInfo=cpuBackend.makeTensorInfo(resultShape,"float32",result.imag),sizeInfo=cpuBackend.makeTensorInfo([],"float32",dist.ZSL.createScalarValue(inputSize,"float32")),sizeInfoCopy=Identity_identity({inputs:{x:sizeInfo},backend:cpuBackend}),divRealInfo=realDivConfig.kernelFunc({inputs:{a:realInfo,b:sizeInfo},backend:cpuBackend}),divImagInfo=realDivConfig.kernelFunc({inputs:{a:imagInfo,b:sizeInfoCopy},backend:cpuBackend}),divRealVals=cpuBackend.data.get(divRealInfo.dataId).values,divImagVals=cpuBackend.data.get(divImagInfo.dataId).values;return cpuBackend.disposeIntermediateTensorInfo(realInfo),cpuBackend.disposeIntermediateTensorInfo(imagInfo),cpuBackend.disposeIntermediateTensorInfo(sizeInfo),cpuBackend.disposeIntermediateTensorInfo(sizeInfoCopy),cpuBackend.disposeIntermediateTensorInfo(divRealInfo),cpuBackend.disposeIntermediateTensorInfo(divImagInfo),{real:divRealVals,imag:divImagVals}}return result}{const rawOutput=function fourierTransformByMatmul(data,size,inverse){const ret=new Float32Array(2*size);for(let r=0;r<size;r++){let real=0,imag=0;for(let c=0;c<size;c++){const e=dist.C0T.exponent(r*c,size,inverse),term=dist.C0T.getComplexWithIndex(data,c);real+=term.real*e.real-term.imag*e.imag,imag+=term.real*e.imag+term.imag*e.real}inverse&&(real/=size,imag/=size),dist.C0T.assignToTypedArray(ret,real,imag,r)}return ret}(dist.C0T.mergeRealAndImagArrays(realVals,imagVals),inputSize,inverse);return dist.C0T.splitRealAndImagArrays(rawOutput)}}function fftRadix2(realVals,imagVals,size,inverse,cpuBackend){if(1===size)return{real:realVals,imag:imagVals};const data=dist.C0T.mergeRealAndImagArrays(realVals,imagVals),half=size/2,evenComplex=dist.C0T.complexWithEvenIndex(data),evenRealVals=evenComplex.real,evenImagVals=evenComplex.imag,evenShape=[evenRealVals.length],evenRealInfo=cpuBackend.makeTensorInfo(evenShape,"float32",evenRealVals),evenImagInfo=cpuBackend.makeTensorInfo(evenShape,"float32",evenImagVals),evenTensorInfo=complex({inputs:{real:evenRealInfo,imag:evenImagInfo},backend:cpuBackend}),oddComplex=dist.C0T.complexWithOddIndex(data),oddRealVals=oddComplex.real,oddImagVals=oddComplex.imag,oddShape=[oddRealVals.length],oddRealInfo=cpuBackend.makeTensorInfo(oddShape,"float32",oddRealVals),oddImagInfo=cpuBackend.makeTensorInfo(oddShape,"float32",oddImagVals),oddTensorInfo=complex({inputs:{real:oddRealInfo,imag:oddImagInfo},backend:cpuBackend}),$evenComplex=fftRadix2(evenRealVals,evenImagVals,half,inverse,cpuBackend),$evenRealVals=$evenComplex.real,$evenImagVals=$evenComplex.imag,$evenShape=[$evenRealVals.length],$evenRealInfo=cpuBackend.makeTensorInfo($evenShape,"float32",$evenRealVals),$evenImagInfo=cpuBackend.makeTensorInfo($evenShape,"float32",$evenImagVals),$evenTensorInfo=complex({inputs:{real:$evenRealInfo,imag:$evenImagInfo},backend:cpuBackend}),$oddComplex=fftRadix2(oddRealVals,oddImagVals,half,inverse,cpuBackend),$oddRealVals=$oddComplex.real,$oddImagVals=$oddComplex.imag,$oddShape=[$oddRealVals.length],$oddRealInfo=cpuBackend.makeTensorInfo($oddShape,"float32",$oddRealVals),$oddImagInfo=cpuBackend.makeTensorInfo($oddShape,"float32",$oddImagVals),$oddTensorInfo=complex({inputs:{real:$oddRealInfo,imag:$oddImagInfo},backend:cpuBackend}),e=dist.C0T.exponents(size,inverse),eShape=[e.real.length],eRealInfo=cpuBackend.makeTensorInfo(eShape,"float32",e.real),eImagInfo=cpuBackend.makeTensorInfo(eShape,"float32",e.imag),complexInfo=complex({inputs:{real:eRealInfo,imag:eImagInfo},backend:cpuBackend}),exponentInfo=Multiply_multiply({inputs:{a:complexInfo,b:$oddTensorInfo},backend:cpuBackend}),addPart=Add_add({inputs:{a:$evenTensorInfo,b:exponentInfo},backend:cpuBackend}),subPart=Sub_sub({inputs:{a:$evenTensorInfo,b:exponentInfo},backend:cpuBackend}),addPartReal=real({inputs:{input:addPart},backend:cpuBackend}),subPartReal=real({inputs:{input:subPart},backend:cpuBackend}),addPartImag=imag({inputs:{input:addPart},backend:cpuBackend}),subPartImag=imag({inputs:{input:subPart},backend:cpuBackend}),$real=Concat_concat({inputs:[addPartReal,subPartReal],backend:cpuBackend,attrs:{axis:0}}),$imag=Concat_concat({inputs:[addPartImag,subPartImag],backend:cpuBackend,attrs:{axis:0}}),$realVals=cpuBackend.data.get($real.dataId).values,$imagVals=cpuBackend.data.get($imag.dataId).values;return cpuBackend.disposeIntermediateTensorInfo(evenRealInfo),cpuBackend.disposeIntermediateTensorInfo(evenImagInfo),cpuBackend.disposeIntermediateTensorInfo(evenTensorInfo),cpuBackend.disposeIntermediateTensorInfo(oddRealInfo),cpuBackend.disposeIntermediateTensorInfo(oddImagInfo),cpuBackend.disposeIntermediateTensorInfo(oddTensorInfo),cpuBackend.disposeIntermediateTensorInfo($evenRealInfo),cpuBackend.disposeIntermediateTensorInfo($evenImagInfo),cpuBackend.disposeIntermediateTensorInfo($evenTensorInfo),cpuBackend.disposeIntermediateTensorInfo($oddRealInfo),cpuBackend.disposeIntermediateTensorInfo($oddImagInfo),cpuBackend.disposeIntermediateTensorInfo($oddTensorInfo),cpuBackend.disposeIntermediateTensorInfo(eRealInfo),cpuBackend.disposeIntermediateTensorInfo(eImagInfo),cpuBackend.disposeIntermediateTensorInfo(complexInfo),cpuBackend.disposeIntermediateTensorInfo(exponentInfo),cpuBackend.disposeIntermediateTensorInfo(addPart),cpuBackend.disposeIntermediateTensorInfo(subPart),cpuBackend.disposeIntermediateTensorInfo(addPartReal),cpuBackend.disposeIntermediateTensorInfo(addPartImag),cpuBackend.disposeIntermediateTensorInfo(subPartReal),cpuBackend.disposeIntermediateTensorInfo(subPartImag),cpuBackend.disposeIntermediateTensorInfo($real),cpuBackend.disposeIntermediateTensorInfo($imag),{real:$realVals,imag:$imagVals}}const fftConfig={kernelName:dist.rGP,backendName:"cpu",kernelFunc:function FFT_fft(args){const{inputs,backend}=args,{input}=inputs,inputSize=dist.ZSL.sizeFromShape(input.shape),innerDimensionSize=input.shape[input.shape.length-1],input2D=Reshape_reshape({inputs:{x:input},backend,attrs:{shape:[inputSize/innerDimensionSize,innerDimensionSize]}}),result=fftBatch(input2D,!1,backend),resultReshaped=Reshape_reshape({inputs:{x:result},backend,attrs:{shape:input.shape}});return backend.disposeIntermediateTensorInfo(input2D),backend.disposeIntermediateTensorInfo(result),resultReshaped}};function fill(args){const{backend,attrs}=args,{shape,value,dtype}=attrs,$dtype=dtype||dist.ZSL.inferDtype(value),values=dist.ZSL.getArrayFromDType($dtype,dist.ZSL.sizeFromShape(shape));return function fillValues(values,value,dtype){values.fill(value)}(values,value),backend.makeTensorInfo(shape,$dtype,values)}const fillConfig={kernelName:dist.SQl,backendName:"cpu",kernelFunc:fill};const flipLeftRightConfig={kernelName:dist.BxF,backendName:"cpu",kernelFunc:({inputs,attrs,backend})=>{const{image}=inputs,cpuBackend=backend,output=dist.ZSL.getTypedArrayFromDType(image.dtype,dist.ZSL.sizeFromShape(image.shape)),[batch,imageHeight,imageWidth,numChannels]=image.shape,imageVals=cpuBackend.data.get(image.dataId).values;for(let batchIdx=0;batchIdx<batch;batchIdx++){const batchOffset=batchIdx*imageWidth*imageHeight*numChannels;for(let row=0;row<imageHeight;row++){const rowOffset=row*(imageWidth*numChannels);for(let col=0;col<imageWidth;col++){const colOffset=col*numChannels;for(let channel=0;channel<numChannels;channel++){const coordX=Math.round(imageWidth-col-1),outIdx=batchOffset+rowOffset+colOffset+channel;let outputValue=imageVals[outIdx];if(coordX>=0&&coordX<imageWidth){outputValue=imageVals[batchOffset+rowOffset+coordX*numChannels+channel]}output[outIdx]=outputValue}}}}return{dataId:cpuBackend.write(output,image.shape,image.dtype),shape:image.shape,dtype:image.dtype}}};const fusedConv2DConfig={kernelName:dist.aAr,backendName:"cpu",kernelFunc:function fusedConv2D(args){const{inputs,backend,attrs}=args,{x,filter,bias,preluActivationWeights}=inputs,{strides,pad,dataFormat,dilations,dimRoundingMode,activation,leakyreluAlpha}=attrs;let result=conv2D({inputs:{x,filter},backend,attrs:{strides,pad,dataFormat,dilations,dimRoundingMode}});if(bias){const resultOld=result;if("NCHW"===dataFormat&&1===bias.shape.length&&1!==bias.shape[0]){const reshapedBias=Reshape_reshape({inputs:{x:bias},backend,attrs:{shape:[bias.shape[0],1,1]}});result=Add_add({inputs:{a:result,b:reshapedBias},backend}),backend.disposeIntermediateTensorInfo(reshapedBias)}else result=Add_add({inputs:{a:result,b:bias},backend});backend.disposeIntermediateTensorInfo(resultOld)}if(activation){const resultOld=result;if("NCHW"===dataFormat&&"prelu"===activation&&1===preluActivationWeights.shape.length&&1!==preluActivationWeights.shape[0]){const reshapedAlpha=Reshape_reshape({inputs:{x:preluActivationWeights},backend,attrs:{shape:[preluActivationWeights.shape[0],1,1]}});result=applyActivation(backend,result,activation,reshapedAlpha,leakyreluAlpha),backend.disposeIntermediateTensorInfo(reshapedAlpha)}else result=applyActivation(backend,result,activation,preluActivationWeights,leakyreluAlpha);backend.disposeIntermediateTensorInfo(resultOld)}return result}};const fusedDepthwiseConv2DConfig={kernelName:dist.T7M,backendName:"cpu",kernelFunc:function fusedDepthwiseConv2D(args){const{inputs,backend,attrs}=args,{x,filter,bias,preluActivationWeights}=inputs,{strides,pad,dataFormat,dilations,dimRoundingMode,activation,leakyreluAlpha}=attrs;let result=depthwiseConv2dNative({inputs:{x,filter},backend,attrs:{strides,pad,dataFormat,dilations,dimRoundingMode}});if(bias){const oldResult=result;result=Add_add({inputs:{a:result,b:bias},backend}),backend.disposeIntermediateTensorInfo(oldResult)}if(activation){const oldResult=result;result=applyActivation(backend,result,activation,preluActivationWeights,leakyreluAlpha),backend.disposeIntermediateTensorInfo(oldResult)}return result}};const gatherNdConfig={kernelName:dist.O4G,backendName:"cpu",kernelFunc:function gatherNd(args){const{inputs,backend}=args,{params,indices}=inputs,paramsSize=dist.ZSL.sizeFromShape(params.shape),indicesShape=indices.shape,sliceRank=indicesShape[indicesShape.length-1],[resultShape,numSlices,sliceSize,strides]=dist.C0T.prepareAndValidate(params,indices);if(0===numSlices)return backend.makeTensorInfo(resultShape,params.dtype,[]);const outBuf=gatherNdImpl(backend.data.get(indices.dataId).values,backend.bufferSync(params),params.dtype,numSlices,sliceRank,sliceSize,strides,params.shape,paramsSize);return backend.makeTensorInfo(resultShape,params.dtype,outBuf.values)}};const gatherV2Config={kernelName:dist.mxL,backendName:"cpu",kernelFunc:function gatherV2(args){const{inputs,backend,attrs}=args,{x,indices}=inputs,{axis,batchDims}=attrs;(0,cpu_util.C)([x,indices],"gatherV2");const parsedAxis=dist.ZSL.parseAxisParam(axis,x.shape)[0],indicesVals=backend.data.get(indices.dataId).values,axisDim=x.shape[parsedAxis];for(let i=0;i<indicesVals.length;++i){const index=indicesVals[i];dist.ZSL.assert(index<=axisDim-1&&index>=0,()=>`GatherV2: the index value ${index} is not in [0, ${axisDim-1}]`)}let $batchDims=batchDims;null==batchDims&&($batchDims=0);const indicesSize=dist.ZSL.sizeFromShape(indices.shape),shapeInfo=dist.C0T.segment_util.collectGatherOpShapeInfo(x,indices,parsedAxis,$batchDims),flattenX=Reshape_reshape({inputs:{x},backend,attrs:{shape:[shapeInfo.batchSize,shapeInfo.outerSize,shapeInfo.dimSize,shapeInfo.sliceSize]}}),flattenIndex=Reshape_reshape({inputs:{x:indices},backend,attrs:{shape:[shapeInfo.batchSize,indicesSize/shapeInfo.batchSize]}}),flattenOutputShape=[shapeInfo.batchSize,shapeInfo.outerSize,indicesSize/shapeInfo.batchSize,shapeInfo.sliceSize],indicesBuf=backend.bufferSync(flattenIndex),outBuf=gatherV2Impl(backend.bufferSync(flattenX),indicesBuf,flattenOutputShape);return backend.disposeIntermediateTensorInfo(flattenX),backend.disposeIntermediateTensorInfo(flattenIndex),backend.makeTensorInfo(shapeInfo.outputShape,outBuf.dtype,outBuf.values)}};const ifftConfig={kernelName:dist.OAQ,backendName:"cpu",kernelFunc:function IFFT_ifft(args){const{inputs,backend}=args,{input}=inputs,inputSize=dist.ZSL.sizeFromShape(input.shape),innerDimensionSize=input.shape[input.shape.length-1],input2D=Reshape_reshape({inputs:{x:input},backend,attrs:{shape:[inputSize/innerDimensionSize,innerDimensionSize]}}),result=fftBatch(input2D,!0,backend),resultReshaped=Reshape_reshape({inputs:{x:result},backend,attrs:{shape:input.shape}});return backend.disposeIntermediateTensorInfo(input2D),backend.disposeIntermediateTensorInfo(result),resultReshaped}},IsFinite_isFinite=unaryKernelFunc(dist.gIW,xi=>Number.isFinite(xi)?1:0,"bool"),isFiniteConfig={kernelName:dist.gIW,backendName:"cpu",kernelFunc:IsFinite_isFinite},isInf=unaryKernelFunc(dist.E3$,xi=>Math.abs(xi)===1/0?1:0,"bool"),isInfConfig={kernelName:dist.E3$,backendName:"cpu",kernelFunc:isInf},IsNaN_isNaN=unaryKernelFunc(dist.iPs,xi=>Number.isNaN(xi)?1:0,"bool"),isNaNConfig={kernelName:dist.iPs,backendName:"cpu",kernelFunc:IsNaN_isNaN};const linSpaceConfig={kernelName:dist.mnI,backendName:"cpu",kernelFunc:function linSpace(args){const{backend,attrs}=args,{start,stop,num}=attrs,outVals=linSpaceImpl(start,stop,num);return backend.makeTensorInfo([outVals.length],"float32",outVals)}},Log1p_log1p=unaryKernelFunc(dist.Cg$,xi=>Math.log1p(xi)),log1pConfig={kernelName:dist.Cg$,backendName:"cpu",kernelFunc:Log1p_log1p},logicalAndImpl=createSimpleBinaryKernelImpl((a,b)=>a&&b),logicalAnd=binaryKernelFunc(dist.RUm,logicalAndImpl,null,"bool"),logicalAndConfig={kernelName:dist.RUm,backendName:"cpu",kernelFunc:logicalAnd},logicalNot=unaryKernelFunc(dist.nZd,xi=>xi?0:1,"bool"),logicalNotConfig={kernelName:dist.nZd,backendName:"cpu",kernelFunc:logicalNot},logicalOrImpl=createSimpleBinaryKernelImpl((a,b)=>a||b),logicalOr=binaryKernelFunc(dist.LXA,logicalOrImpl,null,"bool"),logicalOrConfig={kernelName:dist.LXA,backendName:"cpu",kernelFunc:logicalOr};const LRNConfig={kernelName:dist.jM4,backendName:"cpu",kernelFunc:function lRN(args){const{inputs,backend,attrs}=args,{x}=inputs,{depthRadius,bias,alpha,beta}=attrs;(0,cpu_util.C)(x,"LRN");const channels=x.shape[3],maxD=channels-1,xValues=backend.data.get(x.dataId).values,size=dist.ZSL.sizeFromShape(x.shape),result=new Float32Array(size);function sumAcrossChannels(offset){const currentChannel=offset%channels;let beginSumOffset=offset-currentChannel+Math.max(0,currentChannel-depthRadius);const endSumOffset=offset-currentChannel+Math.min(currentChannel+depthRadius,maxD);let sum=0;for(;beginSumOffset<=endSumOffset;beginSumOffset++){const z=xValues[beginSumOffset];sum+=z*z}return sum}for(let offset=0;offset<size;offset++){const sum=sumAcrossChannels(offset),val=xValues[offset]*Math.pow(bias+alpha*sum,-beta);result[offset]=val}return backend.makeTensorInfo(x.shape,x.dtype,result)}};const LRNGradConfig={kernelName:dist.ToN,backendName:"cpu",kernelFunc:function lRNGrad(args){const{inputs,backend,attrs}=args,{x,y,dy}=inputs,{depthRadius,bias,alpha,beta}=attrs;(0,cpu_util.C)(dy,"LRNGrad");const dySize=dist.ZSL.sizeFromShape(dy.shape),channels=dy.shape[3],dyValues=backend.data.get(dy.dataId).values,xValues=backend.data.get(x.dataId).values,yValues=backend.data.get(y.dataId).values,result=new Float32Array(dySize),size=dySize;for(let offset=0;offset<size;offset++){const currentChannel=offset%channels,depthBegin=offset-currentChannel+Math.max(0,currentChannel-depthRadius),depthEnd=offset-currentChannel+Math.min(channels,currentChannel+depthRadius+1);let norm=0;for(let k=depthBegin;k<depthEnd;k++)norm+=Math.pow(xValues[k],2);norm=alpha*norm+bias;for(let k=depthBegin;k<depthEnd;k++){let dyi=-2*alpha*beta*xValues[k]*yValues[offset]/norm;offset===k&&(dyi+=Math.pow(norm,-beta)),dyi*=dyValues[offset],result[k]+=dyi}}return backend.makeTensorInfo(dy.shape,x.dtype,result)}};function Max_max(args){const{inputs,backend,attrs}=args,{x}=inputs,{reductionIndices,keepDims}=attrs,cpuBackend=backend;let xShape=x.shape;const xRank=xShape.length,origAxes=dist.ZSL.parseAxisParam(reductionIndices,xShape);let axes=origAxes;const permutedAxes=dist.C0T.getAxesPermutation(axes,xRank);let xVals=cpuBackend.data.get(x.dataId).values;if(null!=permutedAxes){const newShape=new Array(xRank);for(let i=0;i<newShape.length;i++)newShape[i]=xShape[permutedAxes[i]];xVals=transposeImpl(xVals,xShape,x.dtype,permutedAxes,newShape),axes=dist.C0T.getInnerMostAxes(axes.length,xRank),xShape=newShape}(0,cpu_util.C)(x,"max"),dist.C0T.assertAxesAreInnerMostDims("max",axes,xRank);const[maxOutShape,reduceShape]=dist.C0T.computeOutAndReduceShapes(xShape,axes),result=maxImpl(xVals,dist.ZSL.sizeFromShape(reduceShape),maxOutShape,x.dtype),dataId=cpuBackend.write(result,maxOutShape,x.dtype);let outShape=maxOutShape;if(keepDims){outShape=dist.C0T.expandShapeToKeepDim(maxOutShape,origAxes)}return{dataId,shape:outShape,dtype:x.dtype}}const maxConfig={kernelName:dist.VAI,backendName:"cpu",kernelFunc:Max_max};const maxPoolConfig={kernelName:dist.t3d,backendName:"cpu",kernelFunc:function maxPool(args){const{inputs,backend,attrs}=args,{x}=inputs;(0,cpu_util.C)(x,"maxPool");const{filterSize,strides,pad,dimRoundingMode}=attrs;dist.ZSL.assert(dist.C0T.eitherStridesOrDilationsAreOne(strides,1),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '1'`);const convInfo=dist.C0T.computePool2DInfo(x.shape,filterSize,strides,1,pad,dimRoundingMode);let res;if(1===convInfo.filterWidth&&1===convInfo.filterHeight&&dist.ZSL.arraysEqual(convInfo.inShape,convInfo.outShape))res=Identity_identity({inputs:{x},backend});else{const xValues=backend.data.get(x.dataId).values,strides=dist.ZSL.computeStrides(x.shape),buffer=pool_utils_pool(xValues,x.shape,x.dtype,strides,convInfo,"max");res=backend.makeTensorInfo(convInfo.outShape,x.dtype,buffer.values)}return res}};const maxPool3DConfig={kernelName:dist.ySp,backendName:"cpu",kernelFunc:function maxPool3D(args){const{inputs,backend,attrs}=args,{x}=inputs,{filterSize,strides,pad,dimRoundingMode,dataFormat}=attrs;(0,cpu_util.C)(x,"maxPool3d");const convInfo=dist.C0T.computePool3DInfo(x.shape,filterSize,strides,1,pad,dimRoundingMode,dataFormat),outBuf=pool_utils_pool3d(backend.data.get(x.dataId).values,x.shape,x.dtype,dist.ZSL.computeStrides(x.shape),convInfo,"max");return backend.makeTensorInfo(outBuf.shape,"float32",outBuf.values)}};const MaxPool3DGrad_maxPool3DGradConfig={kernelName:dist.cHb,backendName:"cpu",kernelFunc:function maxPool3DGrad(args){const{inputs,backend,attrs}=args,{dy,input}=inputs,{filterSize,strides,pad,dimRoundingMode}=attrs;(0,cpu_util.C)([dy,input],"maxPool3DGrad");const convInfo=dist.C0T.computePool3DInfo(input.shape,filterSize,strides,1,pad,dimRoundingMode),maxPosBuf=function maxPool3dPositions(xBuf,convInfo){const maxPositions=(0,dist.ra8)(convInfo.outShape,"int32"),strideDepth=convInfo.strideDepth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationDepth=convInfo.dilationDepth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,effectiveFilterDepth=convInfo.effectiveFilterDepth,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padFront=convInfo.padInfo.front,padTop=convInfo.padInfo.top,padLeft=convInfo.padInfo.left;for(let batch=0;batch<convInfo.batchSize;++batch)for(let channel=0;channel<convInfo.inChannels;++channel)for(let yDepth=0;yDepth<convInfo.outDepth;++yDepth){const xDepthCorner=yDepth*strideDepth-padFront;let xDepthMin=xDepthCorner;for(;xDepthMin<0;)xDepthMin+=dilationDepth;const xDepthMax=Math.min(convInfo.inDepth,effectiveFilterDepth+xDepthCorner);for(let yRow=0;yRow<convInfo.outHeight;++yRow){const xRowCorner=yRow*strideHeight-padTop;let xRowMin=xRowCorner;for(;xRowMin<0;)xRowMin+=dilationHeight;const xRowMax=Math.min(convInfo.inHeight,effectiveFilterHeight+xRowCorner);for(let yCol=0;yCol<convInfo.outWidth;++yCol){const xColCorner=yCol*strideWidth-padLeft;let xColMin=xColCorner;for(;xColMin<0;)xColMin+=dilationWidth;const xColMax=Math.min(convInfo.inWidth,effectiveFilterWidth+xColCorner);let maxValue=Number.NEGATIVE_INFINITY,maxPosition=-1;for(let xDepth=xDepthMin;xDepth<xDepthMax;xDepth+=dilationDepth){const wDepth=xDepth-xDepthCorner;for(let xRow=xRowMin;xRow<xRowMax;xRow+=dilationHeight){const wRow=xRow-xRowCorner;for(let xCol=xColMin;xCol<xColMax;xCol+=dilationWidth){const wCol=xCol-xColCorner,pixel=xBuf.get(batch,xDepth,xRow,xCol,channel);pixel>=maxValue&&(maxValue=pixel,maxPosition=wDepth*effectiveFilterHeight*effectiveFilterWidth+wRow*effectiveFilterHeight+wCol)}}}maxPositions.set(maxPosition,batch,yDepth,yRow,yCol,channel)}}}return maxPositions}(backend.bufferSync(input),convInfo),strideDepth=convInfo.strideDepth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationDepth=convInfo.dilationDepth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,effectiveFilterDepth=convInfo.effectiveFilterDepth,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padFront=effectiveFilterDepth-1-convInfo.padInfo.front,padLeft=effectiveFilterWidth-1-convInfo.padInfo.left,padTop=effectiveFilterHeight-1-convInfo.padInfo.top,dx=(0,dist.ra8)(input.shape,"float32"),dyBuf=backend.bufferSync(dy);for(let batch=0;batch<convInfo.batchSize;++batch)for(let channel=0;channel<convInfo.inChannels;++channel)for(let dxDepth=0;dxDepth<convInfo.inDepth;++dxDepth)for(let dxRow=0;dxRow<convInfo.inHeight;++dxRow)for(let dxCol=0;dxCol<convInfo.inWidth;++dxCol){const dyDepthCorner=dxDepth-padFront,dyRowCorner=dxRow-padTop,dyColCorner=dxCol-padLeft;let dotProd=0;for(let wDepth=0;wDepth<effectiveFilterDepth;wDepth+=dilationDepth){const dyDepth=(dyDepthCorner+wDepth)/strideDepth;if(!(dyDepth<0||dyDepth>=convInfo.outDepth||Math.floor(dyDepth)!==dyDepth))for(let wRow=0;wRow<effectiveFilterHeight;wRow+=dilationHeight){const dyRow=(dyRowCorner+wRow)/strideHeight;if(!(dyRow<0||dyRow>=convInfo.outHeight||Math.floor(dyRow)!==dyRow))for(let wCol=0;wCol<effectiveFilterWidth;wCol+=dilationWidth){const dyCol=(dyColCorner+wCol)/strideWidth;if(dyCol<0||dyCol>=convInfo.outWidth||Math.floor(dyCol)!==dyCol)continue;const mask=effectiveFilterDepth*effectiveFilterHeight*effectiveFilterWidth-1-maxPosBuf.get(batch,dyDepth,dyRow,dyCol,channel)===wDepth*effectiveFilterHeight*effectiveFilterWidth+wRow*effectiveFilterWidth+wCol?1:0;if(0===mask)continue;dotProd+=dyBuf.get(batch,dyDepth,dyRow,dyCol,channel)*mask}}}dx.set(dotProd,batch,dxDepth,dxRow,dxCol,channel)}return backend.makeTensorInfo(dx.shape,dx.dtype,dx.values)}};const MaxPoolGrad_maxPoolGradConfig={kernelName:dist.RXX,backendName:"cpu",kernelFunc:function MaxPoolGrad_maxPoolGrad(args){const{inputs,backend,attrs}=args,{dy,input,output}=inputs,x=input;(0,cpu_util.C)([input,output],"maxPoolGrad");const{filterSize,strides,pad,dimRoundingMode}=attrs,convInfo=dist.C0T.computePool2DInfo(x.shape,filterSize,strides,1,pad,dimRoundingMode),xValues=backend.data.get(x.dataId).values,maxPosBuf=(0,dist.ra8)(convInfo.outShape,x.dtype,maxPoolPositions(xValues,x.shape,x.dtype,convInfo).values),strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padLeft=effectiveFilterWidth-1-convInfo.padInfo.left,padTop=effectiveFilterHeight-1-convInfo.padInfo.top,dx=(0,dist.ra8)(x.shape,"float32"),dyData=backend.data.get(dy.dataId).values,dyBuf=(0,dist.ra8)(dy.shape,"float32",dyData);for(let b=0;b<convInfo.batchSize;++b)for(let d=0;d<convInfo.inChannels;++d)for(let dxR=0;dxR<convInfo.inHeight;++dxR)for(let dxC=0;dxC<convInfo.inWidth;++dxC){const dyRCorner=dxR-padTop,dyCCorner=dxC-padLeft;let dotProd=0;for(let wR=0;wR<effectiveFilterHeight;wR+=dilationHeight){const dyR=(dyRCorner+wR)/strideHeight;if(!(dyR<0||dyR>=convInfo.outHeight||Math.floor(dyR)!==dyR))for(let wC=0;wC<effectiveFilterWidth;wC+=dilationWidth){const dyC=(dyCCorner+wC)/strideWidth;if(dyC<0||dyC>=convInfo.outWidth||Math.floor(dyC)!==dyC)continue;const mask=effectiveFilterHeight*effectiveFilterWidth-1-maxPosBuf.get(b,dyR,dyC,d)===wR*effectiveFilterWidth+wC?1:0;if(0===mask)continue;dotProd+=dyBuf.get(b,dyR,dyC,d)*mask}}dx.set(dotProd,b,dxR,dxC,d)}return backend.makeTensorInfo(dx.shape,dx.dtype,dx.values)}};const maxPoolWithArgmaxConfig={kernelName:dist.TL8,backendName:"cpu",kernelFunc:({inputs,attrs,backend})=>{const{x}=inputs,{filterSize,strides,pad,includeBatchInIndex}=attrs,cpuBackend=backend;(0,cpu_util.C)(x,"MaxPoolWithArgmax");const values=cpuBackend.data.get(x.dataId).values,convInfo=dist.C0T.computePool2DInfo(x.shape,filterSize,strides,[1,1],pad),[pooled,indexes]=function maxPoolWithArgmaxImpl(xValues,xShape,dtype,includeBatchInIndex,convInfo){const maxPools=pool_utils_pool(xValues,0,dtype,dist.ZSL.computeStrides(xShape),convInfo,"max"),maxPositions=maxPoolPositions(xValues,xShape,dtype,convInfo,!0,includeBatchInIndex);return[maxPools.values,maxPositions.values]}(values,x.shape,x.dtype,includeBatchInIndex,convInfo),pooledDataId=cpuBackend.write(pooled,convInfo.outShape,x.dtype),indexesDataId=cpuBackend.write(indexes,convInfo.outShape,x.dtype);return[{dataId:pooledDataId,shape:convInfo.outShape,dtype:x.dtype},{dataId:indexesDataId,shape:convInfo.outShape,dtype:"int32"}]}};const meanConfig={kernelName:dist.g5A,backendName:"cpu",kernelFunc:function Mean_mean(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,keepDims}=attrs,axes=dist.ZSL.parseAxisParam(axis,x.shape),reduceShape=dist.C0T.computeOutAndReduceShapes(x.shape,axes)[1],reduceSize=dist.ZSL.sizeFromShape(reduceShape),toDispose=[],reduceSizeScalar=backend.makeTensorInfo([],"float32",new Float32Array([reduceSize]));toDispose.push(reduceSizeScalar);const $x=Cast_cast({inputs:{x},backend,attrs:{dtype:"float32"}});toDispose.push($x);const res=RealDiv_div({inputs:{a:$x,b:reduceSizeScalar},backend});toDispose.push(res);const result=Sum_sum({inputs:{x:res},backend,attrs:{axis,keepDims}});return toDispose.forEach(t=>backend.disposeIntermediateTensorInfo(t)),result}};const minConfig={kernelName:dist.lNG,backendName:"cpu",kernelFunc:function Min_min(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,keepDims}=attrs;(0,cpu_util.C)(x,"min");const origAxes=dist.ZSL.parseAxisParam(axis,x.shape);let axes=origAxes;const permutedAxes=dist.C0T.getAxesPermutation(axes,x.shape.length);let $x=x;null!=permutedAxes&&($x=Transpose_transpose({inputs:{x},backend,attrs:{perm:permutedAxes}}),axes=dist.C0T.getInnerMostAxes(axes.length,x.shape.length)),dist.C0T.assertAxesAreInnerMostDims("min",axes,$x.shape.length);const[outShape,reduceShape]=dist.C0T.computeOutAndReduceShapes($x.shape,axes),reduceSize=dist.ZSL.sizeFromShape(reduceShape),vals=dist.ZSL.makeZerosTypedArray(dist.ZSL.sizeFromShape(outShape),$x.dtype),aVals=backend.data.get($x.dataId).values;for(let i=0;i<vals.length;++i){const offset=i*reduceSize;let min=aVals[offset];for(let j=0;j<reduceSize;++j){const value=aVals[offset+j];(Number.isNaN(value)||value<min)&&(min=value)}vals[i]=min}null!=permutedAxes&&backend.disposeIntermediateTensorInfo($x);const result=backend.makeTensorInfo(outShape,$x.dtype,vals);if(keepDims){const reshapedResult=Reshape_reshape({inputs:{x:result},backend,attrs:{shape:dist.C0T.expandShapeToKeepDim(outShape,origAxes)}});return backend.disposeIntermediateTensorInfo(result),reshapedResult}return result}};const mirrorPadConfig={kernelName:dist.x7F,backendName:"cpu",kernelFunc:function mirrorPad(args){const{inputs,backend,attrs}=args,{x}=inputs,{paddings,mode}=attrs;(0,cpu_util.C)(x,"mirrorPad");const outShape=paddings.map((p,i)=>p[0]+x.shape[i]+p[1]),start=paddings.map(p=>p[0]),end=paddings.map((p,i)=>p[0]+x.shape[i]),offset="reflect"===mode?0:1,xVals=backend.data.get(x.dataId).values,xRank=x.shape.length,xStrides=dist.ZSL.computeStrides(x.shape),resultSize=dist.ZSL.sizeFromShape(outShape),resultRank=outShape.length,resultStrides=dist.ZSL.computeStrides(outShape),resVals=dist.ZSL.getTypedArrayFromDType(x.dtype,resultSize);for(let i=0;i<resultSize;i++){let coords=dist.ZSL.indexToLoc(i,resultRank,resultStrides);for(let i=0;i<resultRank;i++)coords[i]<start[i]?coords[i]=2*start[i]-coords[i]-offset:coords[i]>=end[i]&&(coords[i]=2*(end[i]-1)-coords[i]+offset);coords=coords.map((c,i)=>c-start[i]);const inIndex=dist.ZSL.locToIndex(coords,xRank,xStrides);resVals[i]=xVals[inIndex]}return{dataId:backend.write(resVals,outShape,x.dtype),shape:outShape,dtype:x.dtype}}},modImpl=createSimpleBinaryKernelImpl((aValue,bValue)=>{const rem=aValue%bValue;return aValue<0&&bValue<0||aValue>=0&&bValue>=0?rem:(rem+bValue)%bValue}),Mod_mod=binaryKernelFunc(dist.BLA,modImpl),modConfig={kernelName:dist.BLA,backendName:"cpu",kernelFunc:Mod_mod};function Softmax_softmax(args){const{inputs,backend,attrs}=args,{logits}=inputs,{dim}=attrs,logitsRank=logits.shape.length;let $dim=dim;if(-1===$dim&&($dim=logitsRank-1),$dim!==logitsRank-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${logitsRank} and dim was ${$dim}`);const axes=dist.ZSL.parseAxisParam([$dim],logits.shape),maxLogit=Max_max({inputs:{x:logits},backend,attrs:{reductionIndices:axes,keepDims:!1}}),expandedShape=dist.C0T.expandShapeToKeepDim(maxLogit.shape,axes),maxLogitReshaped=Reshape_reshape({inputs:{x:maxLogit},backend,attrs:{shape:expandedShape}}),a=Sub_sub({inputs:{a:logits,b:maxLogitReshaped},backend}),b=Exp_exp({inputs:{x:a},backend}),sumExp=Sum_sum({inputs:{x:b},backend,attrs:{axis:axes,keepDims:!1}}),sumReshaped=Reshape_reshape({inputs:{x:sumExp},backend,attrs:{shape:expandedShape}}),result=RealDiv_div({inputs:{a:b,b:sumReshaped},backend});return backend.disposeIntermediateTensorInfo(maxLogit),backend.disposeIntermediateTensorInfo(maxLogitReshaped),backend.disposeIntermediateTensorInfo(a),backend.disposeIntermediateTensorInfo(b),backend.disposeIntermediateTensorInfo(sumExp),backend.disposeIntermediateTensorInfo(sumReshaped),result}const softmaxConfig={kernelName:dist.rFG,backendName:"cpu",kernelFunc:Softmax_softmax};const multinomialConfig={kernelName:dist.WT3,backendName:"cpu",kernelFunc:function multinomial(args){const{inputs,backend,attrs}=args,{logits}=inputs,{numSamples,seed,normalized}=attrs;(0,cpu_util.C)(logits,"multinomial");const probabilities=normalized?logits:Softmax_softmax({inputs:{logits},backend,attrs:{dim:-1}}),batchSize=probabilities.shape[0],numEvents=probabilities.shape[1],probVals=backend.data.get(probabilities.dataId).values,resShape=[batchSize,numSamples],resVals=dist.ZSL.makeZerosTypedArray(dist.ZSL.sizeFromShape(resShape),"int32");for(let b=0;b<batchSize;++b){const offset=b*numEvents,cdf=new Float32Array(numEvents-1);cdf[0]=probVals[offset];for(let event=1;event<cdf.length;++event)cdf[event]=cdf[event-1]+probVals[offset+event];const random=seedrandom.alea(seed.toString()),outOffset=b*numSamples;for(let sampleId=0;sampleId<numSamples;++sampleId){const r=random();resVals[outOffset+sampleId]=cdf.length;for(let event=0;event<cdf.length;event++)if(r<cdf[event]){resVals[outOffset+sampleId]=event;break}}}return normalized||backend.disposeIntermediateTensorInfo(probabilities),backend.makeTensorInfo(resShape,"int32",resVals)}},nonMaxSuppressionV3Impl=dist.kpo.nonMaxSuppressionV3Impl;const nonMaxSuppressionV3Config={kernelName:dist.SDM,backendName:"cpu",kernelFunc:function nonMaxSuppressionV3(args){const{inputs,backend,attrs}=args,{boxes,scores}=inputs,{maxOutputSize,iouThreshold,scoreThreshold}=attrs;(0,cpu_util.C)(boxes,"NonMaxSuppression");const boxesVals=backend.data.get(boxes.dataId).values,scoresVals=backend.data.get(scores.dataId).values,{selectedIndices}=nonMaxSuppressionV3Impl(boxesVals,scoresVals,maxOutputSize,iouThreshold,scoreThreshold);return backend.makeTensorInfo([selectedIndices.length],"int32",new Int32Array(selectedIndices))}},nonMaxSuppressionV4Impl=dist.kpo.nonMaxSuppressionV4Impl;const nonMaxSuppressionV4Config={kernelName:dist.Zl4,backendName:"cpu",kernelFunc:function nonMaxSuppressionV4(args){const{inputs,backend,attrs}=args,{boxes,scores}=inputs,{maxOutputSize,iouThreshold,scoreThreshold,padToMaxOutputSize}=attrs;(0,cpu_util.C)(boxes,"NonMaxSuppressionPadded");const boxesVals=backend.data.get(boxes.dataId).values,scoresVals=backend.data.get(scores.dataId).values,{selectedIndices,validOutputs}=nonMaxSuppressionV4Impl(boxesVals,scoresVals,maxOutputSize,iouThreshold,scoreThreshold,padToMaxOutputSize);return[backend.makeTensorInfo([selectedIndices.length],"int32",new Int32Array(selectedIndices)),backend.makeTensorInfo([],"int32",new Int32Array([validOutputs]))]}},nonMaxSuppressionV5Impl=dist.kpo.nonMaxSuppressionV5Impl;const nonMaxSuppressionV5Config={kernelName:dist.e0f,backendName:"cpu",kernelFunc:function nonMaxSuppressionV5(args){const{inputs,backend,attrs}=args,{boxes,scores}=inputs,{maxOutputSize,iouThreshold,scoreThreshold,softNmsSigma}=attrs;(0,cpu_util.C)(boxes,"NonMaxSuppressionWithScore");const boxesVals=backend.data.get(boxes.dataId).values,scoresVals=backend.data.get(scores.dataId).values,maxOutputSizeVal=maxOutputSize,iouThresholdVal=iouThreshold,scoreThresholdVal=scoreThreshold,softNmsSigmaVal=softNmsSigma,{selectedIndices,selectedScores}=nonMaxSuppressionV5Impl(boxesVals,scoresVals,maxOutputSizeVal,iouThresholdVal,scoreThresholdVal,softNmsSigmaVal);return[backend.makeTensorInfo([selectedIndices.length],"int32",new Int32Array(selectedIndices)),backend.makeTensorInfo([selectedScores.length],"float32",new Float32Array(selectedScores))]}};const oneHotConfig={kernelName:dist.urI,backendName:"cpu",kernelFunc:function OneHot_oneHot(args){const{inputs,backend,attrs}=args,{indices}=inputs,{dtype,depth,onValue,offValue}=attrs;(0,cpu_util.C)(indices,"oneHot");const indicesSize=dist.ZSL.sizeFromShape(indices.shape),res=new Float32Array(indicesSize*depth);res.fill(offValue);const indicesVal=backend.data.get(indices.dataId).values;for(let event=0;event<indicesSize;++event)indicesVal[event]>=0&&indicesVal[event]<depth&&(res[event*depth+indicesVal[event]]=onValue);return backend.makeTensorInfo([...indices.shape,depth],dtype,res)}};function ZerosLike_zerosLike(args){const{inputs,backend}=args,{x}=inputs;if("string"===x.dtype)throw new Error("zerosLike is not supported for string tensors");if("complex64"===x.dtype){const realPart=real({inputs:{input:x},backend}),r=ZerosLike_zerosLike({inputs:{x:realPart},backend}),imagPart=imag({inputs:{input:x},backend}),i=ZerosLike_zerosLike({inputs:{x:imagPart},backend}),result=complex({inputs:{real:r,imag:i},backend});return backend.disposeIntermediateTensorInfo(realPart),backend.disposeIntermediateTensorInfo(r),backend.disposeIntermediateTensorInfo(imagPart),backend.disposeIntermediateTensorInfo(i),result}return fill({backend,attrs:{shape:x.shape,value:0,dtype:x.dtype}})}const zerosLikeConfig={kernelName:dist.xJ3,backendName:"cpu",kernelFunc:ZerosLike_zerosLike};const onesLikeConfig={kernelName:dist.LWX,backendName:"cpu",kernelFunc:function OnesLike_onesLike(args){const{inputs,backend}=args,{x}=inputs;if("string"===x.dtype)throw new Error("onesLike is not supported for string tensors");if("complex64"===x.dtype){const realPart=real({inputs:{input:x},backend}),r=OnesLike_onesLike({inputs:{x:realPart},backend}),imagPart=imag({inputs:{input:x},backend}),i=ZerosLike_zerosLike({inputs:{x:imagPart},backend}),result=complex({inputs:{real:r,imag:i},backend});return backend.disposeIntermediateTensorInfo(realPart),backend.disposeIntermediateTensorInfo(r),backend.disposeIntermediateTensorInfo(imagPart),backend.disposeIntermediateTensorInfo(i),result}return fill({backend,attrs:{shape:x.shape,value:1,dtype:x.dtype}})}};function pack(args){const{inputs,backend,attrs}=args,{axis}=attrs;if(1===inputs.length)return ExpandDims_expandDims({inputs:{input:inputs[0]},backend,attrs:{dim:axis}});const shape=inputs[0].shape,dtype=inputs[0].dtype;inputs.forEach(t=>{dist.ZSL.assertShapesMatch(shape,t.shape,"All tensors passed to stack must have matching shapes"),dist.ZSL.assert(dtype===t.dtype,()=>"All tensors passed to stack must have matching dtypes")});const intermediateTensorInfos=[],result=Concat_concat({inputs:inputs.map(t=>{const expandedT=ExpandDims_expandDims({inputs:{input:t},backend,attrs:{dim:axis}});return intermediateTensorInfos.push(expandedT),expandedT}),backend,attrs:{axis}});return intermediateTensorInfos.forEach(t=>backend.disposeIntermediateTensorInfo(t)),result}const packConfig={kernelName:dist.mM$,backendName:"cpu",kernelFunc:pack};const padV2Config={kernelName:dist.ODT,backendName:"cpu",kernelFunc:function padV2(args){const{inputs,backend,attrs}=args,{x}=inputs,{paddings,constantValue}=attrs;(0,cpu_util.C)(x,"pad");const outShape=paddings.map((p,i)=>p[0]+x.shape[i]+p[1]),start=paddings.map(p=>p[0]),xVals=backend.data.get(x.dataId).values,xSize=dist.ZSL.sizeFromShape(x.shape),xRank=x.shape.length,xStrides=dist.ZSL.computeStrides(x.shape),resultSize=dist.ZSL.sizeFromShape(outShape),resultRank=outShape.length,resultStrides=dist.ZSL.computeStrides(outShape),resVals=dist.ZSL.getTypedArrayFromDType(x.dtype,resultSize);0!==constantValue&&resVals.fill(constantValue);for(let i=0;i<xSize;i++){const outCoords=dist.ZSL.indexToLoc(i,xRank,xStrides).map((c,i)=>c+start[i]);resVals[dist.ZSL.locToIndex(outCoords,resultRank,resultStrides)]=xVals[i]}return{dataId:backend.write(resVals,outShape,x.dtype),shape:outShape,dtype:x.dtype}}},powImpl=createSimpleBinaryKernelImpl((a,b)=>Math.pow(a,b)),Pow_pow=binaryKernelFunc(dist.pyJ,powImpl),powConfig={kernelName:dist.pyJ,backendName:"cpu",kernelFunc:Pow_pow};const raggedGatherConfig={kernelName:dist.oJ2,backendName:"cpu",kernelFunc:function raggedGather(args){const{inputs,backend,attrs}=args,{paramsNestedSplits,paramsDenseValues,indices}=inputs,{outputRaggedRank}=attrs,$paramsNestedSplits=paramsNestedSplits.map(t=>backend.data.get(t.dataId).values),$paramsNestedSplitsShapes=paramsNestedSplits.map(t=>t.shape),$paramsDenseValues=backend.data.get(paramsDenseValues.dataId).values,$indices=backend.data.get(indices.dataId).values,[outputNestedSplits,outputDenseValues,outputDenseValuesShape]=raggedGatherImpl($paramsNestedSplits,$paramsNestedSplitsShapes,$paramsDenseValues,paramsDenseValues.shape,paramsDenseValues.dtype,$indices,indices.shape),outputNestedSplitsTensors=outputNestedSplits.map(splits=>backend.makeTensorInfo([splits.length],"int32",splits)),outputDenseValuesTensor=backend.makeTensorInfo(outputDenseValuesShape,paramsDenseValues.dtype,outputDenseValues);return outputNestedSplitsTensors.concat([outputDenseValuesTensor])}};const raggedRangeConfig={kernelName:dist.CQC,backendName:"cpu",kernelFunc:function raggedRange(args){const{inputs,backend}=args,{starts,limits,deltas}=inputs,$starts=backend.data.get(starts.dataId).values,$limits=backend.data.get(limits.dataId).values,$deltas=backend.data.get(deltas.dataId).values,[rtNestedSplitsData,rtDenseValuesData]=raggedRangeImpl($starts,starts.shape,starts.dtype,$limits,limits.shape,$deltas,deltas.shape);return[backend.makeTensorInfo([rtNestedSplitsData.length],"int32",rtNestedSplitsData),backend.makeTensorInfo([rtDenseValuesData.length],starts.dtype,rtDenseValuesData)]}};const raggedTensorToTensorConfig={kernelName:dist.mH5,backendName:"cpu",kernelFunc:function raggedTensorToTensor(args){const{inputs,backend,attrs}=args,{shape,values,defaultValue,rowPartitionTensors}=inputs,{rowPartitionTypes}=attrs,$shape=backend.data.get(shape.dataId).values,$values=backend.data.get(values.dataId).values,$defaultValue=backend.data.get(defaultValue.dataId).values,$rowPartitionValues=rowPartitionTensors.map(t=>backend.data.get(t.dataId).values),rowPartitionValuesShapes=rowPartitionTensors.map(t=>t.shape),[outputShape,output]=raggedTensorToTensorImpl($shape,shape.shape,$values,values.shape,values.dtype,$defaultValue,defaultValue.shape,$rowPartitionValues,rowPartitionValuesShapes,rowPartitionTypes);return backend.makeTensorInfo(outputShape,values.dtype,output)}};const rangeConfig={kernelName:dist.Q6t,backendName:"cpu",kernelFunc:function Range_range(args){const{backend,attrs}=args,{start,stop,dtype,step}=attrs,values=(0,Range_impl.q)(start,stop,step,dtype);return backend.makeTensorInfo([values.length],dtype,values)}},Reciprocal_reciprocal=unaryKernelFunc(dist.huO,xi=>1/xi),reciprocalConfig={kernelName:dist.huO,backendName:"cpu",kernelFunc:Reciprocal_reciprocal};const resizeBilinearConfig={kernelName:dist.hgw,backendName:"cpu",kernelFunc:function ResizeBilinear_resizeBilinear(args){const{inputs,backend,attrs}=args,{images}=inputs,{alignCorners,halfPixelCenters,size}=attrs;(0,cpu_util.C)(images,"resizeBilinear");const imagesStrides=dist.ZSL.computeStrides(images.shape),[newHeight,newWidth]=size,[batch,oldHeight,oldWidth,numChannels]=images.shape,xValues=backend.data.get(images.dataId).values,result=new Float32Array(dist.ZSL.sizeFromShape([batch,newHeight,newWidth,numChannels])),effectiveInputSize=[alignCorners&&newHeight>1?oldHeight-1:oldHeight,alignCorners&&newWidth>1?oldWidth-1:oldWidth],effectiveOutputSize=[alignCorners&&newHeight>1?newHeight-1:newHeight,alignCorners&&newWidth>1?newWidth-1:newWidth];let outputIdx=0;const effectiveRowSizeRatio=effectiveInputSize[0]/effectiveOutputSize[0],effectiveColSizeRatio=effectiveInputSize[1]/effectiveOutputSize[1];for(let b=0;b<batch;b++)for(let r=0;r<newHeight;r++){let sourceFracRow;sourceFracRow=halfPixelCenters?effectiveRowSizeRatio*(r+.5)-.5:effectiveRowSizeRatio*r;const sourceRowFloor=Math.max(0,Math.floor(sourceFracRow)),rowFrac=sourceFracRow-sourceRowFloor,sourceRowCeil=Math.min(oldHeight-1,Math.ceil(sourceFracRow)),topRowOffset=b*imagesStrides[0]+sourceRowFloor*imagesStrides[1],botRowOffset=b*imagesStrides[0]+sourceRowCeil*imagesStrides[1];for(let c=0;c<newWidth;c++){let sourceFracCol;sourceFracCol=halfPixelCenters?effectiveColSizeRatio*(c+.5)-.5:effectiveColSizeRatio*c;const sourceColFloor=Math.max(0,Math.floor(sourceFracCol)),colFrac=sourceFracCol-sourceColFloor,sourceColCeil=Math.min(oldWidth-1,Math.ceil(sourceFracCol)),topLeftOffest=topRowOffset+sourceColFloor*imagesStrides[2],botLeftOffset=botRowOffset+sourceColFloor*imagesStrides[2],topRightOffset=topRowOffset+sourceColCeil*imagesStrides[2],botRightOffest=botRowOffset+sourceColCeil*imagesStrides[2];for(let d=0;d<numChannels;d++){const topLeft=xValues[topLeftOffest+d],bottomLeft=xValues[botLeftOffset+d],top=topLeft+(xValues[topRightOffset+d]-topLeft)*colFrac,newValue=top+(bottomLeft+(xValues[botRightOffest+d]-bottomLeft)*colFrac-top)*rowFrac;result[outputIdx++]=newValue}}}return backend.makeTensorInfo([batch,newHeight,newWidth,numChannels],"float32",result)}};const ResizeBilinearGrad_resizeBilinearGradConfig={kernelName:dist.FCQ,backendName:"cpu",kernelFunc:function resizeBilinearGrad(args){const{inputs,backend,attrs}=args,{images,dy}=inputs,{alignCorners}=attrs;(0,cpu_util.C)([dy,images],"resizeBilinearGrad");const imagesStrides=dist.ZSL.computeStrides(images.shape),[batch,xHeight,xWidth,depth]=images.shape,[,yHeight,yWidth]=dy.shape,output=new Float32Array(batch*xHeight*xWidth*depth),effectiveXSize=[alignCorners&&yHeight>1?xHeight-1:xHeight,alignCorners&&yWidth>1?xWidth-1:xWidth],effectiveYSize=[alignCorners&&yHeight>1?yHeight-1:yHeight,alignCorners&&yWidth>1?yWidth-1:yWidth],heightScale=effectiveXSize[0]/effectiveYSize[0],widthScale=effectiveXSize[1]/effectiveYSize[1],dyValues=backend.data.get(dy.dataId).values;let offset=0;for(let b=0;b<batch;b++){const bOffset=b*imagesStrides[0];for(let r=0;r<yHeight;r++){const dxR=r*heightScale,topDxRIndex=Math.floor(dxR),bottomDxRIndex=Math.min(Math.ceil(dxR),xHeight-1),topDxROffset=bOffset+topDxRIndex*imagesStrides[1],bottomDxROffset=bOffset+bottomDxRIndex*imagesStrides[1],dxRLerp=dxR-topDxRIndex,inverseDxRLerp=1-dxRLerp;for(let c=0;c<yWidth;c++){const dxC=c*widthScale,leftDxCIndex=Math.floor(dxC),rightDxCIndex=Math.min(Math.ceil(dxC),xWidth-1),dxCLerp=dxC-leftDxCIndex,inverseDxCLerp=1-dxCLerp,topLeftRCOffset=topDxROffset+leftDxCIndex*imagesStrides[2],topRightRCOffset=topDxROffset+rightDxCIndex*imagesStrides[2],bottomLeftRCOffset=bottomDxROffset+leftDxCIndex*imagesStrides[2],bottomRightRCOffset=bottomDxROffset+rightDxCIndex*imagesStrides[2],inverseDxRLerpTimesInverseDxCLerp=inverseDxRLerp*inverseDxCLerp,inverseDxRLerpTimesDxCLerp=inverseDxRLerp*dxCLerp,dxRLerpTimesInverseDxCLerp=dxRLerp*inverseDxCLerp,dxRLerpTimesDxCLerp=dxRLerp*dxCLerp;for(let d=0;d<depth;d++){const dyVal=dyValues[offset++];output[topLeftRCOffset+d]+=dyVal*inverseDxRLerpTimesInverseDxCLerp,output[topRightRCOffset+d]+=dyVal*inverseDxRLerpTimesDxCLerp,output[bottomLeftRCOffset+d]+=dyVal*dxRLerpTimesInverseDxCLerp,output[bottomRightRCOffset+d]+=dyVal*dxRLerpTimesDxCLerp}}}}return backend.makeTensorInfo([batch,xWidth,xHeight,depth],"float32",output)}};const resizeNearestNeighborConfig={kernelName:dist.jOE,backendName:"cpu",kernelFunc:function resizeNearestNeighbor(args){const{inputs,backend,attrs}=args,{images}=inputs,{alignCorners,halfPixelCenters,size}=attrs;(0,cpu_util.C)(images,"resizeNearestNeighbor");const imagesStrides=dist.ZSL.computeStrides(images.shape),[newHeight,newWidth]=size,[batch,oldHeight,oldWidth,numChannels]=images.shape,xValues=backend.data.get(images.dataId).values,output=new Float32Array(batch*newHeight*newWidth*numChannels),effectiveInputSize=[alignCorners&&newHeight>1?oldHeight-1:oldHeight,alignCorners&&newWidth>1?oldWidth-1:oldWidth],effectiveOutputSize=[alignCorners&&newHeight>1?newHeight-1:newHeight,alignCorners&&newWidth>1?newWidth-1:newWidth],effectiveRowSizeRatio=effectiveInputSize[0]/effectiveOutputSize[0],effectiveColSizeRatio=effectiveInputSize[1]/effectiveOutputSize[1];let outputOffset=0;for(let b=0;b<batch;b++){const batchOffset=b*imagesStrides[0];for(let r=0;r<newHeight;r++){const sourceFracRow=halfPixelCenters?effectiveRowSizeRatio*(r+.5):effectiveRowSizeRatio*r;let sourceNearestRow=Math.min(oldHeight-1,alignCorners?Math.round(sourceFracRow):Math.floor(sourceFracRow));halfPixelCenters&&(sourceNearestRow=Math.max(0,sourceNearestRow));const rowOffset=batchOffset+sourceNearestRow*imagesStrides[1];for(let c=0;c<newWidth;c++){const sourceFracCol=halfPixelCenters?effectiveColSizeRatio*(c+.5):effectiveColSizeRatio*c;let sourceNearestCol=Math.min(oldWidth-1,alignCorners?Math.round(sourceFracCol):Math.floor(sourceFracCol));halfPixelCenters&&(sourceNearestCol=Math.max(0,sourceNearestCol));const colOffset=rowOffset+sourceNearestCol*imagesStrides[2];for(let d=0;d<numChannels;d++){const newVal=xValues[colOffset+d];output[outputOffset++]=newVal}}}}return backend.makeTensorInfo([batch,newHeight,newWidth,numChannels],images.dtype,output)}};const ResizeNearestNeighborGrad_resizeNearestNeighborGradConfig={kernelName:dist.XQy,backendName:"cpu",kernelFunc:function resizeNearestNeighborGrad(args){const{inputs,backend,attrs}=args,{images,dy}=inputs,{alignCorners}=attrs;(0,cpu_util.C)([dy,images],"resizeNearestNeighborGrad");const imagesStrides=dist.ZSL.computeStrides(images.shape),dyStrides=dist.ZSL.computeStrides(dy.shape),[batch,xHeight,xWidth,depth]=images.shape,[,yHeight,yWidth]=dy.shape,output=new Float32Array(batch*xHeight*xWidth*depth),dyValues=backend.data.get(dy.dataId).values,effectiveXSize=[alignCorners&&yHeight>1?xHeight-1:xHeight,alignCorners&&yWidth>1?xWidth-1:xWidth],effectiveYSize=[alignCorners&&yHeight>1?yHeight-1:yHeight,alignCorners&&yWidth>1?yWidth-1:yWidth],heightScale=effectiveXSize[0]/effectiveYSize[0],widthScale=effectiveXSize[1]/effectiveYSize[1],invHeightScale=1/heightScale,invWidthScale=1/widthScale,winHeight=2*Math.ceil(invHeightScale)+2,winWidth=2*Math.ceil(invWidthScale)+2;for(let b=0;b<batch;b++){const batchOffset=b*imagesStrides[0];for(let r=0;r<xHeight;r++){const rowOffset=batchOffset+r*imagesStrides[1],startRLerp=Math.floor(r*invHeightScale),startDyR=Math.floor(startRLerp-winHeight/2);for(let c=0;c<xWidth;c++){const colOffset=rowOffset+c*imagesStrides[2],startCLerp=Math.floor(c*invWidthScale),startDyC=Math.floor(startCLerp-winWidth/2);for(let d=0;d<depth;d++){let accum=0;for(let dyRIndex=0;dyRIndex<winHeight;dyRIndex++){const dyR=dyRIndex+startDyR;if(dyR<0||dyR>=yHeight)continue;const dyROffset=batchOffset+dyR*dyStrides[1],sourceFracRow=dyR*heightScale;if(r===Math.min(xHeight-1,alignCorners?Math.round(sourceFracRow):Math.floor(sourceFracRow)))for(let dyCIndex=0;dyCIndex<winWidth;dyCIndex++){const dyC=dyCIndex+startDyC;if(dyC<0||dyC>=yWidth)continue;const dyCOffset=dyROffset+dyC*dyStrides[2],sourceFracCol=dyC*widthScale;c===Math.min(xWidth-1,alignCorners?Math.round(sourceFracCol):Math.floor(sourceFracCol))&&(accum+=dyValues[dyCOffset+d])}}output[colOffset+d]=accum}}}}return backend.makeTensorInfo(images.shape,images.dtype,output)}};const reverseConfig={kernelName:dist.D7i,backendName:"cpu",kernelFunc:function Reverse_reverse(args){const{inputs,backend,attrs}=args,{x}=inputs,{dims}=attrs;(0,cpu_util.C)(x,"reverse");const xRank=x.shape.length,$dims=dist.ZSL.parseAxisParam(dims,x.shape);if(0===xRank)return Identity_identity({inputs:{x},backend});const outBuf=new dist.ylz(x.shape,x.dtype),xBuf=backend.bufferSync(x);for(let i=0;i<outBuf.size;i++){const outLoc=outBuf.indexToLoc(i),inLoc=outLoc.slice();$dims.forEach(d=>inLoc[d]=x.shape[d]-1-inLoc[d]),outBuf.set(xBuf.get(...inLoc),...outLoc)}return backend.makeTensorInfo(outBuf.shape,outBuf.dtype,outBuf.values)}},rotateWithOffsetConfig={kernelName:dist.BK4,backendName:"cpu",kernelFunc:({inputs,attrs,backend})=>{const{image}=inputs,{radians,fillValue,center}=attrs,cpuBackend=backend,output=dist.ZSL.getTypedArrayFromDType(image.dtype,dist.ZSL.sizeFromShape(image.shape)),[batch,imageHeight,imageWidth,numChannels]=image.shape,[centerX,centerY]=dist.C0T.getImageCenter(center,imageHeight,imageWidth),sinFactor=Math.sin(radians),cosFactor=Math.cos(radians),imageVals=cpuBackend.data.get(image.dataId).values;for(let batchIdx=0;batchIdx<batch;batchIdx++){const batchOffset=batchIdx*imageWidth*imageHeight*numChannels;for(let row=0;row<imageHeight;row++){const rowOffset=row*(imageWidth*numChannels);for(let col=0;col<imageWidth;col++){const colOffset=col*numChannels;for(let channel=0;channel<numChannels;channel++){const coords=[batch,row,col,channel],x=coords[2],y=coords[1];let coordX=(x-centerX)*cosFactor-(y-centerY)*sinFactor,coordY=(x-centerX)*sinFactor+(y-centerY)*cosFactor;coordX=Math.round(coordX+centerX),coordY=Math.round(coordY+centerY);let outputValue=fillValue;if("number"!=typeof fillValue&&(outputValue=3===channel?255:fillValue[channel]),coordX>=0&&coordX<imageWidth&&coordY>=0&&coordY<imageHeight){outputValue=imageVals[batchOffset+coordY*(imageWidth*numChannels)+coordX*numChannels+channel]}output[batchOffset+rowOffset+colOffset+channel]=outputValue}}}}return{dataId:cpuBackend.write(output,image.shape,image.dtype),shape:image.shape,dtype:image.dtype}}},Round_round=unaryKernelFunc(dist.hVg,xi=>{const base=Math.floor(xi);return xi-base<.5?Math.floor(xi):xi-base>.5?Math.ceil(xi):base%2==0?base:base+1}),roundConfig={kernelName:dist.hVg,backendName:"cpu",kernelFunc:Round_round};const scatterNdConfig={kernelName:dist.pJc,backendName:"cpu",kernelFunc:function scatterNd(args){const{inputs,backend,attrs}=args,{indices,updates}=inputs,{shape}=attrs,{sliceRank,numUpdates,sliceSize,strides,outputSize}=dist.C0T.calculateShapes(updates,indices,shape),outBuf=scatterImpl(backend.bufferSync(indices),backend.bufferSync(updates),shape,outputSize,sliceSize,numUpdates,sliceRank,strides,0,!0);return backend.makeTensorInfo(shape,outBuf.dtype,outBuf.values)}};function lowerBound(array,value){let left=0,right=array.length,mid=0;for(;left<right;)mid=Math.floor((left+right)/2),array[mid]<value?left=mid+1:right=mid;return right}function upperBound(array,value){let left=0,right=array.length,mid=0;for(;left<right;)mid=Math.floor((left+right)/2),array[mid]<=value?left=mid+1:right=mid;return right}const searchSortedConfig={kernelName:dist.uWl,backendName:"cpu",kernelFunc:function searchSorted(args){const{inputs,backend,attrs}=args,{sortedSequence,values}=inputs,{side}=attrs,output=function searchSortedImpl(sortedInputs,values,batchSize,numInputs,numValues,side){const output=dist.ZSL.getArrayFromDType("int32",batchSize*numValues);for(let b=0;b<batchSize;++b){const sortedInputsSlice=sortedInputs.slice(b*numInputs,(b+1)*numInputs),outputOffset=b*numValues;for(let i=0;i<numValues;++i)output[outputOffset+i]="left"===side?lowerBound(sortedInputsSlice,values[i+outputOffset]):upperBound(sortedInputsSlice,values[i+outputOffset])}return output}(backend.data.get(sortedSequence.dataId).values,backend.data.get(values.dataId).values,sortedSequence.shape[0],sortedSequence.shape[1],values.shape[1],side);return backend.makeTensorInfo(values.shape,"int32",output)}};const selectConfig={kernelName:dist.l6P,backendName:"cpu",kernelFunc:function Select_select(args){const{inputs,backend}=args,{condition,t,e}=inputs;(0,cpu_util.C)([condition,t,e],"select");const conditionRank=condition.shape.length,values=backend.data.get(condition.dataId).values,tValues=backend.data.get(t.dataId).values,eValues=backend.data.get(e.dataId).values,resultDtype=(0,dist.TuY)(t.dtype,e.dtype),newValues=dist.ZSL.makeZerosTypedArray(dist.ZSL.sizeFromShape(t.shape),resultDtype);let index=0;const offset=0===conditionRank||conditionRank>1||1===t.shape.length?1:dist.ZSL.sizeFromShape(t.shape.slice(1));for(let i=0;i<values.length;i++)for(let j=0;j<offset;j++)1===values[i]?newValues[index++]=tValues[i]:newValues[index++]=eValues[i];return backend.makeTensorInfo(t.shape,resultDtype,newValues)}},scaleAlpha=dist.C0T.SELU_SCALEALPHA,scale=dist.C0T.SELU_SCALE,Selu_selu=unaryKernelFunc(dist.u$b,xi=>xi>=0?scale*xi:scaleAlpha*(Math.exp(xi)-1)),seluConfig={kernelName:dist.u$b,backendName:"cpu",kernelFunc:Selu_selu},Sign_sign=unaryKernelFunc(dist.YVe,xi=>xi<0?-1:xi>0?1:0),signConfig={kernelName:dist.YVe,backendName:"cpu",kernelFunc:Sign_sign},Sin_sin=unaryKernelFunc(dist.hql,xi=>Math.sin(xi)),sinConfig={kernelName:dist.hql,backendName:"cpu",kernelFunc:Sin_sin},Sinh_sinh=unaryKernelFunc(dist.J3C,xi=>Math.sinh(xi)),sinhConfig={kernelName:dist.J3C,backendName:"cpu",kernelFunc:Sinh_sinh},threshold=Math.log(1.1920928955078125e-7)+2,Softplus_softplus=unaryKernelFunc(dist.Fin,xi=>{const tooLarge=xi>-threshold,tooSmall=xi<threshold,expX=Math.exp(xi);let result;return result=tooSmall?expX:tooLarge?xi:Math.log(1+expX),result}),softplusConfig={kernelName:dist.Fin,backendName:"cpu",kernelFunc:Softplus_softplus};const spaceToBatchNDConfig={kernelName:dist.A8B,backendName:"cpu",kernelFunc:function spaceToBatchND(args){const{inputs,backend,attrs}=args,{x}=inputs,{blockShape,paddings}=attrs;(0,cpu_util.C)([x],"spaceToBatchND");const prod=dist.ZSL.sizeFromShape(blockShape),completePaddings=[[0,0]];completePaddings.push(...paddings);for(let i=1+blockShape.length;i<x.shape.length;++i)completePaddings.push([0,0]);const paddedX=padV2Config.kernelFunc({inputs:{x},backend,attrs:{paddings:completePaddings,constantValue:0}}),reshapedPaddedShape=dist.C0T.getReshaped(paddedX.shape,blockShape,prod,!1),permutedReshapedPaddedPermutation=dist.C0T.getPermuted(reshapedPaddedShape.length,blockShape.length,!1),flattenShape=dist.C0T.getReshapedPermuted(paddedX.shape,blockShape,prod,!1),paddedXReshaped=Reshape_reshape({inputs:{x:paddedX},backend,attrs:{shape:reshapedPaddedShape}}),paddedXT=Transpose_transpose({inputs:{x:paddedXReshaped},backend,attrs:{perm:permutedReshapedPaddedPermutation}}),result=Reshape_reshape({inputs:{x:paddedXT},backend,attrs:{shape:flattenShape}});return backend.disposeIntermediateTensorInfo(paddedX),backend.disposeIntermediateTensorInfo(paddedXReshaped),backend.disposeIntermediateTensorInfo(paddedXT),result}};const sparseFillEmptyRowsConfig={kernelName:dist.C8s,backendName:"cpu",kernelFunc:function sparseFillEmptyRows(args){const{inputs,backend}=args,{indices,values,denseShape,defaultValue}=inputs;if(1!==denseShape.shape.length)throw new Error(`Dense shape must be a vector, saw:\n        ${denseShape.shape}`);if(2!==indices.shape.length)throw new Error(`Indices must be a matrix, saw:\n        ${indices.shape}`);if(1!==values.shape.length)throw new Error(`Values must be a vector, saw:\n        ${values.shape}`);if(0!==defaultValue.shape.length)throw new Error(`Default value must be a scalar, saw:\n        ${defaultValue.shape}`);const $indices=backend.data.get(indices.dataId).values,$values=backend.data.get(values.dataId).values,$denseShape=backend.data.get(denseShape.dataId).values,$defaultValue=backend.data.get(defaultValue.dataId).values[0],[outputIndices,outputIndicesShape,outputValues,emptyRowIndicator,reverseIndexMap]=sparseFillEmptyRowsImpl($indices,indices.shape,indices.dtype,$values,values.dtype,$denseShape,$defaultValue);return[backend.makeTensorInfo(outputIndicesShape,indices.dtype,outputIndices),backend.makeTensorInfo([outputIndicesShape[0]],values.dtype,outputValues),backend.makeTensorInfo([emptyRowIndicator.length],"bool",new Uint8Array(emptyRowIndicator.map(value=>Number(value)))),backend.makeTensorInfo([reverseIndexMap.length],indices.dtype,new Int32Array(reverseIndexMap))]}};const sparseReshapeConfig={kernelName:dist.BoJ,backendName:"cpu",kernelFunc:function sparseReshape(args){const{inputs,backend}=args,{inputIndices,inputShape,newShape}=inputs;if(2!==inputIndices.shape.length)throw new Error(`Input indices should be a matrix but received shape\n        ${inputIndices.shape}`);if(1!==inputShape.shape.length)throw new Error(`Input shape should be a vector but received shape\n        ${inputShape.shape}`);if(1!==newShape.shape.length)throw new Error(`Target shape should be a vector but received shape ${newShape.shape}`);const $inputShape=Array.from(backend.data.get(inputShape.dataId).values),$inputIndices=backend.data.get(inputIndices.dataId).values,targetShape=Array.from(backend.data.get(newShape.dataId).values),[newIndices,indicesShape,outputShape]=sparseReshapeImpl($inputIndices,inputIndices.shape,inputIndices.dtype,$inputShape,targetShape);return[backend.makeTensorInfo(indicesShape,inputIndices.dtype,newIndices),backend.makeTensorInfo([outputShape.length],newShape.dtype,new Int32Array(outputShape))]}};const sparseSegmentMeanConfig={kernelName:dist.L6G,backendName:"cpu",kernelFunc:function sparseSegmentMean(args){const{inputs,backend}=args,{data,indices,segmentIds}=inputs;if(data.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==indices.shape.length)throw new Error(`Indices should be a vector but received shape\n          ${indices.shape}`);if(1!==segmentIds.shape.length)throw new Error(`Segment ids should be a vector but received shape\n          ${segmentIds.shape}`);if(indices.shape[0]!==segmentIds.shape[0])throw new Error("segmentIds and indices should have same size.");const $data=backend.data.get(data.dataId).values,$indices=backend.data.get(indices.dataId).values,$segmentIds=backend.data.get(segmentIds.dataId).values,[outputData,outputDataShape]=sparseSegmentReductionImpl($data,data.shape,data.dtype,$indices,$segmentIds,!0);return backend.makeTensorInfo(outputDataShape,data.dtype,outputData)}};const sparseSegmentSumConfig={kernelName:dist.DvZ,backendName:"cpu",kernelFunc:function sparseSegmentSum(args){const{inputs,backend}=args,{data,indices,segmentIds}=inputs;if(data.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==indices.shape.length)throw new Error(`Indices should be a vector but received shape\n         ${indices.shape}`);if(1!==segmentIds.shape.length)throw new Error(`Segment ids should be a vector but received shape\n         ${segmentIds.shape}`);if(indices.shape[0]!==segmentIds.shape[0])throw new Error("segmentIds and indices should have same size.");const $data=backend.data.get(data.dataId).values,$indices=backend.data.get(indices.dataId).values,$segmentIds=backend.data.get(segmentIds.dataId).values,[outputData,outputDataShape]=sparseSegmentReductionImpl($data,data.shape,data.dtype,$indices,$segmentIds);return backend.makeTensorInfo(outputDataShape,data.dtype,outputData)}};const sparseToDenseConfig={kernelName:dist.jgd,backendName:"cpu",kernelFunc:function sparseToDense(args){const{inputs,backend,attrs}=args,{sparseIndices,sparseValues,defaultValue}=inputs,{outputShape}=attrs,{sliceRank,numUpdates,sliceSize,strides,outputSize}=dist.C0T.calculateShapes(sparseValues,sparseIndices,outputShape),indicesBuf=backend.bufferSync(sparseIndices);let outBuf;switch(sparseValues.dtype){case"bool":outBuf=scatterImpl(indicesBuf,backend.bufferSync(sparseValues),outputShape,outputSize,sliceSize,numUpdates,sliceRank,strides,Boolean(backend.data.get(defaultValue.dataId).values[0]),false);break;case"float32":outBuf=scatterImpl(indicesBuf,backend.bufferSync(sparseValues),outputShape,outputSize,sliceSize,numUpdates,sliceRank,strides,backend.data.get(defaultValue.dataId).values[0],false);break;case"int32":outBuf=scatterImpl(indicesBuf,backend.bufferSync(sparseValues),outputShape,outputSize,sliceSize,numUpdates,sliceRank,strides,backend.data.get(defaultValue.dataId).values[0],false);break;case"string":outBuf=scatterImpl(indicesBuf,backend.bufferSync(sparseValues),outputShape,outputSize,sliceSize,numUpdates,sliceRank,strides,dist.ZSL.decodeString(backend.data.get(defaultValue.dataId).values[0]),false);break;default:throw new Error(`Unsupported type ${sparseValues.dtype}`)}return backend.makeTensorInfo(outputShape,outBuf.dtype,outBuf.values)}};const splitVConfig={kernelName:dist.Blb,backendName:"cpu",kernelFunc:function splitV(args){const{inputs,backend,attrs}=args,{x}=inputs,{numOrSizeSplits,axis}=attrs,$axis=dist.ZSL.parseAxisParam(axis,x.shape)[0],splitSizes=dist.C0T.prepareSplitSize(x,numOrSizeSplits,$axis),begin=new Array(x.shape.length).fill(0),size=x.shape.slice();return splitSizes.map(s=>{const sliceSize=[...size];sliceSize[$axis]=s;const sliceT=(0,Slice.di)({inputs:{x},backend,attrs:{begin,size:sliceSize}});return begin[$axis]+=s,sliceT})}},squareConfig={kernelName:dist.M6A,backendName:"cpu",kernelFunc:({inputs,backend})=>{const{x}=inputs,cpuBackend=backend;(0,cpu_util.C)(x,"square");const values=cpuBackend.data.get(x.dataId).values,newValues=new Float32Array(values.length);for(let i=0;i<values.length;++i){const value=values[i];newValues[i]=value*value}return{dataId:cpuBackend.write(newValues,x.shape,x.dtype),shape:x.shape,dtype:x.dtype}}},Step_step=unaryKernelFunc(dist.pnw,(xi,attrs)=>{const stepAttrs=attrs;return isNaN(xi)?NaN:xi>0?1:stepAttrs.alpha}),stepConfig={kernelName:dist.pnw,backendName:"cpu",kernelFunc:Step_step};const stridedSliceConfig={kernelName:dist.UcO,backendName:"cpu",kernelFunc:function stridedSlice(args){const{inputs,backend,attrs}=args,{x}=inputs,{begin,end,strides,beginMask,endMask,ellipsisMask,newAxisMask,shrinkAxisMask}=attrs;(0,cpu_util.C)(x,"stridedSlice");const{finalShapeSparse,finalShape,isIdentity,sliceDim0,isSimpleSlice,begin:$begin,end:$end,strides:$strides}=dist.Kro.sliceInfo(x.shape,begin,end,strides,beginMask,endMask,ellipsisMask,newAxisMask,shrinkAxisMask);let result;if(isIdentity)result=Reshape_reshape({inputs:{x},backend,attrs:{shape:finalShape}});else if(sliceDim0||isSimpleSlice){dist.ZSL.assert(x.shape.length>=1,()=>`Input must have rank at least 1, got: ${x.shape.length}`);const size=dist.Kro.computeOutShape($begin,$end,$strides),sliced=(0,Slice.di)({inputs:{x},backend,attrs:{begin:$begin,size}});result=Reshape_reshape({inputs:{x:sliced},backend,attrs:{shape:finalShape}}),backend.disposeIntermediateTensorInfo(sliced)}else{const outBuf=stridedSliceImpl(finalShapeSparse,backend.bufferSync(x),$strides,$begin);result=backend.makeTensorInfo(finalShape,outBuf.dtype,outBuf.values)}return result}};const stringNGramsConfig={kernelName:dist.YAb,backendName:"cpu",kernelFunc:function stringNGrams(args){const{inputs,backend,attrs}=args,{separator,nGramWidths,leftPad,rightPad,padWidth,preserveShortSequences}=attrs,{data,dataSplits}=inputs,$data=backend.data.get(data.dataId).values,$dataSplits=backend.data.get(dataSplits.dataId).values,[nGrams,nGramsSplits]=(0,StringNGrams_impl.G)($data,$dataSplits,separator,nGramWidths,leftPad,rightPad,padWidth,preserveShortSequences);return[backend.makeTensorInfo([nGrams.length],"string",nGrams),backend.makeTensorInfo(dataSplits.shape,"int32",nGramsSplits)]}};const stringSplitConfig={kernelName:dist.iW0,backendName:"cpu",kernelFunc:function stringSplit(args){const{inputs,backend,attrs}=args,{skipEmpty}=attrs,{input,delimiter}=inputs;if("string"!==input.dtype)throw new Error("Input must be of datatype string");if(1!==input.shape.length)throw new Error(`Input must be a vector, got shape: ${input.shape}`);if(0!==delimiter.shape.length)throw new Error(`Delimiter must be a scalar, got shape: ${delimiter.shape}`);const $input=backend.data.get(input.dataId).values,$delimiter=backend.data.get(delimiter.dataId).values[0],[indices,values,shape]=(0,StringSplit_impl.S)($input,$delimiter,skipEmpty),outputSize=values.length;return[backend.makeTensorInfo([outputSize,2],"int32",indices),backend.makeTensorInfo([outputSize],"string",values),backend.makeTensorInfo([2],"int32",new Int32Array(shape))]}};const stringToHashBucketFastConfig={kernelName:dist.$jE,backendName:"cpu",kernelFunc:function stringToHashBucketFast(args){const{inputs,backend,attrs}=args,{numBuckets}=attrs,{input}=inputs;if("string"!==input.dtype)throw new Error("Input must be of datatype string");if(numBuckets<=0)throw new Error("Number of buckets must be at least 1");const $input=backend.data.get(input.dataId).values,output=(0,StringToHashBucketFast_impl.f)($input,numBuckets);return backend.makeTensorInfo(input.shape,"int32",output)}},Tan_tan=unaryKernelFunc(dist.oFs,xi=>Math.tan(xi)),tanConfig={kernelName:dist.oFs,backendName:"cpu",kernelFunc:Tan_tan},Tanh_tanh=unaryKernelFunc(dist.iuW,xi=>Math.tanh(xi)),tanhConfig={kernelName:dist.iuW,backendName:"cpu",kernelFunc:Tanh_tanh};const tensorScatterUpdateConfig={kernelName:dist.X4r,backendName:"cpu",kernelFunc:function tensorScatterUpdate(args){const{inputs,backend}=args,{tensor,indices,updates}=inputs,{sliceRank,numUpdates,sliceSize,strides,outputSize}=dist.C0T.calculateShapes(updates,indices,tensor.shape),indicesBuf=backend.bufferSync(indices),updatesBuf=backend.bufferSync(updates),tensorBuf=backend.bufferSync(tensor),outBuf=scatterImpl(indicesBuf,updatesBuf,tensor.shape,outputSize,sliceSize,numUpdates,sliceRank,strides,tensorBuf,!1);return backend.makeTensorInfo(tensor.shape,outBuf.dtype,outBuf.values)}};const tileConfig={kernelName:dist.FAs,backendName:"cpu",kernelFunc:function Tile_tile(args){const{inputs,backend,attrs}=args,{x}=inputs,{reps}=attrs;(0,cpu_util.C)(x,"tile");const outBuf=tileImpl(backend.bufferSync(x),reps);return backend.makeTensorInfo(outBuf.shape,outBuf.dtype,outBuf.values)}};const topKConfig={kernelName:dist.TBb,backendName:"cpu",kernelFunc:function topK(args){const{inputs,backend,attrs}=args,{x}=inputs,{k,sorted}=attrs;(0,cpu_util.C)(x,"topk");const xVals=backend.data.get(x.dataId).values,[allTopKVals,allTopKIndices]=topKImpl(xVals,x.shape,x.dtype,k,sorted);return[backend.makeTensorInfo(allTopKVals.shape,allTopKVals.dtype,allTopKVals.values),backend.makeTensorInfo(allTopKIndices.shape,allTopKIndices.dtype,allTopKIndices.values)]}};const transformConfig={kernelName:dist.dLy,backendName:"cpu",kernelFunc:function transform(args){const{inputs,attrs,backend}=args,{image,transforms}=inputs,{interpolation,fillMode,fillValue,outputShape}=attrs,[batch,imageHeight,imageWidth,numChannels]=image.shape,[outHeight,outWidth]=null!=outputShape?outputShape:[imageHeight,imageWidth],outShape=[batch,outHeight,outWidth,numChannels],inStrides=dist.ZSL.computeStrides(image.shape),batchInStride=inStrides[0],rowInStride=inStrides[1],colInStride=inStrides[2],outStrides=dist.ZSL.computeStrides(outShape),batchOutStride=outStrides[0],rowOutStride=outStrides[1],colOutStride=outStrides[2],outVals=dist.ZSL.getTypedArrayFromDType(image.dtype,dist.ZSL.sizeFromShape(outShape));outVals.fill(fillValue);const imageVals=backend.data.get(image.dataId).values,transformVals=backend.data.get(transforms.dataId).values;for(let b=0;b<batch;++b){const transform=1===transforms.shape[0]?transformVals:transformVals.subarray(8*b,8*b+8);for(let outY=0;outY<outHeight;++outY)for(let outX=0;outX<outWidth;++outX)for(let channel=0;channel<numChannels;++channel){let val;const projection=transform[6]*outX+transform[7]*outY+1;if(0===projection)continue;const inX=(transform[0]*outX+transform[1]*outY+transform[2])/projection,inY=(transform[3]*outX+transform[4]*outY+transform[5])/projection,x=mapCoord(inX,imageWidth,fillMode),y=mapCoord(inY,imageHeight,fillMode);switch(interpolation){case"nearest":val=nearestInterpolation(imageVals,imageHeight,imageWidth,batchInStride,rowInStride,colInStride,b,y,x,channel,fillValue);break;case"bilinear":val=bilinearInterpolation(imageVals,imageHeight,imageWidth,batchInStride,rowInStride,colInStride,b,y,x,channel,fillValue);break;default:throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${interpolation}`)}outVals[b*batchOutStride+outY*rowOutStride+outX*colOutStride+channel]=val}return backend.makeTensorInfo(outShape,image.dtype,outVals)}return{dataId:backend.write(outVals,outShape,image.dtype),shape:image.shape,dtype:image.dtype}}};function mapCoord(outCoord,len,mode){switch(mode){case"reflect":return function mapCoordReflect(outCoord,len){let inCoord=outCoord;if(inCoord<0)if(len<=1)inCoord=0;else{const sz2=2*len;inCoord<sz2&&(inCoord=sz2*Math.trunc(-inCoord/sz2)+inCoord),inCoord=inCoord<-len?inCoord+sz2:-inCoord-1}else if(inCoord>len-1)if(len<=1)inCoord=0;else{const sz2=2*len;inCoord-=sz2*Math.trunc(inCoord/sz2),inCoord>=len&&(inCoord=sz2-inCoord-1)}return dist.ZSL.clamp(0,inCoord,len-1)}(outCoord,len);case"wrap":return function mapCoordWrap(outCoord,len){let inCoord=outCoord;if(inCoord<0)if(len<=1)inCoord=0;else{const sz=len-1;inCoord+=len*(Math.trunc(-inCoord/sz)+1)}else if(inCoord>len-1)if(len<=1)inCoord=0;else{const sz=len-1;inCoord-=len*Math.trunc(inCoord/sz)}return dist.ZSL.clamp(0,inCoord,len-1)}(outCoord,len);case"nearest":return function mapCoordNearest(outCoord,len){return dist.ZSL.clamp(0,outCoord,len-1)}(outCoord,len);default:return function mapCoordConstant(outCoord,len){return outCoord}(outCoord)}}function readWithFillValue(imageVals,imageHeight,imageWidth,batchStride,rowStride,colStride,batch,y,x,channel,fillValue){return 0<=y&&y<imageHeight&&0<=x&&x<imageWidth?imageVals[batch*batchStride+y*rowStride+x*colStride+channel]:fillValue}function nearestInterpolation(imageVals,imageHeight,imageWidth,batchStride,rowStride,colStride,batch,y,x,channel,fillValue){return readWithFillValue(imageVals,imageHeight,imageWidth,batchStride,rowStride,colStride,batch,Math.round(y),Math.round(x),channel,fillValue)}function bilinearInterpolation(imageVals,imageHeight,imageWidth,batchStride,rowStride,colStride,batch,y,x,channel,fillValue){const yFloor=Math.floor(y),xFloor=Math.floor(x),yCeil=yFloor+1,xCeil=xFloor+1;return(yCeil-y)*((xCeil-x)*readWithFillValue(imageVals,imageHeight,imageWidth,batchStride,rowStride,colStride,batch,yFloor,xFloor,channel,fillValue)+(x-xFloor)*readWithFillValue(imageVals,imageHeight,imageWidth,batchStride,rowStride,colStride,batch,yFloor,xCeil,channel,fillValue))+(y-yFloor)*((xCeil-x)*readWithFillValue(imageVals,imageHeight,imageWidth,batchStride,rowStride,colStride,batch,yCeil,xFloor,channel,fillValue)+(x-xFloor)*readWithFillValue(imageVals,imageHeight,imageWidth,batchStride,rowStride,colStride,batch,yCeil,xCeil,channel,fillValue))}const uniqueConfig={kernelName:dist.EwU,backendName:"cpu",kernelFunc:function Unique_unique(args){const{inputs,attrs,backend}=args,{axis}=attrs,{x}=inputs;(0,cpu_util.C)(x,"unique");const values=backend.data.get(x.dataId).values,{outputValues,outputShape,indices}=(0,Unique_impl.w)(values,axis,x.shape,x.dtype);return[backend.makeTensorInfo(outputShape,x.dtype,outputValues),backend.makeTensorInfo([indices.length],"int32",indices)]}};const unpackConfig={kernelName:dist.dXR,backendName:"cpu",kernelFunc:function unpack(args){const{inputs,backend,attrs}=args,{value}=inputs;let{axis}=attrs;axis<0&&(axis+=value.shape.length);const valueRank=value.shape.length,num=value.shape[axis],outShape=new Array(valueRank-1);let outIndex=0;for(let i=0;i<valueRank;i++)i!==axis&&(outShape[outIndex++]=value.shape[i]);const begin=new Array(valueRank).fill(0),size=value.shape.slice();size[axis]=1;const res=new Array(num);for(let i=0;i<res.length;i++){begin[axis]=i;const tempRes=(0,Slice.di)({inputs:{x:value},backend,attrs:{begin,size}});res[i]=Reshape_reshape({inputs:{x:tempRes},backend,attrs:{shape:outShape}}),backend.disposeIntermediateTensorInfo(tempRes)}return res}};const unsortedSegmentSumConfig={kernelName:dist.pPe,backendName:"cpu",kernelFunc:function unsortedSegmentSum(args){const{inputs,backend,attrs}=args,{x,segmentIds}=inputs,{numSegments}=attrs;(0,cpu_util.C)(x,"unsortedSegmentSum");const res=[],intermediates=[],numIters=x.shape.length-segmentIds.shape.length;let $segmentIds=segmentIds;for(let i=0;i<numIters;++i){const expanded=ExpandDims_expandDims({inputs:{input:$segmentIds},backend,attrs:{dim:i+1}});$segmentIds=expanded,intermediates.push(expanded)}for(let i=0;i<numSegments;++i){const scalarValue=dist.ZSL.createScalarValue(i,"int32"),segmentId=backend.makeTensorInfo([],"int32",scalarValue),mask=Equal_equal({inputs:{a:segmentId,b:$segmentIds},backend}),maskCasted=Cast_cast({inputs:{x:mask},backend,attrs:{dtype:"float32"}}),mul=Multiply_multiply({inputs:{a:maskCasted,b:x},backend}),sumTensorInfo=Sum_sum({inputs:{x:mul},backend,attrs:{axis:0,keepDims:!1}});res.push(sumTensorInfo),intermediates.push(segmentId),intermediates.push(mask),intermediates.push(maskCasted),intermediates.push(mul),intermediates.push(sumTensorInfo)}const result=pack({inputs:res,backend,attrs:{axis:0}});return intermediates.forEach(t=>backend.disposeIntermediateTensorInfo(t)),result}},kernelConfigs=[_fusedMatMulConfig,absConfig,acosConfig,acoshConfig,addConfig,addNConfig,allConfig,anyConfig,argMaxConfig,argMinConfig,asinConfig,asinhConfig,atanConfig,atan2Config,atanhConfig,avgPoolConfig,avgPool3DConfig,AvgPool3DGrad_avgPool3DGradConfig,AvgPoolGrad_avgPoolGradConfig,batchMatMulConfig,batchNormConfig,batchToSpaceNDConfig,bincountConfig,bitwiseAndConfig,broadcastArgsConfig,castConfig,ceilConfig,clipByValueConfig,complexConfig,complexAbsConfig,concatConfig,conv2DConfig,conv2DBackpropFilterConfig,conv2DBackpropInputConfig,conv3DConfig,conv3DBackpropFilterV2Config,conv3DBackpropInputV2Config,cosConfig,coshConfig,cropAndResizeConfig,cumprodConfig,cumsumConfig,denseBincountConfig,depthToSpaceConfig,depthwiseConv2dNativeConfig,depthwiseConv2dNativeBackpropFilterConfig,depthwiseConv2dNativeBackpropInputConfig,diagConfig,dilation2DConfig,dilation2DBackpropFilterConfig,dilation2DBackpropInputConfig,drawConfig,einsumConfig,eluConfig,EluGrad_eluGradConfig,equalConfig,erfConfig,expConfig,expandDimsConfig,expm1Config,fftConfig,fillConfig,flipLeftRightConfig,floorConfig,floorDivConfig,fusedConv2DConfig,fusedDepthwiseConv2DConfig,gatherNdConfig,gatherV2Config,greaterConfig,greaterEqualConfig,identityConfig,ifftConfig,imagConfig,isFiniteConfig,isInfConfig,isNaNConfig,leakyReluConfig,lessConfig,lessEqualConfig,linSpaceConfig,logConfig,log1pConfig,logicalAndConfig,logicalNotConfig,logicalOrConfig,LRNConfig,LRNGradConfig,maxConfig,maximumConfig,maxPoolConfig,maxPool3DConfig,MaxPool3DGrad_maxPool3DGradConfig,MaxPoolGrad_maxPoolGradConfig,maxPoolWithArgmaxConfig,meanConfig,minConfig,minimumConfig,mirrorPadConfig,modConfig,multinomialConfig,multiplyConfig,negConfig,nonMaxSuppressionV3Config,nonMaxSuppressionV4Config,nonMaxSuppressionV5Config,notEqualConfig,oneHotConfig,onesLikeConfig,packConfig,padV2Config,powConfig,preluConfig,prodConfig,raggedGatherConfig,raggedRangeConfig,raggedTensorToTensorConfig,rangeConfig,realConfig,realDivConfig,reciprocalConfig,reluConfig,relu6Config,reshapeConfig,resizeBilinearConfig,ResizeBilinearGrad_resizeBilinearGradConfig,resizeNearestNeighborConfig,ResizeNearestNeighborGrad_resizeNearestNeighborGradConfig,reverseConfig,rotateWithOffsetConfig,roundConfig,rsqrtConfig,scatterNdConfig,searchSortedConfig,selectConfig,seluConfig,sigmoidConfig,signConfig,sinConfig,sinhConfig,Slice.lv,softmaxConfig,softplusConfig,spaceToBatchNDConfig,sparseFillEmptyRowsConfig,sparseReshapeConfig,sparseSegmentMeanConfig,sparseSegmentSumConfig,sparseToDenseConfig,splitVConfig,sqrtConfig,squareConfig,squaredDifferenceConfig,staticRegexReplaceConfig,stepConfig,stridedSliceConfig,stringNGramsConfig,stringSplitConfig,stringToHashBucketFastConfig,subConfig,sumConfig,tanConfig,tanhConfig,tensorScatterUpdateConfig,tileConfig,topKConfig,transformConfig,transposeConfig,uniqueConfig,unpackConfig,unsortedSegmentSumConfig,zerosLikeConfig];for(const kernelConfig of kernelConfigs)(0,dist.tAK)(kernelConfig);var canvas_util_console=__webpack_require__("./node_modules/console-browserify/index.js");const contexts={},WEBGL_ATTRIBUTES={alpha:!1,antialias:!1,premultipliedAlpha:!1,preserveDrawingBuffer:!1,depth:!1,stencil:!1,failIfMajorPerformanceCaveat:!0};function setWebGLContext(webGLVersion,gl){contexts[webGLVersion]=gl}function getWebGLContext(webGLVersion,customCanvas){if(!(webGLVersion in contexts)||null!=customCanvas){const newCtx=function getWebGLRenderingContext(webGLVersion,customCanvas){if(1!==webGLVersion&&2!==webGLVersion)throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");const canvas=null==customCanvas?function createCanvas(webGLVersion){if((0,dist._K2)().getBool("IS_SAFARI")||"undefined"==typeof OffscreenCanvas||2!==webGLVersion){if("undefined"!=typeof document)return document.createElement("canvas");throw new Error("Cannot create a canvas in this context")}return new OffscreenCanvas(300,150)}(webGLVersion):customCanvas;canvas.addEventListener("webglcontextlost",ev=>{ev.preventDefault(),delete contexts[webGLVersion]},!1),(0,dist._K2)().getBool("SOFTWARE_WEBGL_ENABLED")&&(WEBGL_ATTRIBUTES.failIfMajorPerformanceCaveat=!1);if(1===webGLVersion)return canvas.getContext("webgl",WEBGL_ATTRIBUTES)||canvas.getContext("experimental-webgl",WEBGL_ATTRIBUTES);return canvas.getContext("webgl2",WEBGL_ATTRIBUTES)}(webGLVersion,customCanvas);if(null===newCtx)return canvas_util_console.log("Could not get context for WebGL version",webGLVersion),null;contexts[webGLVersion]=newCtx}const gl=contexts[webGLVersion];return null==gl||gl.isContextLost()?(delete contexts[webGLVersion],getWebGLContext(webGLVersion)):(gl.disable(gl.DEPTH_TEST),gl.disable(gl.STENCIL_TEST),gl.disable(gl.BLEND),gl.disable(gl.DITHER),gl.disable(gl.POLYGON_OFFSET_FILL),gl.disable(gl.SAMPLE_COVERAGE),gl.enable(gl.SCISSOR_TEST),gl.enable(gl.CULL_FACE),gl.cullFace(gl.BACK),contexts[webGLVersion])}var PackingScheme,TextureUsage,PhysicalTextureType;function getUnpackedMatrixTextureShapeWidthHeight(rows,columns){return[columns,rows]}function getDenseTexShape(shape){const size=dist.ZSL.sizeFromShape(shape),texelsNeeded=Math.ceil(size/4);return dist.ZSL.sizeToSquarishShape(texelsNeeded)}function getPackedMatrixTextureShapeWidthHeight(rows,columns){return[Math.max(1,Math.ceil(columns/2)),Math.max(1,Math.ceil(rows/2))]}function getTextureConfig(gl,textureHalfFloatExtension){const glany=gl;let internalFormatFloat,internalFormatHalfFloat,internalFormatPackedHalfFloat,internalFormatPackedFloat,textureFormatFloat,downloadTextureFormat,downloadUnpackNumChannels,defaultNumChannels,textureTypeHalfFloat,textureTypeFloat;return 2===(0,dist._K2)().getNumber("WEBGL_VERSION")?(internalFormatFloat=glany.R32F,internalFormatHalfFloat=glany.R16F,internalFormatPackedHalfFloat=glany.RGBA16F,internalFormatPackedFloat=glany.RGBA32F,textureFormatFloat=glany.RED,downloadUnpackNumChannels=4,defaultNumChannels=1,textureTypeHalfFloat=glany.HALF_FLOAT,textureTypeFloat=glany.FLOAT,downloadTextureFormat=glany.RGBA8):(internalFormatFloat=gl.RGBA,internalFormatHalfFloat=gl.RGBA,internalFormatPackedHalfFloat=gl.RGBA,internalFormatPackedFloat=glany.RGBA,textureFormatFloat=gl.RGBA,downloadUnpackNumChannels=4,defaultNumChannels=4,textureTypeHalfFloat=null!=textureHalfFloatExtension?textureHalfFloatExtension.HALF_FLOAT_OES:null,textureTypeFloat=gl.FLOAT,downloadTextureFormat=gl.RGBA),{internalFormatFloat,internalFormatHalfFloat,internalFormatPackedHalfFloat,internalFormatPackedFloat,textureFormatFloat,downloadTextureFormat,downloadUnpackNumChannels,defaultNumChannels,textureTypeHalfFloat,textureTypeFloat}}!function(PackingScheme){PackingScheme[PackingScheme.DENSE=0]="DENSE",PackingScheme[PackingScheme.SHARED_BATCH=1]="SHARED_BATCH"}(PackingScheme||(PackingScheme={})),function(TextureUsage){TextureUsage[TextureUsage.RENDER=0]="RENDER",TextureUsage[TextureUsage.UPLOAD=1]="UPLOAD",TextureUsage[TextureUsage.PIXELS=2]="PIXELS",TextureUsage[TextureUsage.DOWNLOAD=3]="DOWNLOAD"}(TextureUsage||(TextureUsage={})),function(PhysicalTextureType){PhysicalTextureType[PhysicalTextureType.UNPACKED_FLOAT16=0]="UNPACKED_FLOAT16",PhysicalTextureType[PhysicalTextureType.UNPACKED_FLOAT32=1]="UNPACKED_FLOAT32",PhysicalTextureType[PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE=2]="PACKED_4X1_UNSIGNED_BYTE",PhysicalTextureType[PhysicalTextureType.PACKED_2X2_FLOAT32=3]="PACKED_2X2_FLOAT32",PhysicalTextureType[PhysicalTextureType.PACKED_2X2_FLOAT16=4]="PACKED_2X2_FLOAT16"}(PhysicalTextureType||(PhysicalTextureType={}));var webgl_util_console=__webpack_require__("./node_modules/console-browserify/index.js");function callAndCheck(gl,func){const returnValue=func();return(0,dist._K2)().getBool("DEBUG")&&function checkWebGLError(gl){const error=gl.getError();if(error!==gl.NO_ERROR)throw new Error("WebGL Error: "+getWebGLErrorMessage(gl,error))}(gl),returnValue}const MIN_FLOAT16=5.96e-8,MAX_FLOAT16=65504;function canBeRepresented(num){return!!((0,dist._K2)().getBool("WEBGL_RENDER_FLOAT32_ENABLED")||0===num||MIN_FLOAT16<Math.abs(num)&&Math.abs(num)<MAX_FLOAT16)}function getWebGLErrorMessage(gl,status){switch(status){case gl.NO_ERROR:return"NO_ERROR";case gl.INVALID_ENUM:return"INVALID_ENUM";case gl.INVALID_VALUE:return"INVALID_VALUE";case gl.INVALID_OPERATION:return"INVALID_OPERATION";case gl.INVALID_FRAMEBUFFER_OPERATION:return"INVALID_FRAMEBUFFER_OPERATION";case gl.OUT_OF_MEMORY:return"OUT_OF_MEMORY";case gl.CONTEXT_LOST_WEBGL:return"CONTEXT_LOST_WEBGL";default:return`Unknown error code ${status}`}}function getExtensionOrThrow(gl,extensionName){return throwIfNull(gl,()=>gl.getExtension(extensionName),'Extension "'+extensionName+'" not supported on this browser.')}function createVertexShader(gl,vertexShaderSource){const vertexShader=throwIfNull(gl,()=>gl.createShader(gl.VERTEX_SHADER),"Unable to create vertex WebGLShader.");if(callAndCheck(gl,()=>gl.shaderSource(vertexShader,vertexShaderSource)),callAndCheck(gl,()=>gl.compileShader(vertexShader)),!1===gl.getShaderParameter(vertexShader,gl.COMPILE_STATUS))throw webgl_util_console.log(gl.getShaderInfoLog(vertexShader)),new Error("Failed to compile vertex shader.");return vertexShader}function createFragmentShader(gl,fragmentShaderSource){const fragmentShader=throwIfNull(gl,()=>gl.createShader(gl.FRAGMENT_SHADER),"Unable to create fragment WebGLShader.");if(callAndCheck(gl,()=>gl.shaderSource(fragmentShader,fragmentShaderSource)),callAndCheck(gl,()=>gl.compileShader(fragmentShader)),(0,dist._K2)().get("ENGINE_COMPILE_ONLY"))return fragmentShader;if(!1===gl.getShaderParameter(fragmentShader,gl.COMPILE_STATUS))throw logShaderSourceAndInfoLog(fragmentShaderSource,gl.getShaderInfoLog(fragmentShader)),new Error("Failed to compile fragment shader.");return fragmentShader}const lineNumberRegex=/ERROR: [0-9]+:([0-9]+):/g;function logShaderSourceAndInfoLog(shaderSource,shaderInfoLog){const lineNumberRegexResult=lineNumberRegex.exec(shaderInfoLog);if(null==lineNumberRegexResult)return webgl_util_console.log(`Couldn't parse line number in error: ${shaderInfoLog}`),void webgl_util_console.log(shaderSource);const lineNumber=+lineNumberRegexResult[1],shaderLines=shaderSource.split("\n"),pad=shaderLines.length.toString().length+2,linesWithLineNumbers=shaderLines.map((line,lineNumber)=>dist.ZSL.rightPad((lineNumber+1).toString(),pad)+line);let maxLineLength=0;for(let i=0;i<linesWithLineNumbers.length;i++)maxLineLength=Math.max(linesWithLineNumbers[i].length,maxLineLength);const beforeErrorLines=linesWithLineNumbers.slice(0,lineNumber-1),errorLine=linesWithLineNumbers.slice(lineNumber-1,lineNumber),afterErrorLines=linesWithLineNumbers.slice(lineNumber);webgl_util_console.log(beforeErrorLines.join("\n")),webgl_util_console.log(shaderInfoLog.split("\n")[0]),webgl_util_console.log(`%c ${dist.ZSL.rightPad(errorLine[0],maxLineLength)}`,"border:1px solid red; background-color:#e3d2d2; color:#a61717"),webgl_util_console.log(afterErrorLines.join("\n"))}function createProgram(gl){return throwIfNull(gl,()=>gl.createProgram(),"Unable to create WebGLProgram.")}function linkProgram(gl,program){if(callAndCheck(gl,()=>gl.linkProgram(program)),!(0,dist._K2)().get("ENGINE_COMPILE_ONLY")&&!1===gl.getProgramParameter(program,gl.LINK_STATUS))throw webgl_util_console.log(gl.getProgramInfoLog(program)),new Error("Failed to link vertex and fragment shaders.")}function validateProgram(gl,program){if(callAndCheck(gl,()=>gl.validateProgram(program)),!1===gl.getProgramParameter(program,gl.VALIDATE_STATUS))throw webgl_util_console.log(gl.getProgramInfoLog(program)),new Error("Shader program validation failed.")}function createStaticVertexBuffer(gl,data){const buffer=throwIfNull(gl,()=>gl.createBuffer(),"Unable to create WebGLBuffer");return callAndCheck(gl,()=>gl.bindBuffer(gl.ARRAY_BUFFER,buffer)),callAndCheck(gl,()=>gl.bufferData(gl.ARRAY_BUFFER,data,gl.STATIC_DRAW)),buffer}function createStaticIndexBuffer(gl,data){const buffer=throwIfNull(gl,()=>gl.createBuffer(),"Unable to create WebGLBuffer");return callAndCheck(gl,()=>gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER,buffer)),callAndCheck(gl,()=>gl.bufferData(gl.ELEMENT_ARRAY_BUFFER,data,gl.STATIC_DRAW)),buffer}function getNumChannels(){return 2===(0,dist._K2)().getNumber("WEBGL_VERSION")?1:4}function createTexture(gl){return throwIfNull(gl,()=>gl.createTexture(),"Unable to create WebGLTexture.")}function validateTextureSize(width,height){const maxTextureSize=(0,dist._K2)().getNumber("WEBGL_MAX_TEXTURE_SIZE");if(width<=0||height<=0){throw new Error("Requested texture size "+`[${width}x${height}]`+" is invalid.")}if(width>maxTextureSize||height>maxTextureSize){throw new Error("Requested texture size "+`[${width}x${height}]`+" greater than WebGL maximum on this browser / GPU "+`[${maxTextureSize}x${maxTextureSize}]`+".")}}function createFramebuffer(gl){return throwIfNull(gl,()=>gl.createFramebuffer(),"Unable to create WebGLFramebuffer.")}function bindVertexBufferToProgramAttribute(gl,program,attribute,buffer,arrayEntriesPerItem,itemStrideInBytes,itemOffsetInBytes){const loc=gl.getAttribLocation(program,attribute);return-1!==loc&&(callAndCheck(gl,()=>gl.bindBuffer(gl.ARRAY_BUFFER,buffer)),callAndCheck(gl,()=>gl.vertexAttribPointer(loc,arrayEntriesPerItem,gl.FLOAT,!1,itemStrideInBytes,itemOffsetInBytes)),callAndCheck(gl,()=>gl.enableVertexAttribArray(loc)),!0)}function bindTextureUnit(gl,texture,textureUnit){validateTextureUnit(gl,textureUnit),callAndCheck(gl,()=>gl.activeTexture(gl.TEXTURE0+textureUnit)),callAndCheck(gl,()=>gl.bindTexture(gl.TEXTURE_2D,texture))}function unbindTextureUnit(gl,textureUnit){validateTextureUnit(gl,textureUnit),callAndCheck(gl,()=>gl.activeTexture(gl.TEXTURE0+textureUnit)),callAndCheck(gl,()=>gl.bindTexture(gl.TEXTURE_2D,null))}function getProgramUniformLocationOrThrow(gl,program,uniformName){return throwIfNull(gl,()=>gl.getUniformLocation(program,uniformName),'uniform "'+uniformName+'" not present in program.')}function getProgramUniformLocation(gl,program,uniformName){return gl.getUniformLocation(program,uniformName)}function bindTextureToProgramUniformSampler(gl,texture,uniformSamplerLocation,textureUnit){callAndCheck(gl,()=>bindTextureUnit(gl,texture,textureUnit)),callAndCheck(gl,()=>gl.uniform1i(uniformSamplerLocation,textureUnit))}function bindCanvasToFramebuffer(gl){callAndCheck(gl,()=>gl.bindFramebuffer(gl.FRAMEBUFFER,null)),callAndCheck(gl,()=>gl.viewport(0,0,gl.canvas.width,gl.canvas.height)),callAndCheck(gl,()=>gl.scissor(0,0,gl.canvas.width,gl.canvas.height))}function bindColorTextureToFramebuffer(gl,texture,framebuffer){callAndCheck(gl,()=>gl.bindFramebuffer(gl.FRAMEBUFFER,framebuffer)),callAndCheck(gl,()=>gl.framebufferTexture2D(gl.FRAMEBUFFER,gl.COLOR_ATTACHMENT0,gl.TEXTURE_2D,texture,0))}function unbindColorTextureFromFramebuffer(gl,framebuffer){callAndCheck(gl,()=>gl.bindFramebuffer(gl.FRAMEBUFFER,framebuffer)),callAndCheck(gl,()=>gl.framebufferTexture2D(gl.FRAMEBUFFER,gl.COLOR_ATTACHMENT0,gl.TEXTURE_2D,null,0))}function validateFramebuffer(gl){const status=gl.checkFramebufferStatus(gl.FRAMEBUFFER);if(status!==gl.FRAMEBUFFER_COMPLETE)throw new Error("Error binding framebuffer: "+getFramebufferErrorMessage(gl,status))}function getFramebufferErrorMessage(gl,status){switch(status){case gl.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_ATTACHMENT";case gl.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";case gl.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:return"FRAMEBUFFER_INCOMPLETE_DIMENSIONS";case gl.FRAMEBUFFER_UNSUPPORTED:return"FRAMEBUFFER_UNSUPPORTED";default:return`unknown error ${status}`}}function throwIfNull(gl,returnTOrNull,failureMessage){const tOrNull=callAndCheck(gl,()=>returnTOrNull());if(null==tOrNull)throw new Error(failureMessage);return tOrNull}function validateTextureUnit(gl,textureUnit){const maxTextureUnit=gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS-1,glTextureUnit=textureUnit+gl.TEXTURE0;if(glTextureUnit<gl.TEXTURE0||glTextureUnit>maxTextureUnit){throw new Error(`textureUnit must be in ${`[gl.TEXTURE0, gl.TEXTURE${maxTextureUnit}]`}.`)}}function getBatchDim(shape,dimsToSkip=2){return dist.ZSL.sizeFromShape(shape.slice(0,shape.length-dimsToSkip))}function getRowsCols(shape){if(0===shape.length)throw Error("Cannot get rows and columns of an empty shape array.");return[shape.length>1?shape[shape.length-2]:1,shape[shape.length-1]]}function getShapeAs3D(shape){let shapeAs3D=[1,1,1];return 0===shape.length||1===shape.length&&1===shape[0]||(shapeAs3D=[getBatchDim(shape),...getRowsCols(shape)]),shapeAs3D}function getTextureShapeFromLogicalShape(logShape,isPacked=!1){let maxTexSize=(0,dist._K2)().getNumber("WEBGL_MAX_TEXTURE_SIZE"),maxSizeForNarrowTex=(0,dist._K2)().getNumber("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE");if(maxSizeForNarrowTex===1/0&&(0,dist._K2)().getBool("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE")&&(maxSizeForNarrowTex=maxTexSize/2),isPacked&&(maxTexSize*=2,maxSizeForNarrowTex*=2,1===(logShape=logShape.map((d,i)=>i>=logShape.length-2?dist.ZSL.nearestLargerEven(logShape[i]):logShape[i])).length&&(logShape=[2,logShape[0]])),2!==logShape.length){const squeezeResult=dist.ZSL.squeezeShape(logShape);logShape=squeezeResult.newShape}let size=dist.ZSL.sizeFromShape(logShape),textureShape=null;logShape.length<=1&&size<=maxTexSize?textureShape=[1,size]:2===logShape.length&&logShape[0]<=maxTexSize&&logShape[1]<=maxTexSize?textureShape=logShape:3===logShape.length&&logShape[0]*logShape[1]<=maxTexSize&&logShape[2]<=maxTexSize?textureShape=[logShape[0]*logShape[1],logShape[2]]:3===logShape.length&&logShape[0]<=maxTexSize&&logShape[1]*logShape[2]<=maxTexSize?textureShape=[logShape[0],logShape[1]*logShape[2]]:4===logShape.length&&logShape[0]*logShape[1]*logShape[2]<=maxTexSize&&logShape[3]<=maxTexSize?textureShape=[logShape[0]*logShape[1]*logShape[2],logShape[3]]:4===logShape.length&&logShape[0]<=maxTexSize&&logShape[1]*logShape[2]*logShape[3]<=maxTexSize&&(textureShape=[logShape[0],logShape[1]*logShape[2]*logShape[3]]);const isLongNarrowTex=null!=textureShape&&Math.max(...textureShape)>maxSizeForNarrowTex&&Math.min(...textureShape)<=(isPacked?2:1)&&Math.min(...textureShape)>0;if(null==textureShape||isLongNarrowTex)if(isPacked){const batchDim=getBatchDim(logShape);let rows=2,cols=2;logShape.length&&([rows,cols]=getRowsCols(logShape)),size=batchDim*(rows/2)*(cols/2),textureShape=dist.ZSL.sizeToSquarishShape(size).map(d=>2*d)}else textureShape=dist.ZSL.sizeToSquarishShape(size);return textureShape}function isEven(n){return n%2==0}function isReshapeFree(shape1,shape2){if(shape1=shape1.slice(-2),shape2=shape2.slice(-2),dist.ZSL.arraysEqual(shape1,shape2))return!0;if(!shape1.length||!shape2.length)return!0;if(0===shape1[0]||0===shape1[1]||0===shape2[0]||0===shape2[1])return!0;if(shape1.length!==shape2.length){const shape1Cols=shape1[shape1.length-1],shape2Cols=shape2[shape2.length-1];if(shape1Cols===shape2Cols)return!0;if(isEven(shape1Cols)&&isEven(shape2Cols)&&(1===shape1[0]||1===shape2[0]))return!0}return shape1[1]===shape2[1]&&isEven(shape1[0])&&isEven(shape2[0])}let MAX_TEXTURE_SIZE,MAX_TEXTURES_IN_SHADER;function getWebGLMaxTextureSize(webGLVersion){if(null==MAX_TEXTURE_SIZE){const gl=getWebGLContext(webGLVersion);MAX_TEXTURE_SIZE=gl.getParameter(gl.MAX_TEXTURE_SIZE)}return MAX_TEXTURE_SIZE}function resetMaxTextureSize(){MAX_TEXTURE_SIZE=null}function resetMaxTexturesInShader(){MAX_TEXTURES_IN_SHADER=null}function getMaxTexturesInShader(webGLVersion){if(null==MAX_TEXTURES_IN_SHADER){const gl=getWebGLContext(webGLVersion);MAX_TEXTURES_IN_SHADER=gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS)}return Math.min(16,MAX_TEXTURES_IN_SHADER)}function getWebGLDisjointQueryTimerVersion(webGLVersion){if(0===webGLVersion)return 0;let queryTimerVersion;const gl=getWebGLContext(webGLVersion);return queryTimerVersion=hasExtension(gl,"EXT_disjoint_timer_query_webgl2")&&2===webGLVersion?2:hasExtension(gl,"EXT_disjoint_timer_query")?1:0,queryTimerVersion}function hasExtension(gl,extensionName){return null!=gl.getExtension(extensionName)}function isWebGLVersionEnabled(webGLVersion){try{if(null!=getWebGLContext(webGLVersion))return!0}catch(e){return webgl_util_console.log("Error when getting WebGL context: ",e),!1}return!1}function isCapableOfRenderingToFloatTexture(webGLVersion){if(0===webGLVersion)return!1;const gl=getWebGLContext(webGLVersion);if(1===webGLVersion){if(!hasExtension(gl,"OES_texture_float"))return!1}else if(!hasExtension(gl,"EXT_color_buffer_float"))return!1;return createFloatTextureAndBindToFramebuffer(gl)}function isDownloadFloatTextureEnabled(webGLVersion){if(0===webGLVersion)return!1;const gl=getWebGLContext(webGLVersion);if(1!==webGLVersion){if(hasExtension(gl,"EXT_color_buffer_float"))return createFloatTextureAndBindToFramebuffer(gl);const COLOR_BUFFER_HALF_FLOAT="EXT_color_buffer_half_float";if(hasExtension(gl,COLOR_BUFFER_HALF_FLOAT)){const textureHalfFloatExtension=gl.getExtension(COLOR_BUFFER_HALF_FLOAT);return function createHalfFloatTextureAndBindToFramebuffer(gl,textureHalfFloatExtension){const texConfig=getTextureConfig(gl,textureHalfFloatExtension),texture=gl.createTexture();gl.bindTexture(gl.TEXTURE_2D,texture);const width=1,height=1;gl.texImage2D(gl.TEXTURE_2D,0,texConfig.internalFormatHalfFloat,width,height,0,texConfig.textureFormatFloat,texConfig.textureTypeHalfFloat,null);const frameBuffer=gl.createFramebuffer();gl.bindFramebuffer(gl.FRAMEBUFFER,frameBuffer),gl.framebufferTexture2D(gl.FRAMEBUFFER,gl.COLOR_ATTACHMENT0,gl.TEXTURE_2D,texture,0);const isFrameBufferComplete=gl.checkFramebufferStatus(gl.FRAMEBUFFER)===gl.FRAMEBUFFER_COMPLETE;return gl.bindTexture(gl.TEXTURE_2D,null),gl.bindFramebuffer(gl.FRAMEBUFFER,null),gl.deleteTexture(texture),gl.deleteFramebuffer(frameBuffer),isFrameBufferComplete}(gl,textureHalfFloatExtension)}return!1}if(!hasExtension(gl,"OES_texture_float"))return!1;if(!hasExtension(gl,"WEBGL_color_buffer_float"))return!1;return createFloatTextureAndBindToFramebuffer(gl)}function createFloatTextureAndBindToFramebuffer(gl){const texConfig=getTextureConfig(gl),texture=gl.createTexture();gl.bindTexture(gl.TEXTURE_2D,texture);gl.texImage2D(gl.TEXTURE_2D,0,texConfig.internalFormatFloat,1,1,0,texConfig.textureFormatFloat,texConfig.textureTypeFloat,null);const frameBuffer=gl.createFramebuffer();gl.bindFramebuffer(gl.FRAMEBUFFER,frameBuffer),gl.framebufferTexture2D(gl.FRAMEBUFFER,gl.COLOR_ATTACHMENT0,gl.TEXTURE_2D,texture,0);const isFrameBufferComplete=gl.checkFramebufferStatus(gl.FRAMEBUFFER)===gl.FRAMEBUFFER_COMPLETE;return gl.bindTexture(gl.TEXTURE_2D,null),gl.bindFramebuffer(gl.FRAMEBUFFER,null),gl.deleteTexture(texture),gl.deleteFramebuffer(frameBuffer),isFrameBufferComplete}function isWebGLFenceEnabled(webGLVersion){if(2!==webGLVersion)return!1;return null!=getWebGLContext(webGLVersion).fenceSync}function assertNotComplex(tensor,opName){Array.isArray(tensor)||(tensor=[tensor]),tensor.forEach(t=>{null!=t&&dist.ZSL.assert("complex64"!==t.dtype,()=>`${opName} does not support complex64 tensors in the WebGL backend.`)})}const flags_webgl_ENV=(0,dist._K2)();function getGlslDifferences(){let version,attribute,varyingVs,varyingFs,texture2D,output,defineOutput,defineSpecialNaN,defineSpecialInf,defineRound;return 2===(0,dist._K2)().getNumber("WEBGL_VERSION")?(version="#version 300 es",attribute="in",varyingVs="out",varyingFs="in",texture2D="texture",output="outputColor",defineOutput="out vec4 outputColor;",defineSpecialNaN=(0,dist._K2)().getBool("WEBGL2_ISNAN_CUSTOM")?"\n      bool isnan_custom(float val) {\n        uint floatToUint = floatBitsToUint(val);\n        return (floatToUint & 0x7fffffffu) > 0x7f800000u;\n      }\n\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan_custom(val.x),\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\n      }\n\n      #define isnan(value) isnan_custom(value)\n    ":"",defineSpecialInf="",defineRound="\n      #define round(value) newRound(value)\n      int newRound(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 newRound(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "):(version="",attribute="attribute",varyingVs="varying",varyingFs="varying",texture2D="texture2D",output="gl_FragColor",defineOutput="",defineSpecialNaN="\n      #define isnan(value) isnan_custom(value)\n      bool isnan_custom(float val) {\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\n      }\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\n      }\n    ",defineSpecialInf="\n      uniform float INFINITY;\n\n      bool isinf(float val) {\n        return abs(val) == INFINITY;\n      }\n      bvec4 isinf(vec4 val) {\n        return equal(abs(val), vec4(INFINITY));\n      }\n    ",defineRound="\n      int round(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 round(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "),{version,attribute,varyingVs,varyingFs,texture2D,output,defineOutput,defineSpecialNaN,defineSpecialInf,defineRound}}function getLogicalCoordinatesFromFlatIndex(coords,shape,index="index"){const strides=dist.ZSL.computeStrides(shape);return strides.map((stride,i)=>`${`int ${coords[i]} = ${index} / ${stride}`}; ${i===strides.length-1?`int ${coords[i+1]} = ${index} - ${coords[i]} * ${stride}`:`index -= ${coords[i]} * ${stride}`};`).join("")}function getOutputLogicalCoordinatesFromFlatIndexByUniform(coords,shape,index="index"){const strides=dist.ZSL.computeStrides(shape);return strides.map((_,i)=>`${`int ${coords[i]} = ${index} / outShapeStrides[${i}]`}; ${i===strides.length-1?`int ${coords[i+1]} = ${index} - ${coords[i]} * outShapeStrides[${i}]`:`index -= ${coords[i]} * outShapeStrides[${i}]`};`).join("")}function getLogicalCoordinatesFromFlatIndexByUniform(coords,variableName,index="index"){const strides=function symbolicallyComputeStrides(indicesArr,variableName){const numCoords=indicesArr.length,shape=indicesArr.map(d=>`${variableName}[${d}]`),strides=new Array(numCoords-1);strides[numCoords-2]=shape[numCoords-1];for(let i=numCoords-3;i>=0;--i)strides[i]=`(${strides[i+1]} * ${shape[i+1]})`;return strides}(coords.map((_,i)=>i),variableName);return strides.map((_,i)=>`${`int ${coords[i]} = ${index} / ${strides[i]}`}; ${i===strides.length-1?`int ${coords[i+1]} = ${index} - ${coords[i]} * ${strides[i]}`:`index -= ${coords[i]} * ${strides[i]}`};`).join("")}function getFlatIndexFrom3D(shape){const strides=dist.ZSL.computeStrides(shape).map(d=>d.toString());return`\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * ${strides[0]} + coords.y * ${strides[1]} + coords.z;\n  }\n`}flags_webgl_ENV.registerFlag("HAS_WEBGL",()=>flags_webgl_ENV.getNumber("WEBGL_VERSION")>0),flags_webgl_ENV.registerFlag("WEBGL_VERSION",()=>isWebGLVersionEnabled(2)?2:isWebGLVersionEnabled(1)?1:0),flags_webgl_ENV.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS",()=>!1),flags_webgl_ENV.registerFlag("WEBGL_BUFFER_SUPPORTED",()=>2===flags_webgl_ENV.get("WEBGL_VERSION")),flags_webgl_ENV.registerFlag("WEBGL_CPU_FORWARD",()=>!0),flags_webgl_ENV.registerFlag("WEBGL_FORCE_F16_TEXTURES",()=>!1),flags_webgl_ENV.registerFlag("WEBGL_PACK",()=>flags_webgl_ENV.getBool("HAS_WEBGL")),flags_webgl_ENV.registerFlag("WEBGL_PACK_NORMALIZATION",()=>flags_webgl_ENV.getBool("WEBGL_PACK")),flags_webgl_ENV.registerFlag("WEBGL_PACK_CLIP",()=>flags_webgl_ENV.getBool("WEBGL_PACK")),flags_webgl_ENV.registerFlag("WEBGL_PACK_DEPTHWISECONV",()=>flags_webgl_ENV.getBool("WEBGL_PACK")),flags_webgl_ENV.registerFlag("WEBGL_PACK_BINARY_OPERATIONS",()=>flags_webgl_ENV.getBool("WEBGL_PACK")),flags_webgl_ENV.registerFlag("WEBGL_PACK_UNARY_OPERATIONS",()=>flags_webgl_ENV.getBool("WEBGL_PACK")),flags_webgl_ENV.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS",()=>flags_webgl_ENV.getBool("WEBGL_PACK")),flags_webgl_ENV.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS",()=>flags_webgl_ENV.getBool("WEBGL_PACK")),flags_webgl_ENV.registerFlag("WEBGL_PACK_REDUCE",()=>flags_webgl_ENV.getBool("WEBGL_PACK")),flags_webgl_ENV.registerFlag("WEBGL_LAZILY_UNPACK",()=>flags_webgl_ENV.getBool("WEBGL_PACK")),flags_webgl_ENV.registerFlag("WEBGL_CONV_IM2COL",()=>flags_webgl_ENV.getBool("WEBGL_PACK")),flags_webgl_ENV.registerFlag("WEBGL_PACK_CONV2DTRANSPOSE",()=>flags_webgl_ENV.getBool("WEBGL_PACK")),flags_webgl_ENV.registerFlag("WEBGL_MAX_TEXTURE_SIZE",()=>getWebGLMaxTextureSize(flags_webgl_ENV.getNumber("WEBGL_VERSION"))),flags_webgl_ENV.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER",()=>getMaxTexturesInShader(flags_webgl_ENV.getNumber("WEBGL_VERSION"))),flags_webgl_ENV.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION",()=>{const webGLVersion=flags_webgl_ENV.getNumber("WEBGL_VERSION");return 0===webGLVersion?0:getWebGLDisjointQueryTimerVersion(webGLVersion)}),flags_webgl_ENV.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE",()=>flags_webgl_ENV.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0&&!dist.eMq.isMobile()),flags_webgl_ENV.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE",()=>isCapableOfRenderingToFloatTexture(flags_webgl_ENV.getNumber("WEBGL_VERSION"))),flags_webgl_ENV.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED",()=>!flags_webgl_ENV.getBool("WEBGL_FORCE_F16_TEXTURES")&&flags_webgl_ENV.getBool("WEBGL_RENDER_FLOAT32_CAPABLE")),flags_webgl_ENV.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED",()=>isDownloadFloatTextureEnabled(flags_webgl_ENV.getNumber("WEBGL_VERSION"))),flags_webgl_ENV.registerFlag("WEBGL_FENCE_API_ENABLED",()=>isWebGLFenceEnabled(flags_webgl_ENV.getNumber("WEBGL_VERSION"))),flags_webgl_ENV.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM",()=>flags_webgl_ENV.getBool("WEBGL_RENDER_FLOAT32_ENABLED")?4:0),flags_webgl_ENV.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD",()=>-1,threshold=>{if("number"!=typeof threshold)throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be a number but got ${threshold}.`);if(threshold<0&&-1!==threshold)throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ${threshold}.`)}),flags_webgl_ENV.registerFlag("WEBGL_FLUSH_THRESHOLD",()=>dist.eMq.isMobile()?1:-1,threshold=>{if("number"!=typeof threshold)throw new Error(`WEBGL_FLUSH_THRESHOLD must be a number but got ${threshold}.`);if(threshold<0&&-1!==threshold)throw new Error(`WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got ${threshold}.`)}),flags_webgl_ENV.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD",()=>128),flags_webgl_ENV.registerFlag("WEBGL_USE_SHAPES_UNIFORMS",()=>!1),flags_webgl_ENV.registerFlag("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD",()=>1e5),flags_webgl_ENV.registerFlag("TOPK_K_CPU_HANDOFF_THRESHOLD",()=>128),flags_webgl_ENV.registerFlag("WEBGL_EXP_CONV",()=>!1),flags_webgl_ENV.registerFlag("SOFTWARE_WEBGL_ENABLED",()=>flags_webgl_ENV.getBool("IS_TEST")),flags_webgl_ENV.registerFlag("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE",()=>1/0),flags_webgl_ENV.registerFlag("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE",()=>!1),flags_webgl_ENV.registerFlag("WEBGL2_ISNAN_CUSTOM",()=>!1),flags_webgl_ENV.registerFlag("ENGINE_COMPILE_ONLY",()=>!1);const ENCODE_FLOAT_SNIPPET="\n  const float FLOAT_MAX = 1.70141184e38;\n  const float FLOAT_MIN = 1.17549435e-38;\n\n  lowp vec4 encode_float(highp float v) {\n    if (isnan(v)) {\n      return vec4(255, 255, 255, 255);\n    }\n\n    highp float av = abs(v);\n\n    if(av < FLOAT_MIN) {\n      return vec4(0.0, 0.0, 0.0, 0.0);\n    } else if(v > FLOAT_MAX) {\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\n    } else if(v < -FLOAT_MAX) {\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\n    }\n\n    highp vec4 c = vec4(0,0,0,0);\n\n    highp float e = floor(log2(av));\n    highp float m = exp2(fract(log2(av))) - 1.0;\n\n    c[2] = floor(128.0 * m);\n    m -= c[2] / 128.0;\n    c[1] = floor(32768.0 * m);\n    m -= c[1] / 32768.0;\n    c[0] = floor(8388608.0 * m);\n\n    highp float ebias = e + 127.0;\n    c[3] = floor(ebias / 2.0);\n    ebias -= c[3] * 2.0;\n    c[2] += floor(ebias) * 128.0;\n\n    c[3] += 128.0 * step(0.0, -v);\n\n    return c / 255.0;\n  }\n",{getBroadcastDims}=dist.C0T;function makeShader(inputsInfo,outputShape,program){const prefixSnippets=[];if(inputsInfo.forEach(x=>{const size=dist.ZSL.sizeFromShape(x.shapeInfo.logicalShape);if(x.shapeInfo.isUniform?prefixSnippets.push(`uniform float ${x.name}${size>1?`[${size}]`:""};`):(prefixSnippets.push(`uniform sampler2D ${x.name};`),prefixSnippets.push(`uniform int offset${x.name};`)),program.enableShapeUniforms){const{uniformShape}=getUniformInfoFromShape(program.packedInputs,x.shapeInfo.logicalShape,x.shapeInfo.texShape);switch(uniformShape.length){case 1:prefixSnippets.push(`uniform int ${x.name}Shape;`);break;case 2:prefixSnippets.push(`uniform ivec2 ${x.name}Shape;`);break;case 3:prefixSnippets.push(`uniform ivec3 ${x.name}Shape;`);break;case 4:prefixSnippets.push(`uniform ivec4 ${x.name}Shape;`)}prefixSnippets.push(`uniform ivec2 ${x.name}TexShape;`)}}),program.enableShapeUniforms){switch(outputShape.logicalShape.length){case 1:prefixSnippets.push("uniform int outShape;");break;case 2:prefixSnippets.push("uniform ivec2 outShape;"),prefixSnippets.push("uniform int outShapeStrides;");break;case 3:prefixSnippets.push("uniform ivec3 outShape;"),prefixSnippets.push("uniform ivec2 outShapeStrides;");break;case 4:prefixSnippets.push("uniform ivec4 outShape;"),prefixSnippets.push("uniform ivec3 outShapeStrides;")}prefixSnippets.push("uniform ivec2 outTexShape;")}program.customUniforms&&program.customUniforms.forEach(d=>{prefixSnippets.push(`uniform ${d.type} ${d.name}${d.arrayIndex?`[${d.arrayIndex}]`:""};`)});const inputPrefixSnippet=prefixSnippets.join("\n"),inputSamplingSnippet=inputsInfo.map(x=>function getInputSamplingSnippet(inInfo,outShapeInfo,usesPackedTextures=!1,enableShapeUniforms){let res="";res+=usesPackedTextures?getPackedSamplerFromInInfo(inInfo,enableShapeUniforms):getSamplerFromInInfo(inInfo,enableShapeUniforms);const inShape=inInfo.shapeInfo.logicalShape,outShape=outShapeInfo.logicalShape;inShape.length<=outShape.length&&(res+=usesPackedTextures?function getPackedSamplerAtOutputCoords(inputInfo,outShapeInfo){const texName=inputInfo.name,texFuncSnippet=texName.charAt(0).toUpperCase()+texName.slice(1),funcName="get"+texFuncSnippet+"AtOutCoords",inRank=inputInfo.shapeInfo.logicalShape.length,outRank=outShapeInfo.logicalShape.length,broadcastDims=getBroadcastDims(inputInfo.shapeInfo.logicalShape,outShapeInfo.logicalShape),type=getCoordsDataType(outRank),rankDiff=outRank-inRank;let coordsSnippet;const fields=["x","y","z","w","u","v"];coordsSnippet=0===inRank?"":outRank<2&&broadcastDims.length>=1?"coords = 0;":broadcastDims.map(d=>`coords.${fields[d+rankDiff]} = 0;`).join("\n");let unpackedCoordsSnippet="";unpackedCoordsSnippet=outRank<2&&inRank>0?"coords":inputInfo.shapeInfo.logicalShape.map((s,i)=>`coords.${fields[i+rankDiff]}`).join(", ");let output="return outputValue;";const isInputScalar=1===dist.ZSL.sizeFromShape(inputInfo.shapeInfo.logicalShape),outSize=dist.ZSL.sizeFromShape(outShapeInfo.logicalShape),isOutputScalar=1===outSize;if(1!==inRank||isInputScalar||isOutputScalar){if(isInputScalar&&!isOutputScalar)output=1===outRank?"\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\n      ":"\n        return vec4(outputValue.x);\n      ";else if(broadcastDims.length){const rows=inRank-2,cols=inRank-1;broadcastDims.indexOf(rows)>-1&&broadcastDims.indexOf(cols)>-1?output="return vec4(outputValue.x);":broadcastDims.indexOf(rows)>-1?output="return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);":broadcastDims.indexOf(cols)>-1&&(output="return vec4(outputValue.xx, outputValue.zz);")}}else output="\n      return vec4(outputValue.xy, outputValue.xy);\n    ";return`\n    vec4 ${funcName}() {\n      ${type} coords = getOutputCoords();\n      ${coordsSnippet}\n      vec4 outputValue = get${texFuncSnippet}(${unpackedCoordsSnippet});\n      ${output}\n    }\n  `}(inInfo,outShapeInfo):function getSamplerAtOutputCoords(inputInfo,outShapeInfo){const texName=inputInfo.name,texFuncSnippet=texName.charAt(0).toUpperCase()+texName.slice(1),funcName="get"+texFuncSnippet+"AtOutCoords",outTexShape=outShapeInfo.texShape,inTexShape=inputInfo.shapeInfo.texShape,inRank=inputInfo.shapeInfo.logicalShape.length,outRank=outShapeInfo.logicalShape.length;if(!inputInfo.shapeInfo.isUniform&&inRank===outRank&&null==inputInfo.shapeInfo.flatOffset&&dist.ZSL.arraysEqual(inTexShape,outTexShape))return`\n      float ${funcName}() {\n        return sampleTexture(${texName}, resultUV);\n      }\n    `;const type=getCoordsDataType(outRank),broadcastDims=getBroadcastDims(inputInfo.shapeInfo.logicalShape,outShapeInfo.logicalShape),rankDiff=outRank-inRank;let coordsSnippet;const fields=["x","y","z","w","u","v"];coordsSnippet=0===inRank?"":outRank<2&&broadcastDims.length>=1?"coords = 0;":broadcastDims.map(d=>`coords.${fields[d+rankDiff]} = 0;`).join("\n");let unpackedCoordsSnippet="";unpackedCoordsSnippet=outRank<2&&inRank>0?"coords":inputInfo.shapeInfo.logicalShape.map((s,i)=>`coords.${fields[i+rankDiff]}`).join(", ");return`\n    float ${funcName}() {\n      ${type} coords = getOutputCoords();\n      ${coordsSnippet}\n      return get${texFuncSnippet}(${unpackedCoordsSnippet});\n    }\n  `}(inInfo,outShapeInfo));return res}(x,outputShape,program.packedInputs,program.enableShapeUniforms)).join("\n"),outTexShape=outputShape.texShape,glsl=getGlslDifferences(),floatTextureSampleSnippet=function getFloatTextureSampleSnippet(glsl){return`\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\n      return ${glsl.texture2D}(textureSampler, uv).r;\n    }\n  `}(glsl);let outputSamplingSnippet,floatTextureSetOutputSnippet,shaderPrefix=function getShaderPrefix(glsl){const SHADER_PREFIX=`${glsl.version}\n    precision highp float;\n    precision highp int;\n    precision highp sampler2D;\n    ${glsl.varyingFs} vec2 resultUV;\n    ${glsl.defineOutput}\n    const vec2 halfCR = vec2(0.5, 0.5);\n\n    struct ivec5\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n    };\n\n    struct ivec6\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n      int v;\n    };\n\n    uniform float NAN;\n    ${glsl.defineSpecialNaN}\n    ${glsl.defineSpecialInf}\n    ${glsl.defineRound}\n\n    int imod(int x, int y) {\n      return x - y * (x / y);\n    }\n\n    int idiv(int a, int b, float sign) {\n      int res = a / b;\n      int mod = imod(a, b);\n      if (sign < 0. && mod != 0) {\n        res -= 1;\n      }\n      return res;\n    }\n\n    //Based on the work of Dave Hoskins\n    //https://www.shadertoy.com/view/4djSRW\n    #define HASHSCALE1 443.8975\n    float random(float seed){\n      vec2 p = resultUV * seed;\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\n      p3 += dot(p3, p3.yzx + 19.19);\n      return fract((p3.x + p3.y) * p3.z);\n    }\n\n    ${SAMPLE_1D_SNIPPET}\n    ${SAMPLE_2D_SNIPPET}\n    ${SAMPLE_3D_SNIPPET}\n  `;return SHADER_PREFIX}(glsl);outputShape.isPacked?(outputSamplingSnippet=function getPackedOutputSamplingSnippet(outShape,outTexShape,enableShapeUniforms){switch(outShape.length){case 0:return getOutputScalarCoords();case 1:return function getOutputPacked1DCoords(shape,texShape,enableShapeUniforms){const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)];if(1===packedTexShape[0])return enableShapeUniforms?"\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));\n      }\n    ":`\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ${packedTexShape[1]}.0);\n      }\n    `;if(1===packedTexShape[1])return enableShapeUniforms?"\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));\n      }\n    ":`\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ${packedTexShape[0]}.0);\n      }\n    `;if(enableShapeUniforms)return"\n    int getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);\n    }\n  ";return`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));\n      return 2 * (resTexRC.x * ${packedTexShape[1]} + resTexRC.y);\n    }\n  `}(0,outTexShape,enableShapeUniforms);case 2:return function getOutputPacked2DCoords(shape,texShape,enableShapeUniforms){const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)];if(dist.ZSL.arraysEqual(shape,texShape))return enableShapeUniforms?"\n      ivec2 getOutputCoords() {\n        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        return 2 * ivec2(resultUV.yx * vec2(${packedTexShape[0]}, ${packedTexShape[1]}));\n      }\n    `;const texelsInLogicalRow=Math.ceil(shape[1]/2);if(enableShapeUniforms)return"\n    ivec2 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec2(r, c);\n    }\n  ";return`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));\n\n      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;\n      int r = 2 * (index / ${texelsInLogicalRow});\n      int c = imod(index, ${texelsInLogicalRow}) * 2;\n\n      return ivec2(r, c);\n    }\n  `}(outShape,outTexShape,enableShapeUniforms);case 3:return function getOutputPacked3DCoords(shape,texShape,enableShapeUniforms){if(enableShapeUniforms)return"\n    ivec3 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec3(b, r, c);\n    }\n  ";const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)],texelsInLogicalRow=Math.ceil(shape[2]/2),texelsInBatch=texelsInLogicalRow*Math.ceil(shape[1]/2);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));\n      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;\n\n      int b = index / ${texelsInBatch};\n      index -= b * ${texelsInBatch};\n\n      int r = 2 * (index / ${texelsInLogicalRow});\n      int c = imod(index, ${texelsInLogicalRow}) * 2;\n\n      return ivec3(b, r, c);\n    }\n  `}(outShape,outTexShape,enableShapeUniforms);default:return function getOutputPackedNDCoords(shape,texShape,enableShapeUniforms){if(enableShapeUniforms)return"\n    ivec4 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatchN = texelsInBatch * outShape[1];\n\n      int b2 = index / texelsInBatchN;\n      index -= b2 * texelsInBatchN;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec4(b2, b, r, c);\n    }\n  ";const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)],texelsInLogicalRow=Math.ceil(shape[shape.length-1]/2),texelsInBatch=texelsInLogicalRow*Math.ceil(shape[shape.length-2]/2);let texelsInBatchN=texelsInBatch,batches="",coords="b, r, c";for(let b=2;b<shape.length-1;b++)texelsInBatchN*=shape[shape.length-b-1],batches=`\n      int b${b} = index / ${texelsInBatchN};\n      index -= b${b} * ${texelsInBatchN};\n    `+batches,coords=`b${b}, `+coords;return`\n    ivec${shape.length} getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));\n      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;\n\n      ${batches}\n\n      int b = index / ${texelsInBatch};\n      index -= b * ${texelsInBatch};\n\n      int r = 2 * (index / ${texelsInLogicalRow});\n      int c = imod(index, ${texelsInLogicalRow}) * 2;\n\n      return ivec${shape.length}(${coords});\n    }\n  `}(outShape,outTexShape,enableShapeUniforms)}}(outputShape.logicalShape,outTexShape,program.enableShapeUniforms),floatTextureSetOutputSnippet=function getFloatTextureSetRGBASnippet(glsl){return`\n    void setOutput(vec4 val) {\n      ${glsl.output} = val;\n    }\n  `}(glsl)):(outputSamplingSnippet=function getOutputSamplingSnippet(outShape,outTexShape,enableShapeUniforms){switch(outShape.length){case 0:return getOutputScalarCoords();case 1:return function getOutput1DCoords(shape,texShape,enableShapeUniforms){if(1===texShape[0])return enableShapeUniforms?"\n      int getOutputCoords() {\n        return int(resultUV.x * float(outTexShape[1]));\n      }\n    ":`\n      int getOutputCoords() {\n        return int(resultUV.x * ${texShape[1]}.0);\n      }\n    `;if(1===texShape[1])return enableShapeUniforms?"\n      int getOutputCoords() {\n        return int(resultUV.y * float(outTexShape[0]));\n      }\n    ":`\n      int getOutputCoords() {\n        return int(resultUV.y * ${texShape[0]}.0);\n      }\n    `;if(enableShapeUniforms)return"\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      return resTexRC.x * outTexShape[1] + resTexRC.y;\n    }\n  ";return`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${texShape[0]}, ${texShape[1]}));\n      return resTexRC.x * ${texShape[1]} + resTexRC.y;\n    }\n  `}(0,outTexShape,enableShapeUniforms);case 2:return function getOutput2DCoords(shape,texShape,enableShapeUniforms){if(dist.ZSL.arraysEqual(shape,texShape))return enableShapeUniforms?"\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(${texShape[0]}, ${texShape[1]}));\n      }\n    `;if(1===shape[1])return enableShapeUniforms?"\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${texShape[0]}, ${texShape[1]}));\n        int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    `;if(1===shape[0])return enableShapeUniforms?"\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(0, index);\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${texShape[0]}, ${texShape[1]}));\n        int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n        return ivec2(0, index);\n      }\n    `;if(enableShapeUniforms)return"\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      int r = index / outShape[1];\n      int c = index - r * outShape[1];\n      return ivec2(r, c);\n    }\n  ";return`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${texShape[0]}, ${texShape[1]}));\n      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n      int r = index / ${shape[1]};\n      int c = index - r * ${shape[1]};\n      return ivec2(r, c);\n    }\n  `}(outShape,outTexShape,enableShapeUniforms);case 3:return function getOutput3DCoords(shape,texShape,enableShapeUniforms){if(enableShapeUniforms){return`\n  ivec3 getOutputCoords() {\n    ivec2 resTexRC = ivec2(resultUV.yx *\n                           vec2(outTexShape[0], outTexShape[1]));\n    int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n    ${getOutputLogicalCoordinatesFromFlatIndexByUniform(["r","c","d"],shape)}\n    return ivec3(r, c, d);\n  }\n`}const coordsFromIndexSnippet=getLogicalCoordinatesFromFlatIndex(["r","c","d"],shape);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${texShape[0]}, ${texShape[1]}));\n      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n      ${coordsFromIndexSnippet}\n      return ivec3(r, c, d);\n    }\n  `}(outShape,outTexShape,enableShapeUniforms);case 4:return function getOutput4DCoords(shape,texShape,enableShapeUniforms){if(enableShapeUniforms){return`\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      ${getOutputLogicalCoordinatesFromFlatIndexByUniform(["r","c","d","d2"],shape)}\n      return ivec4(r, c, d, d2);\n    }\n  `}const coordsFromIndexSnippet=getLogicalCoordinatesFromFlatIndex(["r","c","d","d2"],shape);return`\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${texShape[0]}, ${texShape[1]}));\n      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n      ${coordsFromIndexSnippet}\n      return ivec4(r, c, d, d2);\n    }\n  `}(outShape,outTexShape,enableShapeUniforms);case 5:return function getOutput5DCoords(shape,texShape){const coordsFromIndexSnippet=getLogicalCoordinatesFromFlatIndex(["r","c","d","d2","d3"],shape);return`\n    ivec5 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${texShape[0]},\n                             ${texShape[1]}));\n\n      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n\n      ${coordsFromIndexSnippet}\n\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\n      return outShape;\n    }\n  `}(outShape,outTexShape);case 6:return function getOutput6DCoords(shape,texShape){const coordsFromIndexSnippet=getLogicalCoordinatesFromFlatIndex(["r","c","d","d2","d3","d4"],shape);return`\n    ivec6 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${texShape[0]}, ${texShape[1]}));\n      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n\n      ${coordsFromIndexSnippet}\n\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\n      return result;\n    }\n  `}(outShape,outTexShape);default:throw new Error(`${outShape.length}-D output sampling is not yet supported`)}}(outputShape.logicalShape,outTexShape,program.enableShapeUniforms),floatTextureSetOutputSnippet=function getFloatTextureSetRSnippet(glsl){return`\n    void setOutput(float val) {\n      ${glsl.output} = vec4(val, 0, 0, 0);\n    }\n  `}(glsl)),program.packedInputs&&(shaderPrefix+=SHADER_PACKED_PREFIX);return[shaderPrefix,floatTextureSampleSnippet,floatTextureSetOutputSnippet,inputPrefixSnippet,outputSamplingSnippet,inputSamplingSnippet,program.userCode].join("\n")}function getSamplerFromInInfo(inInfo,enableShapeUniforms=!1){const shape=inInfo.shapeInfo.logicalShape;switch(shape.length){case 0:return function getSamplerScalar(inputInfo,enableShapeUniforms){const texName=inputInfo.name,funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);if(inputInfo.shapeInfo.isUniform)return`float ${funcName}() {return ${texName};}`;const[texNumR,texNumC]=inputInfo.shapeInfo.texShape;if(1===texNumR&&1===texNumC)return`\n      float ${funcName}() {\n        return sampleTexture(${texName}, halfCR);\n      }\n    `;const offset=getFlatOffsetUniformName(texName);if(enableShapeUniforms)return`\n    float ${funcName}() {\n      vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], ${offset});\n      return sampleTexture(${texName}, uv);\n    }\n  `;const[tNumR,tNumC]=inputInfo.shapeInfo.texShape;return`\n    float ${funcName}() {\n      vec2 uv = uvFromFlat(${tNumR}, ${tNumC}, ${offset});\n      return sampleTexture(${texName}, uv);\n    }\n  `}(inInfo,enableShapeUniforms);case 1:return function getSampler1D(inputInfo,enableShapeUniforms){const texName=inputInfo.name,funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);if(inputInfo.shapeInfo.isUniform)return`\n      float ${funcName}(int index) {\n        ${getUniformSampler(inputInfo)}\n      }\n    `;const texShape=inputInfo.shapeInfo.texShape,tNumR=texShape[0],tNumC=texShape[1];if(1===tNumC&&1===tNumR)return`\n      float ${funcName}(int index) {\n        return sampleTexture(${texName}, halfCR);\n      }\n    `;const offset=getFlatOffsetUniformName(texName);if(1===tNumC)return enableShapeUniforms?`\n      float ${funcName}(int index) {\n        vec2 uv = vec2(0.5, (float(index + ${offset}) + 0.5) / float(${texName}TexShape[0]));\n        return sampleTexture(${texName}, uv);\n      }\n    `:`\n      float ${funcName}(int index) {\n        vec2 uv = vec2(0.5, (float(index + ${offset}) + 0.5) / ${tNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `;if(1===tNumR)return enableShapeUniforms?`\n      float ${funcName}(int index) {\n        vec2 uv = vec2((float(index + ${offset}) + 0.5) / float(${texName}TexShape[1]), 0.5);\n        return sampleTexture(${texName}, uv);\n      }\n    `:`\n      float ${funcName}(int index) {\n        vec2 uv = vec2((float(index + ${offset}) + 0.5) / ${tNumC}.0, 0.5);\n        return sampleTexture(${texName}, uv);\n      }\n    `;if(enableShapeUniforms)return`\n    float ${funcName}(int index) {\n      vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], index + ${offset});\n      return sampleTexture(${texName}, uv);\n    }\n  `;return`\n    float ${funcName}(int index) {\n      vec2 uv = uvFromFlat(${tNumR}, ${tNumC}, index + ${offset});\n      return sampleTexture(${texName}, uv);\n    }\n  `}(inInfo,enableShapeUniforms);case 2:return function getSampler2D(inputInfo,enableShapeUniforms){const shape=inputInfo.shapeInfo.logicalShape,texName=inputInfo.name,funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1),texShape=inputInfo.shapeInfo.texShape;if(null!=texShape&&dist.ZSL.arraysEqual(shape,texShape)){if(enableShapeUniforms)return`\n      float ${funcName}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${texName}TexShape[1], ${texName}TexShape[0]);\n        return sampleTexture(${texName}, uv);\n      }\n    `;const texNumR=texShape[0];return`\n    float ${funcName}(int row, int col) {\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(${texShape[1]}.0, ${texNumR}.0);\n      return sampleTexture(${texName}, uv);\n    }\n  `}const{newShape,keptDims}=dist.ZSL.squeezeShape(shape),squeezedShape=newShape;if(squeezedShape.length<shape.length){const params=["row","col"];return`\n      ${getSamplerFromInInfo(squeezeInputInfo(inputInfo,squeezedShape),enableShapeUniforms)}\n      float ${funcName}(int row, int col) {\n        return ${funcName}(${getSqueezedParams(params,keptDims)});\n      }\n    `}if(inputInfo.shapeInfo.isUniform)return`\n      float ${funcName}(int row, int col) {\n        int index = round(dot(vec2(row, col), vec2(${shape[1]}, 1)));\n        ${getUniformSampler(inputInfo)}\n      }\n    `;const texNumR=texShape[0],texNumC=texShape[1],offset=getFlatOffsetUniformName(texName);if(1===texNumC)return enableShapeUniforms?`\n      float ${funcName}(int row, int col) {\n        float index = dot(vec3(row, col, ${offset}), vec3(${texName}Shape[1], 1, 1));\n        vec2 uv = vec2(0.5, (index + 0.5) / float(${texName}TexShape[0]));\n        return sampleTexture(${texName}, uv);\n      }\n    `:`\n    float ${funcName}(int row, int col) {\n      float index = dot(vec3(row, col, ${offset}), vec3(${shape[1]}, 1, 1));\n      vec2 uv = vec2(0.5, (index + 0.5) / ${texNumR}.0);\n      return sampleTexture(${texName}, uv);\n    }\n  `;if(1===texNumR)return enableShapeUniforms?`\n      float ${funcName}(int row, int col) {\n        float index = dot(vec3(row, col, ${offset}), vec3(${texName}Shape[1], 1, 1));\n        vec2 uv = vec2((index + 0.5) / float(${texName}TexShape[1]), 0.5);\n        return sampleTexture(${texName}, uv);\n      }\n    `:`\n    float ${funcName}(int row, int col) {\n      float index = dot(vec3(row, col, ${offset}), vec3(${shape[1]}, 1, 1));\n      vec2 uv = vec2((index + 0.5) / ${texNumC}.0, 0.5);\n      return sampleTexture(${texName}, uv);\n    }\n  `;if(enableShapeUniforms)return`\n      float ${funcName}(int row, int col) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ${texName}Shape[1] + col + ${offset};\n        vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], index);\n        return sampleTexture(${texName}, uv);\n      }\n    `;return`\n  float ${funcName}(int row, int col) {\n    // Explicitly use integer operations as dot() only works on floats.\n    int index = row * ${shape[1]} + col + ${offset};\n    vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);\n    return sampleTexture(${texName}, uv);\n  }\n`}(inInfo,enableShapeUniforms);case 3:return function getSampler3D(inputInfo,enableShapeUniforms){const shape=inputInfo.shapeInfo.logicalShape,texName=inputInfo.name,funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1),stride0=shape[1]*shape[2],stride1=shape[2],{newShape,keptDims}=dist.ZSL.squeezeShape(shape),squeezedShape=newShape;if(squeezedShape.length<shape.length){const params=["row","col","depth"];return`\n        ${getSamplerFromInInfo(squeezeInputInfo(inputInfo,squeezedShape),enableShapeUniforms)}\n        float ${funcName}(int row, int col, int depth) {\n          return ${funcName}(${getSqueezedParams(params,keptDims)});\n        }\n      `}if(inputInfo.shapeInfo.isUniform)return`\n      float ${funcName}(int row, int col, int depth) {\n        int index = round(dot(vec3(row, col, depth),\n                          vec3(${stride0}, ${stride1}, 1)));\n        ${getUniformSampler(inputInfo)}\n      }\n    `;const texShape=inputInfo.shapeInfo.texShape,texNumR=texShape[0],texNumC=texShape[1],flatOffset=inputInfo.shapeInfo.flatOffset;if(texNumC===stride0&&null==flatOffset)return enableShapeUniforms?`\n      float ${funcName}(int row, int col, int depth) {\n        int stride1 = ${texName}Shape[2];\n        float texR = float(row);\n        float texC = dot(vec2(col, depth), vec2(stride1, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${texName}TexShape[1], ${texName}TexShape[0]);\n        return sampleTexture(${texName}, uv);\n      }\n    `:`\n        float ${funcName}(int row, int col, int depth) {\n          float texR = float(row);\n          float texC = dot(vec2(col, depth), vec2(${stride1}, 1));\n          vec2 uv = (vec2(texC, texR) + halfCR) /\n                     vec2(${texNumC}.0, ${texNumR}.0);\n          return sampleTexture(${texName}, uv);\n        }\n      `;if(texNumC===stride1&&null==flatOffset)return enableShapeUniforms?`\n      float ${funcName}(int row, int col, int depth) {\n        float texR = dot(vec2(row, col), vec2(${texName}Shape[1], 1));\n        float texC = float(depth);\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${texName}TexShape[1], ${texName}TexShape[0]);\n        return sampleTexture(${texName}, uv);\n      }\n    `:`\n    float ${funcName}(int row, int col, int depth) {\n      float texR = dot(vec2(row, col), vec2(${shape[1]}, 1));\n      float texC = float(depth);\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${texNumC}.0, ${texNumR}.0);\n      return sampleTexture(${texName}, uv);\n    }\n  `;const offset=getFlatOffsetUniformName(texName);if(enableShapeUniforms)return`\n    float ${funcName}(int row, int col, int depth) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int stride0 = ${texName}Shape[1] * ${texName}Shape[2];\n      int stride1 = ${texName}Shape[2];\n      int index = row * stride0 + col * stride1 + depth + ${offset};\n      vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], index);\n      return sampleTexture(${texName}, uv);\n    }\n    `;return`\n      float ${funcName}(int row, int col, int depth) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ${stride0} + col * ${stride1} + depth + ${offset};\n        vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);\n        return sampleTexture(${texName}, uv);\n      }\n  `}(inInfo,enableShapeUniforms);case 4:return function getSampler4D(inputInfo,enableShapeUniforms){const shape=inputInfo.shapeInfo.logicalShape,texName=inputInfo.name,funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1),stride2=shape[3],stride1=shape[2]*stride2,stride0=shape[1]*stride1,{newShape,keptDims}=dist.ZSL.squeezeShape(shape);if(newShape.length<shape.length){const params=["row","col","depth","depth2"];return`\n      ${getSamplerFromInInfo(squeezeInputInfo(inputInfo,newShape),enableShapeUniforms)}\n      float ${funcName}(int row, int col, int depth, int depth2) {\n        return ${funcName}(${getSqueezedParams(params,keptDims)});\n      }\n    `}if(inputInfo.shapeInfo.isUniform)return`\n      float ${funcName}(int row, int col, int depth, int depth2) {\n        int index = round(dot(vec4(row, col, depth, depth2),\n                          vec4(${stride0}, ${stride1}, ${stride2}, 1)));\n        ${getUniformSampler(inputInfo)}\n      }\n    `;const flatOffset=inputInfo.shapeInfo.flatOffset,texShape=inputInfo.shapeInfo.texShape,texNumR=texShape[0],texNumC=texShape[1],stride2Str=`int stride2 = ${texName}Shape[3];`,stride1Str=`int stride1 = ${texName}Shape[2] * stride2;`,stride0Str=`int stride0 = ${texName}Shape[1] * stride1;`;if(texNumC===stride0&&null==flatOffset)return enableShapeUniforms?`\n      float ${funcName}(int row, int col, int depth, int depth2) {\n        ${stride2Str}\n        ${stride1Str}\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(stride1, stride2, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${texName}TexShape[1], ${texName}TexShape[0]);\n        return sampleTexture(${texName}, uv);\n      }\n    `:`\n      float ${funcName}(int row, int col, int depth, int depth2) {\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(${stride1}, ${stride2}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${texNumC}.0, ${texNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `;if(texNumC===stride2&&null==flatOffset)return enableShapeUniforms?`\n      float ${funcName}(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(${texName}Shape[1] * ${texName}Shape[2], ${texName}Shape[2], 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${texName}TexShape[1], ${texName}TexShape[0]);\n        return sampleTexture(${texName}, uv);\n      }\n    `:`\n      float ${funcName}(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(${shape[1]*shape[2]}, ${shape[2]}, 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${texNumC}.0, ${texNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `;const offset=getFlatOffsetUniformName(texName);if(enableShapeUniforms)return`\n    float ${funcName}(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      ${stride2Str}\n      ${stride1Str}\n      ${stride0Str}\n      int index = row * stride0 + col * stride1 +\n          depth * stride2 + depth2;\n      vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], index + ${offset});\n      return sampleTexture(${texName}, uv);\n    }\n  `;return`\n    float ${funcName}(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${stride0} + col * ${stride1} +\n          depth * ${stride2} + depth2;\n      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index + ${offset});\n      return sampleTexture(${texName}, uv);\n    }\n  `}(inInfo,enableShapeUniforms);case 5:return function getSampler5D(inputInfo){const shape=inputInfo.shapeInfo.logicalShape,texName=inputInfo.name,funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1),stride3=shape[4],stride2=shape[3]*stride3,stride1=shape[2]*stride2,stride0=shape[1]*stride1,{newShape,keptDims}=dist.ZSL.squeezeShape(shape);if(newShape.length<shape.length){const params=["row","col","depth","depth2","depth3"];return`\n      ${getSamplerFromInInfo(squeezeInputInfo(inputInfo,newShape))}\n      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {\n        return ${funcName}(${getSqueezedParams(params,keptDims)});\n      }\n    `}if(inputInfo.shapeInfo.isUniform)return`\n      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {\n        float index = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${stride0}, ${stride1}, ${stride2}, ${stride3})) +\n          depth3;\n        ${getUniformSampler(inputInfo)}\n      }\n    `;const flatOffset=inputInfo.shapeInfo.flatOffset,texShape=inputInfo.shapeInfo.texShape,texNumR=texShape[0],texNumC=texShape[1];if(texNumC===stride0&&null==flatOffset)return`\n      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n                         vec4(${stride1}, ${stride2}, ${stride3}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${texNumC}.0, ${texNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `;if(texNumC===stride3&&null==flatOffset)return`\n      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {\n        float texR = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${shape[1]*shape[2]*shape[3]},\n               ${shape[2]*shape[3]}, ${shape[3]}, 1));\n        int texC = depth3;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${texNumC}.0, ${texNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `;const offset=getFlatOffsetUniformName(texName);return`\n    float ${funcName}(int row, int col, int depth, int depth2, int depth3) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${stride0} + col * ${stride1} + depth * ${stride2} +\n          depth2 * ${stride3} + depth3 + ${offset};\n      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);\n      return sampleTexture(${texName}, uv);\n    }\n  `}(inInfo);case 6:return function getSampler6D(inputInfo){const shape=inputInfo.shapeInfo.logicalShape,texName=inputInfo.name,funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1),{newShape,keptDims}=dist.ZSL.squeezeShape(shape);if(newShape.length<shape.length){const params=["row","col","depth","depth2","depth3","depth4"];return`\n      ${getSamplerFromInInfo(squeezeInputInfo(inputInfo,newShape))}\n      float ${funcName}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        return ${funcName}(${getSqueezedParams(params,keptDims)});\n      }\n    `}const stride4=shape[5],stride3=shape[4]*stride4,stride2=shape[3]*stride3,stride1=shape[2]*stride2,stride0=shape[1]*stride1;if(inputInfo.shapeInfo.isUniform)return`\n      float ${funcName}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n        int index = round(dot(\n          vec4(row, col, depth, depth2),\n          vec4(${stride0}, ${stride1}, ${stride2}, ${stride3})) +\n          dot(\n            vec2(depth3, depth4),\n            vec2(${stride4}, 1)));\n        ${getUniformSampler(inputInfo)}\n      }\n    `;const flatOffset=inputInfo.shapeInfo.flatOffset,texShape=inputInfo.shapeInfo.texShape,texNumR=texShape[0],texNumC=texShape[1];if(texNumC===stride0&&null==flatOffset)return`\n      float ${funcName}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n          vec4(${stride1}, ${stride2}, ${stride3}, ${stride4})) +\n               float(depth4);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${texNumC}.0, ${texNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `;if(texNumC===stride4&&null==flatOffset)return`\n      float ${funcName}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        float texR = dot(vec4(row, col, depth, depth2),\n          vec4(${shape[1]*shape[2]*shape[3]*shape[4]},\n               ${shape[2]*shape[3]*shape[4]},\n               ${shape[3]*shape[4]},\n               ${shape[4]})) + float(depth3);\n        int texC = depth4;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${texNumC}.0, ${texNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `;const offset=getFlatOffsetUniformName(texName);return`\n    float ${funcName}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${stride0} + col * ${stride1} + depth * ${stride2} +\n          depth2 * ${stride3} + depth3 * ${stride4} + depth4 + ${offset};\n      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);\n      return sampleTexture(${texName}, uv);\n    }\n  `}(inInfo);default:throw new Error(`${shape.length}-D input sampling is not yet supported`)}}function getPackedSamplerFromInInfo(inInfo,enableShapeUniforms){switch(inInfo.shapeInfo.logicalShape.length){case 0:return function getPackedSamplerScalar(inputInfo){const texName=inputInfo.name,funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1),glsl=getGlslDifferences();return`\n    vec4 ${funcName}() {\n      return ${glsl.texture2D}(${texName}, halfCR);\n    }\n  `}(inInfo);case 1:return function getPackedSampler1D(inputInfo,enableShapeUniforms){const texName=inputInfo.name,funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1),texShape=inputInfo.shapeInfo.texShape,glsl=getGlslDifferences();if(enableShapeUniforms)return`\n    vec4 ${funcName}(int index) {\n      ivec2 packedTexShape = ivec2(ceil(float(${texName}TexShape[0]) / 2.0), ceil(float(${texName}TexShape[1]) / 2.0));\n      vec2 uv = packedUVfrom1D(\n        packedTexShape[0], packedTexShape[1], index);\n      return ${glsl.texture2D}(${texName}, uv);\n    }\n  `;const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)];return`\n    vec4 ${funcName}(int index) {\n      vec2 uv = packedUVfrom1D(\n        ${packedTexShape[0]}, ${packedTexShape[1]}, index);\n      return ${glsl.texture2D}(${texName}, uv);\n    }\n  `}(inInfo,enableShapeUniforms);case 2:return function getPackedSampler2D(inputInfo,enableShapeUniforms){const shape=inputInfo.shapeInfo.logicalShape,texName=inputInfo.name,funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1),texShape=inputInfo.shapeInfo.texShape,texNumR=texShape[0],texNumC=texShape[1],glsl=getGlslDifferences();if(null!=texShape&&dist.ZSL.arraysEqual(shape,texShape))return enableShapeUniforms?`\n      vec4 ${funcName}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${texName}TexShape[1], ${texName}TexShape[0]);\n\n        return ${glsl.texture2D}(${texName}, uv);\n      }\n    `:`\n      vec4 ${funcName}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${texNumC}.0, ${texNumR}.0);\n\n        return ${glsl.texture2D}(${texName}, uv);\n      }\n    `;if(enableShapeUniforms)return`\n    vec4 ${funcName}(int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(${texName}TexShape[0]) / 2.0), ceil(float(${texName}TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(${texName}Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);\n      return ${glsl.texture2D}(${texName}, uv);\n    }\n  `;const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)],valuesPerRow=Math.ceil(shape[1]/2);return`\n    vec4 ${funcName}(int row, int col) {\n      vec2 uv = packedUVfrom2D(${valuesPerRow}, ${packedTexShape[0]}, ${packedTexShape[1]}, row, col);\n      return ${glsl.texture2D}(${texName}, uv);\n    }\n  `}(inInfo,enableShapeUniforms);case 3:return function getPackedSampler3D(inputInfo,enableShapeUniforms){const shape=inputInfo.shapeInfo.logicalShape,texName=inputInfo.name,funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1),texShape=inputInfo.shapeInfo.texShape,packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)];if(1===shape[0]){const keptDims=[1,2],params=["b","row","col"];return`\n        ${getPackedSamplerFromInInfo(squeezeInputInfo(inputInfo,shape.slice(1)),enableShapeUniforms)}\n        vec4 ${funcName}(int b, int row, int col) {\n          return ${funcName}(${getSqueezedParams(params,keptDims)});\n        }\n      `}const glsl=getGlslDifferences();if(enableShapeUniforms)return`\n    vec4 ${funcName}(int b, int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(${texName}TexShape[0]) / 2.0), ceil(float(${texName}TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(${texName}Shape[2]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(${texName}Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom3D(\n        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);\n      return ${glsl.texture2D}(${texName}, uv);\n    }\n  `;const texNumR=packedTexShape[0],texNumC=packedTexShape[1],valuesPerRow=Math.ceil(shape[2]/2),texelsInBatch=valuesPerRow*Math.ceil(shape[1]/2);return`\n    vec4 ${funcName}(int b, int row, int col) {\n      vec2 uv = packedUVfrom3D(\n        ${texNumR}, ${texNumC}, ${texelsInBatch}, ${valuesPerRow}, b, row, col);\n      return ${glsl.texture2D}(${texName}, uv);\n    }\n  `}(inInfo,enableShapeUniforms);default:return function getPackedSamplerND(inputInfo,enableShapeUniforms){const texName=inputInfo.name,funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1),glsl=getGlslDifferences();if(enableShapeUniforms)return`\n    vec4 ${funcName}(int b2, int b, int row, int col) {\n      int valuesPerRow = int(ceil(float(${texName}Shape[3]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(${texName}Shape[2]) / 2.0));\n      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);\n      texelsInBatch *= ${texName}Shape[1];\n      index = b2 * texelsInBatch + index;\n      ivec2 packedTexShape = ivec2(ceil(float(${texName}TexShape[0]) / 2.0), ceil(float(${texName}TexShape[1]) / 2.0));\n      int texR = index / packedTexShape[1];\n      int texC = index - texR * packedTexShape[1];\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return ${glsl.texture2D}(${texName}, uv);\n    }\n  `;const shape=inputInfo.shapeInfo.logicalShape,rank=shape.length,texShape=inputInfo.shapeInfo.texShape,packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)],texNumR=packedTexShape[0],texNumC=packedTexShape[1],valuesPerRow=Math.ceil(shape[rank-1]/2);let texelsInBatch=valuesPerRow*Math.ceil(shape[rank-2]/2),params="int b, int row, int col",index=`b * ${texelsInBatch} + (row / 2) * ${valuesPerRow} + (col / 2)`;for(let b=2;b<rank-1;b++)params=`int b${b}, `+params,texelsInBatch*=shape[rank-b-1],index=`b${b} * ${texelsInBatch} + `+index;return`\n    vec4 ${funcName}(${params}) {\n      int index = ${index};\n      int texR = index / ${texNumC};\n      int texC = index - texR * ${texNumC};\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${texNumC}, ${texNumR});\n      return ${glsl.texture2D}(${texName}, uv);\n    }\n  `}(inInfo,enableShapeUniforms)}}const SAMPLE_1D_SNIPPET="\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\n  int texelIndex = index / 2;\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",SAMPLE_2D_SNIPPET="\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\n  int texNumC, int row, int col) {\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",SAMPLE_3D_SNIPPET="\nvec2 packedUVfrom3D(int texNumR, int texNumC,\n    int texelsInBatch, int texelsInLogicalRow, int b,\n    int row, int col) {\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",SHADER_PACKED_PREFIX="\n  float getChannel(vec4 frag, vec2 innerDims) {\n    vec2 modCoord = mod(innerDims, 2.);\n    return modCoord.x == 0. ?\n      (modCoord.y == 0. ? frag.r : frag.g) :\n      (modCoord.y == 0. ? frag.b : frag.a);\n  }\n  float getChannel(vec4 frag, int dim) {\n    float modCoord = mod(float(dim), 2.);\n    return modCoord == 0. ? frag.r : frag.g;\n  }\n";function getOutputScalarCoords(){return"\n    int getOutputCoords() {\n      return 0;\n    }\n  "}function getFlatOffsetUniformName(texName){return`offset${texName}`}function getUniformSampler(inputInfo){const texName=inputInfo.name,inSize=dist.ZSL.sizeFromShape(inputInfo.shapeInfo.logicalShape);return inSize<2?`return ${texName};`:`\n    for (int i = 0; i < ${inSize}; i++) {\n      if (i == index) {\n        return ${texName}[i];\n      }\n    }\n  `}function getCoordsDataType(rank){if(rank<=1)return"int";if(2===rank)return"ivec2";if(3===rank)return"ivec3";if(4===rank)return"ivec4";if(5===rank)return"ivec5";if(6===rank)return"ivec6";throw Error(`GPU for rank ${rank} is not yet supported`)}function getUniformInfoFromShape(isPacked,shape,texShape){const{newShape,keptDims}=dist.ZSL.squeezeShape(shape),rank=shape.length,useSqueezePackedShape=isPacked&&3===rank&&1===shape[0],squeezeShape=useSqueezePackedShape?shape.slice(1):newShape,useSqueezeShape=!isPacked&&rank>1&&!dist.ZSL.arraysEqual(shape,texShape)&&newShape.length<rank||useSqueezePackedShape;return{useSqueezeShape,uniformShape:useSqueezeShape?squeezeShape:shape,keptDims}}function squeezeInputInfo(inInfo,squeezedShape){const newInputInfo=JSON.parse(JSON.stringify(inInfo));return newInputInfo.shapeInfo.logicalShape=squeezedShape,newInputInfo}function getSqueezedParams(params,keptDims){return keptDims.map(d=>params[d]).join(", ")}function getUniformLocations(gpgpu,program,webGLProgram){const variablesLocations=[],customUniformLocations=[];let outShapeLocation,outTexShapeLocation,outShapeStridesLocation,infLoc=null,nanLoc=null;nanLoc=gpgpu.getUniformLocation(webGLProgram,"NAN",!1),1===(0,dist._K2)().getNumber("WEBGL_VERSION")&&(infLoc=gpgpu.getUniformLocation(webGLProgram,"INFINITY",!1));for(const varName of program.variableNames){const varLocs={name:varName,uniform:gpgpu.getUniformLocation(webGLProgram,varName,false),offset:gpgpu.getUniformLocation(webGLProgram,`offset${varName}`,false)};program.enableShapeUniforms&&(varLocs.shape=gpgpu.getUniformLocation(webGLProgram,`${varName}Shape`,false),varLocs.texShape=gpgpu.getUniformLocation(webGLProgram,`${varName}TexShape`,false)),variablesLocations.push(varLocs)}if(program.enableShapeUniforms&&(outShapeLocation=gpgpu.getUniformLocation(webGLProgram,"outShape",false),outShapeStridesLocation=gpgpu.getUniformLocation(webGLProgram,"outShapeStrides",false),outTexShapeLocation=gpgpu.getUniformLocation(webGLProgram,"outTexShape",false)),program.customUniforms)for(const d of program.customUniforms)customUniformLocations.push(gpgpu.getUniformLocation(webGLProgram,d.name,false));return{variablesLocations,customUniformLocations,infLoc,nanLoc,outShapeLocation,outShapeStridesLocation,outTexShapeLocation}}function validateBinaryAndProgram(shapeInfos,inputs){if(shapeInfos.length!==inputs.length)throw Error(`Binary was compiled with ${shapeInfos.length} inputs, but was executed with ${inputs.length} inputs`);shapeInfos.forEach((s,i)=>{const shapeA=s.logicalShape,input=inputs[i],shapeB=input.shape;if(!dist.ZSL.arraysEqual(shapeA,shapeB))throw Error(`Binary was compiled with different shapes than the current args. Shapes ${shapeA} and ${shapeB} must match`);if(s.isUniform&&input.isUniform)return;const texShapeA=s.texShape,texShapeB=input.isUniform?null:input.texData.texShape;if(!dist.ZSL.arraysEqual(texShapeA,texShapeB))throw Error(`Binary was compiled with different texture shapes than the current args. Shape ${texShapeA} and ${texShapeB} must match`)})}function useShapeUniforms(rank){return(0,dist._K2)().getBool("WEBGL_USE_SHAPES_UNIFORMS")&&rank<=4}class DecodeMatrixProgram{constructor(outputShape){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.outPackingScheme=PackingScheme.DENSE,this.customUniforms=[{name:"texShape",type:"ivec2"}];const glsl=getGlslDifferences();this.outputShape=outputShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length),this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${this.enableShapeUniforms?getOutputLogicalCoordinatesFromFlatIndexByUniform(["r","c","d"],outputShape):getLogicalCoordinatesFromFlatIndex(["r","c","d"],outputShape)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));\n        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getA(rc.x, rc.y, rc.z);\n        }\n\n        ${glsl.output} = result;\n      }\n    `}}class DecodeMatrixPackedProgram{constructor(outputShape){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outPackingScheme=PackingScheme.DENSE,this.customUniforms=[{name:"texShape",type:"ivec2"}];const glsl=getGlslDifferences();this.outputShape=outputShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length),this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${this.enableShapeUniforms?getOutputLogicalCoordinatesFromFlatIndexByUniform(["r","c","d"],outputShape):getLogicalCoordinatesFromFlatIndex(["r","c","d"],outputShape)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));\n        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\n        }\n\n        ${glsl.output} = result;\n      }\n    `}}class EncodeFloatProgram{constructor(outputShape){this.variableNames=["A"],this.outTexUsage=TextureUsage.DOWNLOAD;const glsl=getGlslDifferences();this.outputShape=outputShape,this.userCode=`\n      ${ENCODE_FLOAT_SNIPPET}\n\n      void main() {\n        float x = getAAtOutCoords();\n        ${glsl.output} = encode_float(x);\n      }\n    `}}class EncodeFloatPackedProgram{constructor(outputShape){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!1,this.outTexUsage=TextureUsage.DOWNLOAD;const glsl=getGlslDifferences();this.outputShape=outputShape,this.userCode=`\n      ${ENCODE_FLOAT_SNIPPET}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\n        ${glsl.output} = encode_float(x);\n      }\n    `}}const CHANNEL_CHAR_TO_INDEX_MAP={R:0,G:1,B:2,A:3};class EncodeMatrixProgram{constructor(outputShape,inputIsUnsignedByte=!1,usedChannels="RGBA"){this.variableNames=["A"],this.customUniforms=[{name:"texShape",type:"ivec2"}];const glsl=getGlslDifferences();this.outputShape=outputShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length);let output="result";inputIsUnsignedByte&&(output="floor(result * 255. + 0.5)");let mainLoop="";for(let usedChannelIndex=0;usedChannelIndex<usedChannels.length;usedChannelIndex++){const curChannel=usedChannels[usedChannelIndex];mainLoop+=`\n          if(offset == ${usedChannelIndex}) {\n            result = values[${CHANNEL_CHAR_TO_INDEX_MAP[curChannel]}];\n          }`}this.userCode=`\n      ${this.enableShapeUniforms?"\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;\n  }\n":getFlatIndexFrom3D(outputShape)}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int flatIndex = getFlatIndex(coords);\n        float result = 0.;\n        int offset = imod(flatIndex, ${usedChannels.length});\n\n        flatIndex = idiv(flatIndex, ${usedChannels.length}, 1.);\n\n        int r = flatIndex / texShape[1];\n        if (r < texShape[0]) {\n          int c = imod(flatIndex, texShape[1]);\n          vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);\n          vec4 values = ${glsl.texture2D}(A, uv);\n          ${mainLoop}\n        }\n        ${glsl.output} = vec4(${output}, 0., 0., 0.);\n      }\n    `}}class EncodeMatrixPackedProgram{constructor(outputShape,inputIsUnsignedByte=!1){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.customUniforms=[{name:"texShape",type:"ivec2"}];const glsl=getGlslDifferences();this.outputShape=outputShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length);let mainLoop="",output="result";inputIsUnsignedByte&&(output="floor(result * 255. + 0.5)");for(let row=0;row<=1;row++)for(let col=0;col<=1;col++){const channel=2*row+col;mainLoop+=`\n          localCoords = coords;\n          if(localCoords[2] + ${col} < ${this.enableShapeUniforms?"outShape[2]":`${outputShape[2]}`}) {\n          localCoords[2] += ${col};\n          if (localCoords[1] + ${row} < ${this.enableShapeUniforms?"outShape[1]":`${outputShape[1]}`}) {\n            localCoords[1] += ${row};\n\n            flatIndex = getFlatIndex(localCoords);\n            offset = imod(flatIndex, 4);\n\n            flatIndex = idiv(flatIndex, 4, 1.);\n\n            int r = flatIndex / texShape[1];\n            int c = imod(flatIndex, texShape[1]);\n            vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);\n            values = ${glsl.texture2D}(A, uv);\n\n            if (offset == 0) {\n              result[${channel}] = values[0];\n            } else if (offset == 1) {\n              result[${channel}] = values[1];\n            } else if (offset == 2) {\n              result[${channel}] = values[2];\n            } else {\n              result[${channel}] = values[3];\n            }\n          }\n        }\n        `}this.userCode=`\n        ${this.enableShapeUniforms?"\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;\n  }\n":getFlatIndexFrom3D(outputShape)}\n\n        void main() {\n          ivec3 coords = getOutputCoords();\n\n          vec4 result = vec4(0.);\n          int flatIndex, r, c, offset;\n          ivec3 localCoords;\n          vec2 uv;\n          vec4 values;\n\n          ${mainLoop}\n\n          ${glsl.output} = ${output};\n        }\n    `}}function gpgpu_util_createVertexShader(gl){const glsl=getGlslDifferences();return createVertexShader(gl,`${glsl.version}\n    precision highp float;\n    ${glsl.attribute} vec3 clipSpacePos;\n    ${glsl.attribute} vec2 uv;\n    ${glsl.varyingVs} vec2 resultUV;\n\n    void main() {\n      gl_Position = vec4(clipSpacePos, 1);\n      resultUV = uv;\n    }`)}function createVertexBuffer(gl){return createStaticVertexBuffer(gl,new Float32Array([-1,1,0,0,1,-1,-1,0,0,0,1,1,0,1,1,1,-1,0,1,0]))}function createIndexBuffer(gl){return createStaticIndexBuffer(gl,new Uint16Array([0,1,2,2,1,3]))}function createAndConfigureTexture(gl,width,height,internalFormat,textureFormat,textureType){validateTextureSize(width,height);const texture=createTexture(gl),tex2d=gl.TEXTURE_2D;return callAndCheck(gl,()=>gl.bindTexture(tex2d,texture)),callAndCheck(gl,()=>gl.texParameteri(tex2d,gl.TEXTURE_WRAP_S,gl.CLAMP_TO_EDGE)),callAndCheck(gl,()=>gl.texParameteri(tex2d,gl.TEXTURE_WRAP_T,gl.CLAMP_TO_EDGE)),callAndCheck(gl,()=>gl.texParameteri(tex2d,gl.TEXTURE_MIN_FILTER,gl.NEAREST)),callAndCheck(gl,()=>gl.texParameteri(tex2d,gl.TEXTURE_MAG_FILTER,gl.NEAREST)),1===(0,dist._K2)().getNumber("WEBGL_VERSION")?callAndCheck(gl,()=>gl.texImage2D(tex2d,0,internalFormat,width,height,0,textureFormat,textureType,null)):callAndCheck(gl,()=>gl.texStorage2D(tex2d,1,internalFormat,width,height)),callAndCheck(gl,()=>gl.bindTexture(gl.TEXTURE_2D,null)),{texture,texShape:[height,width]}}function getInternalFormatForFloat32MatrixTexture(textureConfig){return textureConfig.internalFormatFloat}function createFloat32MatrixTexture(gl,rows,columns,textureConfig){const[width,height]=getUnpackedMatrixTextureShapeWidthHeight(rows,columns);return createAndConfigureTexture(gl,width,height,getInternalFormatForFloat32MatrixTexture(textureConfig),textureConfig.textureFormatFloat,gl.FLOAT)}function getInternalFormatForFloat16MatrixTexture(textureConfig){return textureConfig.internalFormatHalfFloat}function createFloat16MatrixTexture(gl,rows,columns,textureConfig){const[width,height]=getUnpackedMatrixTextureShapeWidthHeight(rows,columns);return createAndConfigureTexture(gl,width,height,getInternalFormatForFloat16MatrixTexture(textureConfig),textureConfig.textureFormatFloat,textureConfig.textureTypeHalfFloat)}function getInternalFormatForUnsignedBytesMatrixTexture(textureConfig){return textureConfig.downloadTextureFormat}function createUnsignedBytesMatrixTexture(gl,rows,columns,textureConfig){const[width,height]=getUnpackedMatrixTextureShapeWidthHeight(rows,columns);return createAndConfigureTexture(gl,width,height,getInternalFormatForUnsignedBytesMatrixTexture(textureConfig),gl.RGBA,gl.UNSIGNED_BYTE)}function getInternalFormatForPackedMatrixTexture(textureConfig){return textureConfig.internalFormatPackedFloat}function createPackedMatrixTexture(gl,rows,columns,textureConfig){const[width,height]=getPackedMatrixTextureShapeWidthHeight(rows,columns);return createAndConfigureTexture(gl,width,height,getInternalFormatForPackedMatrixTexture(textureConfig),gl.RGBA,gl.FLOAT)}function getInternalFormatForFloat16PackedMatrixTexture(textureConfig){return textureConfig.internalFormatPackedHalfFloat}function createFloat16PackedMatrixTexture(gl,rows,columns,textureConfig){const[width,height]=getPackedMatrixTextureShapeWidthHeight(rows,columns);return createAndConfigureTexture(gl,width,height,getInternalFormatForFloat16PackedMatrixTexture(textureConfig),gl.RGBA,textureConfig.textureTypeHalfFloat)}function bindVertexProgramAttributeStreams(gl,program,vertexBuffer){callAndCheck(gl,()=>gl.bindBuffer(gl.ARRAY_BUFFER,vertexBuffer));return bindVertexBufferToProgramAttribute(gl,program,"clipSpacePos",vertexBuffer,3,20,0)&&bindVertexBufferToProgramAttribute(gl,program,"uv",vertexBuffer,2,20,12)}function uploadDenseMatrixToTexture(gl,texture,width,height,data,textureConfig){let dataForUpload,texelDataType,internalFormat;callAndCheck(gl,()=>gl.bindTexture(gl.TEXTURE_2D,texture)),data instanceof Uint8Array?(dataForUpload=new Uint8Array(width*height*4),texelDataType=gl.UNSIGNED_BYTE,internalFormat=gl.RGBA):(dataForUpload=new Float32Array(width*height*4),texelDataType=gl.FLOAT,internalFormat=textureConfig.internalFormatPackedFloat),dataForUpload.set(data),2===(0,dist._K2)().getNumber("WEBGL_VERSION")?callAndCheck(gl,()=>gl.texSubImage2D(gl.TEXTURE_2D,0,0,0,width,height,gl.RGBA,texelDataType,dataForUpload)):callAndCheck(gl,()=>gl.texImage2D(gl.TEXTURE_2D,0,internalFormat,width,height,0,gl.RGBA,texelDataType,dataForUpload)),callAndCheck(gl,()=>gl.bindTexture(gl.TEXTURE_2D,null))}function uploadPixelDataToTexture(gl,texture,pixels){callAndCheck(gl,()=>gl.bindTexture(gl.TEXTURE_2D,texture)),pixels.data instanceof Uint8Array?2===(0,dist._K2)().getNumber("WEBGL_VERSION")?callAndCheck(gl,()=>gl.texSubImage2D(gl.TEXTURE_2D,0,0,0,pixels.width,pixels.height,gl.RGBA,gl.UNSIGNED_BYTE,pixels.data)):callAndCheck(gl,()=>gl.texImage2D(gl.TEXTURE_2D,0,gl.RGBA,pixels.width,pixels.height,0,gl.RGBA,gl.UNSIGNED_BYTE,pixels.data)):2===(0,dist._K2)().getNumber("WEBGL_VERSION")?callAndCheck(gl,()=>gl.texSubImage2D(gl.TEXTURE_2D,0,0,0,gl.RGBA,gl.UNSIGNED_BYTE,pixels)):callAndCheck(gl,()=>gl.texImage2D(gl.TEXTURE_2D,0,gl.RGBA,gl.RGBA,gl.UNSIGNED_BYTE,pixels)),callAndCheck(gl,()=>gl.bindTexture(gl.TEXTURE_2D,null))}function createBufferFromOutputTexture(gl2,rows,columns,textureConfig){const buffer=gl2.createBuffer();callAndCheck(gl2,()=>gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER,buffer));const bufferSizeBytes=16*rows*columns;return callAndCheck(gl2,()=>gl2.bufferData(gl2.PIXEL_PACK_BUFFER,bufferSizeBytes,gl2.STREAM_READ)),callAndCheck(gl2,()=>gl2.readPixels(0,0,columns,rows,gl2.RGBA,gl2.FLOAT,0)),callAndCheck(gl2,()=>gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER,null)),buffer}function downloadFloat32MatrixFromBuffer(gl,buffer,size){const gl2=gl,downloadTarget=new Float32Array(size);return gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER,buffer),gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER,0,downloadTarget),gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER,null),downloadTarget}function downloadByteEncodedFloatMatrixFromOutputTexture(gl,rows,columns,textureConfig){const[w,h]=getUnpackedMatrixTextureShapeWidthHeight(rows,columns),downloadTarget=new Uint8Array(function getUnpackedArraySizeFromMatrixSize(matrixSize,channelsPerTexture){return matrixSize*channelsPerTexture}(rows*columns,4));return callAndCheck(gl,()=>gl.readPixels(0,0,w,h,textureConfig.downloadTextureFormat,gl.UNSIGNED_BYTE,downloadTarget)),new Float32Array(downloadTarget.buffer)}function downloadPackedMatrixFromBuffer(gl,buffer,batch,rows,cols,physicalRows,physicalCols,textureConfig){const gl2=gl,downloadTarget=new Float32Array(function getPackedRGBAArraySizeFromMatrixShape(rows,columns){const[w,h]=getPackedMatrixTextureShapeWidthHeight(rows,columns);return w*h*4}(physicalRows,physicalCols));return gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER,buffer),gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER,0,downloadTarget),gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER,null),downloadTarget}function downloadMatrixFromPackedOutputTexture(gl,physicalRows,physicalCols){const packedRGBA=new Float32Array(physicalRows*physicalCols*4);return callAndCheck(gl,()=>gl.readPixels(0,0,physicalCols,physicalRows,gl.RGBA,gl.FLOAT,packedRGBA)),packedRGBA}var gpgpu_context_console=__webpack_require__("./node_modules/console-browserify/index.js");class GPGPUContext{constructor(gl){this.outputTexture=null,this.program=null,this.disposed=!1,this.itemsToPoll=[];const glVersion=(0,dist._K2)().getNumber("WEBGL_VERSION");if(null!=gl?(this.gl=gl,setWebGLContext(glVersion,gl)):this.gl=getWebGLContext(glVersion),gl=this.gl,2===(0,dist._K2)().getNumber("WEBGL_VERSION")){const gl2=gl;this.createVertexArray=()=>callAndCheck(gl2,()=>gl2.createVertexArray()),this.bindVertexArray=vao=>callAndCheck(gl2,()=>gl2.bindVertexArray(vao)),this.deleteVertexArray=vao=>callAndCheck(gl2,()=>gl2.deleteVertexArray(vao)),this.getVertexArray=()=>callAndCheck(gl2,()=>gl2.getParameter(gl2.VERTEX_ARRAY_BINDING))}else if(null!=gl){const ext=gl.getExtension("OES_vertex_array_object");if(null==ext)throw new Error("All WebGL1 implementations are expected to offer OES_vertex_array_object.");this.createVertexArray=()=>callAndCheck(gl,()=>ext.createVertexArrayOES()),this.bindVertexArray=vao=>callAndCheck(gl,()=>ext.bindVertexArrayOES(vao)),this.deleteVertexArray=vao=>callAndCheck(gl,()=>ext.deleteVertexArrayOES(vao)),this.getVertexArray=()=>callAndCheck(gl,()=>gl.getParameter(ext.VERTEX_ARRAY_BINDING_OES))}let COLOR_BUFFER_FLOAT="WEBGL_color_buffer_float";if(this.parallelCompilationExtension=this.gl.getExtension("KHR_parallel_shader_compile"),1===(0,dist._K2)().getNumber("WEBGL_VERSION")){const TEXTURE_FLOAT="OES_texture_float",TEXTURE_HALF_FLOAT="OES_texture_half_float";if(this.textureFloatExtension=getExtensionOrThrow(this.gl,TEXTURE_FLOAT),hasExtension(this.gl,TEXTURE_HALF_FLOAT))this.textureHalfFloatExtension=getExtensionOrThrow(this.gl,TEXTURE_HALF_FLOAT);else if((0,dist._K2)().get("WEBGL_FORCE_F16_TEXTURES"))throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");if(this.colorBufferFloatExtension=this.gl.getExtension(COLOR_BUFFER_FLOAT),hasExtension(this.gl,"EXT_color_buffer_half_float"))this.colorBufferHalfFloatExtension=getExtensionOrThrow(this.gl,"EXT_color_buffer_half_float");else if((0,dist._K2)().get("WEBGL_FORCE_F16_TEXTURES"))throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.")}else if(COLOR_BUFFER_FLOAT="EXT_color_buffer_float",hasExtension(this.gl,COLOR_BUFFER_FLOAT))this.colorBufferFloatExtension=this.gl.getExtension(COLOR_BUFFER_FLOAT);else{if(!hasExtension(this.gl,"EXT_color_buffer_half_float"))throw new Error("GL context does not support color renderable floats");this.colorBufferHalfFloatExtension=this.gl.getExtension("EXT_color_buffer_half_float")}this.vertexBuffer=createVertexBuffer(this.gl),this.indexBuffer=createIndexBuffer(this.gl),this.framebuffer=createFramebuffer(this.gl),this.textureConfig=getTextureConfig(this.gl,this.textureHalfFloatExtension)}get debug(){return(0,dist._K2)().getBool("DEBUG")}dispose(){if(this.disposed)return;null!=this.program&&gpgpu_context_console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing."),null!=this.outputTexture&&gpgpu_context_console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");const gl=this.gl;callAndCheck(gl,()=>gl.finish()),callAndCheck(gl,()=>gl.bindFramebuffer(gl.FRAMEBUFFER,null)),callAndCheck(gl,()=>gl.deleteFramebuffer(this.framebuffer)),callAndCheck(gl,()=>gl.bindBuffer(gl.ARRAY_BUFFER,null)),callAndCheck(gl,()=>gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER,null)),callAndCheck(gl,()=>gl.deleteBuffer(this.indexBuffer)),this.disposed=!0}createFloat32MatrixTexture(rows,columns){return this.throwIfDisposed(),createFloat32MatrixTexture(this.gl,rows,columns,this.textureConfig)}createFloat16MatrixTexture(rows,columns){return this.throwIfDisposed(),createFloat16MatrixTexture(this.gl,rows,columns,this.textureConfig)}createUnsignedBytesMatrixTexture(rows,columns){return this.throwIfDisposed(),createUnsignedBytesMatrixTexture(this.gl,rows,columns,this.textureConfig)}uploadPixelDataToTexture(texture,pixels){this.throwIfDisposed(),uploadPixelDataToTexture(this.gl,texture,pixels)}uploadDenseMatrixToTexture(texture,width,height,data){this.throwIfDisposed(),uploadDenseMatrixToTexture(this.gl,texture,width,height,data,this.textureConfig)}createFloat16PackedMatrixTexture(rows,columns){return this.throwIfDisposed(),createFloat16PackedMatrixTexture(this.gl,rows,columns,this.textureConfig)}createPackedMatrixTexture(rows,columns){return this.throwIfDisposed(),createPackedMatrixTexture(this.gl,rows,columns,this.textureConfig)}deleteMatrixTexture(texture){this.throwIfDisposed(),this.outputTexture===texture&&(unbindColorTextureFromFramebuffer(this.gl,this.framebuffer),this.outputTexture=null),callAndCheck(this.gl,()=>this.gl.deleteTexture(texture))}downloadByteEncodedFloatMatrixFromOutputTexture(texture,rows,columns){return this.downloadMatrixDriver(texture,()=>downloadByteEncodedFloatMatrixFromOutputTexture(this.gl,rows,columns,this.textureConfig))}downloadPackedMatrixFromBuffer(buffer,batch,rows,columns,physicalRows,physicalCols){return downloadPackedMatrixFromBuffer(this.gl,buffer,0,0,0,physicalRows,physicalCols,this.textureConfig)}downloadFloat32MatrixFromBuffer(buffer,size){return downloadFloat32MatrixFromBuffer(this.gl,buffer,size)}createBufferFromTexture(texture,rows,columns){this.bindTextureToFrameBuffer(texture);const result=createBufferFromOutputTexture(this.gl,rows,columns,this.textureConfig);return this.unbindTextureToFrameBuffer(),result}createAndWaitForFence(){const fenceContext=this.createFence(this.gl);return this.pollFence(fenceContext)}createFence(gl){let query,isFencePassed;if((0,dist._K2)().getBool("WEBGL_FENCE_API_ENABLED")){const gl2=gl,sync=gl2.fenceSync(gl2.SYNC_GPU_COMMANDS_COMPLETE,0);gl.flush(),isFencePassed=()=>{const status=gl2.clientWaitSync(sync,0,0);return status===gl2.ALREADY_SIGNALED||status===gl2.CONDITION_SATISFIED},query=sync}else(0,dist._K2)().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0?(query=this.beginQuery(),this.endQuery(),isFencePassed=()=>this.isQueryAvailable(query,(0,dist._K2)().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))):isFencePassed=()=>!0;return{query,isFencePassed}}downloadMatrixFromPackedTexture(texture,physicalRows,physicalCols){return this.downloadMatrixDriver(texture,()=>downloadMatrixFromPackedOutputTexture(this.gl,physicalRows,physicalCols))}createProgram(fragmentShader){this.throwIfDisposed();const gl=this.gl;null==this.vertexShader&&(this.vertexShader=gpgpu_util_createVertexShader(gl));const program=createProgram(gl);callAndCheck(gl,()=>gl.attachShader(program,this.vertexShader)),callAndCheck(gl,()=>gl.attachShader(program,fragmentShader)),linkProgram(gl,program);const program2=Object.assign(program,{vao:this.createVertexArray()});return this.debug&&validateProgram(gl,program2),program2}buildVao(program){this.setProgram(program),this.bindVertexArray(program.vao);const gl=this.gl;callAndCheck(gl,()=>gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER,this.indexBuffer)),bindVertexProgramAttributeStreams(gl,program,this.vertexBuffer)}deleteProgram(program){this.throwIfDisposed(),program===this.program&&(this.program=null),null!=program&&(callAndCheck(this.gl,()=>this.gl.deleteProgram(program)),this.deleteVertexArray(program.vao))}setProgram(program){this.throwIfDisposed(),this.program=program,null!=this.program&&this.debug&&validateProgram(this.gl,this.program),callAndCheck(this.gl,()=>this.gl.useProgram(program))}getUniformLocation(program,uniformName,shouldThrow=!0){return this.throwIfDisposed(),shouldThrow?getProgramUniformLocationOrThrow(this.gl,program,uniformName):getProgramUniformLocation(this.gl,program,uniformName)}getAttributeLocation(program,attribute){return this.throwIfDisposed(),callAndCheck(this.gl,()=>this.gl.getAttribLocation(program,attribute))}getUniformLocationNoThrow(program,uniformName){return this.throwIfDisposed(),this.gl.getUniformLocation(program,uniformName)}setInputMatrixTexture(inputMatrixTexture,uniformLocation,textureUnit){this.throwIfDisposed(),this.throwIfNoProgram(),bindTextureToProgramUniformSampler(this.gl,inputMatrixTexture,uniformLocation,textureUnit)}setOutputMatrixTexture(outputMatrixTexture,rows,columns){this.setOutputMatrixTextureDriver(outputMatrixTexture,columns,rows)}setOutputPackedMatrixTexture(outputPackedMatrixTexture,rows,columns){this.throwIfDisposed();const[width,height]=getPackedMatrixTextureShapeWidthHeight(rows,columns);this.setOutputMatrixTextureDriver(outputPackedMatrixTexture,width,height)}setOutputMatrixWriteRegion(startRow,numRows,startColumn,numColumns){this.setOutputMatrixWriteRegionDriver(startColumn,startRow,numColumns,numRows)}setOutputPackedMatrixWriteRegion(startRow,numRows,startColumn,numColumns){throw new Error("setOutputPackedMatrixWriteRegion not implemented.")}debugValidate(){null!=this.program&&validateProgram(this.gl,this.program),validateFramebuffer(this.gl)}executeProgram(){this.throwIfDisposed(),this.throwIfNoProgram();const gl=this.gl;if(this.debug){const boundVao=this.getVertexArray();gpgpu_context_console.assert(boundVao===this.program.vao,"VAO changed between setProgram and executeProgram!"),this.debugValidate()}callAndCheck(gl,()=>gl.drawElements(gl.TRIANGLES,6,gl.UNSIGNED_SHORT,0))}blockUntilAllProgramsCompleted(){this.throwIfDisposed(),callAndCheck(this.gl,()=>this.gl.finish())}getQueryTimerExtension(){return null==this.disjointQueryTimerExtension&&(this.disjointQueryTimerExtension=getExtensionOrThrow(this.gl,2===(0,dist._K2)().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")?"EXT_disjoint_timer_query_webgl2":"EXT_disjoint_timer_query")),this.disjointQueryTimerExtension}getQueryTimerExtensionWebGL2(){return this.getQueryTimerExtension()}getQueryTimerExtensionWebGL1(){return this.getQueryTimerExtension()}beginQuery(){if(2===(0,dist._K2)().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")){const gl2=this.gl,ext=this.getQueryTimerExtensionWebGL2(),query=gl2.createQuery();return gl2.beginQuery(ext.TIME_ELAPSED_EXT,query),query}const ext=this.getQueryTimerExtensionWebGL1(),query=ext.createQueryEXT();return ext.beginQueryEXT(ext.TIME_ELAPSED_EXT,query),query}endQuery(){if(2===(0,dist._K2)().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")){const gl2=this.gl,ext=this.getQueryTimerExtensionWebGL2();return void gl2.endQuery(ext.TIME_ELAPSED_EXT)}const ext=this.getQueryTimerExtensionWebGL1();ext.endQueryEXT(ext.TIME_ELAPSED_EXT)}async waitForQueryAndGetTime(query){return await dist.ZSL.repeatedTry(()=>this.disposed||this.isQueryAvailable(query,(0,dist._K2)().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))),this.getQueryTime(query,(0,dist._K2)().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))}getQueryTime(query,queryTimerVersion){if(0===queryTimerVersion)return null;if(2===queryTimerVersion){const gl2=this.gl;return gl2.getQueryParameter(query,gl2.QUERY_RESULT)/1e6}{const ext=this.getQueryTimerExtensionWebGL1();return ext.getQueryObjectEXT(query,ext.QUERY_RESULT_EXT)/1e6}}isQueryAvailable(query,queryTimerVersion){if(0===queryTimerVersion)return!0;if(2===queryTimerVersion){const gl2=this.gl,ext=this.getQueryTimerExtensionWebGL2(),available=gl2.getQueryParameter(query,gl2.QUERY_RESULT_AVAILABLE);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(ext.GPU_DISJOINT_EXT)),available&&!this.disjoint}{const ext=this.getQueryTimerExtensionWebGL1(),available=ext.getQueryObjectEXT(query,ext.QUERY_RESULT_AVAILABLE_EXT);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(ext.GPU_DISJOINT_EXT)),available&&!this.disjoint}}pollFence(fenceContext){return new Promise(resolve=>{this.addItemToPoll(()=>fenceContext.isFencePassed(),()=>resolve())})}pollItems(){const index=function linearSearchLastTrue(arr){let i=0;for(;i<arr.length;++i){if(!arr[i]())break}return i-1}(this.itemsToPoll.map(x=>x.isDoneFn));for(let i=0;i<=index;++i){const{resolveFn}=this.itemsToPoll[i];resolveFn()}this.itemsToPoll=this.itemsToPoll.slice(index+1)}addItemToPoll(isDoneFn,resolveFn){if(this.itemsToPoll.push({isDoneFn,resolveFn}),this.itemsToPoll.length>1)return;let scheduleFn;"setTimeoutCustom"in(0,dist._K2)().platform&&(scheduleFn=(0,dist._K2)().platform.setTimeoutCustom.bind((0,dist._K2)().platform)),dist.ZSL.repeatedTry(()=>(this.pollItems(),0===this.itemsToPoll.length),()=>0,null,scheduleFn)}bindTextureToFrameBuffer(texture){this.throwIfDisposed(),bindColorTextureToFramebuffer(this.gl,texture,this.framebuffer),this.debug&&validateFramebuffer(this.gl)}unbindTextureToFrameBuffer(){null!=this.outputTexture?(bindColorTextureToFramebuffer(this.gl,this.outputTexture,this.framebuffer),this.debug&&validateFramebuffer(this.gl)):unbindColorTextureFromFramebuffer(this.gl,this.framebuffer)}downloadMatrixDriver(texture,downloadAndDecode){this.bindTextureToFrameBuffer(texture);const result=downloadAndDecode();return this.unbindTextureToFrameBuffer(),result}setOutputMatrixTextureDriver(outputMatrixTextureMaybePacked,width,height){this.throwIfDisposed();const gl=this.gl;bindColorTextureToFramebuffer(gl,outputMatrixTextureMaybePacked,this.framebuffer),this.debug&&validateFramebuffer(gl),this.outputTexture=outputMatrixTextureMaybePacked,callAndCheck(gl,()=>gl.viewport(0,0,width,height)),callAndCheck(gl,()=>gl.scissor(0,0,width,height))}setOutputMatrixWriteRegionDriver(x,y,width,height){this.throwIfDisposed(),callAndCheck(this.gl,()=>this.gl.scissor(x,y,width,height))}throwIfDisposed(){if(this.disposed)throw new Error("Attempted to use disposed GPGPUContext.")}throwIfNoProgram(){if(null==this.program)throw new Error("No GPU program is currently set.")}}const{addImpl:addImplCPU,bincountImpl:bincountImplCPU,bincountReduceImpl:bincountReduceImplCPU,bitwiseAndImpl:bitwiseAndImplCPU,castImpl:castImplCPU,ceilImpl:ceilImplCPU,concatImpl:concatImplCPU,equalImpl:equalImplCPU,expImpl:expImplCPU,expm1Impl:expm1ImplCPU,floorImpl:floorImplCPU,gatherNdImpl:gatherNdImplCPU,gatherV2Impl:gatherV2ImplCPU,greaterImpl:greaterImplCPU,greaterEqualImpl:greaterEqualImplCPU,lessImpl:lessImplCPU,lessEqualImpl:lessEqualImplCPU,linSpaceImpl:linSpaceImplCPU,logImpl:logImplCPU,maxImpl:maxImplCPU,maximumImpl:maximumImplCPU,minimumImpl:minimumImplCPU,multiplyImpl:multiplyImplCPU,negImpl:negImplCPU,notEqualImpl:notEqualImplCPU,prodImpl:prodImplCPU,raggedGatherImpl:raggedGatherImplCPU,raggedRangeImpl:raggedRangeImplCPU,raggedTensorToTensorImpl:raggedTensorToTensorImplCPU,rangeImpl:rangeImplCPU,rsqrtImpl:rsqrtImplCPU,scatterImpl:scatterImplCPU,sigmoidImpl:sigmoidImplCPU,simpleAbsImpl:simpleAbsImplCPU,sliceImpl:sliceImplCPU,sparseFillEmptyRowsImpl:sparseFillEmptyRowsImplCPU,sparseReshapeImpl:sparseReshapeImplCPU,sparseSegmentReductionImpl:sparseSegmentReductionImplCPU,sqrtImpl:sqrtImplCPU,staticRegexReplaceImpl:staticRegexReplaceImplCPU,stridedSliceImpl:stridedSliceImplCPU,stringNGramsImpl:stringNGramsImplCPU,stringSplitImpl:stringSplitImplCPU,stringToHashBucketFastImpl:stringToHashBucketFastImplCPU,subImpl:subImplCPU,tileImpl:tileImplCPU,topKImpl:topKImplCPU,transposeImpl:transposeImplCPU,uniqueImpl:uniqueImplCPU}=shared_namespaceObject;function getVecChannels(name,rank){return["x","y","z","w","u","v"].slice(0,rank).map(d=>`${name}.${d}`)}function getChannels(name,rank){return 1===rank?[name]:getVecChannels(name,rank)}class PackProgram{constructor(outputShape){if(this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.outputShape=outputShape,this.rank=outputShape.length,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length),0===this.rank)this.userCode="\n        void main() {\n          setOutput(vec4(getA(), 0., 0., 0.));\n        }\n      ";else{const channels=getChannels("rc",this.rank),dtype=getCoordsDataType(this.rank),outOfBoundsCondition=this.getOutOfBoundsCondition(channels),setup=this.getSetup(channels),output=this.getOutput(channels);this.userCode=`\n        void main() {\n          ${dtype} rc = getOutputCoords();\n\n          if(${outOfBoundsCondition}) {\n            setOutput(vec4(0));\n          } else {\n            ${setup}\n\n            setOutput(vec4(${output}));\n          }\n        }\n      `}}getSourceCoordsArr(dims){const coords=[];for(let row=0;row<=1;row++)for(let col=0;col<=1;col++){let coord=`${0===row?"r":"rp1"}, ${0===col?"c":"cp1"}`;for(let d=2;d<this.rank;d++)coord=`${dims[dims.length-1-d]},`+coord;coords.push(coord)}return coords}getOutOfBoundsCondition(dims){if(1===this.rank)return`rc > ${this.enableShapeUniforms?"outShape":this.outputShape[0]}`;let cond="";for(let i=this.rank-2;i<this.rank;i++)cond+=`${dims[i]} >= ${this.enableShapeUniforms?`outShape[${i}]`:this.outputShape[i]}`,i<this.rank-1&&(cond+="||");return cond}getSetup(dims){if(1===this.rank)return"";const innerDims=dims.slice(-2),col=this.enableShapeUniforms?`outShape[${this.rank} - 1]`:this.outputShape[this.rank-1],row=this.enableShapeUniforms?`outShape[${this.rank} - 2]`:this.outputShape[this.rank-2];return`\n      int r = ${innerDims[0]};\n      int c = ${innerDims[1]};\n      int rp1 = r + 1;\n      int cp1 = c + 1;\n\n      bool cEdge = cp1 >= ${col};\n      bool rEdge = rp1 >= ${row};\n    `}getOutput(dims){const sourceCoords=this.getSourceCoordsArr(dims);if(1===this.rank){return`getA(rc), (rc + 1 >= ${this.enableShapeUniforms?"outShape":this.outputShape[0]} ? 0. : getA(rc + 1)), 0, 0`}return`getA(${sourceCoords[0]}),\n            cEdge ? 0. : getA(${sourceCoords[1]}),\n            rEdge ? 0. : getA(${sourceCoords[2]}),\n            rEdge || cEdge ? 0. : getA(${sourceCoords[3]})`}}class ReshapePackedProgram{constructor(outputShape,inputShape){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"inputShape",type:"ivec3"}],this.outputShape=outputShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length);let mainLoop="";for(let i=0;i<4;i++){let thisRC="thisRC = rc;";i%2==1&&(thisRC+="thisRC.z += 1;"),i>1&&(thisRC+="thisRC.y += 1;"),mainLoop+=`\n        ${thisRC}\n        ${i>0?"if(thisRC.y < rows && thisRC.z < cols){":""}\n          int flatIndex = getFlatIndex(thisRC);\n\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\n\n          result[${i}] =\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\n        ${i>0?"}":""}\n      `}this.userCode=`\n      ${function getReshapedInputCoords(shape,enableShapeUniforms){return`\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\n      ${enableShapeUniforms?getLogicalCoordinatesFromFlatIndexByUniform(["r","c","d"],"inputShape"):getLogicalCoordinatesFromFlatIndex(["r","c","d"],shape)}\n      return ivec3(r, c, d);\n    }\n  `}(inputShape,this.enableShapeUniforms)}\n      ${this.enableShapeUniforms?"\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;\n  }\n":getFlatIndexFrom3D(outputShape)}\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0.);\n\n        ivec3 thisRC;\n        int rows = ${this.enableShapeUniforms?"outShape[1]":outputShape[1]};\n        int cols = ${this.enableShapeUniforms?"outShape[2]":outputShape[2]};\n\n        ${mainLoop}\n\n        setOutput(result);\n      }\n    `}}var texture_manager_console=__webpack_require__("./node_modules/console-browserify/index.js");class TextureManager{constructor(gpgpu){this.gpgpu=gpgpu,this.numUsedTextures=0,this.numFreeTextures=0,this._numBytesAllocated=0,this._numBytesFree=0,this.freeTextures={},this.usedTextures={},this.logEnabled=!1}acquireTexture(shapeRC,usage,isPacked){const physicalTexType=getPhysicalFromLogicalTextureType(usage,isPacked),shapeKey=getKeyFromTextureShape(shapeRC,physicalTexType,isPacked);shapeKey in this.freeTextures||(this.freeTextures[shapeKey]=[]),shapeKey in this.usedTextures||(this.usedTextures[shapeKey]=[]);const texBytes=computeBytes(shapeRC,physicalTexType,this.gpgpu.gl,this.gpgpu.textureConfig,isPacked);if(this.freeTextures[shapeKey].length>0){this.numFreeTextures--,this.numUsedTextures++,this._numBytesFree-=texBytes,this.log();const newTexture=this.freeTextures[shapeKey].pop();return this.usedTextures[shapeKey].push(newTexture),newTexture}let newTexture;return physicalTexType===PhysicalTextureType.PACKED_2X2_FLOAT32?newTexture=this.gpgpu.createPackedMatrixTexture(shapeRC[0],shapeRC[1]):physicalTexType===PhysicalTextureType.PACKED_2X2_FLOAT16?newTexture=this.gpgpu.createFloat16PackedMatrixTexture(shapeRC[0],shapeRC[1]):physicalTexType===PhysicalTextureType.UNPACKED_FLOAT32?newTexture=this.gpgpu.createFloat32MatrixTexture(shapeRC[0],shapeRC[1]):physicalTexType===PhysicalTextureType.UNPACKED_FLOAT16?newTexture=this.gpgpu.createFloat16MatrixTexture(shapeRC[0],shapeRC[1]):physicalTexType===PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE&&(newTexture=this.gpgpu.createUnsignedBytesMatrixTexture(shapeRC[0],shapeRC[1])),this.usedTextures[shapeKey].push(newTexture),this.numUsedTextures++,this._numBytesAllocated+=texBytes,this.log(),newTexture}releaseTexture(texture,shape,logicalTexType,isPacked){if(null==this.freeTextures)return;const physicalTexType=getPhysicalFromLogicalTextureType(logicalTexType,isPacked),shapeKey=getKeyFromTextureShape(shape,physicalTexType,isPacked);shapeKey in this.freeTextures||(this.freeTextures[shapeKey]=[]);const texBytes=computeBytes(shape,physicalTexType,this.gpgpu.gl,this.gpgpu.textureConfig,isPacked),deleteTexThreshold=(0,dist._K2)().getNumber("WEBGL_DELETE_TEXTURE_THRESHOLD");-1!==deleteTexThreshold&&this._numBytesAllocated>deleteTexThreshold?(this.gpgpu.deleteMatrixTexture(texture.texture),this._numBytesAllocated-=texBytes):(this.freeTextures[shapeKey].push(texture),this.numFreeTextures++,this._numBytesFree+=texBytes),this.numUsedTextures--;const texList=this.usedTextures[shapeKey],texIndex=texList&&texList.indexOf(texture);if(null==texIndex||texIndex<0)throw new Error("Cannot release a texture that was never provided by this texture manager");texList[texIndex]=texList[texList.length-1],texList.pop(),this.log()}log(){if(!this.logEnabled)return;const total=this.numFreeTextures+this.numUsedTextures;texture_manager_console.log("Free/Used",`${this.numFreeTextures} / ${this.numUsedTextures}`,`(${total})`);const freeRatio=this._numBytesFree/this._numBytesAllocated;texture_manager_console.log(`Bytes allocated: ${this._numBytesAllocated}`),texture_manager_console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100*freeRatio)}%)`)}get numBytesAllocated(){return this._numBytesAllocated}get numBytesFree(){return this._numBytesFree}getNumUsedTextures(){return this.numUsedTextures}getNumFreeTextures(){return this.numFreeTextures}dispose(){if(null!=this.freeTextures){for(const texShape in this.freeTextures)this.freeTextures[texShape].forEach(tex=>{this.gpgpu.deleteMatrixTexture(tex.texture)});for(const texShape in this.usedTextures)this.usedTextures[texShape].forEach(tex=>{this.gpgpu.deleteMatrixTexture(tex.texture)});this.freeTextures=null,this.usedTextures=null,this.numUsedTextures=0,this.numFreeTextures=0,this._numBytesAllocated=0,this._numBytesFree=0}}}function computeBytes(shape,physicalTexType,gl,textureConfig,isPacked){const internalFormat=function internalFormatForPhysicalTexType(physicalTexType,textureConfig){switch(physicalTexType){case PhysicalTextureType.PACKED_2X2_FLOAT32:return getInternalFormatForPackedMatrixTexture(textureConfig);case PhysicalTextureType.PACKED_2X2_FLOAT16:return getInternalFormatForFloat16PackedMatrixTexture(textureConfig);case PhysicalTextureType.UNPACKED_FLOAT32:return getInternalFormatForFloat32MatrixTexture(textureConfig);case PhysicalTextureType.UNPACKED_FLOAT16:return getInternalFormatForFloat16MatrixTexture(textureConfig);case PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE:return getInternalFormatForUnsignedBytesMatrixTexture(textureConfig);default:throw new Error(`Unknown physical texture type ${physicalTexType}`)}}(physicalTexType,textureConfig);let numElements;if(isPacked){const[packedWidth,packedHeight]=getPackedMatrixTextureShapeWidthHeight(shape[0],shape[1]);numElements=packedWidth*packedHeight}else{const[width,height]=getUnpackedMatrixTextureShapeWidthHeight(shape[0],shape[1]);numElements=width*height}const bytesPerElement=function numBytesForInternalFormat(gl,internalFormat){const glany=gl;if(internalFormat===glany.R32F)return 4;if(internalFormat===glany.R16F)return 2;if(internalFormat===glany.RGBA32F)return 16;if(internalFormat===gl.RGBA)return 16;if(internalFormat===glany.RGBA16F)return 8;if(internalFormat===glany.RGBA8)return 4;throw new Error(`Unknown internal format ${internalFormat}`)}(gl,internalFormat);return numElements*bytesPerElement}function getPhysicalFromLogicalTextureType(logicalTexType,isPacked){if(logicalTexType===TextureUsage.UPLOAD)return PhysicalTextureType.PACKED_2X2_FLOAT32;if(logicalTexType===TextureUsage.RENDER||null==logicalTexType)return function getPhysicalTextureForRendering(isPacked){return(0,dist._K2)().getBool("WEBGL_RENDER_FLOAT32_ENABLED")?isPacked?PhysicalTextureType.PACKED_2X2_FLOAT32:PhysicalTextureType.UNPACKED_FLOAT32:isPacked?PhysicalTextureType.PACKED_2X2_FLOAT16:PhysicalTextureType.UNPACKED_FLOAT16}(isPacked);if(logicalTexType===TextureUsage.DOWNLOAD||logicalTexType===TextureUsage.PIXELS)return PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE;throw new Error(`Unknown logical texture type ${logicalTexType}`)}function getKeyFromTextureShape(shapeRowsCol,physicalTexType,isPacked){return`${shapeRowsCol[0]}_${shapeRowsCol[1]}_${physicalTexType}_${isPacked}`}class UnaryOpProgram{constructor(aShape,opSnippet){this.variableNames=["A"],this.outputShape=aShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length),this.userCode=`\n      float unaryOperation(float x) {\n        ${opSnippet}\n      }\n\n      void main() {\n        float x = getAAtOutCoords();\n        float y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}const CHECK_NAN_SNIPPET="if (isnan(x)) return x;",ABS="return abs(x);";const RELU=CHECK_NAN_SNIPPET+"\n  return (x < 0.0) ? 0.0 : x;\n",RELU6=CHECK_NAN_SNIPPET+"\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",CLONE="return x;";class UnaryOpPackedProgram{constructor(aShape,opSnippet){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=aShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length),this.userCode=`\n      vec4 unaryOperation(vec4 x) {\n        ${opSnippet}\n      }\n\n      void main() {\n        vec4 x = getAAtOutCoords();\n        vec4 y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}class UnpackProgram{constructor(outputShape){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!1,this.outputShape=outputShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length);const rank=outputShape.length,channels=getChannels("rc",rank),dtype=getCoordsDataType(rank),sourceCoords=function getSourceCoords(rank,dims){if(1===rank)return"rc";let coords="";for(let i=0;i<rank;i++)coords+=dims[i],i<rank-1&&(coords+=",");return coords}(rank,channels),innerDims=channels.slice(-2),coords=rank<=1?"rc":`vec2(${innerDims.join(",")})`;this.userCode=`\n      void main() {\n        ${dtype} rc = getOutputCoords();\n        vec4 packedInput = getA(${sourceCoords});\n\n        setOutput(getChannel(packedInput, ${coords}));\n      }\n    `}}var backend_webgl_console=__webpack_require__("./node_modules/console-browserify/index.js");const backend_webgl_whereImpl=dist.kpo.whereImpl,binaryCaches={};const CPU_HANDOFF_SIZE_THRESHOLD=(0,dist._K2)().getNumber("CPU_HANDOFF_SIZE_THRESHOLD");class MathBackendWebGL extends dist.uI_{nextDataId(){return MathBackendWebGL.nextDataId++}constructor(gpuResource){if(super(),this.pendingRead=new WeakMap,this.pendingDisposal=new WeakSet,this.dataRefCount=new WeakMap,this.numBytesInGPU=0,this.uploadWaitMs=0,this.downloadWaitMs=0,this.lastGlFlushTime=0,this.warnedAboutMemory=!1,this.pendingDeletes=0,this.disposed=!1,!(0,dist._K2)().getBool("HAS_WEBGL"))throw new Error("WebGL is not supported on this device");let newGPGPU;if(null!=gpuResource){if(gpuResource instanceof GPGPUContext)newGPGPU=gpuResource;else{const gl=getWebGLContext((0,dist._K2)().getNumber("WEBGL_VERSION"),gpuResource);newGPGPU=new GPGPUContext(gl)}this.binaryCache={},this.gpgpuCreatedLocally=!1}else{const gl=getWebGLContext((0,dist._K2)().getNumber("WEBGL_VERSION"));newGPGPU=new GPGPUContext(gl),this.binaryCache=function getBinaryCache(webGLVersion){return webGLVersion in binaryCaches||(binaryCaches[webGLVersion]={}),binaryCaches[webGLVersion]}((0,dist._K2)().getNumber("WEBGL_VERSION")),this.gpgpuCreatedLocally=!0}this.gpgpu=newGPGPU,this.canvas=this.gpgpu.gl.canvas,this.textureManager=new TextureManager(this.gpgpu),this.numMBBeforeWarning=function numMBBeforeWarning(){return null==(0,dist._K2)().global.screen?1024:(0,dist._K2)().global.screen.height*(0,dist._K2)().global.screen.width*window.devicePixelRatio*600/1024/1024}(),this.texData=new dist.GJx(this,(0,dist.Hi9)())}numDataIds(){return this.texData.numDataIds()-this.pendingDeletes}writeTexture(texture,shape,dtype,texHeight,texWidth,channels){const input=this.makeTensorInfo(shape,dtype),inData=this.texData.get(input.dataId);inData.isPacked=!1,inData.texture={texture,texShape:[texHeight,texWidth]},inData.texShape=[texHeight,texWidth];const shapeAs3D=getShapeAs3D(shape),program=new EncodeMatrixProgram(shapeAs3D,!1,channels),output=this.runWebGLProgram(program,[input],dtype,[[texHeight,texWidth]]);return output.shape=shape,inData.texture=null,this.disposeIntermediateTensorInfo(input),output.dataId}write(values,shape,dtype){if(((0,dist._K2)().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS")||(0,dist._K2)().getBool("DEBUG"))&&this.checkNumericalProblems(values),"complex64"===dtype&&null!=values)throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");const dataId={id:this.nextDataId()};return this.texData.set(dataId,{shape,dtype,values,usage:TextureUsage.UPLOAD,refCount:1}),dataId}refCount(dataId){if(this.texData.has(dataId)){return this.texData.get(dataId).refCount}return 0}incRef(dataId){this.texData.get(dataId).refCount++}decRef(dataId){if(this.texData.has(dataId)){this.texData.get(dataId).refCount--}}move(dataId,values,shape,dtype,refCount){if((0,dist._K2)().getBool("DEBUG")&&this.checkNumericalProblems(values),"complex64"===dtype)throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");this.texData.set(dataId,{shape,dtype,values,usage:TextureUsage.UPLOAD,refCount})}disposeIntermediateTensorInfo(tensorInfo){this.disposeData(tensorInfo.dataId)}readSync(dataId){const texData=this.texData.get(dataId),{values,dtype,complexTensorInfos,slice,shape,isPacked}=texData;if(null!=slice){let program;program=isPacked?new UnaryOpPackedProgram(shape,CLONE):new UnaryOpProgram(shape,CLONE);const res=this.runWebGLProgram(program,[{dataId,shape,dtype}],dtype),data=this.readSync(res.dataId);return this.disposeIntermediateTensorInfo(res),data}if(null!=values)return this.convertAndCacheOnCPU(dataId);if("string"===dtype)return values;const shouldTimeProgram=null!=this.activeTimers;let start,result;if(shouldTimeProgram&&(start=dist.ZSL.now()),"complex64"===dtype){const realValues=this.readSync(complexTensorInfos.real.dataId),imagValues=this.readSync(complexTensorInfos.imag.dataId);result=dist.C0T.mergeRealAndImagArrays(realValues,imagValues)}else result=this.getValuesFromTexture(dataId);return shouldTimeProgram&&(this.downloadWaitMs+=dist.ZSL.now()-start),this.convertAndCacheOnCPU(dataId,result)}async read(dataId){if(this.pendingRead.has(dataId)){const subscribers=this.pendingRead.get(dataId);return new Promise(resolve=>subscribers.push(resolve))}const texData=this.texData.get(dataId),{values,shape,slice,dtype,complexTensorInfos,isPacked}=texData;if(null!=slice){let program;program=isPacked?new UnaryOpPackedProgram(shape,CLONE):new UnaryOpProgram(shape,CLONE);const res=this.runWebGLProgram(program,[{dataId,shape,dtype}],dtype),data=this.read(res.dataId);return this.disposeIntermediateTensorInfo(res),data}if(null!=values)return this.convertAndCacheOnCPU(dataId);if((0,dist._K2)().getBool("DEBUG")&&!(0,dist._K2)().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")&&2===(0,dist._K2)().getNumber("WEBGL_VERSION"))throw new Error("tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.");let tmpDownloadTarget,vals,buffer=null;if("complex64"!==dtype&&(0,dist._K2)().get("WEBGL_BUFFER_SUPPORTED")){tmpDownloadTarget=this.decode(dataId);const tmpData=this.texData.get(tmpDownloadTarget.dataId);buffer=this.gpgpu.createBufferFromTexture(tmpData.texture.texture,...getDenseTexShape(shape))}if(this.pendingRead.set(dataId,[]),"complex64"!==dtype&&await this.gpgpu.createAndWaitForFence(),"complex64"===dtype){const ps=await Promise.all([this.read(complexTensorInfos.real.dataId),this.read(complexTensorInfos.imag.dataId)]),realValues=ps[0],imagValues=ps[1];vals=dist.C0T.mergeRealAndImagArrays(realValues,imagValues)}else if(null==buffer)vals=this.getValuesFromTexture(dataId);else{const size=dist.ZSL.sizeFromShape(shape);vals=this.gpgpu.downloadFloat32MatrixFromBuffer(buffer,size)}if(null!=tmpDownloadTarget&&this.disposeIntermediateTensorInfo(tmpDownloadTarget),null!=buffer){const gl=this.gpgpu.gl;callAndCheck(gl,()=>gl.deleteBuffer(buffer))}const dTypeVals=this.convertAndCacheOnCPU(dataId,vals),subscribers=this.pendingRead.get(dataId);return this.pendingRead.delete(dataId),subscribers.forEach(resolve=>resolve(dTypeVals)),this.pendingDisposal.has(dataId)&&(this.pendingDisposal.delete(dataId),this.disposeData(dataId)&&(0,dist.Hi9)().removeDataId(dataId,this),this.pendingDeletes--),dTypeVals}readToGPU(dataId,options={}){const texData=this.texData.get(dataId),{values,shape,slice,dtype,isPacked,texture}=texData;if("complex64"===dtype)throw new Error("Does not support reading texture for complex64 dtype.");if(null!=slice){let program;program=isPacked?new UnaryOpPackedProgram(shape,CLONE):new UnaryOpProgram(shape,CLONE);const res=this.runWebGLProgram(program,[{dataId,shape,dtype}],dtype),gpuResouorce=this.readToGPU(res,options);return this.disposeIntermediateTensorInfo(res),gpuResouorce}if(null==texture)throw null!=values?new Error("Data is not on GPU but on CPU."):new Error("There is no data on GPU or CPU.");const tmpTarget=this.decode(dataId,options.customTexShape),tensorRef=(0,dist.Hi9)().makeTensorFromTensorInfo(tmpTarget),tmpData=this.texData.get(tmpTarget.dataId);return Object.assign({tensorRef},tmpData.texture)}bufferSync(t){const data=this.readSync(t.dataId);if("string"===t.dtype)try{const strings=data.map(d=>dist.ZSL.decodeString(d));return(0,dist.ra8)(t.shape,t.dtype,strings)}catch(_a){throw new Error("Failed to decode encoded string bytes into utf-8")}return(0,dist.ra8)(t.shape,t.dtype,data)}checkNumericalProblems(values){if(null!=values)for(let i=0;i<values.length;i++){const num=values[i];if(!canBeRepresented(num)){if((0,dist._K2)().getBool("WEBGL_RENDER_FLOAT32_CAPABLE"))throw Error(`The value ${num} cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`);throw Error(`The value ${num} cannot be represented on this device.`)}}}getValuesFromTexture(dataId){const{shape,dtype,isPacked}=this.texData.get(dataId),size=dist.ZSL.sizeFromShape(shape);if((0,dist._K2)().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")){const tmpTarget=this.decode(dataId),tmpData=this.texData.get(tmpTarget.dataId),vals=this.gpgpu.downloadMatrixFromPackedTexture(tmpData.texture.texture,...getDenseTexShape(shape)).subarray(0,size);return this.disposeIntermediateTensorInfo(tmpTarget),vals}const shouldUsePackedProgram=(0,dist._K2)().getBool("WEBGL_PACK")&&!0===isPacked,outputShape=shouldUsePackedProgram?getShapeAs3D(shape):shape,program=shouldUsePackedProgram?new EncodeFloatPackedProgram(outputShape):new EncodeFloatProgram(outputShape),output=this.runWebGLProgram(program,[{shape:outputShape,dtype,dataId}],"float32"),tmpData=this.texData.get(output.dataId),vals=this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(tmpData.texture.texture,tmpData.texShape[0],tmpData.texShape[1]).subarray(0,size);return this.disposeIntermediateTensorInfo(output),vals}timerAvailable(){return(0,dist._K2)().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0}time(f){const oldActiveTimers=this.activeTimers,newActiveTimers=[];let outerMostTime=!1;null==this.programTimersStack?(this.programTimersStack=newActiveTimers,outerMostTime=!0):this.activeTimers.push(newActiveTimers),this.activeTimers=newActiveTimers,f();const flattenedActiveTimerQueries=dist.ZSL.flatten(this.activeTimers.map(d=>d.query)).filter(d=>null!=d),flattenedActiveTimerNames=dist.ZSL.flatten(this.activeTimers.map(d=>d.name)).filter(d=>null!=d);this.activeTimers=oldActiveTimers,outerMostTime&&(this.programTimersStack=null);const res={uploadWaitMs:this.uploadWaitMs,downloadWaitMs:this.downloadWaitMs,kernelMs:null,wallMs:null};return(async()=>{if((0,dist._K2)().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0){const kernelMs=await Promise.all(flattenedActiveTimerQueries);res.kernelMs=dist.ZSL.sum(kernelMs),res.getExtraProfileInfo=()=>kernelMs.map((d,i)=>({name:flattenedActiveTimerNames[i],ms:d})).map(d=>`${d.name}: ${d.ms}`).join(", ")}else res.kernelMs={error:"WebGL query timers are not supported in this environment."};return this.uploadWaitMs=0,this.downloadWaitMs=0,res})()}memory(){return{unreliable:!1,numBytesInGPU:this.numBytesInGPU,numBytesInGPUAllocated:this.textureManager.numBytesAllocated,numBytesInGPUFree:this.textureManager.numBytesFree}}startTimer(){return(0,dist._K2)().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?this.gpgpu.beginQuery():{startMs:dist.ZSL.now(),endMs:null}}endTimer(query){return(0,dist._K2)().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?(this.gpgpu.endQuery(),query):(query.endMs=dist.ZSL.now(),query)}async getQueryTime(query){if((0,dist._K2)().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0)return this.gpgpu.waitForQueryAndGetTime(query);const timerQuery=query;return timerQuery.endMs-timerQuery.startMs}disposeData(dataId,force=!1){if(this.pendingDisposal.has(dataId))return!1;if(!this.texData.has(dataId))return!0;if(force?this.texData.get(dataId).refCount=0:this.texData.get(dataId).refCount--,!force&&this.texData.get(dataId).refCount>0)return!1;if(this.pendingRead.has(dataId))return this.pendingDisposal.add(dataId),this.pendingDeletes++,!1;this.releaseGPUData(dataId);const{complexTensorInfos}=this.texData.get(dataId);return null!=complexTensorInfos&&(this.disposeData(complexTensorInfos.real.dataId,force),this.disposeData(complexTensorInfos.imag.dataId,force)),this.texData.delete(dataId),!0}releaseGPUData(dataId){const{texture,dtype,texShape,usage,isPacked,slice}=this.texData.get(dataId),key=slice&&slice.origDataId||dataId,refCount=this.dataRefCount.get(key);refCount>1?this.dataRefCount.set(key,refCount-1):(this.dataRefCount.delete(key),null!=texture&&(this.numBytesInGPU-=this.computeBytes(texShape,dtype),this.textureManager.releaseTexture(texture,texShape,usage,isPacked)));const texData=this.texData.get(dataId);texData.texture=null,texData.texShape=null,texData.isPacked=!1,texData.slice=null}getTexture(dataId){return this.uploadToGPU(dataId),this.texData.get(dataId).texture.texture}getDataInfo(dataId){return this.texData.get(dataId)}shouldExecuteOnCPU(inputs,sizeThreshold=CPU_HANDOFF_SIZE_THRESHOLD){return(0,dist._K2)().getBool("WEBGL_CPU_FORWARD")&&inputs.every(input=>null==this.texData.get(input.dataId).texture&&dist.ZSL.sizeFromShape(input.shape)<sizeThreshold)}getGPGPUContext(){return this.gpgpu}where(condition){dist.C0T.warn("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");const condVals=condition.dataSync();return backend_webgl_whereImpl(condition.shape,condVals)}packedUnaryOp(x,op,dtype){const program=new UnaryOpPackedProgram(x.shape,op),outInfo=this.compileAndRun(program,[x],dtype);return(0,dist.Hi9)().makeTensorFromTensorInfo(outInfo)}abs(x){if(this.shouldExecuteOnCPU([x])&&"complex64"!==x.dtype){const outValues=simpleAbsImplCPU(this.texData.get(x.dataId).values);return this.makeOutput(x.shape,x.dtype,outValues)}if((0,dist._K2)().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(x,ABS,x.dtype);const program=new UnaryOpProgram(x.shape,ABS),outInfo=this.compileAndRun(program,[x]);return(0,dist.Hi9)().makeTensorFromTensorInfo(outInfo)}makeTensorInfo(shape,dtype,values){let dataId;if("string"===dtype&&null!=values&&values.length>0&&dist.ZSL.isString(values[0])){const encodedValues=values.map(d=>dist.ZSL.encodeString(d));dataId=this.write(encodedValues,shape,dtype)}else dataId=this.write(values,shape,dtype);return this.texData.get(dataId).usage=null,{dataId,shape,dtype}}makeOutput(shape,dtype,values){return(0,dist.Hi9)().makeTensorFromTensorInfo(this.makeTensorInfo(shape,dtype,values),this)}unpackTensor(input){const program=new UnpackProgram(input.shape);return this.runWebGLProgram(program,[input],input.dtype)}packTensor(input){const program=new PackProgram(input.shape);return this.runWebGLProgram(program,[input],input.dtype,null,!0)}packedReshape(input,afterShape){const input3DShape=[getBatchDim(input.shape),...getRowsCols(input.shape)],input3D={dtype:input.dtype,shape:input3DShape,dataId:input.dataId},afterShapeAs3D=[getBatchDim(afterShape),...getRowsCols(afterShape)],program=new ReshapePackedProgram(afterShapeAs3D,input3DShape),customValues=[input3DShape],output=this.runWebGLProgram(program,[input3D],input.dtype,customValues,!0);return{dataId:output.dataId,shape:afterShape,dtype:output.dtype}}decode(dataId,customTexShape){const texData=this.texData.get(dataId),{isPacked,shape,dtype}=texData;if(null!=customTexShape){const size=dist.ZSL.sizeFromShape(shape),texSize=customTexShape[0]*customTexShape[1]*4;dist.ZSL.assert(size<=texSize,()=>"customTexShape is too small. Row * Column * 4 should be equal or larger than the size of the tensor data.")}const shapeAs3D=getShapeAs3D(shape);let program;program=isPacked?new DecodeMatrixPackedProgram(shapeAs3D):new DecodeMatrixProgram(shapeAs3D);const customValues=[null!=customTexShape?customTexShape:getDenseTexShape(shapeAs3D)];return{dtype,shape,dataId:this.runWebGLProgram(program,[{shape:shapeAs3D,dtype,dataId}],dtype,customValues,!0,customTexShape).dataId}}runWebGLProgram(program,inputs,outputDtype,customUniformValues,preventEagerUnpackingOfOutput=!1,customTexShape){const output=this.makeTensorInfo(program.outputShape,outputDtype),outData=this.texData.get(output.dataId);if(program.packedOutput&&(outData.isPacked=!0),program.outPackingScheme===PackingScheme.DENSE){const texelShape=null!=customTexShape?customTexShape:getDenseTexShape(program.outputShape);outData.texShape=texelShape.map(d=>2*d)}if(null!=program.outTexUsage&&(outData.usage=program.outTexUsage),0===dist.ZSL.sizeFromShape(output.shape))return outData.values=dist.ZSL.getTypedArrayFromDType(output.dtype,0),output;const dataToDispose=[],inputsData=inputs.map(input=>{if("complex64"===input.dtype)throw new Error("GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.");let texData=this.texData.get(input.dataId);if(null==texData.texture){if(!program.packedInputs&&dist.ZSL.sizeFromShape(input.shape)<=(0,dist._K2)().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM"))return{shape:input.shape,texData:null,isUniform:!0,uniformValues:texData.values};program.packedInputs&&(texData.isPacked=!0,texData.shape=input.shape)}if(this.uploadToGPU(input.dataId),!!texData.isPacked!=!!program.packedInputs)input=texData.isPacked?this.unpackTensor(input):this.packTensor(input),dataToDispose.push(input),texData=this.texData.get(input.dataId);else if(texData.isPacked&&!isReshapeFree(texData.shape,input.shape)){const savedInput=input,targetShape=input.shape;input.shape=texData.shape,input=this.packedReshape(input,targetShape),dataToDispose.push(input),texData=this.texData.get(input.dataId),savedInput.shape=targetShape}return{shape:input.shape,texData,isUniform:!1}});this.uploadToGPU(output.dataId);const outputData={shape:output.shape,texData:outData,isUniform:!1},key=function makeShaderKey(program,inputs,output){let keyInputs="";inputs.concat(output).forEach(x=>{const hasOffset=null!=x.texData&&null!=x.texData.slice&&x.texData.slice.flatOffset>0;if(program.enableShapeUniforms&&!x.isUniform){const xTexShape=x.texData.texShape,{useSqueezeShape,uniformShape,keptDims}=getUniformInfoFromShape(program.packedInputs,x.shape,xTexShape);let rank1="",rank2="",rank34="";if(1===uniformShape.length&&program.packedInputs){const packedTexShape=[Math.ceil(xTexShape[0]/2),Math.ceil(xTexShape[1]/2)];rank1=`${packedTexShape[0]>1}_${packedTexShape[1]>1}`}else if(2!==uniformShape.length||program.packedInputs){if(uniformShape.length>2&&!program.packedInputs){const strides=dist.ZSL.computeStrides(uniformShape);rank34=`${strides[0]===xTexShape[1]}_${strides[strides.length-1]===xTexShape[1]}`}}else rank2=`${uniformShape[0]>1}_${uniformShape[1]>1}`;const xRank=x.shape.length,isLogicalShapTexShapeEqual=2===uniformShape.length&&dist.ZSL.arraysEqual(x.shape,xTexShape),isScalar=1===dist.ZSL.sizeFromShape(x.shape),broadcastDims=dist.C0T.getBroadcastDims(x.shape,output.shape),isInOutTexShapeEqual=!program.packedInputs&&xRank===output.shape.length&&dist.ZSL.arraysEqual(xTexShape,output.texData.texShape),isTexShapeGreaterThanOne=program.packedInputs||uniformShape.length>2?"":`${xTexShape[0]>1}_${xTexShape[1]>1}`;keyInputs+=`${xRank}_${isInOutTexShapeEqual}_${useSqueezeShape?keptDims:""}_${uniformShape.length}_${isScalar}_${broadcastDims}_${isLogicalShapTexShapeEqual}_${rank1}_${rank2}_${rank34}_${isTexShapeGreaterThanOne}_${hasOffset}`}else{const texShape=x.isUniform?"uniform":x.texData.texShape;keyInputs+=`${x.shape}_${texShape}_${hasOffset}`}});const keyUserCode=program.userCode;let key=program.constructor.name;return key+="_"+keyInputs+"_"+keyUserCode+`${(0,dist._K2)().getNumber("WEBGL_VERSION")}`,key}(program,inputsData,outputData),binary=this.getAndSaveBinary(key,()=>function compileProgram(gpgpu,program,inputs,output){const inputInfos=inputs.map((input,i)=>{const shapeInfo={logicalShape:input.shape,texShape:input.isUniform?null:input.texData.texShape,isUniform:input.isUniform,isPacked:!input.isUniform&&input.texData.isPacked,flatOffset:null};return null!=input.texData&&null!=input.texData.slice&&input.texData.slice.flatOffset>0&&(shapeInfo.flatOffset=input.texData.slice.flatOffset),{name:program.variableNames[i],shapeInfo}}),inShapeInfos=inputInfos.map(x=>x.shapeInfo),outShapeInfo={logicalShape:output.shape,texShape:output.texData.texShape,isUniform:!1,isPacked:output.texData.isPacked,flatOffset:null},source=makeShader(inputInfos,outShapeInfo,program),fragmentShader=createFragmentShader(gpgpu.gl,source),webGLProgram=gpgpu.createProgram(fragmentShader);return(0,dist._K2)().get("ENGINE_COMPILE_ONLY")?{program,fragmentShader,source,webGLProgram,inShapeInfos,outShapeInfo,variablesLocations:null,customUniformLocations:null,infLoc:null,nanLoc:null,outShapeLocation:null,outShapeStridesLocation:null,outTexShapeLocation:null}:(gpgpu.buildVao(webGLProgram),Object.assign({program,fragmentShader,source,webGLProgram,inShapeInfos,outShapeInfo},getUniformLocations(gpgpu,program,webGLProgram)))}(this.gpgpu,program,inputsData,outputData)),shouldTimeProgram=null!=this.activeTimers;let query;shouldTimeProgram&&(query=this.startTimer()),(0,dist._K2)().get("ENGINE_COMPILE_ONLY")||function runProgram(gpgpu,binary,inputs,output,customUniformValues){binary.program.enableShapeUniforms||(validateBinaryAndProgram(binary.inShapeInfos,inputs),validateBinaryAndProgram([binary.outShapeInfo],[output]));const outTex=output.texData.texture,outTexShape=output.texData.texShape;output.texData.isPacked?gpgpu.setOutputPackedMatrixTexture(outTex.texture,outTexShape[0],outTexShape[1]):gpgpu.setOutputMatrixTexture(outTex.texture,outTexShape[0],outTexShape[1]),gpgpu.setProgram(binary.webGLProgram),gpgpu.bindVertexArray(binary.webGLProgram.vao),1===(0,dist._K2)().getNumber("WEBGL_VERSION")&&null!==binary.infLoc&&gpgpu.gl.uniform1f(binary.infLoc,1/0),null!==binary.nanLoc&&gpgpu.gl.uniform1f(binary.nanLoc,NaN);for(let i=0;i<inputs.length;++i){const input=inputs[i],{uniform:varLoc,offset:varOffsetLoc,shape:varShapeLoc,texShape:varTexShapeLoc}=binary.variablesLocations[i];if(varShapeLoc){const{uniformShape}=getUniformInfoFromShape(binary.program.packedInputs,input.shape,input.texData.texShape);switch(uniformShape.length){case 1:gpgpu.gl.uniform1iv(varShapeLoc,new Int32Array(uniformShape));break;case 2:gpgpu.gl.uniform2iv(varShapeLoc,new Int32Array(uniformShape));break;case 3:gpgpu.gl.uniform3iv(varShapeLoc,new Int32Array(uniformShape));break;case 4:gpgpu.gl.uniform4iv(varShapeLoc,new Int32Array(uniformShape))}}if(varTexShapeLoc&&gpgpu.gl.uniform2i(varTexShapeLoc,input.texData.texShape[0],input.texData.texShape[1]),null!=varLoc)if(input.isUniform)if(dist.ZSL.sizeFromShape(input.shape)<2)gpgpu.gl.uniform1f(varLoc,input.uniformValues[0]);else{let vals=input.uniformValues;vals instanceof Float32Array||(vals=new Float32Array(vals)),gpgpu.gl.uniform1fv(varLoc,vals)}else null!=input.texData.slice&&null!=varOffsetLoc&&gpgpu.gl.uniform1i(varOffsetLoc,input.texData.slice.flatOffset),gpgpu.setInputMatrixTexture(input.texData.texture.texture,varLoc,i)}const outShapeLoc=binary.outShapeLocation;if(outShapeLoc)switch(output.shape.length){case 1:gpgpu.gl.uniform1iv(outShapeLoc,new Int32Array(output.shape));break;case 2:gpgpu.gl.uniform2iv(outShapeLoc,new Int32Array(output.shape));break;case 3:gpgpu.gl.uniform3iv(outShapeLoc,new Int32Array(output.shape));break;case 4:gpgpu.gl.uniform4iv(outShapeLoc,new Int32Array(output.shape))}if(binary.outShapeStridesLocation){const strides=dist.ZSL.computeStrides(output.shape);switch(output.shape.length){case 2:gpgpu.gl.uniform1iv(binary.outShapeStridesLocation,new Int32Array(strides));break;case 3:gpgpu.gl.uniform2iv(binary.outShapeStridesLocation,new Int32Array(strides));break;case 4:gpgpu.gl.uniform3iv(binary.outShapeStridesLocation,new Int32Array(strides))}}if(binary.outTexShapeLocation&&gpgpu.gl.uniform2i(binary.outTexShapeLocation,output.texData.texShape[0],output.texData.texShape[1]),binary.program.customUniforms&&customUniformValues)for(let i=0;i<binary.program.customUniforms.length;++i){const d=binary.program.customUniforms[i],customLoc=binary.customUniformLocations[i],customValue=customUniformValues[i];if("float"===d.type)gpgpu.gl.uniform1fv(customLoc,customValue);else if("vec2"===d.type)gpgpu.gl.uniform2fv(customLoc,customValue);else if("vec3"===d.type)gpgpu.gl.uniform3fv(customLoc,customValue);else if("vec4"===d.type)gpgpu.gl.uniform4fv(customLoc,customValue);else if("int"===d.type)gpgpu.gl.uniform1iv(customLoc,customValue);else if("ivec2"===d.type)gpgpu.gl.uniform2iv(customLoc,customValue);else if("ivec3"===d.type)gpgpu.gl.uniform3iv(customLoc,customValue);else{if("ivec4"!==d.type)throw Error(`uniform type ${d.type} is not supported yet.`);gpgpu.gl.uniform4iv(customLoc,customValue)}}gpgpu.executeProgram()}(this.gpgpu,binary,inputsData,outputData,customUniformValues),dataToDispose.forEach(info=>this.disposeIntermediateTensorInfo(info)),shouldTimeProgram&&(query=this.endTimer(query),this.activeTimers.push({name:program.constructor.name,query:this.getQueryTime(query)}));const glFlushThreshold=(0,dist._K2)().getNumber("WEBGL_FLUSH_THRESHOLD");if(glFlushThreshold>0){const time=dist.ZSL.now();time-this.lastGlFlushTime>glFlushThreshold&&(this.gpgpu.gl.flush(),this.lastGlFlushTime=time)}if(!(0,dist._K2)().getBool("WEBGL_LAZILY_UNPACK")&&outData.isPacked&&!1===preventEagerUnpackingOfOutput){const unpacked=this.unpackTensor(output);return this.disposeIntermediateTensorInfo(output),unpacked}return output}compileAndRun(program,inputs,outputDtype,customUniformValues,preventEagerUnpackingOfOutput=!1){outputDtype=outputDtype||inputs[0].dtype;return this.runWebGLProgram(program,inputs,outputDtype,customUniformValues,preventEagerUnpackingOfOutput)}getAndSaveBinary(key,getBinary){return key in this.binaryCache||(this.binaryCache[key]=getBinary()),this.binaryCache[key]}getTextureManager(){return this.textureManager}dispose(){if(!this.disposed){if(!(0,dist._K2)().getBool("IS_TEST")){Object.keys(this.binaryCache).forEach(key=>{this.gpgpu.deleteProgram(this.binaryCache[key].webGLProgram),delete this.binaryCache[key]})}this.textureManager.dispose(),null!=this.canvas&&"undefined"!=typeof HTMLCanvasElement&&this.canvas instanceof HTMLCanvasElement?this.canvas.remove():this.canvas=null,this.gpgpuCreatedLocally&&(this.gpgpu.program=null,this.gpgpu.dispose()),this.disposed=!0}}floatPrecision(){return null==this.floatPrecisionValue&&(this.floatPrecisionValue=(0,dist.DZQ)(()=>{if(!(0,dist._K2)().get("WEBGL_RENDER_FLOAT32_ENABLED")){const debugFlag=(0,dist._K2)().getBool("DEBUG");(0,dist._K2)().set("DEBUG",!1);const underflowCheckValue=this.abs((0,dist.d_2)(1e-8)).dataSync()[0];if((0,dist._K2)().set("DEBUG",debugFlag),underflowCheckValue>0)return 32}return 16})),this.floatPrecisionValue}epsilon(){return 32===this.floatPrecision()?1e-7:1e-4}uploadToGPU(dataId){const texData=this.texData.get(dataId),{shape,dtype,values,texture,usage,isPacked}=texData;if(null!=texture)return;const shouldTimeProgram=null!=this.activeTimers;let start;shouldTimeProgram&&(start=dist.ZSL.now());let texShape=texData.texShape;if(null==texShape&&(texShape=getTextureShapeFromLogicalShape(shape,isPacked),texData.texShape=texShape),null!=values){const shapeAs3D=getShapeAs3D(shape);let program,width=texShape[1],height=texShape[0];const isByteArray=values instanceof Uint8Array||values instanceof Uint8ClampedArray;!isPacked&&isByteArray||([width,height]=getPackedMatrixTextureShapeWidthHeight(texShape[0],texShape[1])),program=isPacked?new EncodeMatrixPackedProgram(shapeAs3D,isByteArray):new EncodeMatrixProgram(shapeAs3D,isByteArray);const tempDenseInputTexShape=isByteArray?[height,width]:texShape,tempDenseInputHandle=this.makeTensorInfo(tempDenseInputTexShape,dtype),tempDenseInputTexData=this.texData.get(tempDenseInputHandle.dataId);tempDenseInputTexData.usage=isByteArray?TextureUsage.PIXELS:TextureUsage.UPLOAD,tempDenseInputTexData.texShape=tempDenseInputTexShape,this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(tempDenseInputHandle.dataId),width,height,values);const customValues=[[height,width]],preventEagerUnpacking=!0,encodedOutputTarget=this.runWebGLProgram(program,[tempDenseInputHandle],dtype,customValues,preventEagerUnpacking),outputTexData=this.texData.get(encodedOutputTarget.dataId);texData.texShape=outputTexData.texShape,texData.isPacked=outputTexData.isPacked,texData.usage=outputTexData.usage,(0,dist._K2)().get("ENGINE_COMPILE_ONLY")?this.disposeData(encodedOutputTarget.dataId):(texData.texture=outputTexData.texture,texData.values=null,this.texData.delete(encodedOutputTarget.dataId)),this.disposeIntermediateTensorInfo(tempDenseInputHandle),shouldTimeProgram&&(this.uploadWaitMs+=dist.ZSL.now()-start)}else{const newTexture=this.acquireTexture(texShape,usage,dtype,isPacked);texData.texture=newTexture}}convertAndCacheOnCPU(dataId,float32Values){const texData=this.texData.get(dataId),{dtype}=texData;return null!=float32Values&&(texData.values=function float32ToTypedArray(a,dtype){if("float32"===dtype||"complex64"===dtype)return a;if("int32"===dtype||"bool"===dtype){const result="int32"===dtype?new Int32Array(a.length):new Uint8Array(a.length);for(let i=0;i<result.length;++i)result[i]=Math.round(a[i]);return result}throw new Error(`Unknown dtype ${dtype}`)}(float32Values,dtype)),texData.values}acquireTexture(texShape,texType,dtype,isPacked){if(this.numBytesInGPU+=this.computeBytes(texShape,dtype),!this.warnedAboutMemory&&this.numBytesInGPU>1024*this.numMBBeforeWarning*1024){const mb=(this.numBytesInGPU/1024/1024).toFixed(2);this.warnedAboutMemory=!0,backend_webgl_console.warn(`High memory usage in GPU: ${mb} MB, most likely due to a memory leak`)}return this.textureManager.acquireTexture(texShape,texType,isPacked)}computeBytes(shape,dtype){return shape[0]*shape[1]*dist.ZSL.bytesPerElement(dtype)}checkCompileCompletion(){for(const[,binary]of Object.entries(this.binaryCache))this.checkCompletion_(binary)}async checkCompileCompletionAsync(){const ps=[];if(this.gpgpu.parallelCompilationExtension){for(const[,binary]of Object.entries(this.binaryCache))ps.push(this.checkCompletionAsync_(binary));return Promise.all(ps)}for(const[,binary]of Object.entries(this.binaryCache)){const p=new Promise(resolve=>{try{this.checkCompletion_(binary),resolve(!0)}catch(error){throw error}});ps.push(p)}return Promise.all(ps)}async checkCompletionAsync_(binary){return this.gpgpu.gl.getProgramParameter(binary.webGLProgram,this.gpgpu.parallelCompilationExtension.COMPLETION_STATUS_KHR)?this.checkCompletion_(binary):(await(0,dist.dA1)(),this.checkCompletionAsync_(binary))}checkCompletion_(binary){if(!1===this.gpgpu.gl.getProgramParameter(binary.webGLProgram,this.gpgpu.gl.LINK_STATUS)){if(backend_webgl_console.log(this.gpgpu.gl.getProgramInfoLog(binary.webGLProgram)),!1===this.gpgpu.gl.getShaderParameter(binary.fragmentShader,this.gpgpu.gl.COMPILE_STATUS))throw logShaderSourceAndInfoLog(binary.source,this.gpgpu.gl.getShaderInfoLog(binary.fragmentShader)),new Error("Failed to compile fragment shader.");throw new Error("Failed to link vertex and fragment shaders.")}return!0}getUniformLocations(){for(const binary of Object.values(this.binaryCache)){this.gpgpu.buildVao(binary.webGLProgram);const{variablesLocations,customUniformLocations,infLoc,nanLoc,outShapeLocation,outShapeStridesLocation,outTexShapeLocation}=getUniformLocations(this.gpgpu,binary.program,binary.webGLProgram);binary.variablesLocations=variablesLocations,binary.customUniformLocations=customUniformLocations,binary.infLoc=infLoc,binary.nanLoc=nanLoc,binary.outShapeLocation=outShapeLocation,binary.outShapeStridesLocation=outShapeStridesLocation,binary.outTexShapeLocation=outTexShapeLocation}}createTensorFromGPUData(values,shape,dtype){values.channels=values.channels||"RGBA";const{texture,height,width,channels}=values,backend=(0,dist.Hi9)().backend;if(!backend.gpgpu.gl.isTexture(texture))throw new Error("The texture is invalid. Also, please make sure the texture and the TFJS WebGL backend are using the same canvas. If you want to use your own custom canvas, you have to create and use the custom TFJS WebGL backend created from the canvas through 'new tf.MathBackendWebGL(customCanvas)'.");const dataId=backend.writeTexture(texture,shape,dtype,height,width,channels);return(0,dist.Hi9)().makeTensorFromDataId(dataId,shape,dtype,backend)}}MathBackendWebGL.nextDataId=0;const tfjs_backend_webgl_dist_version_version="4.22.0";function forceHalfFloat(){(0,dist._K2)().set("WEBGL_FORCE_F16_TEXTURES",!0)}dist.eMq.isBrowser()&&(0,dist.gJX)("webgl",()=>new MathBackendWebGL,2);const webgl={forceHalfFloat};class BinaryOpProgram{constructor(op,aShape,bShape){this.variableNames=["A","B"],this.outputShape=dist.C0T.assertAndGetBroadcastShape(aShape,bShape),this.enableShapeUniforms=useShapeUniforms(this.outputShape.length),this.userCode=`\n      float binaryOperation(float a, float b) {\n        ${op}\n      }\n\n      void main() {\n        float a = getAAtOutCoords();\n        float b = getBAtOutCoords();\n        setOutput(binaryOperation(a, b));\n      }\n    `}}const CHECK_NAN_SNIPPET_PACKED="\n  result.r = isNaN.r ? NAN : result.r;\n  result.g = isNaN.g ? NAN : result.g;\n  result.b = isNaN.b ? NAN : result.b;\n  result.a = isNaN.a ? NAN : result.a;\n";class BinaryOpPackedProgram{constructor(op,aShape,bShape,checkOutOfBounds=!1){this.variableNames=["A","B"],this.supportsBroadcasting=!0,this.packedInputs=!0,this.packedOutput=!0,this.outputShape=dist.C0T.assertAndGetBroadcastShape(aShape,bShape);const rank=this.outputShape.length;this.enableShapeUniforms=useShapeUniforms(rank);let checkOutOfBoundsString="";if(checkOutOfBounds)if(0===rank||1===dist.ZSL.sizeFromShape(this.outputShape))checkOutOfBoundsString="\n          result.y = 0.;\n          result.z = 0.;\n          result.w = 0.;\n        ";else{if(checkOutOfBoundsString=`\n          ${getCoordsDataType(rank)} coords = getOutputCoords();\n        `,1===rank)this.enableShapeUniforms?checkOutOfBoundsString+="\n            result.y = (coords + 1) >= outShape ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          ":checkOutOfBoundsString+=`\n            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          `;else{const channels=getChannels("coords",rank);this.enableShapeUniforms?checkOutOfBoundsString+=`\n            bool nextRowOutOfBounds =\n              (${channels[rank-2]} + 1) >= outShape[${rank} - 2];\n            bool nextColOutOfBounds =\n              (${channels[rank-1]} + 1) >= outShape[${rank} - 1];\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          `:checkOutOfBoundsString+=`\n            bool nextRowOutOfBounds =\n              (${channels[rank-2]} + 1) >= ${this.outputShape[rank-2]};\n            bool nextColOutOfBounds =\n              (${channels[rank-1]} + 1) >= ${this.outputShape[rank-1]};\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          `}}this.userCode=`\n      vec4 binaryOperation(vec4 a, vec4 b) {\n        ${op}\n      }\n\n      void main() {\n        vec4 a = getAAtOutCoords();\n        vec4 b = getBAtOutCoords();\n\n        vec4 result = binaryOperation(a, b);\n        ${checkOutOfBoundsString}\n\n        setOutput(result);\n      }\n    `}}function kernels_Identity_identity(args){const{inputs,backend}=args,{x}=inputs;return backend.incRef(x.dataId),{dataId:x.dataId,shape:x.shape,dtype:x.dtype}}const Identity_identityConfig={kernelName:dist.lzr,backendName:"webgl",kernelFunc:kernels_Identity_identity};function Complex_complex(args){const{inputs,backend}=args,{real,imag}=inputs,complexInfo=backend.makeTensorInfo(real.shape,"complex64"),complex=backend.texData.get(complexInfo.dataId),realTensorInfo=kernels_Identity_identity({inputs:{x:real},backend}),imagTensorInfo=kernels_Identity_identity({inputs:{x:imag},backend});return complex.complexTensorInfos={real:realTensorInfo,imag:imagTensorInfo},complexInfo}const Complex_complexConfig={kernelName:dist.pr3,backendName:"webgl",kernelFunc:Complex_complex},LEAKYRELU="return (a < 0.) ? b * a : a;",LEAKYRELU_PACKED="\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";const LeakyRelu_leakyReluConfig={kernelName:dist.X0$,backendName:"webgl",kernelFunc:function LeakyRelu_leakyRelu(args){const{inputs,backend,attrs}=args,{x}=inputs,{alpha}=attrs,$alpha=backend.makeTensorInfo([],"float32",dist.ZSL.createScalarValue(alpha,"float32")),program=(0,dist._K2)().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram(LEAKYRELU_PACKED,x.shape,$alpha.shape):new BinaryOpProgram(LEAKYRELU,x.shape,$alpha.shape),result=backend.runWebGLProgram(program,[x,$alpha],"float32");return backend.disposeIntermediateTensorInfo($alpha),result}},PRELU="return (a < 0.) ? b * a : a;",PRELU_PACKED="\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";const Prelu_preluConfig={kernelName:dist.Ncv,backendName:"webgl",kernelFunc:function kernels_Prelu_prelu(args){const{inputs,backend}=args,{x,alpha}=inputs,program=(0,dist._K2)().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram(PRELU_PACKED,x.shape,alpha.shape):new BinaryOpProgram(PRELU,x.shape,alpha.shape);return backend.runWebGLProgram(program,[x,alpha],"float32")}};function kernel_funcs_utils_unaryKernelFunc({opSnippet,packedOpSnippet,cpuKernelImpl,dtype}){return({inputs,backend})=>{const{x}=inputs,webglBackend=backend,$dtype=dtype||x.dtype;if(webglBackend.shouldExecuteOnCPU([x])&&null!=cpuKernelImpl){const xData=webglBackend.texData.get(x.dataId),outValues=cpuKernelImpl(xData.values,$dtype);return webglBackend.makeTensorInfo(x.shape,$dtype,outValues)}let program;return program=(0,dist._K2)().getBool("WEBGL_PACK_UNARY_OPERATIONS")&&null!=packedOpSnippet?new UnaryOpPackedProgram(x.shape,packedOpSnippet):new UnaryOpProgram(x.shape,opSnippet),webglBackend.runWebGLProgram(program,[x],$dtype)}}function kernel_funcs_utils_binaryKernelFunc({opSnippet,packedOpSnippet,checkOutOfBounds=!1,supportsComplex=!1,cpuKernelImpl,dtype}){return({inputs,backend})=>{const{a,b}=inputs,webglBackend=backend;if(supportsComplex&&"complex64"===a.dtype){const aData=webglBackend.texData.get(a.dataId),bData=webglBackend.texData.get(b.dataId),[real,imag]=[[aData.complexTensorInfos.real,bData.complexTensorInfos.real],[aData.complexTensorInfos.imag,bData.complexTensorInfos.imag]].map(complexParts=>{const[aPart,bPart]=complexParts,aHandle={dataId:aPart.dataId,dtype:aPart.dtype,shape:a.shape},bHandle={dataId:bPart.dataId,dtype:bPart.dtype,shape:b.shape},program=new BinaryOpProgram(opSnippet,a.shape,b.shape);return webglBackend.runWebGLProgram(program,[aHandle,bHandle],(0,dist.TuY)(aPart.dtype,bPart.dtype))}),complexOutput=Complex_complex({inputs:{real,imag},backend:webglBackend});return webglBackend.disposeIntermediateTensorInfo(real),webglBackend.disposeIntermediateTensorInfo(imag),complexOutput}const $dtype=dtype||(0,dist.TuY)(a.dtype,b.dtype);if(("string"===a.dtype||"string"===b.dtype||webglBackend.shouldExecuteOnCPU([a,b]))&&null!=cpuKernelImpl){const aVals=webglBackend.texData.get(a.dataId).values,bVals=webglBackend.texData.get(b.dataId).values,decodedAVals="string"===a.dtype?dist.C0T.fromUint8ToStringArray(aVals):aVals,decodedBVals="string"===a.dtype?dist.C0T.fromUint8ToStringArray(bVals):bVals,[outValues,outShape]=cpuKernelImpl(a.shape,b.shape,decodedAVals,decodedBVals,$dtype),out=webglBackend.makeTensorInfo(outShape,$dtype);return webglBackend.texData.get(out.dataId).values=outValues,out}let program;return program=(0,dist._K2)().getBool("WEBGL_PACK_BINARY_OPERATIONS")&&null!=packedOpSnippet?new BinaryOpPackedProgram(packedOpSnippet,a.shape,b.shape,checkOutOfBounds):new BinaryOpProgram(opSnippet,a.shape,b.shape),webglBackend.runWebGLProgram(program,[a,b],$dtype)}}function mapActivationToShaderProgram(activation,packed=!1){if("linear"===activation)return"return x;";if("relu"===activation)return packed?"\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n":RELU;if("elu"===activation)return packed?"\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n":"return (x >= 0.0) ? x : (exp(x) - 1.0);";if("relu6"===activation)return packed?"\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n":RELU6;if("prelu"===activation)return packed?PRELU_PACKED:PRELU;if("leakyrelu"===activation)return packed?LEAKYRELU_PACKED:LEAKYRELU;if("sigmoid"===activation)return"return 1.0 / (1.0 + exp(-1.0 * x));";throw new Error(`Activation ${activation} has not been implemented for the WebGL backend.`)}class MatMulPackedProgram{constructor(aShape,bShape,outputShape,transposeA=!1,transposeB=!1,addBias=!1,activation=null,hasPreluActivation=!1,hasLeakyreluActivation=!1){this.variableNames=["matrixA","matrixB"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=outputShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length);const sharedDim=transposeA?aShape[1]:aShape[2],sharedDimensionPacked=Math.ceil(sharedDim/2),aSample=transposeA?"i * 2, rc.y":"rc.y, i * 2",bSample=transposeB?"rc.z, i * 2":"i * 2, rc.z",aSwizzle=transposeA?["a.xxyy","a.zzww"]:["a.xxzz","a.yyww"],bSwizzle=transposeB?["b.xzxz","b.ywyw"]:["b.xyxy","b.zwzw"];let activationSnippet="",applyActivationSnippet="";activation&&(activationSnippet=hasPreluActivation?`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${activation}\n        }`:hasLeakyreluActivation?`vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${activation}\n        }`:`vec4 activation(vec4 x) {\n          ${activation}\n        }`,applyActivationSnippet="result = activation(result);");const addBiasSnippet=addBias?"result += getBiasAtOutCoords();":"";addBias&&this.variableNames.push("bias"),hasPreluActivation&&this.variableNames.push("preluActivationWeights"),hasLeakyreluActivation&&this.variableNames.push("leakyreluAlpha");let batchASnippet="rc.x",batchBSnippet="rc.x";aShape[0]<bShape[0]?batchASnippet=`imod(rc.x, ${aShape[0]})`:bShape[0]<aShape[0]&&(batchBSnippet=`imod(rc.x, ${bShape[0]})`),this.userCode=`\n      ${activationSnippet}\n      // Don't use uniform for sharedDimensionPacked for performance.\n      const float sharedDimension = ${sharedDimensionPacked}.0;\n\n      vec4 dot2x2ARowBCol(ivec3 rc) {\n        vec4 result = vec4(0);\n        int batchA = ${batchASnippet};\n        int batchB = ${batchBSnippet};\n        for (int i = 0; i < ${sharedDimensionPacked}; i++) {\n          vec4 a = getMatrixA(batchA, ${aSample});\n          vec4 b = getMatrixB(batchB, ${bSample});\n\n          // These swizzled products need to be separately added.\n          // See: https://github.com/tensorflow/tfjs/issues/1735\n          result += (${aSwizzle[0]} * ${bSwizzle[0]});\n          result += (${aSwizzle[1]} * ${bSwizzle[1]});\n        }\n        return result;\n      }\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n        vec4 result = dot2x2ARowBCol(rc);\n\n        ${addBiasSnippet}\n\n        ${applyActivationSnippet}\n\n        setOutput(result);\n      }\n    `}}const COMPLEX_MULTIPLY_REAL="return areal * breal - aimag * bimag;",COMPLEX_MULTIPLY_IMAG="return areal * bimag + aimag * breal;";class BinaryOpComplexProgram{constructor(op,aShape,bShape){this.variableNames=["AReal","AImag","BReal","BImag"],this.outputShape=dist.C0T.assertAndGetBroadcastShape(aShape,bShape),this.userCode=`\n      float binaryOpComplex(\n          float areal, float aimag, float breal, float bimag) {\n        ${op}\n      }\n\n      void main() {\n        float areal = getARealAtOutCoords();\n        float aimag = getAImagAtOutCoords();\n        float breal = getBRealAtOutCoords();\n        float bimag = getBImagAtOutCoords();\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\n      }\n    `}}const MUL="return a * b;";function kernels_Multiply_multiply(args){const{inputs,backend}=args,{a,b}=inputs,dtype=dist.C0T.upcastType(a.dtype,b.dtype);if("complex64"===a.dtype){const aData=backend.texData.get(a.dataId),bData=backend.texData.get(b.dataId),realProgram=new BinaryOpComplexProgram(COMPLEX_MULTIPLY_REAL,a.shape,b.shape),imagProgram=new BinaryOpComplexProgram(COMPLEX_MULTIPLY_IMAG,a.shape,b.shape),inputs=[{dataId:aData.complexTensorInfos.real.dataId,dtype:aData.complexTensorInfos.real.dtype,shape:a.shape},{dataId:aData.complexTensorInfos.imag.dataId,dtype:aData.complexTensorInfos.imag.dtype,shape:a.shape},{dataId:bData.complexTensorInfos.real.dataId,dtype:bData.complexTensorInfos.real.dtype,shape:b.shape},{dataId:bData.complexTensorInfos.imag.dataId,dtype:bData.complexTensorInfos.imag.dtype,shape:b.shape}],realPart=backend.runWebGLProgram(realProgram,inputs,"float32"),imagPart=backend.runWebGLProgram(imagProgram,inputs,"float32"),complexOutput=Complex_complex({inputs:{real:realPart,imag:imagPart},backend});return backend.disposeIntermediateTensorInfo(realPart),backend.disposeIntermediateTensorInfo(imagPart),complexOutput}if(backend.shouldExecuteOnCPU([a,b])){const aData=backend.texData.get(a.dataId),bData=backend.texData.get(b.dataId),[outValues,outShape]=multiplyImplCPU(a.shape,b.shape,aData.values,bData.values,dtype),out=backend.makeTensorInfo(outShape,dtype);return backend.texData.get(out.dataId).values=outValues,out}let program;return program=(0,dist._K2)().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram(MUL,a.shape,b.shape):new BinaryOpProgram(MUL,a.shape,b.shape),backend.runWebGLProgram(program,[a,b],dtype)}const Multiply_multiplyConfig={kernelName:dist.xu7,backendName:"webgl",kernelFunc:kernels_Multiply_multiply};function kernels_Reshape_reshape(args){const{inputs,backend,attrs}=args,{x}=inputs,{shape}=attrs,webglBackend=backend,xSize=dist.ZSL.sizeFromShape(x.shape),$shape=dist.ZSL.inferFromImplicitShape(shape,xSize),$xSize=dist.ZSL.sizeFromShape($shape);dist.ZSL.assert(xSize===$xSize,()=>`The new shape (${$shape}) has ${$xSize} elements and the old shape (${x.shape}) has ${xSize} elements. The new shape and old shape must have the same number of elements.`);const xTexData=webglBackend.texData.get(x.dataId);return!xTexData.isPacked||isReshapeFree(x.shape,$shape)||null!==xTexData.texture&&isReshapeFree(xTexData.shape,$shape)?(webglBackend.incRef(x.dataId),{dataId:x.dataId,shape:$shape,dtype:x.dtype}):function packedReshape(input,afterShape,backend){const input3DShape=[getBatchDim(input.shape),...getRowsCols(input.shape)],input3D={dtype:input.dtype,shape:input3DShape,dataId:input.dataId},afterShapeAs3D=[getBatchDim(afterShape),...getRowsCols(afterShape)],program=new ReshapePackedProgram(afterShapeAs3D,input3DShape),customValues=[input3DShape],output=backend.runWebGLProgram(program,[input3D],input.dtype,customValues,!0);return{dataId:output.dataId,shape:afterShape,dtype:output.dtype}}(x,$shape,webglBackend)}const Reshape_reshapeConfig={kernelName:dist.R23,backendName:"webgl",kernelFunc:kernels_Reshape_reshape};class MeanProgram{constructor(reduceInfo,divisor){this.variableNames=["x"];const{windowSize,batchSize,inSize,outSize}=reduceInfo;this.outputShape=[batchSize,outSize];const windowSizeNearestVec4=4*Math.floor(windowSize/4),windowSizeVec4Remainder=windowSize%4;let updateSnippet="sumValue += dot(values, ones);";if(null!=divisor){const denominator=1/divisor;updateSnippet=`sumValue += dot(values * ${dist.ZSL.isInt(denominator)?denominator.toPrecision(2):denominator}, ones);`}let checkOutOfBounds="";inSize%windowSize>0&&(checkOutOfBounds=`\n        if (inIdx < 0 || inIdx >= ${inSize}) {\n          return 0.0;\n        }\n      `),this.userCode=`\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${checkOutOfBounds}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${windowSize};\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${updateSnippet}\n        }\n\n        int inIdx = inOffset + ${windowSizeNearestVec4};\n        if (${1===windowSizeVec4Remainder}) {\n          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);\n\n          ${updateSnippet}\n        } else if (${2===windowSizeVec4Remainder}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1), 0.0, 0.0);\n\n          ${updateSnippet}\n        } else if (${3===windowSizeVec4Remainder}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2), 0.0);\n\n          ${updateSnippet}\n        }\n        setOutput(sumValue);\n      }\n    `}}class ReduceProgram{constructor(reduceInfo,reduceType){this.variableNames=["x"];const{windowSize,batchSize,inSize,outSize}=reduceInfo;this.outputShape=[batchSize,outSize];let initializationValue="0.0",compareOp="";"prod"===reduceType?initializationValue="1.0":"min"===reduceType?(initializationValue="1.0 / 1e-20",compareOp="min"):"max"===reduceType&&(initializationValue="-1.0 / 1e-20",compareOp="max");let returnValue=`${reduceType}(${reduceType}(${reduceType}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"sum"===reduceType?returnValue="sumValue":"prod"===reduceType?returnValue="prodValue":"all"===reduceType?returnValue="allValue":"any"===reduceType&&(returnValue="anyValue");const windowSizeNearestVec4=4*Math.floor(windowSize/4),windowSizeVec4Remainder=windowSize%4;let updateSnippet=`\n      if (${"sum"===reduceType}) {\n        sumValue += dot(values, ones);\n      } else if (${"prod"===reduceType}) {\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\n        prodValue *= tmp[0] * tmp[1];\n      } else {\n        minMaxValue = ${compareOp}(values, minMaxValue);\n        if (${"min"===reduceType} || ${"max"===reduceType}) {\n          minMaxValue = ${compareOp}(values, minMaxValue);\n          bvec4 isNaN = isnan(values);\n          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {\n            minMaxValue = vec4(NAN);\n          }\n        }\n      }\n    `,vecType="vec4";"all"===reduceType?(initializationValue="1.0",updateSnippet="\n        bool reducedAllValue = all(values);\n        float floatedReducedAllValue = float(reducedAllValue);\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\n      ",vecType="bvec4"):"any"===reduceType&&(initializationValue="0.0",updateSnippet="\n        bool reducedAnyValue = any(values);\n        float floatedReducedAnyValue = float(reducedAnyValue);\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\n      ",vecType="bvec4");let checkOutOfBounds="";inSize%windowSize>0&&(checkOutOfBounds=`\n        if (inIdx < 0 || inIdx >= ${inSize}) {\n          return initializationValue;\n        }\n      `),this.userCode=`\n      const float initializationValue = ${initializationValue};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${checkOutOfBounds}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${windowSize};\n\n        vec4 minMaxValue = vec4(${initializationValue});\n        float prodValue = 1.0;\n        float sumValue = 0.0;\n        float allValue = 1.0;\n        float anyValue = 0.0;\n\n        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {\n          int inIdx = inOffset + i;\n          ${vecType} values = ${vecType}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${updateSnippet}\n        }\n\n        int inIdx = inOffset + ${windowSizeNearestVec4};\n        if (${1===windowSizeVec4Remainder}) {\n          ${vecType} values = ${vecType}(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          ${updateSnippet}\n        } else if (${2===windowSizeVec4Remainder}) {\n          ${vecType} values = ${vecType}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          ${updateSnippet}\n        } else if (${3===windowSizeVec4Remainder}) {\n          ${vecType} values = ${vecType}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          ${updateSnippet}\n        }\n        setOutput(${returnValue});\n      }\n    `}}function reduce(x,dtype,reductionType,backend){const reductionStages=function getReductionStages(inShape){const stages=[];for(;0===stages.length||1!==stages[stages.length-1].outSize;){const outSize=stages.length?stages[stages.length-1].outSize:inShape[1],windowSize=dist.C0T.computeOptimalWindowSize(outSize);stages.push({inSize:outSize,windowSize,outSize:Math.ceil(outSize/windowSize)})}return stages}(x.shape);let result=x;for(let i=0;i<reductionStages.length;i++){const{inSize,windowSize,outSize}=reductionStages[i];let program,previousResult;program="mean"===reductionType?0===i?new MeanProgram({windowSize,inSize,batchSize:x.shape[0],outSize},inSize):new MeanProgram({windowSize,inSize,batchSize:x.shape[0],outSize}):new ReduceProgram({windowSize,inSize,batchSize:x.shape[0],outSize},reductionType),previousResult=result,result=backend.runWebGLProgram(program,[result],dtype),previousResult.dataId!==x.dataId&&backend.disposeIntermediateTensorInfo(previousResult)}return result}class TransposeProgram{constructor(aShape,newDim){this.variableNames=["A"];const outputShape=new Array(aShape.length);for(let i=0;i<outputShape.length;i++)outputShape[i]=aShape[newDim[i]];this.outputShape=outputShape,this.rank=outputShape.length;const dtype=getCoordsDataType(this.rank),switched=function getSwitchedCoords(newDim){const rank=newDim.length;if(rank>6)throw Error(`Transpose for rank ${rank} is not yet supported`);const originalOrder=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u","resRC.v"],switchedCoords=new Array(rank);for(let i=0;i<newDim.length;i++)switchedCoords[newDim[i]]=originalOrder[i];return switchedCoords.join()}(newDim);this.userCode=`\n    void main() {\n      ${dtype} resRC = getOutputCoords();\n      setOutput(getA(${switched}));\n    }\n    `}}class TransposePackedProgram{constructor(aShape,newDim){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0;const outputShape=new Array(aShape.length);for(let i=0;i<outputShape.length;i++)outputShape[i]=aShape[newDim[i]];if(this.outputShape=outputShape,this.rank=outputShape.length,this.rank>6)throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`);const dtype=getCoordsDataType(this.rank),outputOrder=getVecChannels("rc",this.rank),switchedOrder=new Array(this.rank);for(let i=0;i<newDim.length;i++)switchedOrder[newDim[i]]=outputOrder[i];const innerDims=`vec2(${switchedOrder.slice(-2).join()})`,nextColumn=`++${outputOrder[this.rank-1]} < ${outputShape[this.rank-1]}`,getc=`getChannel(getA(${switchedOrder.join()}), ${innerDims})`;this.userCode=`\n    void main() {\n      ${dtype} rc = getOutputCoords();\n      vec4 result = vec4(0.);\n      result[0] = ${getc};\n      if(${nextColumn}) {\n        result[1] = ${getc};\n      }\n      --${outputOrder[this.rank-1]};\n      if(++${outputOrder[this.rank-2]} < ${outputShape[this.rank-2]}) {\n        result[2] = ${getc};\n        if(${nextColumn}) {\n          result[3] = ${getc};\n        }\n      }\n      setOutput(result);\n    }\n    `}}function Transpose_impl_transposeImpl(x,perm,backend){const program=(0,dist._K2)().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new TransposePackedProgram(x.shape,perm):new TransposeProgram(x.shape,perm);return backend.runWebGLProgram(program,[x],x.dtype)}function kernels_Sum_sum(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,keepDims}=attrs;return function sumImpl(x,axis,keepDims,backend){const reductionIndices=axis,xRank=x.shape.length,origAxes=dist.ZSL.parseAxisParam(reductionIndices,x.shape);let axes=origAxes;const permutedAxes=dist.C0T.getAxesPermutation(axes,xRank),sumInputIsTransposed=null!=permutedAxes;let sumInput=x;sumInputIsTransposed&&(sumInput=Transpose_impl_transposeImpl(x,permutedAxes,backend),axes=dist.C0T.getInnerMostAxes(axes.length,xRank)),dist.C0T.assertAxesAreInnerMostDims("sum",axes,xRank);const[sumOutShape,reduceShape]=dist.C0T.computeOutAndReduceShapes(sumInput.shape,axes);let outShape=sumOutShape;keepDims&&(outShape=dist.C0T.expandShapeToKeepDim(sumOutShape,origAxes));const inSize=dist.ZSL.sizeFromShape(reduceShape),reshapedInput=kernels_Reshape_reshape({inputs:{x:sumInput},attrs:{shape:[dist.ZSL.sizeFromShape(x.shape)/inSize,inSize]},backend}),reduced=reduce(reshapedInput,(0,dist.chL)(x.dtype),"sum",backend),out=kernels_Reshape_reshape({inputs:{x:reduced},attrs:{shape:outShape},backend});return backend.disposeIntermediateTensorInfo(reshapedInput),backend.disposeIntermediateTensorInfo(reduced),sumInputIsTransposed&&backend.disposeIntermediateTensorInfo(sumInput),out}(x,axis,keepDims,backend)}const Sum_sumConfig={kernelName:dist.WuN,backendName:"webgl",kernelFunc:kernels_Sum_sum};function kernels_Transpose_transpose(args){const{inputs,backend,attrs}=args,{x}=inputs,{perm}=attrs,webglBackend=backend,xRank=x.shape.length,newShape=new Array(xRank);for(let i=0;i<newShape.length;i++)newShape[i]=x.shape[perm[i]];let out;if(webglBackend.shouldExecuteOnCPU([x])){const values=webglBackend.texData.get(x.dataId).values,outValues=transposeImplCPU(values,x.shape,x.dtype,perm,newShape);out=webglBackend.makeTensorInfo(newShape,x.dtype);webglBackend.texData.get(out.dataId).values=outValues}else out=Transpose_impl_transposeImpl(x,perm,webglBackend);return out}const Transpose_transposeConfig={kernelName:dist.wx0,backendName:"webgl",kernelFunc:kernels_Transpose_transpose};function batchMatMulImpl({a,b,transposeA,transposeB,backend,bias=null,preluActivationWeights=null,leakyreluAlpha=0,activation=null}){const aRank=a.shape.length,bRank=b.shape.length,innerShapeA=transposeA?a.shape[aRank-2]:a.shape[aRank-1],innerShapeB=transposeB?b.shape[bRank-1]:b.shape[bRank-2],outerShapeA=transposeA?a.shape[aRank-1]:a.shape[aRank-2],outerShapeB=transposeB?b.shape[bRank-2]:b.shape[bRank-1],outerDimsA=a.shape.slice(0,-2),outerDimsB=b.shape.slice(0,-2),batchDimA=dist.ZSL.sizeFromShape(outerDimsA),batchDimB=dist.ZSL.sizeFromShape(outerDimsB),outShape=dist.ZEY.assertAndGetBroadcastShape(a.shape.slice(0,-2),b.shape.slice(0,-2)).concat([outerShapeA,outerShapeB]);dist.ZSL.assert(innerShapeA===innerShapeB,()=>`Error in matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${a.shape} and ${b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);const a3dShape=transposeA?[batchDimA,innerShapeA,outerShapeA]:[batchDimA,outerShapeA,innerShapeA],b3dShape=transposeB?[batchDimB,outerShapeB,innerShapeB]:[batchDimB,innerShapeB,outerShapeB],a3d=kernels_Reshape_reshape({inputs:{x:a},backend,attrs:{shape:a3dShape}}),b3d=kernels_Reshape_reshape({inputs:{x:b},backend,attrs:{shape:b3dShape}}),intermediates=[a3d,b3d],batchDim=Math.max(batchDimA,batchDimB),sharedDim=transposeA?a3d.shape[1]:a3d.shape[2],hasBias=null!=bias,hasPreluActivationWeights=null!=preluActivationWeights,hasLeakyreluAlpha="leakyrelu"===activation,fusedActivation=null!=activation?mapActivationToShaderProgram(activation,!0):null;let out;if((1===outerShapeA||1===outerShapeB)&&sharedDim>1e3&&!1===(hasBias||hasPreluActivationWeights||hasLeakyreluAlpha||null!=fusedActivation)){let aVec=a3d,bVec=b3d;transposeA&&(aVec=kernels_Transpose_transpose({inputs:{x:a3d},backend,attrs:{perm:[0,2,1]}}),intermediates.push(aVec)),transposeB&&(bVec=kernels_Transpose_transpose({inputs:{x:b3d},backend,attrs:{perm:[0,2,1]}}),intermediates.push(bVec));const shouldReshapeB=1===outerShapeB;let aVec3d=aVec;1!==outerShapeB&&(aVec3d=kernels_Reshape_reshape({inputs:{x:aVec},backend,attrs:{shape:[batchDim,sharedDim,1]}}),intermediates.push(aVec3d));const axis=1===outerShapeB?2:1;let bVec3d=bVec;shouldReshapeB&&(bVec3d=kernels_Reshape_reshape({inputs:{x:bVec},backend,attrs:{shape:[batchDim,1,sharedDim]}}),intermediates.push(bVec3d));const product=kernels_Multiply_multiply({inputs:{a:aVec3d,b:bVec3d},backend});out=kernels_Sum_sum({inputs:{x:product},backend,attrs:{axis,keepDims:!0}}),intermediates.push(product)}else{const dtype=(0,dist.TuY)(a.dtype,b.dtype),program=new MatMulPackedProgram(a3dShape,b3dShape,[batchDim,outerShapeA,outerShapeB],transposeA,transposeB,hasBias,fusedActivation,hasPreluActivationWeights,hasLeakyreluAlpha),inputs=[a3d,b3d];if(null!=bias&&inputs.push(bias),hasPreluActivationWeights&&inputs.push(preluActivationWeights),hasLeakyreluAlpha){const $leakyreluAlpha=backend.makeTensorInfo([],"float32",dist.ZSL.createScalarValue(leakyreluAlpha,"float32"));inputs.push($leakyreluAlpha),intermediates.push($leakyreluAlpha)}out=backend.runWebGLProgram(program,inputs,dtype)}const outReshaped=kernels_Reshape_reshape({inputs:{x:out},backend,attrs:{shape:outShape}});intermediates.push(out);for(const i of intermediates)backend.disposeIntermediateTensorInfo(i);return outReshaped}const _FusedMatMul_fusedMatMulConfig={kernelName:dist.Dr,backendName:"webgl",kernelFunc:function _FusedMatMul_fusedMatMul(args){const{inputs,backend,attrs}=args,{a,b,bias,preluActivationWeights}=inputs,{transposeA,transposeB,activation,leakyreluAlpha}=attrs;return batchMatMulImpl({a,b,transposeA,transposeB,backend,bias,preluActivationWeights,leakyreluAlpha,activation})}};const Abs_absConfig={kernelName:dist.ljI,backendName:"webgl",kernelFunc:function kernels_Abs_abs(args){const{inputs,backend}=args,{x}=inputs;if(backend.shouldExecuteOnCPU([x])&&"complex64"!==x.dtype){const xData=backend.texData.get(x.dataId),outValues=simpleAbsImplCPU(xData.values);return backend.makeTensorInfo(x.shape,x.dtype,outValues)}let program;return program=(0,dist._K2)().getBool("WEBGL_PACK_UNARY_OPERATIONS")?new UnaryOpPackedProgram(x.shape,"return abs(x);"):new UnaryOpProgram(x.shape,"return abs(x);"),backend.runWebGLProgram(program,[x],x.dtype)}},kernels_Acos_acos=kernel_funcs_utils_unaryKernelFunc({opSnippet:CHECK_NAN_SNIPPET+"\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return acos(x);\n"}),Acos_acosConfig={kernelName:dist.Vvy,backendName:"webgl",kernelFunc:kernels_Acos_acos},kernels_Acosh_acosh=kernel_funcs_utils_unaryKernelFunc({opSnippet:CHECK_NAN_SNIPPET+"\n  if (x < 1.0) return NAN;\nreturn log(x + sqrt(x * x - 1.0));"}),Acosh_acoshConfig={kernelName:dist.PH8,backendName:"webgl",kernelFunc:kernels_Acosh_acosh},ADD="return a + b;",addKernelFunc=kernel_funcs_utils_binaryKernelFunc({opSnippet:ADD,packedOpSnippet:ADD,supportsComplex:!0,cpuKernelImpl:addImplCPU}),Add_addConfig={kernelName:dist.OMN,backendName:"webgl",kernelFunc:addKernelFunc};class AddNProgram{constructor(outputShape,shapes){this.outputShape=[],this.outputShape=outputShape,this.variableNames=shapes.map((_,i)=>`T${i}`);const snippets=[];this.variableNames.forEach(variable=>{snippets.push(`float v${variable} = get${variable}AtOutCoords();`)});const operation=this.variableNames.map(variable=>`v${variable}`).join(" + ");this.userCode=`\n      void main() {\n        ${snippets.join("\n        ")}\n\n        float result = ${operation};\n        setOutput(result);\n      }\n    `}}class AddNPackedProgram{constructor(outputShape,shapes){this.outputShape=[],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=outputShape,this.variableNames=shapes.map((_,i)=>`T${i}`);const snippets=[];this.variableNames.forEach(variable=>{snippets.push(`vec4 v${variable} = get${variable}AtOutCoords();`)});const operation=this.variableNames.map(variable=>`v${variable}`).join(" + ");this.userCode=`\n      void main() {\n        ${snippets.join("\n        ")}\n\n        vec4 result = ${operation};\n        setOutput(result);\n      }\n    `}}const AddN_addNConfig={kernelName:dist.EkD,backendName:"webgl",kernelFunc:function AddN_addN(args){const{inputs,backend}=args,tensors=inputs;if(1===tensors.length)return kernels_Identity_identity({inputs:{x:tensors[0]},backend});if(tensors.length>(0,dist._K2)().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")){const midIndex=Math.floor(tensors.length/2),leftSide=AddN_addN({inputs:tensors.slice(0,midIndex),backend}),rightSide=AddN_addN({inputs:tensors.slice(midIndex),backend});return AddN_addN({inputs:[leftSide,rightSide],backend})}const dtype=tensors.map(t=>t.dtype).reduce((d1,d2)=>(0,dist.TuY)(d1,d2)),shapes=tensors.map(t=>t.shape),program=(0,dist._K2)().getBool("WEBGL_PACK")?new AddNPackedProgram(tensors[0].shape,shapes):new AddNProgram(tensors[0].shape,shapes);return backend.runWebGLProgram(program,tensors,dtype)}};const All_allConfig={kernelName:dist.u8Z,backendName:"webgl",kernelFunc:function kernels_All_all(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,keepDims}=attrs,xRank=x.shape.length,origAxes=dist.ZSL.parseAxisParam(axis,x.shape);let axes=origAxes;const permutedAxes=dist.C0T.getAxesPermutation(axes,xRank);let permutedX=x;null!=permutedAxes&&(permutedX=kernels_Transpose_transpose({inputs:{x},backend,attrs:{perm:permutedAxes}}),axes=dist.C0T.getInnerMostAxes(axes.length,xRank)),dist.C0T.assertAxesAreInnerMostDims("all",axes,xRank);const[outShape,reduceShape]=dist.C0T.computeOutAndReduceShapes(permutedX.shape,axes),a2D=kernels_Reshape_reshape({inputs:{x:permutedX},backend,attrs:{shape:[-1,dist.ZSL.sizeFromShape(reduceShape)]}}),reduced=reduce(a2D,a2D.dtype,"all",backend);let res;if(keepDims){res=kernels_Reshape_reshape({inputs:{x:reduced},backend,attrs:{shape:dist.C0T.expandShapeToKeepDim(outShape,origAxes)}})}else res=kernels_Reshape_reshape({inputs:{x:reduced},backend,attrs:{shape:outShape}});return backend.disposeIntermediateTensorInfo(a2D),backend.disposeIntermediateTensorInfo(reduced),null!=permutedAxes&&backend.disposeIntermediateTensorInfo(permutedX),res}};const Any_anyConfig={kernelName:dist.FSt,backendName:"webgl",kernelFunc:function kernels_Any_any(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,keepDims}=attrs,xRank=x.shape.length,origAxes=dist.ZSL.parseAxisParam(axis,x.shape);let axes=origAxes;const permutedAxes=dist.C0T.getAxesPermutation(axes,xRank);let permutedX=x;null!=permutedAxes&&(permutedX=kernels_Transpose_transpose({inputs:{x},backend,attrs:{perm:permutedAxes}}),axes=dist.C0T.getInnerMostAxes(axes.length,xRank)),dist.C0T.assertAxesAreInnerMostDims("any",axes,xRank);const[outShape,reduceShape]=dist.C0T.computeOutAndReduceShapes(permutedX.shape,axes),a2D=kernels_Reshape_reshape({inputs:{x:permutedX},backend,attrs:{shape:[-1,dist.ZSL.sizeFromShape(reduceShape)]}}),reduced=reduce(a2D,a2D.dtype,"any",backend);let res;if(keepDims){res=kernels_Reshape_reshape({inputs:{x:reduced},backend,attrs:{shape:dist.C0T.expandShapeToKeepDim(outShape,origAxes)}})}else res=kernels_Reshape_reshape({inputs:{x:reduced},backend,attrs:{shape:outShape}});return backend.disposeIntermediateTensorInfo(a2D),backend.disposeIntermediateTensorInfo(reduced),null!=permutedAxes&&backend.disposeIntermediateTensorInfo(permutedX),res}};class ArgMinMaxProgram{constructor(reduceInfo,op,firstPass){this.variableNames=["A"];const{windowSize,batchSize,outSize}=reduceInfo;firstPass||this.variableNames.push("bestIndicesA"),this.outputShape=[batchSize,outSize];const compOp="max"===op?">":"<",indexSnippet=firstPass?"inOffset + i;":"round(getBestIndicesA(batch, inOffset + i));";this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${windowSize};\n\n        int bestIndex = inOffset;\n        float bestValue = getA(batch, bestIndex);\n\n        for (int i = 0; i < ${windowSize}; i++) {\n          int inIdx = ${indexSnippet};\n          float candidate = getA(batch, inIdx);\n          if (candidate ${compOp} bestValue) {\n            bestValue = candidate;\n            bestIndex = inIdx;\n          }\n        }\n        setOutput(float(bestIndex));\n      }\n    `}}class ArgMinMaxPackedProgram{constructor(shape,windowSize,op,firstPass){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,dist.ZSL.assert(shape.length>2,()=>`Packed arg${op.charAt(0).toUpperCase()+op.slice(1)} supports only inputs with rank above 2.`);const inSize=shape[shape.length-1],outSize=Math.ceil(inSize/windowSize);this.outputShape=shape.slice(0,-1),outSize>1&&this.outputShape.push(outSize),firstPass||this.variableNames.push("bestIndicesA");const outShape=this.outputShape,rank=outShape.length,dtype=getCoordsDataType(rank),coords=getChannels("coords",rank);let sourceLocSetup,sourceRank;if(1===outSize){sourceRank=rank+1;const sourceLocDType=getCoordsDataType(sourceRank);sourceLocSetup=`\n        ${sourceLocDType} sourceLocR = ${sourceLocDType}(${coords.join()}, 0);\n        ++${coords[rank-1]};\n        ${sourceLocDType} sourceLocG = ${sourceLocDType}(${coords.join()}, 0);\n        ++${coords[rank-2]};\n        ${sourceLocDType} sourceLocA = ${sourceLocDType}(${coords.join()}, 0);\n        --${coords[rank-1]};\n        ${sourceLocDType} sourceLocB = ${sourceLocDType}(${coords.join()}, 0);\n        --${coords[rank-2]};`}else sourceRank=rank,sourceLocSetup=`\n        ${dtype} sourceLocR = coords;\n        ++${coords[rank-1]};\n        ${dtype} sourceLocG = coords;\n        ++${coords[rank-2]};\n        ${dtype} sourceLocA = coords;\n        --${coords[rank-1]};\n        ${dtype} sourceLocB = coords;\n        --${coords[rank-2]};`;const channels=["x","y","z","w","u","v"].slice(0,sourceRank),inChannel="."+channels[sourceRank-1],intChannels=channels.map(x=>"int "+x),srcRCoords=getChannels("sourceLocR",sourceRank-1).concat("inIdx.r"),srcGCoords=getChannels("sourceLocG",sourceRank-1).concat("inIdx.g"),srcBCoords=getChannels("sourceLocB",sourceRank-1).concat("inIdx.b"),srcACoords=getChannels("sourceLocA",sourceRank-1).concat("inIdx.a"),compOp="max"===op?"greaterThan":"lessThan",fetchCandidateIdx=firstPass?"":`\n          inIdx = round(vec4(getBestIndicesAChannel(${srcRCoords.join()}),\n                             getBestIndicesAChannel(${srcGCoords.join()}),\n                             getBestIndicesAChannel(${srcBCoords.join()}),\n                             getBestIndicesAChannel(${srcACoords.join()})));`,fetchValue=`vec4(\n            getAChannel(${srcRCoords.join()}),\n            hasNextCol ? getAChannel(${srcGCoords.join()}) : 0.,\n            hasNextRow ? getAChannel(${srcBCoords.join()}) : 0.,\n            hasNextRow && hasNextCol ? getAChannel(${srcACoords.join()}) : 0.)`,getBestIndicesAChannelSnippet=firstPass?"":`\n      float getBestIndicesAChannel(${intChannels.join()}) {\n        return getChannel(getBestIndicesA(${channels.join()}),\n                                          vec2(${channels.slice(-2).join()}));\n      }`;this.userCode=`\n      float getAChannel(${intChannels.join()}) {\n        return getChannel(getA(${channels.join()}),\n                               vec2(${channels.slice(-2).join()}));\n      }\n      ${getBestIndicesAChannelSnippet}\n      void main() {\n        ${dtype} coords = getOutputCoords();\n        bool hasNextCol = ${coords[rank-1]} < ${outShape[rank-1]-1};\n        bool hasNextRow = ${coords[rank-2]} < ${outShape[rank-2]-1};\n        ${sourceLocSetup}\n        ivec4 srcIdx = ivec4(sourceLocR${inChannel}, sourceLocG${inChannel},\n          sourceLocB${inChannel}, sourceLocA${inChannel}) * ${windowSize};\n        ivec4 inIdx = srcIdx;\n        vec4 bestIndex = vec4(inIdx);\n        vec4 bestValue = ${fetchValue};\n\n        for (int i = 0; i < ${windowSize}; i++) {\n          inIdx = srcIdx;\n          ${fetchCandidateIdx}\n          vec4 candidate = ${fetchValue};\n          bvec4 nan = isnan(candidate);\n          bvec4 replace = bvec4(\n            vec4(${compOp}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\n\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\n                           replace.y  ? candidate.y : bestValue.y,\n                           replace.z  ? candidate.z : bestValue.z,\n                           replace.w  ? candidate.w : bestValue.w);\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\n          srcIdx++;\n        }\n        setOutput(bestIndex);\n      }\n    `}}function argReduce(backend,x,reduceType,bestIndicesA=null){let batchSize=x.shape[0],inSize=x.shape[1];null!=bestIndicesA&&(batchSize=bestIndicesA.shape[0],inSize=bestIndicesA.shape[1]);const windowSize=dist.C0T.computeOptimalWindowSize(inSize),reduceInfo={windowSize,inSize,batchSize,outSize:Math.ceil(inSize/windowSize)},program=new ArgMinMaxProgram(reduceInfo,reduceType,null==bestIndicesA),inputs=[x];null!=bestIndicesA&&inputs.push(bestIndicesA);const output=backend.runWebGLProgram(program,inputs,"int32");if(1===output.shape[1])return output;const result=argReduce(backend,x,reduceType,output);return backend.disposeIntermediateTensorInfo(output),result}function argReducePacked(backend,x,reduceType,bestIndicesA=null){const inShape=null!=bestIndicesA?bestIndicesA.shape:x.shape,inSize=inShape[inShape.length-1],windowSize=dist.C0T.computeOptimalWindowSize(inSize),program=new ArgMinMaxPackedProgram(inShape,windowSize,reduceType,null==bestIndicesA),inputs=null==bestIndicesA?[x]:[x,bestIndicesA],output=backend.runWebGLProgram(program,inputs,"int32");if(output.shape.length===x.shape.length){const result=argReducePacked(backend,x,reduceType,output);return backend.disposeIntermediateTensorInfo(output),result}return output}function argMinMaxReduce(backend,x,axis,reduceType){const axes=[axis];if(dist.C0T.assertAxesAreInnerMostDims("arg"+reduceType.charAt(0).toUpperCase()+reduceType.slice(1),axes,x.shape.length),!(0,dist._K2)().getBool("WEBGL_PACK_REDUCE")||x.shape.length<=2){const intermediateTensorInfos=[],xtexData=backend.texData.get(x.dataId);let xUnPacked=x;null!==xtexData&&xtexData.isPacked&&(xUnPacked=backend.unpackTensor(x),intermediateTensorInfos.push(xUnPacked));const[outShape,reduceShape]=dist.C0T.computeOutAndReduceShapes(xUnPacked.shape,axes),inSize=dist.ZSL.sizeFromShape(reduceShape),a2D=kernels_Reshape_reshape({inputs:{x:xUnPacked},backend,attrs:{shape:[-1,inSize]}});intermediateTensorInfos.push(a2D);const reduced=argReduce(backend,a2D,reduceType);intermediateTensorInfos.push(reduced);const reshaped=kernels_Reshape_reshape({inputs:{x:reduced},backend,attrs:{shape:outShape}});return intermediateTensorInfos.forEach(t=>backend.disposeIntermediateTensorInfo(t)),reshaped}return argReducePacked(backend,x,reduceType)}const ArgMax_argMaxConfig={kernelName:dist.Jp_,backendName:"webgl",kernelFunc:function ArgMax_argMax(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis}=attrs;let axes=dist.ZSL.parseAxisParam(axis,x.shape);const permutedAxes=dist.C0T.getAxesPermutation(axes,x.shape.length);let $x=x;const intermediateTensorInfos=[];null!=permutedAxes&&($x=kernels_Transpose_transpose({inputs:{x},backend,attrs:{perm:permutedAxes}}),intermediateTensorInfos.push($x),axes=dist.C0T.getInnerMostAxes(axes.length,$x.shape.length)),dist.C0T.assertAxesAreInnerMostDims("argMax",[axes[0]],$x.shape.length);const out=argMinMaxReduce(backend,$x,axes[0],"max");return intermediateTensorInfos.forEach(t=>backend.disposeIntermediateTensorInfo(t)),out}};const ArgMin_argMinConfig={kernelName:dist.p_m,backendName:"webgl",kernelFunc:function ArgMin_argMin(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis}=attrs;let axes=dist.ZSL.parseAxisParam(axis,x.shape);const permutedAxes=dist.C0T.getAxesPermutation(axes,x.shape.length);let $x=x;const intermediateTensorInfos=[];null!=permutedAxes&&($x=kernels_Transpose_transpose({inputs:{x},backend,attrs:{perm:permutedAxes}}),intermediateTensorInfos.push($x),axes=dist.C0T.getInnerMostAxes(axes.length,$x.shape.length)),dist.C0T.assertAxesAreInnerMostDims("argMin",[axes[0]],$x.shape.length);const out=argMinMaxReduce(backend,$x,axes[0],"min");return intermediateTensorInfos.forEach(t=>backend.disposeIntermediateTensorInfo(t)),out}},kernels_Asin_asin=kernel_funcs_utils_unaryKernelFunc({opSnippet:CHECK_NAN_SNIPPET+"\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return asin(x);\n"}),Asin_asinConfig={kernelName:dist.QKF,backendName:"webgl",kernelFunc:kernels_Asin_asin},kernels_Asinh_asinh=kernel_funcs_utils_unaryKernelFunc({opSnippet:CHECK_NAN_SNIPPET+"return log(x + sqrt(x * x + 1.0));"}),Asinh_asinhConfig={kernelName:dist.epO,backendName:"webgl",kernelFunc:kernels_Asinh_asinh},kernels_Atan_atan=kernel_funcs_utils_unaryKernelFunc({opSnippet:CHECK_NAN_SNIPPET+"\n  return atan(x);\n"}),Atan_atanConfig={kernelName:dist.TyE,backendName:"webgl",kernelFunc:kernels_Atan_atan},kernels_Atan2_atan2=kernel_funcs_utils_binaryKernelFunc({opSnippet:"\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n\n  return atan(a, b);\n",packedOpSnippet:"\n  vec4 result = atan(a, b);\n  bvec4 isNaNA = isnan(a);\n  bvec4 isNaNB = isnan(b);\n  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);\n  "+CHECK_NAN_SNIPPET_PACKED+"\n  return result;\n"}),Atan2_atan2Config={kernelName:dist.lxb,backendName:"webgl",kernelFunc:kernels_Atan2_atan2},kernels_Atanh_atanh=kernel_funcs_utils_unaryKernelFunc({opSnippet:CHECK_NAN_SNIPPET+"\n  if ((x < -1.0) || (x > 1.0)) return NAN;\nreturn (log(1.0 + x) - log(1.0 - x)) / 2.0;"}),Atanh_atanhConfig={kernelName:dist.zP9,backendName:"webgl",kernelFunc:kernels_Atanh_atanh};class Pool2DProgram{constructor(convInfo,poolType,computePositions,flattenPositions=!1,includeBatchInIndex=!1){if(this.variableNames=["x"],"avg"===poolType&&computePositions)throw new Error("Cannot compute positions for average pool.");const filterWidth=convInfo.filterWidth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padTop=convInfo.padInfo.top,padLeft=convInfo.padInfo.left;this.outputShape=convInfo.outShape;const isAvgPool="avg"===poolType,batchFlattenPositionStr=`((batch  * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + d`,flattenPositionStr=`(xR * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + d`;let initializationValue="0.0";if(isAvgPool||(initializationValue="-1.0 / 1e-20"),computePositions){const compareOp=">=";return void(this.userCode=`\n        const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});\n        const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int batch = coords[0];\n          int d = coords[3];\n\n          ivec2 xRCCorner = coords.yz * strides - pads;\n          int xRCorner = xRCCorner.x;\n          int xCCorner = xRCCorner.y;\n\n          // max/min x(?, ?, d) to get y(yR, yC, d).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n          float avgValue = 0.0;\n\n          for (int wR = 0; wR < ${effectiveFilterHeight};\n              wR += ${dilationHeight}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${convInfo.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${effectiveFilterWidth};\n                wC += ${dilationWidth}) {\n              int xC = xCCorner + wC;\n\n              if (xC < 0 || xC >= ${convInfo.inWidth}) {\n                continue;\n              }\n\n              float value = getX(batch, xR, xC, d);\n\n              // If a min / max value has already been found, use it. If not,\n              // use the current value.\n              float currMinMaxValue = mix(\n                  value, minMaxValue, minMaxValueFound);\n              if (value ${compareOp} currMinMaxValue) {\n                minMaxValue = value;\n                minMaxValueFound = 1.0;\n                minMaxPosition = ${flattenPositions?includeBatchInIndex?batchFlattenPositionStr:flattenPositionStr:`wR * ${effectiveFilterWidth} + wC`};\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `)}let returnValue=`${poolType}(${poolType}(${poolType}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"avg"===poolType&&(returnValue="avgValue / max(count, 1.0)");const filterWidthNearestVec4=4*Math.floor(filterWidth/4),filterWidthVec4Remainder=filterWidth%4,updateSnippet=`\n      if (${isAvgPool}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n      const float initializationValue = ${initializationValue};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xR, int xC, int d) {\n        if (xC < 0 || xC >= ${convInfo.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xR, xC, d);\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d = coords[3];\n\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // max/min x(?, ?, d) to get y(yR, yC, d).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${initializationValue});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wR = 0; wR < ${effectiveFilterHeight};\n            wR += ${dilationHeight}) {\n          int xR = xRCorner + wR;\n\n          if (xR < 0 || xR >= ${convInfo.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${filterWidthNearestVec4}; wC += 4) {\n            int xC = xCCorner + wC * ${dilationWidth};\n\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${dilationWidth}, d),\n              getValue(batch, xR, xC + 2 * ${dilationWidth}, d),\n              getValue(batch, xR, xC + 3 * ${dilationWidth}, d)\n            );\n\n            ${updateSnippet}\n          }\n\n          int xC = xCCorner + ${filterWidthNearestVec4};\n          if (${1===filterWidthVec4Remainder}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              initializationValue,\n              initializationValue,\n              initializationValue\n            );\n\n            ${updateSnippet}\n          } else if (${2===filterWidthVec4Remainder}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${dilationWidth}, d),\n              initializationValue,\n              initializationValue\n            );\n\n            ${updateSnippet}\n          } else if (${3===filterWidthVec4Remainder}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${dilationWidth}, d),\n              getValue(batch, xR, xC + 2 * ${dilationWidth}, d),\n              initializationValue\n            );\n\n            ${updateSnippet}\n          }\n        }\n        setOutput(${returnValue});\n      }\n    `}}class Pool3DProgram{constructor(convInfo,poolType,computePositions,flattenPositions=!1,includeBatchInIndex=!1){if(this.variableNames=["x"],"avg"===poolType&&computePositions)throw new Error("Cannot compute positions for average pool.");const filterWidth=convInfo.filterWidth,strideDepth=convInfo.strideDepth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationDepth=convInfo.dilationDepth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,effectiveFilterDepth=convInfo.effectiveFilterDepth,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padFront=convInfo.padInfo.front,padTop=convInfo.padInfo.top,padLeft=convInfo.padInfo.left;this.outputShape=convInfo.outShape;const isAvgPool="avg"===poolType;let initializationValue="0.0";if(isAvgPool||(initializationValue="-1.0 / 1e-20"),computePositions){const compareOp=">=";return void(this.userCode=`\n        const ivec3 strides =\n            ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});\n        const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});\n\n        void main() {\n          ivec5 coords = getOutputCoords();\n          int batch = coords.x;\n          int ch = coords.u;\n\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n          int xDCorner = xCorner.x;\n          int xRCorner = xCorner.y;\n          int xCCorner = xCorner.z;\n\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n\n          for (int wD = 0; wD < ${effectiveFilterDepth};\n              wD += ${dilationDepth}) {\n            int xD = xDCorner + wD;\n\n            if (xD < 0 || xD >= ${convInfo.inDepth}) {\n              continue;\n            }\n\n            for (int wR = 0; wR < ${effectiveFilterHeight};\n                wR += ${dilationHeight}) {\n              int xR = xRCorner + wR;\n\n              if (xR < 0 || xR >= ${convInfo.inHeight}) {\n                continue;\n              }\n\n              for (int wC = 0; wC < ${effectiveFilterWidth};\n                  wC += ${dilationWidth}) {\n                int xC = xCCorner + wC;\n\n                if (xC < 0 || xC >= ${convInfo.inWidth}) {\n                  continue;\n                }\n\n                float value = getX(batch, xD, xR, xC, ch);\n\n                // If a min / max value has already been found, use it. If not,\n                // use the current value.\n                float currMinMaxValue = mix(\n                    value, minMaxValue, minMaxValueFound);\n                if (value ${compareOp} currMinMaxValue) {\n                  minMaxValue = value;\n                  minMaxValueFound = 1.0;\n                  minMaxPosition = ${flattenPositions?includeBatchInIndex?`(((batch * ${convInfo.inDepth} + xD) * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + ch`:`((xD * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + ch`:`wD * ${effectiveFilterHeight} * ${effectiveFilterWidth} +\n                      wR * ${effectiveFilterWidth} + wC`};\n                }\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `)}let returnValue=`${poolType}(${poolType}(${poolType}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"avg"===poolType&&(returnValue="avgValue / max(count, 1.0)");const filterWidthNearestVec4=4*Math.floor(filterWidth/4),filterWidthVec4Remainder=filterWidth%4,updateSnippet=`\n      if (${isAvgPool}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec3 strides =\n        ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});\n      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});\n      const float initializationValue = ${initializationValue};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\n        if (xC < 0 || xC >= ${convInfo.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xD, xR, xC, ch);\n      }\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xDCorner = xCorner.x;\n        int xRCorner = xCorner.y;\n        int xCCorner = xCorner.z;\n\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${initializationValue});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wD = 0; wD < ${effectiveFilterDepth};\n            wD += ${dilationDepth}) {\n          int xD = xDCorner + wD;\n\n          if (xD < 0 || xD >= ${convInfo.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${effectiveFilterHeight};\n            wR += ${dilationHeight}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${convInfo.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${filterWidthNearestVec4}; wC += 4) {\n              int xC = xCCorner + wC * ${dilationWidth};\n\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${dilationWidth}, ch),\n                getValue(batch, xD, xR, xC + 3 * ${dilationWidth}, ch)\n              );\n\n              ${updateSnippet}\n            }\n\n            int xC = xCCorner + ${filterWidthNearestVec4};\n            if (${1===filterWidthVec4Remainder}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                initializationValue,\n                initializationValue,\n                initializationValue\n              );\n\n              ${updateSnippet}\n            } else if (${2===filterWidthVec4Remainder}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),\n                initializationValue,\n                initializationValue\n              );\n\n              ${updateSnippet}\n            } else if (${3===filterWidthVec4Remainder}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${dilationWidth}, ch),\n                initializationValue\n              );\n\n              ${updateSnippet}\n            }\n          }\n        }\n        setOutput(${returnValue});\n      }\n    `}}const AvgPool_avgPoolConfig={kernelName:dist.ho8,backendName:"webgl",kernelFunc:function AvgPool_avgPool(args){const{inputs,backend,attrs}=args,{x}=inputs;assertNotComplex(x,"avgPool");const{filterSize,strides,pad,dimRoundingMode}=attrs;dist.ZSL.assert(dist.C0T.eitherStridesOrDilationsAreOne(strides,1),()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '1'`);const convInfo=dist.C0T.computePool2DInfo(x.shape,filterSize,strides,1,pad,dimRoundingMode);if(1===convInfo.filterWidth&&1===convInfo.filterHeight&&dist.ZSL.arraysEqual(convInfo.inShape,convInfo.outShape))return kernels_Identity_identity({inputs:{x},backend});const avgPoolProgram=new Pool2DProgram(convInfo,"avg",!1);return backend.runWebGLProgram(avgPoolProgram,[x],"float32")}};const AvgPool3D_avgPool3DConfig={kernelName:dist.cS,backendName:"webgl",kernelFunc:function AvgPool3D_avgPool3D(args){const{inputs,backend,attrs}=args,{x}=inputs,{filterSize,strides,pad,dimRoundingMode,dataFormat}=attrs,convInfo=dist.C0T.computePool3DInfo(x.shape,filterSize,strides,[1,1,1],pad,dimRoundingMode,dataFormat),avgPoolProgram=new Pool3DProgram(convInfo,"avg",!1);return backend.runWebGLProgram(avgPoolProgram,[x],"float32")}};class AvgPool2DBackpropProgram{constructor(convInfo){this.variableNames=["dy"],this.outputShape=convInfo.inShape;const filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padTop=effectiveFilterHeight-1-convInfo.padInfo.top,padLeft=effectiveFilterWidth-1-convInfo.padInfo.left,avgMultiplier=1/(filterHeight*filterWidth);this.userCode=`\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n      const float avgMultiplier = float(${avgMultiplier});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${effectiveFilterHeight};\n            wR += ${dilationHeight}) {\n          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${effectiveFilterWidth};\n            wC+= ${dilationWidth}) {\n            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n\n            dotProd += dyValue * avgMultiplier;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class AvgPool3DBackpropProgram{constructor(convInfo){this.variableNames=["dy"],this.outputShape=convInfo.inShape;const filterDepth=convInfo.filterDepth,filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,strideDepth=convInfo.strideDepth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationDepth=convInfo.dilationDepth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,effectiveFilterDepth=convInfo.effectiveFilterDepth,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padFront=effectiveFilterDepth-1-convInfo.padInfo.front,padTop=effectiveFilterHeight-1-convInfo.padInfo.top,padLeft=effectiveFilterWidth-1-convInfo.padInfo.left,avgMultiplier=1/(filterDepth*filterHeight*filterWidth);this.userCode=`\n      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});\n      const float avgMultiplier = float(${avgMultiplier});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${effectiveFilterDepth};\n            wD += ${dilationDepth}) {\n          float dyD = float(dyDCorner + wD) / ${strideDepth}.0;\n\n          if (dyD < 0.0 || dyD >= ${convInfo.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${effectiveFilterHeight};\n              wR += ${dilationHeight}) {\n            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${effectiveFilterWidth};\n                wC += ${dilationWidth}) {\n              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n\n              dotProd += dyValue * avgMultiplier;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}const kernels_AvgPool3DGrad_avgPool3DGradConfig={kernelName:dist.wwC,backendName:"webgl",kernelFunc:function AvgPool3DGrad_avgPool3DGrad(args){const{inputs,backend,attrs}=args,{dy,input}=inputs,x=input,{filterSize,strides,pad,dimRoundingMode}=attrs,convInfo=dist.C0T.computePool3DInfo(x.shape,filterSize,strides,[1,1,1],pad,dimRoundingMode),avgPoolBackpropProgram=new AvgPool3DBackpropProgram(convInfo);return backend.runWebGLProgram(avgPoolBackpropProgram,[dy],x.dtype)}};const kernels_AvgPoolGrad_avgPoolGradConfig={kernelName:dist.VCH,backendName:"webgl",kernelFunc:function kernels_AvgPoolGrad_avgPoolGrad(args){const{inputs,backend,attrs}=args,{dy,input}=inputs,x=input;assertNotComplex([dy,input],"avgPoolGrad");const{filterSize,strides,pad}=attrs,convInfo=dist.C0T.computePool2DInfo(x.shape,filterSize,strides,1,pad),avgPoolBackpropProgram=new AvgPool2DBackpropProgram(convInfo);return backend.runWebGLProgram(avgPoolBackpropProgram,[dy],x.dtype)}};const BatchMatMul_batchMatMulConfig={kernelName:dist.jAQ,backendName:"webgl",kernelFunc:function BatchMatMul_batchMatMul(args){const{inputs,backend,attrs}=args,{a,b}=inputs,{transposeA,transposeB}=attrs;return batchMatMulImpl({a,b,transposeA,transposeB,backend})}};class BatchNormProgram{constructor(xShape,meanShape,varianceShape,offsetShape,scaleShape,varianceEpsilon){this.outputShape=[],this.variableNames=["x","mean","variance"],dist.C0T.assertAndGetBroadcastShape(xShape,meanShape),dist.C0T.assertAndGetBroadcastShape(xShape,varianceShape);let offsetSnippet="0.0";null!=offsetShape&&(dist.C0T.assertAndGetBroadcastShape(xShape,offsetShape),this.variableNames.push("offset"),offsetSnippet="getOffsetAtOutCoords()");let scaleSnippet="1.0";null!=scaleShape&&(dist.C0T.assertAndGetBroadcastShape(xShape,scaleShape),this.variableNames.push("scale"),scaleSnippet="getScaleAtOutCoords()"),this.outputShape=xShape,this.userCode=`\n      void main() {\n        float x = getXAtOutCoords();\n        float mean = getMeanAtOutCoords();\n        float variance = getVarianceAtOutCoords();\n        float offset = ${offsetSnippet};\n        float scale = ${scaleSnippet};\n        float inv = scale * inversesqrt(variance + float(${varianceEpsilon}));\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\n      }\n    `}}class BatchNormPackedProgram{constructor(xShape,meanShape,varianceShape,offsetShape,scaleShape,varianceEpsilon){this.packedInputs=!0,this.packedOutput=!0,this.variableNames=["x","mean","variance"],dist.C0T.assertAndGetBroadcastShape(xShape,meanShape),dist.C0T.assertAndGetBroadcastShape(xShape,varianceShape);let offsetSnippet="vec4(0.0)";null!=offsetShape&&(dist.C0T.assertAndGetBroadcastShape(xShape,offsetShape),this.variableNames.push("offset"),offsetSnippet="getOffsetAtOutCoords()");let scaleSnippet="vec4(1.0)";null!=scaleShape&&(dist.C0T.assertAndGetBroadcastShape(xShape,scaleShape),this.variableNames.push("scale"),scaleSnippet="getScaleAtOutCoords()"),this.outputShape=xShape,this.userCode=`\n      void main() {\n        vec4 offset = ${offsetSnippet};\n        vec4 scale = ${scaleSnippet};\n\n        vec4 x = getXAtOutCoords();\n        vec4 mean = getMeanAtOutCoords();\n        vec4 variance = getVarianceAtOutCoords();\n\n        vec4 inv = scale * inversesqrt(variance + vec4(${varianceEpsilon}));\n\n        setOutput((x - mean) * inv + offset);\n      }\n    `}}const BatchNorm_batchNormConfig={kernelName:dist.i5R,backendName:"webgl",kernelFunc:({inputs,backend,attrs})=>{const{x,mean,variance,offset,scale}=inputs;dist.ZSL.assert(mean.shape.length===variance.shape.length,()=>"Batch normalization gradient requires mean and variance to have equal ranks."),dist.ZSL.assert(null==offset||mean.shape.length===offset.shape.length,()=>"Batch normalization gradient requires mean and offset to have equal ranks."),dist.ZSL.assert(null==scale||mean.shape.length===scale.shape.length,()=>"Batch normalization gradient requires mean and scale to have equal ranks.");let{varianceEpsilon}=attrs;null==varianceEpsilon&&(varianceEpsilon=.001);const finalInputs=[x,mean,variance];let offsetShape=null;null!=offset&&(offsetShape=offset.shape,finalInputs.push(offset));let scaleShape=null;null!=scale&&(scaleShape=scale.shape,finalInputs.push(scale));const program=(0,dist._K2)().getBool("WEBGL_PACK_NORMALIZATION")?new BatchNormPackedProgram(x.shape,mean.shape,variance.shape,offsetShape,scaleShape,varianceEpsilon):new BatchNormProgram(x.shape,mean.shape,variance.shape,offsetShape,scaleShape,varianceEpsilon);return backend.runWebGLProgram(program,finalInputs,finalInputs[0].dtype)}};class SliceProgram{constructor(destSize){this.variableNames=["source"],this.outputShape=destSize,this.rank=destSize.length;const dtype=getCoordsDataType(this.rank);this.customUniforms=[{name:"start",arrayIndex:this.rank,type:"int"}];const sourceCoords=function getCoords(rank){if(1===rank)return"sourceLoc";if(rank<=6)return coords.slice(0,rank).map(x=>"sourceLoc."+x).join(",");throw Error(`Slicing for rank ${rank} is not yet supported`)}(this.rank);let body;body=`\n        ${dtype} sourceLoc;\n        ${dtype} coords = getOutputCoords();\n        ${destSize.map((_,i)=>`sourceLoc.${coords[i]} = start[${i}] + coords.${coords[i]};`).join("\n")}\n      `,this.userCode=`\n      void main() {\n        ${body}\n        setOutput(getSource(${sourceCoords}));\n      }\n    `}}const coords=["x","y","z","w","u","v"];class SlicePackedProgram{constructor(destSize){this.variableNames=["source"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=destSize,this.rank=destSize.length,this.customUniforms=[{name:"start",arrayIndex:this.rank,type:"int"}];const dtype=getCoordsDataType(this.rank),coords=getChannels("coords",this.rank),sourceLoc=getChannels("sourceLoc",this.rank),innerDims=1===this.rank?"sourceLoc":`vec2(${sourceLoc.slice(-2).join()})`,getChannel=`getChannel(getSource(${sourceLoc.join()}), ${innerDims})`,upperRow=`\n      result.x = ${getChannel};\n      if (++${coords[this.rank-1]} < ${destSize[this.rank-1]}) {\n        ++${sourceLoc[this.rank-1]};\n        result.y = ${getChannel};\n        --${sourceLoc[this.rank-1]};\n      }\n    `,lowerRow=1===this.rank?"":`\n      --${coords[this.rank-1]};\n      if (++${coords[this.rank-2]} < ${destSize[this.rank-2]}) {\n        ++${sourceLoc[this.rank-2]};\n        result.z = ${getChannel};\n        if (++${coords[this.rank-1]} < ${destSize[this.rank-1]}) {\n          ++${sourceLoc[this.rank-1]};\n          result.w = ${getChannel};\n        }\n      }\n    `,sourceLocSetup=this.rank<=4?`sourceLoc = coords +\n            ${dtype}(${destSize.map((_,i)=>`start[${i}]`).join()});`:destSize.map((_,i)=>`${sourceLoc[i]} = ${coords[i]} + start[${i}];`).join("\n");this.userCode=`\n      void main() {\n        ${dtype} coords = getOutputCoords();\n        ${dtype} sourceLoc;\n        ${sourceLocSetup}\n        vec4 result = vec4(0.);\n        ${upperRow}\n        ${lowerRow}\n        setOutput(result);\n      }\n    `}}function Slice_slice(args){const{inputs,backend,attrs}=args,{x}=inputs,{begin,size}=attrs,[$begin,$size]=dist.Kro.parseSliceParams(x,begin,size);if(dist.Kro.assertParamsValid(x,$begin,$size),0===dist.ZSL.sizeFromShape($size))return backend.makeTensorInfo($size,x.dtype,[]);if(backend.shouldExecuteOnCPU([x])||"string"===x.dtype){const xTexData=backend.texData.get(x.dataId),outValues=sliceImplCPU(xTexData.values,$begin,$size,x.shape,x.dtype);return backend.makeTensorInfo($size,x.dtype,outValues)}const{isPacked}=backend.texData.get(x.dataId),isContinous=dist.Kro.isSliceContinous(x.shape,$begin,$size);if(isPacked||!isContinous){const program=(0,dist._K2)().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new SlicePackedProgram($size):new SliceProgram($size),customValues=[$begin];return backend.runWebGLProgram(program,[x],x.dtype,customValues)}return backend.uploadToGPU(x.dataId),function shallowSlice(x,begin,size,backend){const xTexData=backend.texData.get(x.dataId),t=backend.makeTensorInfo(size,x.dtype),newTexData=backend.texData.get(t.dataId);Object.assign(newTexData,xTexData),newTexData.refCount=1,newTexData.shape=size,newTexData.dtype=x.dtype;let flatOffset=dist.Kro.computeFlatOffset(begin,dist.ZSL.computeStrides(x.shape));xTexData.slice&&(flatOffset+=xTexData.slice.flatOffset),newTexData.slice={flatOffset,origDataId:xTexData.slice&&xTexData.slice.origDataId||x.dataId};const refCount=backend.dataRefCount.get(newTexData.slice.origDataId)||1;return backend.dataRefCount.set(newTexData.slice.origDataId,refCount+1),t}(x,$begin,$size,backend)}const sliceConfig={kernelName:dist.JiE,backendName:"webgl",kernelFunc:Slice_slice},BatchToSpaceND_batchToSpaceNDConfig={kernelName:dist.Ik2,backendName:"webgl",kernelFunc:args=>{const{inputs,backend,attrs}=args,{x}=inputs,{blockShape,crops}=attrs;dist.ZSL.assert(x.shape.length<=4,()=>"batchToSpaceND for rank > 4 with a WebGL backend not implemented yet");const prod=blockShape.reduce((a,b)=>a*b),reshaped=dist.C0T.getReshaped(x.shape,blockShape,prod),permuted=dist.C0T.getPermuted(reshaped.length,blockShape.length),reshapedPermuted=dist.C0T.getReshapedPermuted(x.shape,blockShape,prod),sliceBeginCoords=dist.C0T.getSliceBeginCoords(crops,blockShape.length),sliceSize=dist.C0T.getSliceSize(reshapedPermuted,crops,blockShape.length),toDispose=[],reshapedIntermediate=kernels_Reshape_reshape({inputs:{x},backend,attrs:{shape:reshaped}}),transposedIntermediate=kernels_Transpose_transpose({inputs:{x:reshapedIntermediate},backend,attrs:{perm:permuted}}),reshapedIntermediate2=kernels_Reshape_reshape({inputs:{x:transposedIntermediate},backend,attrs:{shape:reshapedPermuted}}),sliced=Slice_slice({inputs:{x:reshapedIntermediate2},backend,attrs:{begin:sliceBeginCoords,size:sliceSize}});return toDispose.push(reshapedIntermediate),toDispose.push(transposedIntermediate),toDispose.push(reshapedIntermediate2),toDispose.forEach(t=>backend.disposeIntermediateTensorInfo(t)),sliced}};const Bincount_bincountConfig={kernelName:dist.N4F,backendName:"webgl",kernelFunc:function Bincount_bincount(args){const{inputs,backend,attrs}=args,{x,weights}=inputs,{size}=attrs,xVals=backend.readSync(x.dataId),weightsVals=backend.readSync(weights.dataId),outVals=bincountImplCPU(xVals,weightsVals,weights.dtype,weights.shape,size);return backend.makeTensorInfo([size],weights.dtype,outVals)}};const BitwiseAnd_bitwiseAndConfig={kernelName:dist.HNs,backendName:"webgl",kernelFunc:function BitwiseAnd_bitwiseAnd(args){const{inputs,backend}=args,{a,b}=inputs,shouldUsePackedProgram=(0,dist._K2)().getBool("WEBGL_PACK_BINARY_OPERATIONS"),versionNumber=(0,dist._K2)().getNumber("WEBGL_VERSION");if(backend.shouldExecuteOnCPU([a,b])||1===versionNumber){const aVals=backend.texData.get(a.dataId).values,bVals=backend.texData.get(b.dataId).values,[outValues,outShape]=bitwiseAndImplCPU(a.shape,b.shape,aVals,bVals,a.dtype),out=backend.makeTensorInfo(outShape,a.dtype);return backend.texData.get(out.dataId).values=outValues,out}let program;return program=shouldUsePackedProgram?new BinaryOpPackedProgram("\n  int r = int(a.r) & int(b.r);\n  int g = int(a.g) & int(b.g);\n  int rb = int(a.b) & int(b.b);\n  int ra = int(a.a) & int(b.a);\n  return vec4(r, g, rb, ra);\n",a.shape,b.shape,!1):new BinaryOpProgram("\n  return float(int(a.r) & int(b.r));\n",a.shape,b.shape),backend.runWebGLProgram(program,[a,b],a.dtype)}};const BroadcastArgs_broadcastArgsConfig={kernelName:dist.vj7,backendName:"webgl",kernelFunc:function BroadcastArgs_broadcastArgs(args){const{inputs,backend}=args,{s0,s1}=inputs,s0Vals=backend.readSync(s0.dataId),s1Vals=backend.readSync(s1.dataId),broadcastShape=dist.C0T.assertAndGetBroadcastShape(Array.from(s0Vals),Array.from(s1Vals));return backend.makeTensorInfo([broadcastShape.length],"int32",Int32Array.from(broadcastShape))}},NotEqual_notEqual=kernel_funcs_utils_binaryKernelFunc({opSnippet:"return float(a != b);",cpuKernelImpl:notEqualImplCPU,dtype:"bool"}),NotEqual_notEqualConfig={kernelName:dist.ylV,backendName:"webgl",kernelFunc:NotEqual_notEqual};function Real_real(args){const{inputs,backend}=args,{input}=inputs;return kernels_Identity_identity({inputs:{x:backend.texData.get(input.dataId).complexTensorInfos.real},backend})}const Real_realConfig={kernelName:dist.LRy,backendName:"webgl",kernelFunc:Real_real};const Cast_castConfig={kernelName:dist.KXH,backendName:"webgl",kernelFunc:function kernels_Cast_cast(args){const{inputs,backend,attrs}=args,{x}=inputs,{dtype}=attrs;if("complex64"===dtype){if("complex64"===x.dtype)return kernels_Identity_identity({inputs:{x},backend});const zerosTensor=dist.Ul9(x.shape),floatX=kernels_Cast_cast({inputs:{x},backend,attrs:{dtype:"float32"}}),result=Complex_complex({inputs:{real:floatX,imag:zerosTensor},backend});return zerosTensor.dispose(),backend.disposeIntermediateTensorInfo(floatX),result}if("complex64"===x.dtype){const realPart=Real_real({inputs:{input:x},backend}),result=kernels_Cast_cast({inputs:{x:realPart},backend,attrs:{dtype}});return backend.disposeIntermediateTensorInfo(realPart),result}if(!dist.ZSL.hasEncodingLoss(x.dtype,dtype)){const result=kernels_Identity_identity({inputs:{x},backend});return{dataId:result.dataId,shape:result.shape,dtype}}if(backend.shouldExecuteOnCPU([x])){const values=backend.texData.get(x.dataId).values,[resultShape,resultType,resultData]=castImplCPU(values,x.shape,x.dtype,dtype);return backend.makeTensorInfo(resultShape,resultType,resultData)}if("int32"===dtype)return function int_int(input,backend){const program=new UnaryOpProgram(input.shape,"return float(int(x));"),output=backend.runWebGLProgram(program,[input],"int32");return{dataId:output.dataId,shape:output.shape,dtype:output.dtype}}(x,backend);if("bool"===dtype){const zerosTensorInfo=backend.makeTensorInfo([],"bool",dist.ZSL.getTypedArrayFromDType("bool",1)),result=NotEqual_notEqual({inputs:{a:x,b:zerosTensorInfo},backend});return backend.disposeIntermediateTensorInfo(zerosTensorInfo),result}throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`)}},CEIL="return ceil(x);",kernels_Ceil_ceil=kernel_funcs_utils_unaryKernelFunc({opSnippet:CEIL,packedOpSnippet:CEIL,cpuKernelImpl:ceilImplCPU}),Ceil_ceilConfig={kernelName:dist.QDP,backendName:"webgl",kernelFunc:kernels_Ceil_ceil};class ClipProgram{constructor(aShape){this.variableNames=["A"],this.customUniforms=[{name:"minVal",type:"float"},{name:"maxVal",type:"float"}],this.outputShape=aShape,this.userCode="\n\n      void main() {\n        float value = getAAtOutCoords();\n        if (isnan(value)) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, minVal, maxVal));\n      }\n    "}}class ClipPackedProgram{constructor(aShape){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"minVal",type:"float"},{name:"maxVal",type:"float"}],this.outputShape=aShape,this.userCode="\n      void main() {\n        vec4 value = getAAtOutCoords();\n\n        if (any(isnan(value))) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\n      }\n    "}}const ClipByValue_clipByValueConfig={kernelName:dist.vaV,backendName:"webgl",kernelFunc:function ClipByValue_clipByValue(args){const{inputs,backend,attrs}=args,{x}=inputs,{clipValueMin,clipValueMax}=attrs;let program;program=(0,dist._K2)().getBool("WEBGL_PACK_CLIP")?new ClipPackedProgram(x.shape):new ClipProgram(x.shape);const customValues=[[clipValueMin],[clipValueMax]];return backend.runWebGLProgram(program,[x],x.dtype,customValues)}};class ComplexAbsProgram{constructor(shape){this.variableNames=["real","imag"],this.outputShape=shape,this.userCode="\n      void main() {\n        float re = abs(getRealAtOutCoords());\n        float im = abs(getImagAtOutCoords());\n        float mx = max(re, im);\n\n        // sadly the length function in glsl is not underflow-safe\n        // (at least not on Intel GPUs). So the safe solution is\n        // to ensure underflow-safety in all cases.\n        setOutput(\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\n        );\n      }\n    "}}function makeComplexComponentTensorInfo(complexTensor,complexPart){return{dataId:complexPart.dataId,dtype:complexPart.dtype,shape:complexTensor.shape}}const ComplexAbs_complexAbsConfig={kernelName:dist.$zE,backendName:"webgl",kernelFunc:function ComplexAbs_complexAbs(args){const{inputs,backend}=args,{x}=inputs,xData=backend.texData.get(x.dataId),program=new ComplexAbsProgram(x.shape),programInputs=[makeComplexComponentTensorInfo(x,xData.complexTensorInfos.real),makeComplexComponentTensorInfo(x,xData.complexTensorInfos.imag)];return backend.runWebGLProgram(program,programInputs,programInputs[0].dtype)}};class ConcatProgram{constructor(shapes){this.outputShape=[],this.outputShape=dist.C0T.computeOutShape(shapes,1),this.variableNames=shapes.map((_,i)=>`T${i}`);const offsets=new Array(shapes.length-1);offsets[0]=shapes[0][1];for(let i=1;i<offsets.length;i++)offsets[i]=offsets[i-1]+shapes[i][1];const snippets=[`if (yC < ${offsets[0]}) setOutput(getT0(yR, yC));`];for(let i=1;i<offsets.length;i++){const shift=offsets[i-1];snippets.push(`else if (yC < ${offsets[i]}) setOutput(getT${i}(yR, yC-${shift}));`)}const lastIndex=offsets.length,lastShift=offsets[offsets.length-1];snippets.push(`else setOutput(getT${lastIndex}(yR, yC-${lastShift}));`),this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int yR = coords.x;\n        int yC = coords.y;\n\n        ${snippets.join("\n        ")}\n      }\n    `}}class ConcatPackedProgram{constructor(shapes,axis){this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[],this.outputShape=dist.C0T.computeOutShape(shapes,axis);const shape=this.outputShape,rank=shape.length,dtype=getCoordsDataType(rank),coords=getChannels("coords",rank),channels=["x","y","z","w","u","v"].slice(0,rank);this.variableNames=shapes.map((_,i)=>`T${i}`);const offsets=new Array(shapes.length-1);offsets[0]=shapes[0][axis];for(let i=1;i<offsets.length;i++)offsets[i]=offsets[i-1]+shapes[i][axis];const channel=channels[axis],lastChannels=channels.slice(-2),allChannels=channels.join();let getValueSnippet=`if (${channel} < ${offsets[0]}) {\n        return getChannel(\n            getT0(${allChannels}), vec2(${lastChannels.join()}));\n        }`;for(let i=1;i<offsets.length;i++){const shift=offsets[i-1];getValueSnippet+=`\n        if (${channel} < ${offsets[i]}  && ${channel} >= ${offsets[i-1]}) {\n          return getChannel(\n            getT${i}(${shiftedChannels(channels,channel,shift)}),\n            vec2(${shiftedChannels(lastChannels,channel,shift)}));\n        }`}const lastIndex=offsets.length,shift=offsets[offsets.length-1];getValueSnippet+=`\n        return getChannel(\n          getT${lastIndex}(${shiftedChannels(channels,channel,shift)}),\n          vec2(${shiftedChannels(lastChannels,channel,shift)}));`,this.userCode=`\n      float getValue(${channels.map(x=>"int "+x)}) {\n        ${getValueSnippet}\n      }\n\n      void main() {\n        ${dtype} coords = getOutputCoords();\n        vec4 result = vec4(getValue(${coords}), 0., 0., 0.);\n\n        ${coords[rank-1]} = ${coords[rank-1]} + 1;\n        if (${coords[rank-1]} < ${shape[rank-1]}) {\n          result.g = getValue(${coords});\n        }\n\n        ${coords[rank-2]} = ${coords[rank-2]} + 1;\n        if (${coords[rank-2]} < ${shape[rank-2]}) {\n          result.a = getValue(${coords});\n        }\n\n        ${coords[rank-1]} = ${coords[rank-1]} - 1;\n        if (${coords[rank-2]} < ${shape[rank-2]} &&\n            ${coords[rank-1]} < ${shape[rank-1]}) {\n          result.b = getValue(${coords});\n        }\n        setOutput(result);\n      }\n    `}}function shiftedChannels(channels,channel,shift){const channelIdx=channels.indexOf(channel);return channels.map((c,idx)=>idx===channelIdx?`${c} - ${shift}`:c).join()}function Imag_imag(args){const{inputs,backend}=args,{input}=inputs;return kernels_Identity_identity({inputs:{x:backend.texData.get(input.dataId).complexTensorInfos.imag},backend})}const Imag_imagConfig={kernelName:dist.dv8,backendName:"webgl",kernelFunc:Imag_imag};function concatImpl(inputs,axis,backend){const dtype=inputs[0].dtype;if("complex64"===dtype){const reals=inputs.map(t=>Real_real({inputs:{input:t},backend})),imags=inputs.map(t=>Imag_imag({inputs:{input:t},backend})),realConcated=concatImpl(reals,axis,backend),imagConcated=concatImpl(imags,axis,backend),result=Complex_complex({inputs:{real:realConcated,imag:imagConcated},backend});return reals.forEach(r=>backend.disposeIntermediateTensorInfo(r)),imags.forEach(i=>backend.disposeIntermediateTensorInfo(i)),backend.disposeIntermediateTensorInfo(realConcated),backend.disposeIntermediateTensorInfo(imagConcated),result}let runOnCpu=backend.shouldExecuteOnCPU(inputs);if("string"===dtype&&(runOnCpu=!0),runOnCpu){const tensors2D=inputs.map(t=>{const innerSize=dist.ZSL.sizeFromShape(t.shape.slice(axis));return kernels_Reshape_reshape({inputs:{x:t},backend,attrs:{shape:[-1,innerSize]}})}),inputsValShapes=tensors2D.map(t=>({vals:backend.readSync(t.dataId),shape:t.shape})),outShape=dist.C0T.computeOutShape(tensors2D.map(t=>t.shape),1),simplyConcat=1===tensors2D[0].shape[0],outVals=concatImplCPU(inputsValShapes,outShape,dtype,simplyConcat),finalOutShape=dist.C0T.computeOutShape(inputs.map(t=>t.shape),axis),outInfo=backend.makeTensorInfo(finalOutShape,dtype,outVals);return tensors2D.forEach(t=>backend.disposeIntermediateTensorInfo(t)),outInfo}const $inputs=inputs.filter(t=>dist.ZSL.sizeFromShape(t.shape)>0),shouldPack=(0,dist._K2)().getBool("WEBGL_PACK_ARRAY_OPERATIONS")&&$inputs[0].shape.length>1;if(1===$inputs.length){const program=shouldPack?new UnaryOpProgram(inputs[0].shape,CLONE):new UnaryOpPackedProgram(inputs[0].shape,CLONE);return backend.runWebGLProgram(program,inputs,dtype)}const maxTexturesInShader=(0,dist._K2)().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER");if($inputs.length>maxTexturesInShader){const reducedInputs=[];for(let i=0;i<$inputs.length;i+=maxTexturesInShader){const subArray=$inputs.slice(i,i+maxTexturesInShader);reducedInputs.push(concatImpl(subArray,axis,backend))}const result=concatImpl(reducedInputs,axis,backend);for(const i of reducedInputs)backend.disposeIntermediateTensorInfo(i);return result}if(shouldPack){const program=new ConcatPackedProgram($inputs.map(t=>t.shape),axis);return backend.runWebGLProgram(program,$inputs,dtype)}const{tensors2D,outShape}=function computeTensors2D(inputs,axis,backend){const outShape=dist.C0T.computeOutShape(inputs.map(t=>t.shape),axis),tensors2D=inputs.map(x=>kernels_Reshape_reshape({inputs:{x},attrs:{shape:[-1,dist.ZSL.sizeFromShape(x.shape.slice(axis))]},backend}));return{tensors2D,outShape}}($inputs,axis,backend),program=new ConcatProgram(tensors2D.map(t=>t.shape)),result=backend.runWebGLProgram(program,tensors2D,dtype);tensors2D.forEach(r=>backend.disposeIntermediateTensorInfo(r));const reshapedResult=kernels_Reshape_reshape({inputs:{x:result},attrs:{shape:outShape},backend});return backend.disposeIntermediateTensorInfo(result),reshapedResult}function kernels_Concat_concat(args){const{inputs,backend,attrs}=args,{axis}=attrs,$axis=dist.ZSL.parseAxisParam(axis,inputs[0].shape)[0],shapes=inputs.map(t=>t.shape);dist.C0T.assertParamsConsistent(shapes,$axis);const outShape=dist.C0T.computeOutShape(inputs.map(t=>t.shape),$axis);if(0===dist.ZSL.sizeFromShape(outShape))return backend.makeTensorInfo(outShape,inputs[0].dtype,[]);const $inputs=inputs.filter(t=>dist.ZSL.sizeFromShape(t.shape)>0);return 1===$inputs.length?kernels_Identity_identity({inputs:{x:$inputs[0]},backend}):concatImpl($inputs,$axis,backend)}const Concat_concatConfig={kernelName:dist.$dB,backendName:"webgl",kernelFunc:kernels_Concat_concat};class Conv2DProgram{constructor(convInfo,addBias=!1,activation=null,hasPreluActivationWeights=!1,hasLeakyreluAlpha=!1){this.variableNames=["x","W"],this.outputShape=convInfo.outShape;const padTop=convInfo.padInfo.top,padLeft=convInfo.padInfo.left,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,inputDepthNearestVec4=4*Math.floor(convInfo.inChannels/4),inputDepthVec4Remainder=convInfo.inChannels%4,isChannelsLast="channelsLast"===convInfo.dataFormat,rowDim=isChannelsLast?1:2,colDim=isChannelsLast?2:3,channelDim=isChannelsLast?3:1;let activationSnippet="",applyActivationSnippet="";activation&&(activationSnippet=hasPreluActivationWeights?`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${activation}\n        }`:hasLeakyreluAlpha?`float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ${activation}\n        }`:`\n          float activation(float x) {\n            ${activation}\n          }\n        `,applyActivationSnippet="result = activation(result);");const addBiasSnippet=addBias?"result += getBiasAtOutCoords();":"";addBias&&this.variableNames.push("bias"),hasPreluActivationWeights&&this.variableNames.push("preluActivationWeights"),hasLeakyreluAlpha&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n      ${activationSnippet}\n\n      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d2 = coords[${channelDim}];\n\n        ivec2 xRCCorner =\n            ivec2(coords[${rowDim}], coords[${colDim}]) * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${filterHeight}; wR++) {\n          int xR = xRCorner + wR * ${dilationHeight};\n\n          if (xR < 0 || xR >= ${convInfo.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${filterWidth}; wC++) {\n            int xC = xCCorner + wC * ${dilationWidth};\n\n            if (xC < 0 || xC >= ${convInfo.inWidth}) {\n              continue;\n            }\n\n            for (int d1 = 0; d1 < ${inputDepthNearestVec4}; d1 += 4) {\n              vec4 wValues = vec4(\n                getW(wR, wC, d1, d2),\n                getW(wR, wC, d1 + 1, d2),\n                getW(wR, wC, d1 + 2, d2),\n                getW(wR, wC, d1 + 3, d2)\n              );\n\n              if (${isChannelsLast}) {\n                vec4 xValues = vec4(\n                  getX(batch, xR, xC, d1),\n                  getX(batch, xR, xC, d1 + 1),\n                  getX(batch, xR, xC, d1 + 2),\n                  getX(batch, xR, xC, d1 + 3)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec4 xValues = vec4(\n                  getX(batch, d1, xR, xC),\n                  getX(batch, d1 + 1, xR, xC),\n                  getX(batch, d1 + 2, xR, xC),\n                  getX(batch, d1 + 3, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n\n            if (${1===inputDepthVec4Remainder}) {\n\n              if (${isChannelsLast}) {\n                dotProd +=\n                    getX(batch, xR, xC, ${inputDepthNearestVec4}) *\n                    getW(wR, wC, ${inputDepthNearestVec4}, d2);\n              } else {\n                dotProd +=\n                    getX(batch, ${inputDepthNearestVec4}, xR, xC) *\n                    getW(wR, wC, ${inputDepthNearestVec4}, d2);\n              }\n\n            } else if (${2===inputDepthVec4Remainder}) {\n              vec2 wValues = vec2(\n                getW(wR, wC, ${inputDepthNearestVec4}, d2),\n                getW(wR, wC, ${inputDepthNearestVec4} + 1, d2)\n              );\n\n              if (${isChannelsLast}) {\n                vec2 xValues = vec2(\n                  getX(batch, xR, xC, ${inputDepthNearestVec4}),\n                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 1)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec2 xValues = vec2(\n                  getX(batch, ${inputDepthNearestVec4}, xR, xC),\n                  getX(batch, ${inputDepthNearestVec4} + 1, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            } else if (${3===inputDepthVec4Remainder}) {\n              vec3 wValues = vec3(\n                getW(wR, wC, ${inputDepthNearestVec4}, d2),\n                getW(wR, wC, ${inputDepthNearestVec4} + 1, d2),\n                getW(wR, wC, ${inputDepthNearestVec4} + 2, d2)\n              );\n\n              if (${isChannelsLast}) {\n                vec3 xValues = vec3(\n                  getX(batch, xR, xC, ${inputDepthNearestVec4}),\n                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 1),\n                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec3 xValues = vec3(\n                  getX(batch, ${inputDepthNearestVec4}, xR, xC),\n                  getX(batch, ${inputDepthNearestVec4} + 1, xR, xC),\n                  getX(batch, ${inputDepthNearestVec4} + 2, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            }\n          }\n        }\n\n        float result = dotProd;\n        ${addBiasSnippet}\n        ${applyActivationSnippet}\n        setOutput(result);\n      }\n    `}}class Conv3DProgram{constructor(convInfo){this.variableNames=["x","W"],this.outputShape=convInfo.outShape;const padFront=convInfo.padInfo.front,padTop=convInfo.padInfo.top,padLeft=convInfo.padInfo.left,strideDepth=convInfo.strideDepth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationDepth=convInfo.dilationDepth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,filterDepth=convInfo.filterDepth,filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,inputDepthNearestVec4=4*Math.floor(convInfo.inChannels/4),inputDepthVec4Remainder=convInfo.inChannels%4;this.userCode=`\n      const ivec3 strides = ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});\n      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d2 = coords.u;\n\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xFCorner = xFRCCorner.x;\n        int xRCorner = xFRCCorner.y;\n        int xCCorner = xFRCCorner.z;\n\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\n        // values in that axis.\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${filterDepth}; wF++) {\n          int xF = xFCorner + wF * ${dilationDepth};\n\n          if (xF < 0 || xF >= ${convInfo.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${filterHeight}; wR++) {\n            int xR = xRCorner + wR * ${dilationHeight};\n\n            if (xR < 0 || xR >= ${convInfo.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${filterWidth}; wC++) {\n              int xC = xCCorner + wC * ${dilationWidth};\n\n              if (xC < 0 || xC >= ${convInfo.inWidth}) {\n                continue;\n              }\n\n              for (int d1 = 0; d1 < ${inputDepthNearestVec4}; d1 += 4) {\n                vec4 xValues = vec4(\n                  getX(batch, xF, xR, xC, d1),\n                  getX(batch, xF, xR, xC, d1 + 1),\n                  getX(batch, xF, xR, xC, d1 + 2),\n                  getX(batch, xF, xR, xC, d1 + 3)\n                );\n                vec4 wValues = vec4(\n                  getW(wF, wR, wC, d1, d2),\n                  getW(wF, wR, wC, d1 + 1, d2),\n                  getW(wF, wR, wC, d1 + 2, d2),\n                  getW(wF, wR, wC, d1 + 3, d2)\n                );\n\n                dotProd += dot(xValues, wValues);\n              }\n\n              if (${1===inputDepthVec4Remainder}) {\n                dotProd +=\n                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}) *\n                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2);\n              } else if (${2===inputDepthVec4Remainder}) {\n                vec2 xValues = vec2(\n                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}),\n                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 1)\n                );\n                vec2 wValues = vec2(\n                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2),\n                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 1, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else if (${3===inputDepthVec4Remainder}) {\n                vec3 xValues = vec3(\n                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}),\n                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 1),\n                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 2)\n                );\n                vec3 wValues = vec3(\n                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2),\n                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 1, d2),\n                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 2, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Conv2DPackedProgram{constructor(convInfo,addBias=!1,activation=null,hasPreluActivation=!1,hasLeakyReluAlpha=!1){this.variableNames=["x","W"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"pads",type:"ivec2"},{name:"strides",type:"ivec2"},{name:"dilations",type:"ivec2"},{name:"inDims",type:"ivec2"}],this.outputShape=convInfo.outShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length);const padLeft=convInfo.padInfo.left,strideWidth=convInfo.strideWidth,dilationWidth=convInfo.dilationWidth,filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,texelsAcross=filterWidth;let mainLoop="\n       int xR; int xC; int xCOffset;\n       vec4 wTexel; vec4 previous; vec4 final;";for(let c=0;c<filterWidth;c++)mainLoop+=`\n           vec4 xTexelC${2*c};\n           int xTexelC${2*c}Ready;\n           vec4 xTexelC${2*c+1};\n           int xTexelC${2*c+1}Ready;\n           vec4 xC${c};`;mainLoop+=`\n     for (int r = 0; r < ${filterHeight}; r++) {\n      for (int d1 = 0; d1 < ${convInfo.inChannels}; d1 += 2) {\n       `;for(let c=0;c<filterWidth;c++)mainLoop+=`\n           xTexelC${2*c} = vec4(0.0);\n           xTexelC${2*c}Ready = 0;\n           xTexelC${2*c+1} = vec4(0.0);\n           xTexelC${2*c+1}Ready = 0;\n           xC${c} = vec4(0.0);`;mainLoop+="\n         xR = xRCorner + r * dilations[0];\n         if (xR >=0 && xR < inDims[0]) {\n       ";for(let texelC=0;texelC<(texelsAcross+1)/2;texelC++){const colIndex=2*texelC;if(mainLoop+=`\n           xC = xCCorner + ${colIndex*dilationWidth};\n           `,1===strideWidth){if(colIndex<filterWidth&&(padLeft%2==1?(mainLoop+=`\n                 xCOffset = xC + 1;\n                 if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                   xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);\n\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC${colIndex}.zw = vec2(0.0);\n                   }\n                   xTexelC${colIndex}Ready = 1;\n                 }\n               `,mainLoop+=1===dilationWidth&&colIndex>0?`\n                 xC${colIndex} = vec4(xTexelC${colIndex-2}.zw, xTexelC${colIndex}.xy);\n                 `:`\n                   xCOffset = xC + 1 - 2;\n\n                   if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                     previous = getX(batch, xR, xCOffset, d1);\n\n                     // Need to manually clear unused channels in case\n                     // we're reading from recycled texture.\n                     if (xCOffset + 1 >= inDims[1]) {\n                       previous.zw = vec2(0.0);\n                     }\n\n                     xC${colIndex} = vec4(previous.zw, xTexelC${colIndex}.xy);\n                   } else {\n                     xC${colIndex} = vec4(0.0, 0.0, xTexelC${colIndex}.xy);\n                   }\n                   `):mainLoop+=`\n                 if (xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                   xTexelC${colIndex} = getX(batch, xR, xC, d1);\n                   if (xC + 1 >= inDims[1]) {\n                     xTexelC${colIndex}.zw = vec2(0.0);\n                   }\n                   xTexelC${colIndex}Ready = 1;\n                 }\n\n                 xC${colIndex} = xTexelC${colIndex};\n                 `,colIndex+1<filterWidth)){const nextTexelOffset=padLeft%2==0?dist.ZSL.nearestLargerEven(dilationWidth):dilationWidth;dilationWidth%2==0&&padLeft%2==1||dilationWidth%2!=0&&padLeft%2!=1?(mainLoop+=`\n                   xCOffset = xC + imod(pads[1], 2) + ${nextTexelOffset};\n\n                   if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex+1}Ready == 0) {\n                     xTexelC${colIndex+1} = getX(batch, xR, xCOffset, d1);\n\n                     // Need to manually clear unused channels in case\n                     // we're reading from recycled texture.\n                     if (xCOffset + 1 >= inDims[1]) {\n                       xTexelC${colIndex+1}.zw = vec2(0.0);\n                     }\n                     xTexelC${colIndex+1}Ready = 1;\n                   }\n                   `,mainLoop+=dilationWidth>1?`\n                     xCOffset -= 2;\n                     if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                      previous = getX(batch, xR, xCOffset, d1);\n                      xC${colIndex+1} = vec4(previous.zw, xTexelC${colIndex+1}.xy);\n                     } else {\n                      xC${colIndex+1} = vec4(0.0, 0.0, xTexelC${colIndex+1}.xy);\n                     }\n                     `:`\n                     xC${colIndex+1} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex+1}.xy);\n                     `):mainLoop+=1===nextTexelOffset?`\n                     xC${colIndex+1} = xTexelC${colIndex};\n                     `:`\n                     xCOffset = xC + ${nextTexelOffset};\n\n                     if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex+1}Ready == 0) {\n                       xTexelC${colIndex+1} = getX(batch, xR, xCOffset, d1);\n                       if (xCOffset + 1 >= inDims[1]) {\n                         xTexelC${colIndex+1}.zw = vec2(0.0);\n                       }\n                       xTexelC${colIndex+1}Ready = 1;\n                     }\n\n                     xC${colIndex+1} = xTexelC${colIndex+1};\n                     `}}else colIndex<filterWidth&&(padLeft%2==1?(mainLoop+=`\n                 xCOffset = xC + 1 - strides[1];\n                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                   xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC${colIndex}.zw = vec2(0.0);\n                   }\n                   xTexelC${colIndex}Ready = 1;\n                 }\n\n                 if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${colIndex+1}Ready == 0) {\n                   xTexelC${colIndex+1} = getX(batch, xR, xC + 1, d1);\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xC + 2 >= inDims[1]) {\n                     xTexelC${colIndex+1}.zw = vec2(0.0);\n                   }\n                   xTexelC${colIndex+1}Ready = 1;\n                 }\n\n                 xC${colIndex} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex+1}.zw);\n               `,colIndex+1<filterWidth&&(mainLoop+=`\n                   final = vec4(0.0);\n                   xCOffset = xC + 1 + strides[1];\n                   if(xCOffset >= 0 && xCOffset < inDims[1]) {\n                     final = getX(batch, xR, xCOffset, d1);\n                   }\n                   xC${colIndex+1} = vec4(xTexelC${colIndex+1}.xy, final.xy);\n                 `)):(mainLoop+=`\n                 if(xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                   xTexelC${colIndex} = getX(batch, xR, xC, d1);\n                   if (xC + 1 >= inDims[1]) {\n                     xTexelC${colIndex}.zw = vec2(0.0);\n                   }\n                   xTexelC${colIndex}Ready = 1;\n                 }\n\n                 xCOffset = xC + strides[1];\n                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex+1}Ready == 0) {\n                   xTexelC${colIndex+1} = getX(batch, xR, xCOffset, d1);\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC${colIndex+1}.zw = vec2(0.);\n                   }\n                   xTexelC${colIndex+1}Ready = 1;\n                 }\n\n                 xC${colIndex} = vec4(\n                   xTexelC${colIndex}.xy, xTexelC${colIndex+1}.xy);\n               `,colIndex+1<filterWidth&&(mainLoop+=`\n                   xC${colIndex+1} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex+1}.zw);\n                 `)));colIndex<filterWidth&&(mainLoop+=`\n             wTexel = getW(r, ${colIndex}, d1, d2);\n             dotProd += xC${colIndex}.xxzz * vec4(wTexel.xy, wTexel.xy);\n             if(d1 + 1 < ${convInfo.inChannels}) {\n               dotProd += xC${colIndex}.yyww * vec4(wTexel.zw, wTexel.zw);\n             }\n           `,colIndex+1<filterWidth&&(mainLoop+=`\n               wTexel = getW(r, ${colIndex+1}, d1, d2);\n               dotProd += xC${colIndex+1}.xxzz * vec4(wTexel.xy, wTexel.xy);\n               if(d1 + 1 < ${convInfo.inChannels}) {\n                 dotProd += xC${colIndex+1}.yyww * vec4(wTexel.zw, wTexel.zw);\n               }\n             `))}mainLoop+="\n     }\n   ",mainLoop+="\n     }\n   ",mainLoop+="\n     }\n   ";let activationSnippet="",applyActivationSnippet="";activation&&(activationSnippet=hasPreluActivation?`vec4 activation(vec4 a) {\n           vec4 b = getPreluActivationWeightsAtOutCoords();\n           ${activation}\n         }`:hasLeakyReluAlpha?`vec4 activation(vec4 a) {\n           vec4 b = getLeakyreluAlphaAtOutCoords();\n           ${activation}\n         }`:`vec4 activation(vec4 x) {\n           ${activation}\n         }`,applyActivationSnippet="result = activation(result);");const addBiasSnippet=addBias?"result += getBiasAtOutCoords();":"";addBias&&this.variableNames.push("bias"),hasPreluActivation&&this.variableNames.push("preluActivationWeights"),hasLeakyReluAlpha&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n       ${activationSnippet}\n\n       void main() {\n         ivec4 coords = getOutputCoords();\n         int batch = coords.x;\n         ivec2 xRCCorner = coords.yz * strides - pads;\n         int d2 = coords.w;\n         int xRCorner = xRCCorner.x;\n         int xCCorner = xRCCorner.y;\n\n         //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n         vec4 dotProd = vec4(0.000000000000001);\n\n         ${mainLoop}\n\n         vec4 result = dotProd - vec4(0.000000000000001);\n         ${addBiasSnippet}\n         ${applyActivationSnippet}\n         setOutput(result);\n       }\n     `}}class Im2ColPackedProgram{constructor(outputShape,convInfo){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"inputShape",type:"ivec4"},{name:"pad",type:"ivec2"},{name:"stride",type:"ivec2"},{name:"dilation",type:"ivec2"},{name:"inChannels",type:"int"},{name:"itemsPerBlockRow",type:"int"},{name:"outWidth",type:"int"}],this.outputShape=outputShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length);const{dataFormat}=convInfo,glsl=getGlslDifferences(),isChannelsLast="channelsLast"===dataFormat,rowDim=isChannelsLast?1:2,colDim=isChannelsLast?2:3,boundsCheckingSnippet=this.enableShapeUniforms?"if(blockIndex < outShape[2] && pos < outShape[1]) {":`if(blockIndex < ${outputShape[2]} && pos < ${outputShape[1]}) {`;let unrolled="";for(let row=0;row<=1;row++)for(let col=0;col<=1;col++)unrolled+=`\n          blockIndex = rc.z + ${col};\n          pos = rc.y + ${row};\n\n          ${boundsCheckingSnippet}\n            offsetY = int(blockIndex / outWidth) * stride[0] - pad[0];\n            d0 = offsetY + dilation[0] * (pos / itemsPerBlockRow);\n\n            if(d0 < inputShape[${rowDim}] && d0 >= 0) {\n              // Use custom imod instead mod. On Intel GPU, mod may generate\n              // unexpected value.\n              // https://github.com/tensorflow/tfjs/issues/5447\n              offsetX = imod(blockIndex, outWidth) * stride[1] - pad[1];\n              d1 = offsetX + dilation[1] * (imod(pos, itemsPerBlockRow) /\n                  inChannels);\n\n              if(d1 < inputShape[${colDim}] && d1 >= 0) {\n\n                ch = imod(pos, inChannels);\n\n                if (${isChannelsLast}) {\n                  innerDims = vec2(d1, ch);\n                  result[${2*row+col}] = getChannel(\n                    getA(rc.x, d0, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                } else {\n                  innerDims = vec2(d0, d1);\n                  result[${2*row+col}] = getChannel(\n                    getA(rc.x, ch, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                }\n              }\n            }\n          }\n        `;this.userCode=`\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0);\n\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\n        vec2 innerDims;\n\n        ${unrolled}\n\n        ${glsl.output} = result;\n      }\n    `}}function getShapeForBatchMatMul(shape,isChannelsLast){const length=shape.length;return length>=3?isChannelsLast?[...shape.slice(0,-3),shape[length-3]*shape[length-2],shape[length-1]]:[...shape.slice(0,-3),shape[length-3],shape[length-2]*shape[length-1]]:!isChannelsLast&&1===length&&shape[0]>1?[shape[0],1]:null}function conv2dByMatMul({x,filter,convInfo,backend,bias=null,preluActivationWeights=null,leakyreluAlpha=0,activation=null}){const xShape=x.shape,xTexData=backend.texData.get(x.dataId),sharedMatMulDim=convInfo.inChannels,outerShapeX=xShape[0]*xShape[1]*xShape[2],outerShapeFilter=convInfo.outChannels,isChannelsLast="channelsLast"===convInfo.dataFormat;let out;const intermediates=[];if(null!=preluActivationWeights){const targetShape=getShapeForBatchMatMul(preluActivationWeights.shape,isChannelsLast);null!=targetShape&&(preluActivationWeights=kernels_Reshape_reshape({inputs:{x:preluActivationWeights},backend,attrs:{shape:targetShape}}),intermediates.push(preluActivationWeights))}if(null!=bias){const targetShape=getShapeForBatchMatMul(bias.shape,isChannelsLast);null!=targetShape&&(bias=kernels_Reshape_reshape({inputs:{x:bias},backend,attrs:{shape:targetShape}}),intermediates.push(bias))}if(!((1===outerShapeX||1===outerShapeFilter)&&sharedMatMulDim>1e3)&&xTexData.isPacked&&isChannelsLast&&null!=xTexData.texture&&xShape[2]%2!=0&&dist.ZSL.arraysEqual(xTexData.shape.slice(-3),xShape.slice(-3))){const targetShape=xShape[0]*xShape[1]*(xShape[2]+1),xReshaped={dataId:x.dataId,shape:[1,targetShape,convInfo.inChannels],dtype:x.dtype},originalXTexDataShape=xTexData.shape;xTexData.shape=xTexData.shape.slice(),xTexData.shape[xTexData.shape.length-2]++,dist.ZSL.assert(isReshapeFree(xTexData.shape,xReshaped.shape),()=>`packed reshape ${xTexData.shape} to ${xReshaped.shape} isn't free`);const filterReshaped=kernels_Reshape_reshape({inputs:{x:filter},backend,attrs:{shape:[1,convInfo.inChannels,convInfo.outChannels]}});intermediates.push(filterReshaped);const pointwiseConv=batchMatMulImpl({a:xReshaped,b:filterReshaped,backend,transposeA:false,transposeB:false,bias,activation,preluActivationWeights,leakyreluAlpha}),pointwiseConvTexData=backend.texData.get(pointwiseConv.dataId);dist.ZSL.assert(pointwiseConvTexData.isPacked,()=>"batchMatMul result is expected to be packed"),xTexData.shape=originalXTexDataShape,pointwiseConvTexData.shape=convInfo.outShape,out=kernels_Identity_identity({inputs:{x:pointwiseConv},backend}),out.shape=convInfo.outShape,intermediates.push(pointwiseConv)}else{const numCols=convInfo.outHeight*convInfo.outWidth,xReshaped=kernels_Reshape_reshape({inputs:{x},backend,attrs:{shape:isChannelsLast?[convInfo.batchSize,numCols,convInfo.inChannels]:[convInfo.batchSize,convInfo.inChannels,numCols]}}),filterReshaped=kernels_Reshape_reshape({inputs:{x:filter},backend,attrs:{shape:[1,convInfo.inChannels,convInfo.outChannels]}}),result=batchMatMulImpl({a:isChannelsLast?xReshaped:filterReshaped,b:isChannelsLast?filterReshaped:xReshaped,transposeA:!isChannelsLast,transposeB:false,backend,bias,activation,preluActivationWeights,leakyreluAlpha});out=kernels_Reshape_reshape({inputs:{x:result},backend,attrs:{shape:convInfo.outShape}}),intermediates.push(xReshaped),intermediates.push(filterReshaped),intermediates.push(result)}for(const i of intermediates)backend.disposeIntermediateTensorInfo(i);return out}function conv2dWithIm2Row({x,filter,convInfo,backend,bias=null,preluActivationWeights=null,leakyreluAlpha=0,activation=null}){const{filterWidth,filterHeight,inChannels,outWidth,outHeight,dataFormat}=convInfo,isChannelsLast="channelsLast"===dataFormat,sharedDim=filterWidth*filterHeight*inChannels,numCols=outHeight*outWidth,x2ColShape=[convInfo.batchSize,sharedDim,numCols],intermediates=[];if(null!=preluActivationWeights){const targetShape=getShapeForBatchMatMul(preluActivationWeights.shape,isChannelsLast);null!=targetShape&&(preluActivationWeights=kernels_Reshape_reshape({inputs:{x:preluActivationWeights},backend,attrs:{shape:targetShape}}),intermediates.push(preluActivationWeights))}if(null!=bias){const targetShape=getShapeForBatchMatMul(bias.shape,isChannelsLast);null!=targetShape&&(bias=kernels_Reshape_reshape({inputs:{x:bias},backend,attrs:{shape:targetShape}}),intermediates.push(bias))}const w2Row=kernels_Reshape_reshape({inputs:{x:filter},backend,attrs:{shape:[1,sharedDim,dist.ZSL.sizeFromShape(filter.shape)/sharedDim]}});intermediates.push(w2Row);const im2ColProgram=new Im2ColPackedProgram(x2ColShape,convInfo),customValues=[x.shape,[convInfo.padInfo.top,convInfo.padInfo.left],[convInfo.strideHeight,convInfo.strideWidth],[convInfo.dilationHeight,convInfo.dilationWidth],[convInfo.inChannels],[convInfo.filterWidth*convInfo.inChannels],[convInfo.outWidth]],im2Col=backend.runWebGLProgram(im2ColProgram,[x],"float32",customValues),im2ColReshaped=kernels_Reshape_reshape({inputs:{x:im2Col},backend,attrs:{shape:x2ColShape}});intermediates.push(im2Col),intermediates.push(im2ColReshaped);const hasBias=null!=bias,hasPreluActivationWeights=null!=preluActivationWeights,hasLeakyreluAlpha="leakyrelu"===activation,fusedActivation=activation?mapActivationToShaderProgram(activation,!0):null,matmulProgram=new MatMulPackedProgram(isChannelsLast?im2ColReshaped.shape:w2Row.shape,isChannelsLast?w2Row.shape:im2ColReshaped.shape,isChannelsLast?[convInfo.batchSize,numCols,convInfo.outChannels]:[convInfo.batchSize,convInfo.outChannels,numCols],!0,!1,hasBias,fusedActivation,hasPreluActivationWeights,hasLeakyreluAlpha),inputs=isChannelsLast?[im2ColReshaped,w2Row]:[w2Row,im2ColReshaped];if(bias&&inputs.push(bias),hasPreluActivationWeights&&inputs.push(preluActivationWeights),hasLeakyreluAlpha){const $leakyreluAlpha=backend.makeTensorInfo([],"float32",dist.ZSL.createScalarValue(leakyreluAlpha,"float32"));inputs.push($leakyreluAlpha),intermediates.push($leakyreluAlpha)}const product=backend.runWebGLProgram(matmulProgram,inputs,"float32"),out=kernels_Reshape_reshape({inputs:{x:product},backend,attrs:{shape:convInfo.outShape}});intermediates.push(product);for(const i of intermediates)backend.disposeIntermediateTensorInfo(i);return out}const Conv2D_conv2DConfig={kernelName:dist.p2J,backendName:"webgl",kernelFunc:function Conv2D_conv2d(args){const{inputs,backend,attrs}=args,{x,filter}=inputs,{strides,pad,dataFormat,dilations,dimRoundingMode}=attrs,$dataFormat=dist.C0T.convertConv2DDataFormat(dataFormat),convInfo=dist.C0T.computeConv2DInfo(x.shape,filter.shape,strides,dilations,pad,dimRoundingMode,!1,$dataFormat);let out;if(1!==convInfo.filterHeight||1!==convInfo.filterWidth||1!==convInfo.dilationHeight||1!==convInfo.dilationWidth||1!==convInfo.strideHeight||1!==convInfo.strideWidth||"SAME"!==convInfo.padInfo.type&&"VALID"!==convInfo.padInfo.type)if(convInfo.strideWidth<=2&&"channelsLast"===$dataFormat&&(0,dist._K2)().getBool("WEBGL_EXP_CONV")){const program=new Conv2DPackedProgram(convInfo),customValues=[[convInfo.padInfo.top,convInfo.padInfo.left],[convInfo.strideHeight,convInfo.strideWidth],[convInfo.dilationHeight,convInfo.dilationWidth],[convInfo.inHeight,convInfo.inWidth]];out=backend.runWebGLProgram(program,[x,filter],"float32",customValues)}else if((0,dist._K2)().getBool("WEBGL_CONV_IM2COL"))out=conv2dWithIm2Row({x,filter,convInfo,backend});else{const program=new Conv2DProgram(convInfo);out=backend.runWebGLProgram(program,[x,filter],"float32")}else out=conv2dByMatMul({x,filter,convInfo,backend});const outReshaped=kernels_Reshape_reshape({inputs:{x:out},backend,attrs:{shape:convInfo.outShape}});return backend.disposeIntermediateTensorInfo(out),outReshaped}};class Conv2DDerFilterProgram{constructor(convInfo){this.variableNames=["x","dy"],this.outputShape=convInfo.filterShape;const strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,padTop=convInfo.padInfo.top,padLeft=convInfo.padInfo.left,isChannelsLast="channelsLast"===convInfo.dataFormat;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int d2 = coords.w;\n\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${convInfo.batchSize}; b++) {\n          for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {\n            int xR = wR + yR * ${strideHeight} - ${padTop};\n\n            if (xR < 0 || xR >= ${convInfo.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {\n              int xC = wC + yC * ${strideWidth} - ${padLeft};\n\n              if (xC < 0 || xC >= ${convInfo.inWidth}) {\n                continue;\n              }\n\n              ${isChannelsLast?"float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);":"float dyValue = getDy(b, d2, yR, yC);\n              float xValue = getX(b, d1, xR, xC);\n              dotProd += (xValue * dyValue);"}\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Conv2DDerInputProgram{constructor(convInfo){this.variableNames=["dy","W"],this.outputShape=convInfo.inShape;const filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,isChannelsLast="channelsLast"===convInfo.dataFormat,padTop=filterHeight-1-convInfo.padInfo.top,padLeft=filterWidth-1-convInfo.padInfo.left,rowDim=isChannelsLast?1:2,colDim=isChannelsLast?2:3,channelDim=isChannelsLast?3:1;this.userCode=`\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[${channelDim}];\n\n        ivec2 dyCorner = ivec2(coords[${rowDim}], coords[${colDim}]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${filterHeight}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${filterHeight} - 1 - wR;\n\n          for (int wC = 0; wC < ${filterWidth}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${filterWidth} - 1 - wC;\n\n            for (int d2 = 0; d2 < ${convInfo.outChannels}; d2++) {\n\n              if (${isChannelsLast}) {\n                float xValue = getDy(batch, idyR, idyC, d2);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              } else {\n                float xValue = getDy(batch, d2, idyR, idyC);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Conv3DDerFilterProgram{constructor(convInfo){this.variableNames=["x","dy"],this.outputShape=convInfo.filterShape;const strideDepth=convInfo.strideDepth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,padFront=convInfo.padInfo.front,padTop=convInfo.padInfo.top,padLeft=convInfo.padInfo.left;this.userCode=`\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int wF = coords.x;\n        int wR = coords.y;\n        int wC = coords.z;\n        int d1 = coords.w;\n        int d2 = coords.u;\n\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${convInfo.batchSize}; b++) {\n          for (int yF = 0; yF < ${convInfo.outDepth}; yF++) {\n            int xF = wF + yF * ${strideDepth} - ${padFront};\n\n            if (xF < 0 || xF >= ${convInfo.inDepth}) {\n              continue;\n            }\n\n            for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {\n              int xR = wR + yR * ${strideHeight} - ${padTop};\n\n              if (xR < 0 || xR >= ${convInfo.inHeight}) {\n                continue;\n              }\n\n              for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {\n                int xC = wC + yC * ${strideWidth} - ${padLeft};\n\n                if (xC < 0 || xC >= ${convInfo.inWidth}) {\n                  continue;\n                }\n\n                float dyValue = getDy(b, yF, yR, yC, d2);\n                float xValue = getX(b, xF, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Conv3DDerInputProgram{constructor(convInfo){this.variableNames=["dy","W"],this.outputShape=convInfo.inShape;const filterDepth=convInfo.filterDepth,filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,strideDepth=convInfo.strideDepth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,padFront=filterDepth-1-convInfo.padInfo.front,padTop=filterHeight-1-convInfo.padInfo.top,padLeft=filterWidth-1-convInfo.padInfo.left;this.userCode=`\n      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.u;\n\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyFCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${filterDepth}; wF++) {\n          float dyF = float(dyFCorner + wF) / ${strideDepth}.0;\n\n          if (dyF < 0.0 || dyF >= ${convInfo.outDepth}.0 || fract(dyF) > 0.0) {\n            continue;\n          }\n          int idyF = int(dyF);\n\n          int wFPerm = ${filterDepth} - 1 - wF;\n\n          for (int wR = 0; wR < ${filterHeight}; wR++) {\n            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||\n              fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            int wRPerm = ${filterHeight} - 1 - wR;\n\n            for (int wC = 0; wC < ${filterWidth}; wC++) {\n              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              int wCPerm = ${filterWidth} - 1 - wC;\n\n              for (int d2 = 0; d2 < ${convInfo.outChannels}; d2++) {\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}const Conv2DBackpropFilter_conv2DBackpropFilterConfig={kernelName:dist.rFm,backendName:"webgl",kernelFunc:function Conv2DBackpropFilter_conv2DBackpropFilter(args){const{inputs,backend,attrs}=args,{x,dy}=inputs,{strides,pad,dataFormat,dimRoundingMode,filterShape}=attrs,$dataFormat=dist.C0T.convertConv2DDataFormat(dataFormat),convInfo=dist.C0T.computeConv2DInfo(x.shape,filterShape,strides,1,pad,dimRoundingMode,!1,$dataFormat),program=new Conv2DDerFilterProgram(convInfo);return backend.runWebGLProgram(program,[x,dy],"float32")}};class Conv2DDerInputPackedProgram{constructor(convInfo){this.variableNames=["dy","W"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"strides",type:"vec2"}],this.outputShape=convInfo.inShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length);const filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,padTop=filterHeight-1-convInfo.padInfo.top,padLeft=filterWidth-1-convInfo.padInfo.left;this.userCode=`\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n\n        ivec2 dyCorner = ivec2(coords[1], coords[2]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        vec4 result = vec4(0.);\n        for (int wR = 0; wR < ${filterHeight}; wR++) {\n          float dyR = float(dyRCorner + wR) / strides[0];\n          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n          int wRPerm = ${filterHeight} - 1 - wR;\n\n          for (int wC = 0; wC < ${filterWidth}; wC++) {\n            int wCPerm = ${filterWidth} - 1 - wC;\n\n            float dyC = float(dyCCorner + wC) / strides[1];\n            bool idyCVal = (dyC >= 0.0) && (dyC < ${convInfo.outWidth}.0)\n              && (fract(dyC) == 0.0);\n            int idyC = int(dyC);\n\n            float dyC2 = float(dyCCorner + wC + 1) / strides[1];\n            bool idyCVal2 = (dyC2 >= 0.0) && (dyC2 < ${convInfo.outWidth}.0)\n              && (fract(dyC2) == 0.0);\n            int idyC2 = int(dyC2);\n\n            if (idyCVal && idyCVal2) {\n              for (int d2 = 0; d2 < ${convInfo.outChannels}; d2 += 2) {\n                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);\n                vec4 dySample = getDy(batch, idyR, idyC, d2);\n                vec4 dySample2 = (idyC / 2 == idyC2 / 2) ?\n                  dySample : getDy(batch, idyR, idyC2, d2);\n\n                vec2 dyValue = mod(float(idyC), 2.) == 0. ?\n                  dySample.xy : dySample.zw;\n                result.xy += vec2(dot(dyValue, wValue.xy),\n                  dot(dyValue, wValue.zw));\n\n                dyValue = mod(float(idyC2), 2.) == 0. ?\n                  dySample2.xy : dySample2.zw;\n                result.zw += vec2(dot(dyValue, wValue.xy),\n                  dot(dyValue, wValue.zw));\n              }\n            } else if (idyCVal) {\n              for (int d2 = 0; d2 < ${convInfo.outChannels}; d2 += 2) {\n                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);\n                vec4 dySample = getDy(batch, idyR, idyC, d2);\n                vec2 dyValue = mod(float(idyC), 2.) == 0. ?\n                  dySample.xy : dySample.zw;\n                result.xy += vec2(dot(dyValue, wValue.xy),\n                  dot(dyValue, wValue.zw));\n              }\n            } else if (idyCVal2) {\n              for (int d2 = 0; d2 < ${convInfo.outChannels}; d2 += 2) {\n                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);\n                vec4 dySample = getDy(batch, idyR, idyC2, d2);\n                vec2 dyValue = mod(float(idyC2), 2.) == 0. ?\n                  dySample.xy : dySample.zw;\n                result.zw += vec2(dot(dyValue, wValue.xy),\n                  dot(dyValue, wValue.zw));\n              }\n            }\n          }\n        }\n        setOutput(result);\n      }\n    `}}const Conv2DBackpropInput_conv2DBackpropInputConfig={kernelName:dist.jfg,backendName:"webgl",kernelFunc:function Conv2DBackpropInput_conv2DBackpropInput(args){const{inputs,backend,attrs}=args,{dy,filter}=inputs,{inputShape,strides,pad,dataFormat,dimRoundingMode}=attrs,$dataFormat=dist.C0T.convertConv2DDataFormat(dataFormat),convInfo=dist.C0T.computeConv2DInfo(inputShape,filter.shape,strides,1,pad,dimRoundingMode,!1,$dataFormat);if((0,dist._K2)().getBool("WEBGL_PACK_CONV2DTRANSPOSE")&&"channelsLast"===$dataFormat){const customValues=[[convInfo.strideHeight,convInfo.strideWidth]],program=new Conv2DDerInputPackedProgram(convInfo);return backend.runWebGLProgram(program,[dy,filter],"float32",customValues)}{const program=new Conv2DDerInputProgram(convInfo);return backend.runWebGLProgram(program,[dy,filter],"float32")}}};const Conv3D_conv3DConfig={kernelName:dist.A1h,backendName:"webgl",kernelFunc:function Conv3D_conv3D(args){const{inputs,backend,attrs}=args,{x,filter}=inputs,{strides,pad,dilations}=attrs,convInfo=dist.C0T.computeConv3DInfo(x.shape,filter.shape,strides,dilations,pad),program=new Conv3DProgram(convInfo);return backend.runWebGLProgram(program,[x,filter],"float32")}};const Conv3DBackpropFilterV2_conv3DBackpropFilterV2Config={kernelName:dist.iGz,backendName:"webgl",kernelFunc:function Conv3DBackpropFilterV2_conv3DBackpropFilterV2(args){const{inputs,backend,attrs}=args,{x,dy}=inputs,{strides,pad,filterShape}=attrs,convInfo=dist.C0T.computeConv3DInfo(x.shape,filterShape,strides,1,pad),program=new Conv3DDerFilterProgram(convInfo);return backend.runWebGLProgram(program,[x,dy],"float32")}};const conv3DBackpropInputConfig={kernelName:dist.gC7,backendName:"webgl",kernelFunc:function conv3DBackpropInput(args){const{inputs,backend,attrs}=args,{dy,filter}=inputs,{pad,strides,inputShape}=attrs,convInfo=dist.C0T.computeConv3DInfo(inputShape,filter.shape,strides,1,pad),program=new Conv3DDerInputProgram(convInfo);return backend.runWebGLProgram(program,[dy,filter],"float32")}},kernels_Cos_cos=kernel_funcs_utils_unaryKernelFunc({opSnippet:"if (isnan(x)) return x;\n  return cos(x);\n",packedOpSnippet:`\n  vec4 result = cos(x);\n  bvec4 isNaN = isnan(x);\n  ${CHECK_NAN_SNIPPET_PACKED}\n  return result;\n`}),Cos_cosConfig={kernelName:dist.Mn0,backendName:"webgl",kernelFunc:kernels_Cos_cos},kernels_Cosh_cosh=kernel_funcs_utils_unaryKernelFunc({opSnippet:"\n  float e2x = exp(-x);\n  return (e2x + 1.0 / e2x) / 2.0;\n"}),Cosh_coshConfig={kernelName:dist.MnK,backendName:"webgl",kernelFunc:kernels_Cosh_cosh};class CropAndResizeProgram{constructor(imageShape,boxShape,cropSize,method,extrapolationValue){this.variableNames=["Image","Boxes","BoxInd"],this.outputShape=[];const[batch,imageHeight,imageWidth,depth]=imageShape,[numBoxes]=boxShape,[cropHeight,cropWidth]=cropSize;this.outputShape=[numBoxes,cropHeight,cropWidth,depth];const methodId="bilinear"===method?1:0,[inputHeightFloat,inputWidthFloat]=[imageHeight-1+".0",imageWidth-1+".0"],[heightRatio,heightScale,inY]=cropHeight>1?[""+(imageHeight-1)/(cropHeight-1),"(y2-y1) * height_ratio",`y1*${inputHeightFloat} + float(y)*(height_scale)`]:["0.0","0.0",`0.5 * (y1+y2) * ${inputHeightFloat}`],[widthRatio,widthScale,inX]=cropWidth>1?[""+(imageWidth-1)/(cropWidth-1),"(x2-x1) * width_ratio",`x1*${inputWidthFloat} + float(x)*(width_scale)`]:["0.0","0.0",`0.5 * (x1+x2) * ${inputWidthFloat}`];this.userCode=`\n      const float height_ratio = float(${heightRatio});\n      const float width_ratio = float(${widthRatio});\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int y = coords[1];\n        int x = coords[2];\n        int d = coords[3];\n\n        // get box vals\n        float y1 = getBoxes(b,0);\n        float x1 = getBoxes(b,1);\n        float y2 = getBoxes(b,2);\n        float x2 = getBoxes(b,3);\n\n        // get image in batch index\n        int bInd = round(getBoxInd(b));\n        if(bInd < 0 || bInd >= ${batch}) {\n          return;\n        }\n\n        float height_scale = ${heightScale};\n        float width_scale = ${widthScale};\n\n        float in_y = ${inY};\n        if( in_y < 0.0 || in_y > ${inputHeightFloat} ) {\n          setOutput(float(${extrapolationValue}));\n          return;\n        }\n        float in_x = ${inX};\n        if( in_x < 0.0 || in_x > ${inputWidthFloat} ) {\n          setOutput(float(${extrapolationValue}));\n          return;\n        }\n\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\n        if(${methodId} == 1) {\n          // Compute the four integer indices.\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\n\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\n\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\n\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          float newValue = top + (bottom - top) * fracCR.y;\n          setOutput(newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          ivec2 sourceNearestCR = ivec2(floor(\n            sourceFracIndexCR + vec2(0.5,0.5)));\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutput(newValue);\n        }\n      }\n    `}}const CropAndResize_cropAndResizeConfig={kernelName:dist.MRQ,backendName:"webgl",kernelFunc:args=>{const{inputs,backend,attrs}=args,{image,boxes,boxInd}=inputs,{cropSize,method,extrapolationValue}=attrs,program=new CropAndResizeProgram(image.shape,boxes.shape,cropSize,method,extrapolationValue);return backend.runWebGLProgram(program,[image,boxes,boxInd],"float32")}};var CumOpType;!function(CumOpType){CumOpType.Prod="*",CumOpType.Sum="+"}(CumOpType||(CumOpType={}));class CumProgram{constructor(op,outputShape,exclusive,reverse){this.op=op,this.outputShape=outputShape,this.variableNames=["x"],this.customUniforms=[{name:"index",type:"float"}];const rank=this.outputShape.length,initVal=this.op===CumOpType.Prod?"1.0":"0.0",val=exclusive?initVal:`getX(${cum_gpu_getCoords(rank,"coords",this.op)})`,length=this.outputShape[this.outputShape.length-1];let condition="",idxString="";exclusive?(condition=reverse?"end != "+(length-1):"end != 0",idxString=reverse?"end + 1":"end - 1"):(condition=reverse?`end + pow2 < ${length}`:"end >= pow2",idxString=reverse?"end + pow2":"end - pow2"),this.userCode=`\n      void main() {\n        ${getCoordsDataType(rank)} coords = getOutputCoords();\n        int end = ${getFinalCoord(rank,"coords",this.op)};\n        float val = ${val};\n        int pow2 = int(pow(2.0, index));\n        if (${condition}) {\n          int idx = ${idxString};\n          ${getFinalCoord(rank,"coords",this.op)} = idx;\n          val ${this.op}= getX(${cum_gpu_getCoords(rank,"coords",this.op)});\n        }\n        setOutput(val);\n      }\n    `}}function cum_gpu_getCoords(rank,name,op){if(1===rank)return`${name}`;if(2===rank)return`${name}.x, ${name}.y`;if(3===rank)return`${name}.x, ${name}.y, ${name}.z`;if(4===rank)return`${name}.x, ${name}.y, ${name}.z, ${name}.w`;throw new Error(`Cumulative ${op} for rank ${rank} is not yet supported`)}function getFinalCoord(rank,name,op){if(1===rank)return`${name}`;if(2===rank)return`${name}.y`;if(3===rank)return`${name}.z`;if(4===rank)return`${name}.w`;throw new Error(`Cumulative ${op} for rank ${rank} is not yet supported`)}function cumImpl(op,x,backend,axis,exclusive,reverse){const xRank=x.shape.length,permutation=dist.C0T.getAxesPermutation([axis],xRank);let permutedX=x;null!=permutation&&(permutedX=kernels_Transpose_transpose({inputs:{x},backend,attrs:{perm:permutation}}));const permutedAxis=dist.C0T.getInnerMostAxes(1,xRank)[0];if(permutedAxis!==xRank-1)throw new Error(`WebGL cumprod shader expects an inner-most axis=${x.shape.length-1} but got axis=${axis}`);const size=permutedX.shape[permutedAxis];let result=kernels_Identity_identity({inputs:{x:permutedX},backend});for(let i=0;i<=Math.ceil(Math.log2(size))-1;i++){const program=new CumProgram(op,permutedX.shape,!1,reverse),customValues=[[i]],prevResult=result;result=backend.runWebGLProgram(program,[result],result.dtype,customValues),backend.disposeIntermediateTensorInfo(prevResult)}if(exclusive){const program=new CumProgram(op,permutedX.shape,exclusive,reverse),prevResult=result;result=backend.runWebGLProgram(program,[result],result.dtype),backend.disposeIntermediateTensorInfo(prevResult)}if(null!=permutation){const reverseTransposedResult=kernels_Transpose_transpose({inputs:{x:result},backend,attrs:{perm:dist.C0T.getUndoAxesPermutation(permutation)}});return backend.disposeIntermediateTensorInfo(result),backend.disposeIntermediateTensorInfo(permutedX),reverseTransposedResult}return result}const Cumprod_cumprodConfig={kernelName:dist.jj_,backendName:"webgl",kernelFunc:function kernels_Cumprod_cumprod(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,exclusive,reverse}=attrs;return cumImpl(CumOpType.Prod,x,backend,axis,exclusive,reverse)}};const Cumsum_cumsumConfig={kernelName:dist.nY8,backendName:"webgl",kernelFunc:function kernels_Cumsum_cumsum(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,exclusive,reverse}=attrs;return cumImpl(CumOpType.Sum,x,backend,axis,exclusive,reverse)}};const DenseBincount_denseBincountConfig={kernelName:dist.wNW,backendName:"webgl",kernelFunc:function DenseBincount_denseBincount(args){const{inputs,backend,attrs}=args,{x,weights}=inputs,{size,binaryOutput}=attrs;if(1===x.shape.length){const xVals=backend.readSync(x.dataId),weightsVals=backend.readSync(weights.dataId),outVals=bincountImplCPU(xVals,weightsVals,weights.dtype,weights.shape,size);return backend.makeTensorInfo([size],weights.dtype,outVals)}if(2===x.shape.length){const xBuf=backend.bufferSync(x),weightsBuf=backend.bufferSync(weights),outBuf=bincountReduceImplCPU(xBuf,weightsBuf,size,binaryOutput);return backend.makeTensorInfo(outBuf.shape,weights.dtype,outBuf.values)}throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${x.shape.length}.`)}};class DepthToSpaceProgram{constructor(outputShape,blockSize,dataFormat){this.variableNames=["x"],this.outputShape=[],this.outputShape=outputShape,this.blockSize=blockSize,this.dataFormat=dataFormat,this.userCode=`\n    void main() {\n      ivec4 coords = getOutputCoords();\n      int b = coords[0];\n      int h = ${this.getHeightCoordString()};\n      int w = ${this.getWidthCoordString()};\n      int d = ${this.getDepthCoordString()};\n\n      int in_h = h / ${blockSize};\n      int offset_h = imod(h, ${blockSize});\n      int in_w = w / ${blockSize};\n      int offset_w = imod(w, ${blockSize});\n      int offset_d = (offset_h * ${blockSize} + offset_w) *\n        ${this.getOutputDepthSize()};\n      int in_d = d + offset_d;\n\n      float result = ${this.getInputSamplingString()};\n      setOutput(result);\n    }\n  `}getHeightCoordString(){return"NHWC"===this.dataFormat?"coords[1]":"coords[2]"}getWidthCoordString(){return"NHWC"===this.dataFormat?"coords[2]":"coords[3]"}getDepthCoordString(){return"NHWC"===this.dataFormat?"coords[3]":"coords[1]"}getOutputDepthSize(){return"NHWC"===this.dataFormat?this.outputShape[3]:this.outputShape[1]}getInputSamplingString(){return"NHWC"===this.dataFormat?"getX(b, in_h, in_w, in_d)":"getX(b, in_d, in_h, in_w)"}}const DepthToSpace_depthToSpaceConfig={kernelName:dist.TMz,backendName:"webgl",kernelFunc:function DepthToSpace_depthToSpace(args){const{inputs,backend,attrs}=args,{x}=inputs,{blockSize,dataFormat}=attrs,batchSize=x.shape[0],outputHeight=("NHWC"===dataFormat?x.shape[1]:x.shape[2])*blockSize,outputWidth=("NHWC"===dataFormat?x.shape[2]:x.shape[3])*blockSize,outputDepth=("NHWC"===dataFormat?x.shape[3]:x.shape[1])/(blockSize*blockSize),program=new DepthToSpaceProgram("NHWC"===dataFormat?[batchSize,outputHeight,outputWidth,outputDepth]:[batchSize,outputDepth,outputHeight,outputWidth],blockSize,dataFormat);return backend.runWebGLProgram(program,[x],x.dtype)}};class DepthwiseConv2DProgram{constructor(convInfo,addBias=!1,activation=null,hasPreluActivation=!1,hasLeakyReluAlpha=!1){this.variableNames=["x","W"],this.customUniforms=[{name:"pads",type:"ivec2"},{name:"strides",type:"ivec2"},{name:"dilations",type:"ivec2"},{name:"inDims",type:"ivec2"}],this.outputShape=convInfo.outShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length);const filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,channelMul=convInfo.outChannels/convInfo.inChannels;let activationSnippet="",applyActivationSnippet="";activation&&(activationSnippet=hasPreluActivation?`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${activation}\n        }`:hasLeakyReluAlpha?`float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ${activation}\n        }`:`\n          float activation(float x) {\n            ${activation}\n          }\n        `,applyActivationSnippet="result = activation(result);");const addBiasSnippet=addBias?"result += getBiasAtOutCoords();":"";addBias&&this.variableNames.push("bias"),hasPreluActivation&&this.variableNames.push("preluActivationWeights"),hasLeakyReluAlpha&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n      ${activationSnippet}\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${channelMul};\n        int q = d2 - d1 * ${channelMul};\n\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\n        for (int wR = 0; wR < ${filterHeight}; wR++) {\n          int xR = xRCorner + wR * dilations[0];\n\n          if (xR < 0 || xR >= inDims[0]) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${filterWidth}; wC++) {\n            int xC = xCCorner + wC * dilations[1];\n\n            if (xC < 0 || xC >= inDims[1]) {\n              continue;\n            }\n\n            float xVal = getX(batch, xR, xC, d1);\n            float wVal = getW(wR, wC, d1, q);\n            dotProd += xVal * wVal;\n          }\n        }\n\n        float result = dotProd;\n        ${addBiasSnippet}\n        ${applyActivationSnippet}\n        setOutput(result);\n      }\n    `}}class DepthwiseConvPacked2DProgram{constructor(convInfo,addBias=!1,activation=null,hasPreluActivation=!1,hasLeakyReluAlpha=!1){this.variableNames=["x","W"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"pads",type:"ivec2"},{name:"strides",type:"ivec2"},{name:"dilations",type:"ivec2"},{name:"inDims",type:"ivec2"}],this.outputShape=convInfo.outShape,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length);const channelMul=convInfo.outChannels/convInfo.inChannels,padLeft=convInfo.padInfo.left,strideWidth=convInfo.strideWidth,dilationWidth=convInfo.dilationWidth,filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,texelsAcross=filterWidth;let mainLoop="\n      int xR; int xC; int xCOffset;\n      vec4 wTexel; vec4 previous; vec4 final;";for(let c=0;c<filterWidth;c++)mainLoop+=`\n          vec4 xTexelC${2*c};\n          int xTexelC${2*c}Ready;\n          vec4 xTexelC${2*c+1};\n          int xTexelC${2*c+1}Ready;\n          vec4 xC${c};`;mainLoop+=`\n    for (int r = 0; r < ${filterHeight}; r++) {\n      `;for(let c=0;c<filterWidth;c++)mainLoop+=`\n          xTexelC${2*c} = vec4(0.0);\n          xTexelC${2*c}Ready = 0;\n          xTexelC${2*c+1} = vec4(0.0);\n          xTexelC${2*c+1}Ready = 0;\n          xC${c} = vec4(0.0);`;mainLoop+="\n        xR = xRCorner + r * dilations[0];\n        if (xR >=0 && xR < inDims[0]) {\n      ";for(let texelC=0;texelC<(texelsAcross+1)/2;texelC++){const colIndex=2*texelC;if(mainLoop+=`\n          xC = xCCorner + ${colIndex*dilationWidth};\n          `,1===strideWidth){if(colIndex<filterWidth&&(padLeft%2==1?(mainLoop+=`\n                xCOffset = xC + 1;\n                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                  xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${colIndex}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex}Ready = 1;\n                }\n              `,mainLoop+=1===dilationWidth&&colIndex>0?`\n                xC${colIndex} = vec4(xTexelC${colIndex-2}.zw, xTexelC${colIndex}.xy);\n                `:`\n                  xCOffset = xC + 1 - 2;\n\n                  if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                    previous = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= inDims[1]) {\n                      previous.zw = vec2(0.0);\n                    }\n\n                    xC${colIndex} = vec4(previous.zw, xTexelC${colIndex}.xy);\n                  } else {\n                    xC${colIndex} = vec4(0.0, 0.0, xTexelC${colIndex}.xy);\n                  }\n                  `):mainLoop+=`\n                if (xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                  xTexelC${colIndex} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= inDims[1]) {\n                    xTexelC${colIndex}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex}Ready = 1;\n                }\n\n                xC${colIndex} = xTexelC${colIndex};\n                `,colIndex+1<filterWidth)){const nextTexelOffset=padLeft%2==0?dist.ZSL.nearestLargerEven(dilationWidth):dilationWidth;dilationWidth%2==0&&padLeft%2==1||dilationWidth%2!=0&&padLeft%2!=1?(mainLoop+=`\n                  xCOffset = xC + imod(pads[1], 2) + ${nextTexelOffset};\n\n                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex+1}Ready == 0) {\n                    xTexelC${colIndex+1} = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= inDims[1]) {\n                      xTexelC${colIndex+1}.zw = vec2(0.0);\n                    }\n                    xTexelC${colIndex+1}Ready = 1;\n                  }\n                  `,mainLoop+=dilationWidth>1?`\n                    xCOffset -= 2;\n                    if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                     previous = getX(batch, xR, xCOffset, d1);\n                     xC${colIndex+1} = vec4(previous.zw, xTexelC${colIndex+1}.xy);\n                    } else {\n                     xC${colIndex+1} = vec4(0.0, 0.0, xTexelC${colIndex+1}.xy);\n                    }\n                    `:`\n                    xC${colIndex+1} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex+1}.xy);\n                    `):mainLoop+=1===nextTexelOffset?`\n                    xC${colIndex+1} = xTexelC${colIndex};\n                    `:`\n                    xCOffset = xC + ${nextTexelOffset};\n\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex+1}Ready == 0) {\n                      xTexelC${colIndex+1} = getX(batch, xR, xCOffset, d1);\n                      if (xCOffset + 1 >= inDims[1]) {\n                        xTexelC${colIndex+1}.zw = vec2(0.0);\n                      }\n                      xTexelC${colIndex+1}Ready = 1;\n                    }\n\n                    xC${colIndex+1} = xTexelC${colIndex+1};\n                    `}}else colIndex<filterWidth&&(padLeft%2==1?(mainLoop+=`\n                xCOffset = xC + 1 - strides[1];\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                  xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${colIndex}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex}Ready = 1;\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${colIndex+1}Ready == 0) {\n                  xTexelC${colIndex+1} = getX(batch, xR, xC + 1, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xC + 2 >= inDims[1]) {\n                    xTexelC${colIndex+1}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex+1}Ready = 1;\n                }\n\n                xC${colIndex} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex+1}.zw);\n              `,colIndex+1<filterWidth&&(mainLoop+=`\n                  final = vec4(0.0);\n                  xCOffset = xC + 1 + strides[1];\n                  if(xCOffset >= 0 && xCOffset < inDims[1]) {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xC${colIndex+1} = vec4(xTexelC${colIndex+1}.xy, final.xy);\n                `)):(mainLoop+=`\n                if(xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                  xTexelC${colIndex} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= inDims[1]) {\n                    xTexelC${colIndex}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex}Ready = 1;\n                }\n\n                xCOffset = xC + strides[1];\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex+1}Ready == 0) {\n                  xTexelC${colIndex+1} = getX(batch, xR, xCOffset, d1);\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${colIndex+1}.zw = vec2(0.);\n                  }\n                  xTexelC${colIndex+1}Ready = 1;\n                }\n\n                xC${colIndex} = vec4(\n                  xTexelC${colIndex}.xy, xTexelC${colIndex+1}.xy);\n              `,colIndex+1<filterWidth&&(mainLoop+=`\n                  xC${colIndex+1} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex+1}.zw);\n                `)));colIndex<filterWidth&&(mainLoop+=`\n            wTexel = getW(r, ${colIndex}, d1, q);\n            dotProd += xC${colIndex} * vec4(wTexel.xz, wTexel.xz);\n          `,colIndex+1<filterWidth&&(mainLoop+=`\n              wTexel = getW(r, ${colIndex+1}, d1, q);\n              dotProd += xC${colIndex+1} * vec4(wTexel.xz, wTexel.xz);\n            `))}mainLoop+="\n    }\n  ",mainLoop+="\n      }\n    ";let activationSnippet="",applyActivationSnippet="";activation&&(activationSnippet=hasPreluActivation?`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${activation}\n        }`:hasLeakyReluAlpha?`vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${activation}\n        }`:`vec4 activation(vec4 x) {\n          ${activation}\n        }`,applyActivationSnippet="result = activation(result);");const addBiasSnippet=addBias?"result += getBiasAtOutCoords();":"";addBias&&this.variableNames.push("bias"),hasPreluActivation&&this.variableNames.push("preluActivationWeights"),hasLeakyReluAlpha&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n      ${activationSnippet}\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${channelMul};\n        int q = d2 - d1 * ${channelMul};\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n        vec4 dotProd = vec4(0.000000000000001);\n\n        ${mainLoop}\n\n        vec4 result = dotProd - vec4(0.000000000000001);\n        ${addBiasSnippet}\n        ${applyActivationSnippet}\n        setOutput(result);\n      }\n    `}}const DepthwiseConv2dNative_depthwiseConv2dNativeConfig={kernelName:dist.tGH,backendName:"webgl",kernelFunc:function DepthwiseConv2dNative_depthwiseConv2dNative(args){const{inputs,backend,attrs}=args,{x,filter}=inputs,{strides,pad,dilations,dimRoundingMode}=attrs;let $dilations=dilations;null==$dilations&&($dilations=[1,1]),dist.ZSL.assert(dist.C0T.eitherStridesOrDilationsAreOne(strides,$dilations),()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);const convInfo=dist.C0T.computeConv2DInfo(x.shape,filter.shape,strides,$dilations,pad,dimRoundingMode,!0);let program;program=(0,dist._K2)().getBool("WEBGL_PACK_DEPTHWISECONV")&&convInfo.strideWidth<=2&&convInfo.outChannels/convInfo.inChannels===1?new DepthwiseConvPacked2DProgram(convInfo):new DepthwiseConv2DProgram(convInfo);const customValues=[[convInfo.padInfo.top,convInfo.padInfo.left],[convInfo.strideHeight,convInfo.strideWidth],[convInfo.dilationHeight,convInfo.dilationWidth],[convInfo.inHeight,convInfo.inWidth]];return backend.runWebGLProgram(program,[x,filter],"float32",customValues)}};class DepthwiseConv2DDerFilterProgram{constructor(convInfo){this.variableNames=["x","dy"],this.outputShape=convInfo.filterShape;const strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,padTop=convInfo.padInfo.top,padLeft=convInfo.padInfo.left,channelMul=convInfo.outChannels/convInfo.inChannels;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int dm = coords.w;\n        int d2 = d1 * ${channelMul} + dm;\n\n        float dotProd = 0.0;\n\n        // TO DO: Vec4 over the batch size\n        for (int b = 0; b < ${convInfo.batchSize}; b++) {\n          for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {\n            int xR = wR + yR * ${strideHeight} - ${padTop};\n\n            if (xR < 0 || xR >= ${convInfo.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {\n              int xC = wC + yC * ${strideWidth} - ${padLeft};\n\n              if (xC < 0 || xC >= ${convInfo.inWidth}) {\n                continue;\n              }\n\n              float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class DepthwiseConv2DDerInputProgram{constructor(convInfo){this.variableNames=["dy","W"],this.outputShape=convInfo.inShape;const filterHeight=convInfo.filterHeight,filterWidth=convInfo.filterWidth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,padTop=filterHeight-1-convInfo.padInfo.top,padLeft=filterWidth-1-convInfo.padInfo.left,channelMul=convInfo.outChannels/convInfo.inChannels;this.userCode=`\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n        ivec2 dyCorner = coords.yz - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        float dotProd = 0.0;\n\n        for (int wR = 0; wR < ${filterHeight}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${filterHeight} - 1 - wR;\n\n          for (int wC = 0; wC < ${filterWidth}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${filterWidth} - 1 - wC;\n\n            // TO DO: Vec4 over the channelMul\n            for (int dm = 0; dm < ${channelMul}; dm++) {\n              int d2 = d1 * ${channelMul} + dm;\n              float xValue = getDy(batch, idyR, idyC, d2);\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\n              dotProd += xValue * wValue;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}const DepthwiseConv2dNativeBackpropFilter_depthwiseConv2dNativeBackpropFilterConfig={kernelName:dist.X$8,backendName:"webgl",kernelFunc:function DepthwiseConv2dNativeBackpropFilter_depthwiseConv2dNativeBackpropFilter(args){const{inputs,backend,attrs}=args,{x,dy}=inputs,{strides,dilations,pad,dimRoundingMode,filterShape}=attrs,convInfo=dist.C0T.computeConv2DInfo(x.shape,filterShape,strides,dilations,pad,dimRoundingMode,!0),program=new DepthwiseConv2DDerFilterProgram(convInfo);return backend.runWebGLProgram(program,[x,dy],"float32")}};const DepthwiseConv2dNativeBackpropInput_depthwiseConv2dNativeBackpropInputConfig={kernelName:dist.nVu,backendName:"webgl",kernelFunc:function DepthwiseConv2dNativeBackpropInput_depthwiseConv2dNativeBackpropInput(args){const{inputs,backend,attrs}=args,{dy,filter}=inputs,{strides,dilations,pad,dimRoundingMode,inputShape}=attrs,convInfo=dist.C0T.computeConv2DInfo(inputShape,filter.shape,strides,dilations,pad,dimRoundingMode,!0),program=new DepthwiseConv2DDerInputProgram(convInfo);return backend.runWebGLProgram(program,[dy,filter],"float32")}};class DiagProgram{constructor(size){this.variableNames=["X"],this.outputShape=[size,size],this.userCode="\n      void main() {\n          ivec2 coords = getOutputCoords();\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\n          setOutput(val);\n      }\n    "}}const Diag_diagConfig={kernelName:dist.ORI,backendName:"webgl",kernelFunc:function Diag_diag(args){const{inputs,backend}=args,{x}=inputs,outShape=[...x.shape,...x.shape],xSize=dist.ZSL.sizeFromShape(x.shape),flat=kernels_Reshape_reshape({inputs:{x},backend,attrs:{shape:[xSize]}}),program=new DiagProgram(xSize),res=backend.runWebGLProgram(program,[flat],flat.dtype),out=kernels_Reshape_reshape({inputs:{x:res},backend,attrs:{shape:outShape}});return backend.disposeIntermediateTensorInfo(flat),backend.disposeIntermediateTensorInfo(res),out}};class Dilation2DProgram{constructor(convInfo){this.variableNames=["x","W"],this.outputShape=convInfo.outShape;const{inHeight,inWidth,padInfo,strideHeight,strideWidth,filterHeight,filterWidth,dilationHeight,dilationWidth}=convInfo,{top:padTop,left:padLeft}=padInfo;this.userCode=`\n      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n      const float neg_infinity = -3.4e38;\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.w;\n        ivec2 outTopLeftCorner =\n            coords.yz * strides - pads;\n        int hBeg = outTopLeftCorner.x;\n        int wBeg = outTopLeftCorner.y;\n\n        float curVal = neg_infinity;\n        for (int h = 0; h < ${filterHeight}; h++) {\n          int hIn = hBeg + h * ${dilationHeight};\n\n          if (hIn >= 0 && hIn < ${inHeight}) {\n            for (int w = 0; w < ${filterWidth}; w++) {\n              int wIn = wBeg + w * ${dilationWidth};\n\n              if (wIn >= 0 && wIn < ${inWidth}) {\n                float xVal = getX(batch, hIn, wIn, d1);\n                float wVal = getW(h, w, d1);\n\n                float val = xVal + wVal;\n                if (val > curVal) {\n                  curVal = val;\n                }\n              }\n            }\n          }\n        }\n\n        float result = curVal;\n        setOutput(result);\n      }\n    `}}const Dilation2D_dilation2DConfig={kernelName:dist.jxD,backendName:"webgl",kernelFunc:function dilation2D(args){const{inputs,backend,attrs}=args,{x,filter}=inputs,{strides,pad,dilations}=attrs,convInfo=dist.C0T.computeDilation2DInfo(x.shape,filter.shape,strides,pad,"NHWC",dilations);let out;const program=new Dilation2DProgram(convInfo);out=backend.runWebGLProgram(program,[x,filter],"float32");const outReshaped=kernels_Reshape_reshape({inputs:{x:out},backend,attrs:{shape:convInfo.outShape}});return backend.disposeIntermediateTensorInfo(out),outReshaped}};const Einsum_einsumConfig={kernelName:dist.Qgm,backendName:"webgl",kernelFunc:function Einsum_einsum(args){const{inputs,backend,attrs}=args,{equation}=attrs,tensors=inputs,{allDims,summedDims,idDims}=dist.C0T.decodeEinsumEquation(equation,tensors.length);dist.C0T.checkEinsumDimSizes(allDims.length,idDims,tensors);const{path,steps}=dist.C0T.getEinsumComputePath(summedDims,idDims),nSteps=steps.length;let out=null,numDimsRemaining=allDims.length;const tensorsToDispose=[];for(let i=0;i<nSteps;++i){for(const idTerm of steps[i]){const{permutationIndices:perm,expandDims:dimsToExpand}=dist.C0T.getEinsumPermutation(numDimsRemaining,idDims[idTerm]);let x;dist.C0T.isIdentityPermutation(perm)?x=tensors[idTerm]:(x=kernels_Transpose_transpose({inputs:{x:tensors[idTerm]},backend,attrs:{perm}}),tensorsToDispose.push(x));const targetShape=x.shape.slice();for(let k=0;k<dimsToExpand.length;++k)targetShape.splice(dimsToExpand[k],0,1);dist.ZSL.arraysEqual(x.shape,targetShape)||(x=kernels_Reshape_reshape({inputs:{x},backend,attrs:{shape:targetShape}}),tensorsToDispose.push(x)),null===out?out=x:(out=kernels_Multiply_multiply({inputs:{a:x,b:out},backend}),tensorsToDispose.push(out))}i<nSteps-1&&(path[i]>=0&&(out=kernels_Sum_sum({inputs:{x:out},backend,attrs:{axis:path[i]-(allDims.length-numDimsRemaining),keepDims:!1}}),tensorsToDispose.push(out)),numDimsRemaining--)}for(const tensorInfo of tensorsToDispose)tensorInfo!==out&&backend.disposeIntermediateTensorInfo(tensorInfo);return out}},kernels_Elu_elu=kernel_funcs_utils_unaryKernelFunc({opSnippet:"return (x >= 0.0) ? x : (exp(x) - 1.0);",packedOpSnippet:"\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n"}),Elu_eluConfig={kernelName:dist.Pah,backendName:"webgl",kernelFunc:kernels_Elu_elu},kernels_EluGrad_eluGradConfig={kernelName:dist.rsH,backendName:"webgl",kernelFunc:args=>{const{inputs,backend}=args,{dy,y}=inputs,program=(0,dist._K2)().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram("\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\n",dy.shape,y.shape):new BinaryOpProgram("return (b >= 0.0) ? a : a * (b + 1.0);",dy.shape,y.shape);return backend.runWebGLProgram(program,[dy,y],dy.dtype)}},kernels_Equal_equal=kernel_funcs_utils_binaryKernelFunc({opSnippet:"return float(a == b);",packedOpSnippet:"\n  return vec4(equal(a, b));\n",dtype:"bool",cpuKernelImpl:equalImplCPU}),Equal_equalConfig={kernelName:dist.BRl,backendName:"webgl",kernelFunc:kernels_Equal_equal},kernels_Erf_erf=kernel_funcs_utils_unaryKernelFunc({opSnippet:`\n  // Error function is calculated approximately with elementary function.\n  // See "Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables", Abramowitz and Stegun.\n  float p = ${dist.C0T.ERF_P};\n  float a1 = ${dist.C0T.ERF_A1};\n  float a2 = ${dist.C0T.ERF_A2};\n  float a3 = ${dist.C0T.ERF_A3};\n  float a4 = ${dist.C0T.ERF_A4};\n  float a5 = ${dist.C0T.ERF_A5};\n\n  float sign = sign(x);\n  x = abs(x);\n  float t = 1.0 / (1.0 + p * x);\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\n`}),Erf_erfConfig={kernelName:dist._s9,backendName:"webgl",kernelFunc:kernels_Erf_erf},kernels_Exp_exp=kernel_funcs_utils_unaryKernelFunc({opSnippet:"if (isnan(x)) return x;\n  return exp(x);\n",packedOpSnippet:"\n  vec4 result = exp(x);\n  bvec4 isNaN = isnan(x);\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",cpuKernelImpl:expImplCPU,dtype:"float32"}),Exp_expConfig={kernelName:dist.ox3,backendName:"webgl",kernelFunc:kernels_Exp_exp};function kernels_ExpandDims_expandDims(args){const{inputs,attrs,backend}=args,{dim}=attrs,{input}=inputs,inputRank=input.shape.length,newShape=input.shape.slice();let $dim=dim;return dim<0&&(dist.ZSL.assert(-(inputRank+1)<=dim,()=>`Axis must be in the interval [${-(inputRank+1)}, ${inputRank}]`),$dim=inputRank+dim+1),newShape.splice($dim,0,1),kernels_Reshape_reshape({inputs:{x:input},backend,attrs:{shape:newShape}})}const ExpandDims_expandDimsConfig={kernelName:dist.ybN,backendName:"webgl",kernelFunc:kernels_ExpandDims_expandDims},EXPM1="return exp(x) - 1.0;",kernels_Expm1_expm1=kernel_funcs_utils_unaryKernelFunc({opSnippet:EXPM1,packedOpSnippet:EXPM1,cpuKernelImpl:expm1ImplCPU}),Expm1_expm1Config={kernelName:dist.ybj,backendName:"webgl",kernelFunc:kernels_Expm1_expm1};class FFTProgram{constructor(component,inputShape,inverse){this.variableNames=["real","imag"];const innerDim=inputShape[1];this.outputShape=inputShape;const exponentMultiplierSnippet=inverse?`2.0 * ${Math.PI}`:`-2.0 * ${Math.PI}`,resultDenominator=inverse?`${innerDim}.0`:"1.0";let opString;if("real"===component)opString="return real * expR - imag * expI;";else{if("imag"!==component)throw new Error(`FFT component must be either "real" or "imag", got ${component}.`);opString="return real * expI + imag * expR;"}this.userCode=`\n      const float exponentMultiplier = ${exponentMultiplierSnippet};\n\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\n        ${opString}\n      }\n\n      float mulMatDFT(int batch, int index) {\n        float indexRatio = float(index) / float(${innerDim});\n        float exponentMultiplierTimesIndexRatio =\n            exponentMultiplier * indexRatio;\n\n        float result = 0.0;\n\n        for (int i = 0; i < ${innerDim}; i++) {\n          // x = (-2|2 * PI / N) * index * i;\n          float x = exponentMultiplierTimesIndexRatio * float(i);\n          float expR = cos(x);\n          float expI = sin(x);\n          float real = getReal(batch, i);\n          float imag = getImag(batch, i);\n\n          result +=\n              unaryOpComplex(real, expR, imag, expI) / ${resultDenominator};\n        }\n\n        return result;\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        setOutput(mulMatDFT(coords[0], coords[1]));\n      }\n    `}}function FFT_impl_fftImpl(x,inverse,backend){const xData=backend.texData.get(x.dataId),inputSize=dist.ZSL.sizeFromShape(x.shape),innerDimensionSize=x.shape[x.shape.length-1],input2D=kernels_Reshape_reshape({inputs:{x},backend,attrs:{shape:[inputSize/innerDimensionSize,innerDimensionSize]}}),xShape=input2D.shape,realProgram=new FFTProgram("real",xShape,inverse),imagProgram=new FFTProgram("imag",xShape,inverse),inputs=[{dataId:xData.complexTensorInfos.real.dataId,dtype:xData.complexTensorInfos.real.dtype,shape:xShape},{dataId:xData.complexTensorInfos.imag.dataId,dtype:xData.complexTensorInfos.imag.dtype,shape:xShape}],realPart=backend.runWebGLProgram(realProgram,inputs,"float32"),imagPart=backend.runWebGLProgram(imagProgram,inputs,"float32"),complexOutput=Complex_complex({inputs:{real:realPart,imag:imagPart},backend});backend.disposeIntermediateTensorInfo(realPart),backend.disposeIntermediateTensorInfo(imagPart);const complexOutputReshaped=kernels_Reshape_reshape({inputs:{x:complexOutput},backend,attrs:{shape:x.shape}});return backend.disposeIntermediateTensorInfo(input2D),backend.disposeIntermediateTensorInfo(complexOutput),complexOutputReshaped}const FFT_fftConfig={kernelName:dist.rGP,backendName:"webgl",kernelFunc:function kernels_FFT_fft(args){const{inputs,backend}=args,{input}=inputs;return FFT_impl_fftImpl(input,!1,backend)}};class FillProgram{constructor(shape,value){this.outputShape=[],this.customUniforms=[{name:"value",type:"float"}],this.variableNames=["x"],this.outputShape=shape,this.userCode="\n      void main() {\n        // Input can be obtained from uniform value.\n        setOutput(value);\n      }\n    "}}function Fill_fill(args){const{backend,attrs}=args,{shape,value}=attrs;let{dtype}=attrs;if(dtype=dtype||dist.ZSL.inferDtype(value),"string"===dtype){const values=dist.ZSL.getArrayFromDType(dtype,dist.ZSL.sizeFromShape(shape));return values.fill(value),backend.makeTensorInfo(shape,dtype,values)}{const program=new FillProgram(shape,value),customValues=[[value]];return backend.runWebGLProgram(program,[],dtype,customValues)}}const Fill_fillConfig={kernelName:dist.SQl,backendName:"webgl",kernelFunc:Fill_fill};class FlipLeftRightProgram{constructor(imageShape){this.variableNames=["Image"],this.outputShape=[];const imageWidth=imageShape[2];this.outputShape=imageShape,this.userCode=`\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n\n          int coordX = ${imageWidth} - x - 1;\n          float outputValue;\n          if(coordX >= 0 && coordX < ${imageWidth}) {\n            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);\n          } else {\n            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}}const FlipLeftRight_flipLeftRightConfig={kernelName:dist.BxF,backendName:"webgl",kernelFunc:({inputs,backend})=>{const{image}=inputs,webglBackend=backend,program=new FlipLeftRightProgram(image.shape);return webglBackend.runWebGLProgram(program,[image],image.dtype)}},FLOOR="return floor(x);",kernels_Floor_floor=kernel_funcs_utils_unaryKernelFunc({opSnippet:FLOOR,packedOpSnippet:FLOOR,cpuKernelImpl:floorImplCPU}),Floor_floorConfig={kernelName:dist.ZgB,backendName:"webgl",kernelFunc:kernels_Floor_floor},kernels_FloorDiv_floorDiv=kernel_funcs_utils_binaryKernelFunc({opSnippet:"\n  float s = sign(a) * sign(b);\n  int ia = round(a);\n  int ib = round(b);\n  if (ib != 0) {\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n    return float(idiv(ia, ib, s));\n  } else {\n    return NAN;\n  }\n",packedOpSnippet:"\n  ivec4 ia = round(a);\n  ivec4 ib = round(b);\n  bvec4 cond = notEqual(ib, ivec4(0));\n  ivec4 result = ivec4(0);\n  vec4 s = sign(a) * sign(b);\n\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n  if (cond[0]) {\n    result[0] = idiv(ia[0], ib[0], s[0]);\n  }\n  if (cond[1]) {\n    result[1] = idiv(ia[1], ib[1], s[1]);\n  }\n  if (cond[2]) {\n    result[2] = idiv(ia[2], ib[2], s[2]);\n  }\n  if (cond[3]) {\n    result[3] = idiv(ia[3], ib[3], s[3]);\n  }\n  return vec4(result);\n",dtype:"int32"}),FloorDiv_floorDivConfig={kernelName:dist.ElG,backendName:"webgl",kernelFunc:kernels_FloorDiv_floorDiv};class FromPixelsProgram{constructor(outputShape){this.variableNames=["A"];const glsl=getGlslDifferences(),[height,width]=outputShape;this.outputShape=outputShape,this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${width}.0, ${height}.0);\n\n        vec4 values = ${glsl.texture2D}(A, uv);\n        float value;\n        if (depth == 0) {\n          value = values.r;\n        } else if (depth == 1) {\n          value = values.g;\n        } else if (depth == 2) {\n          value = values.b;\n        } else if (depth == 3) {\n          value = values.a;\n        }\n\n        setOutput(floor(value * 255.0 + 0.5));\n      }\n    `}}class FromPixelsPackedProgram{constructor(outputShape){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0;const glsl=getGlslDifferences(),[height,width]=outputShape;this.outputShape=outputShape,this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n\n        vec4 result = vec4(0.);\n\n        for(int row=0; row<=1; row++) {\n          for(int col=0; col<=1; col++) {\n            texC = coords[1] + row;\n            depth = coords[2] + col;\n\n            vec2 uv = (vec2(texC, texR) + halfCR) /\n                       vec2(${width}.0, ${height}.0);\n            vec4 values = ${glsl.texture2D}(A, uv);\n            float value;\n            if (depth == 0) {\n              value = values.r;\n            } else if (depth == 1) {\n              value = values.g;\n            } else if (depth == 2) {\n              value = values.b;\n            } else if (depth == 3) {\n              value = values.a;\n            }\n\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\n          }\n        }\n\n        ${glsl.output} = result;\n      }\n    `}}const fromPixelsConfig={kernelName:dist.awo,backendName:"webgl",kernelFunc:function fromPixels(args){const{inputs,backend,attrs}=args;let{pixels}=inputs;const{numChannels}=attrs,isVideo="undefined"!=typeof HTMLVideoElement&&pixels instanceof HTMLVideoElement,isImage="undefined"!=typeof HTMLImageElement&&pixels instanceof HTMLImageElement,[width,height]=isVideo?[pixels.videoWidth,pixels.videoHeight]:[pixels.width,pixels.height],texShape=[height,width],outShape=[height,width,numChannels];if(isImage||isVideo){const newWillReadFrequently=(0,dist._K2)().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");null!=fromPixels2DContext&&newWillReadFrequently===willReadFrequently||(willReadFrequently=newWillReadFrequently,fromPixels2DContext=document.createElement("canvas").getContext("2d",{willReadFrequently})),fromPixels2DContext.canvas.width=width,fromPixels2DContext.canvas.height=height,fromPixels2DContext.drawImage(pixels,0,0,width,height),pixels=fromPixels2DContext.canvas}const tempPixelHandle=backend.makeTensorInfo(texShape,"int32");backend.texData.get(tempPixelHandle.dataId).usage=TextureUsage.PIXELS,backend.gpgpu.uploadPixelDataToTexture(backend.getTexture(tempPixelHandle.dataId),pixels);const program=(0,dist._K2)().getBool("WEBGL_PACK")?new FromPixelsPackedProgram(outShape):new FromPixelsProgram(outShape),res=backend.runWebGLProgram(program,[tempPixelHandle],"int32");return backend.disposeData(tempPixelHandle.dataId),res}};let fromPixels2DContext,willReadFrequently=(0,dist._K2)().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");const FusedConv2D_fusedConv2DConfig={kernelName:dist.aAr,backendName:"webgl",kernelFunc:function fusedConv2d(args){const{inputs,backend,attrs}=args,{x,filter,bias,preluActivationWeights}=inputs,{strides,pad,dataFormat,dilations,dimRoundingMode,activation,leakyreluAlpha}=attrs,$dataFormat=dist.C0T.convertConv2DDataFormat(dataFormat),convInfo=dist.C0T.computeConv2DInfo(x.shape,filter.shape,strides,dilations,pad,dimRoundingMode,!1,$dataFormat);let out;const intermediates=[],hasBias=null!=bias,hasPreluActivationWeights=null!=preluActivationWeights,hasLeakyreluAlpha="leakyrelu"===activation,prepareInputs=()=>{const inputs=[x,filter],alignInputWithDataFormat=(input,dataFormat)=>{if("NCHW"===dataFormat&&1===input.shape.length&&1!==input.shape[0]){const alignedInput=kernels_Reshape_reshape({inputs:{x:input},backend,attrs:{shape:[input.shape[0],1,1]}});return intermediates.push(alignedInput),alignedInput}return input};if(hasBias&&inputs.push(alignInputWithDataFormat(bias,dataFormat)),hasPreluActivationWeights&&inputs.push(alignInputWithDataFormat(preluActivationWeights,dataFormat)),hasLeakyreluAlpha){const $leakyreluAlpha=backend.makeTensorInfo([],"float32",dist.ZSL.createScalarValue(leakyreluAlpha,"float32"));inputs.push($leakyreluAlpha),intermediates.push($leakyreluAlpha)}return inputs};if(1!==convInfo.filterHeight||1!==convInfo.filterWidth||1!==convInfo.dilationHeight||1!==convInfo.dilationWidth||1!==convInfo.strideHeight||1!==convInfo.strideWidth||"SAME"!==convInfo.padInfo.type&&"VALID"!==convInfo.padInfo.type)if(convInfo.strideWidth<=2&&"channelsLast"===$dataFormat&&(0,dist._K2)().getBool("WEBGL_EXP_CONV")){const fusedActivation=activation?mapActivationToShaderProgram(activation,!0):null,program=new Conv2DPackedProgram(convInfo,hasBias,fusedActivation,hasPreluActivationWeights,hasLeakyreluAlpha),customValues=[[convInfo.padInfo.top,convInfo.padInfo.left],[convInfo.strideHeight,convInfo.strideWidth],[convInfo.dilationHeight,convInfo.dilationWidth],[convInfo.inHeight,convInfo.inWidth]],inputs=prepareInputs();out=backend.runWebGLProgram(program,inputs,"float32",customValues)}else if((0,dist._K2)().getBool("WEBGL_CONV_IM2COL"))out=conv2dWithIm2Row({x,filter,convInfo,backend,bias,activation,preluActivationWeights,leakyreluAlpha});else{const fusedActivation=activation?mapActivationToShaderProgram(activation,!1):null,program=new Conv2DProgram(convInfo,hasBias,fusedActivation,hasPreluActivationWeights,hasLeakyreluAlpha),inputs=prepareInputs();out=backend.runWebGLProgram(program,inputs,"float32")}else out=conv2dByMatMul({x,filter,convInfo,backend,bias,activation,preluActivationWeights,leakyreluAlpha});const outReshaped=kernels_Reshape_reshape({inputs:{x:out},backend,attrs:{shape:convInfo.outShape}});return intermediates.push(out),intermediates.forEach(t=>backend.disposeIntermediateTensorInfo(t)),outReshaped}};const FusedDepthwiseConv2D_fusedDepthwiseConv2DConfig={kernelName:dist.T7M,backendName:"webgl",kernelFunc:function FusedDepthwiseConv2D_fusedDepthwiseConv2D(args){const{inputs,backend,attrs}=args,{x,filter,bias,preluActivationWeights}=inputs,{strides,pad,dilations,dimRoundingMode,activation,leakyreluAlpha}=attrs,intermediates=[];let $dilations=dilations;null==$dilations&&($dilations=[1,1]),dist.ZSL.assert(dist.C0T.eitherStridesOrDilationsAreOne(strides,$dilations),()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);const convInfo=dist.C0T.computeConv2DInfo(x.shape,filter.shape,strides,$dilations,pad,dimRoundingMode,!0),shouldPackDepthwiseConv=(0,dist._K2)().getBool("WEBGL_PACK_DEPTHWISECONV")&&convInfo.strideWidth<=2&&convInfo.outChannels/convInfo.inChannels===1,fusedActivation=activation?mapActivationToShaderProgram(activation,shouldPackDepthwiseConv):null,programInputs=[x,filter],hasBias=null!=bias,hasPreluActivationWeights=null!=preluActivationWeights,hasLeakyreluAlpha="leakyrelu"===activation;if(hasBias&&programInputs.push(bias),hasPreluActivationWeights&&programInputs.push(preluActivationWeights),hasLeakyreluAlpha){const $leakyreluAlpha=backend.makeTensorInfo([],"float32",dist.ZSL.createScalarValue(leakyreluAlpha,"float32"));programInputs.push($leakyreluAlpha),intermediates.push($leakyreluAlpha)}let program;program=shouldPackDepthwiseConv?new DepthwiseConvPacked2DProgram(convInfo,hasBias,fusedActivation,hasPreluActivationWeights,hasLeakyreluAlpha):new DepthwiseConv2DProgram(convInfo,hasBias,fusedActivation,hasPreluActivationWeights,hasLeakyreluAlpha);const customValues=[[convInfo.padInfo.top,convInfo.padInfo.left],[convInfo.strideHeight,convInfo.strideWidth],[convInfo.dilationHeight,convInfo.dilationWidth],[convInfo.inHeight,convInfo.inWidth]],result=backend.runWebGLProgram(program,programInputs,"float32",customValues);return intermediates.forEach(t=>backend.disposeIntermediateTensorInfo(t)),result}};class GatherNDProgram{constructor(sliceDim,strides,shape,paramsShape){this.sliceDim=sliceDim,this.strides=strides,this.paramsShape=paramsShape,this.variableNames=["x","indices"],this.outputShape=shape;const dtype=getCoordsDataType(shape.length);let mainLoop="\n    int index;";for(let j=0;j<this.sliceDim;j++)mainLoop+=`\n          index = round(getIndices(coords[0], ${j}));\n          out_of_bounds = out_of_bounds || index < 0;\n          out_of_bounds = out_of_bounds || index >= ${this.paramsShape[j]};\n          flattenIndex += index * ${this.strides[j]};`;this.userCode=`\n         void main() {\n          ${dtype} coords = getOutputCoords();\n          int flattenIndex = 0;\n          bool out_of_bounds = false;\n\n          ${mainLoop}\n\n          setOutput(out_of_bounds ? 0.0 : getX(flattenIndex, coords[1]));\n        }\n      `}}const GatherNd_gatherNdConfig={kernelName:dist.O4G,backendName:"webgl",kernelFunc:function GatherNd_gatherNd(args){const{inputs,backend}=args,{params,indices}=inputs,indicesShape=indices.shape,sliceRank=indicesShape[indicesShape.length-1],paramsSize=dist.ZSL.sizeFromShape(params.shape),[resultShape,numSlices,sliceSize,strides]=dist.C0T.prepareAndValidate(params,indices),flattenIndices=kernels_Reshape_reshape({inputs:{x:indices},backend,attrs:{shape:[numSlices,sliceRank]}}),flattenX=kernels_Reshape_reshape({inputs:{x:params},backend,attrs:{shape:[dist.ZSL.sizeFromShape(params.shape)/sliceSize,sliceSize]}});if(backend.shouldExecuteOnCPU([params,indices])||"string"===params.dtype){const indicesData=backend.readSync(indices.dataId),paramsBuf=backend.bufferSync(params),outValue=gatherNdImplCPU(indicesData,paramsBuf,params.dtype,numSlices,sliceRank,sliceSize,strides,params.shape,paramsSize);return backend.makeTensorInfo(resultShape,params.dtype,outValue.values)}const program=new GatherNDProgram(sliceRank,strides,[numSlices,sliceSize],params.shape),res=backend.runWebGLProgram(program,[flattenX,flattenIndices],flattenX.dtype),reshaped=kernels_Reshape_reshape({inputs:{x:res},backend,attrs:{shape:resultShape}});return backend.disposeIntermediateTensorInfo(flattenIndices),backend.disposeIntermediateTensorInfo(flattenX),backend.disposeIntermediateTensorInfo(res),reshaped}};class GatherProgram{constructor(aShape,outputShape){this.variableNames=["A","indices"],this.outputShape=outputShape,this.rank=outputShape.length;const dtype=getCoordsDataType(this.rank),sourceCoords=function gather_gpu_getSourceCoords(aShape,axis){const currentCoords=["resRC.x","resRC.y","resRC.z","resRC.w"],sourceCoords=[];for(let i=0;i<aShape.length;i++)2===i?sourceCoords.push("index"):sourceCoords.push(`${currentCoords[i]}`);return sourceCoords.join()}(aShape);this.userCode=`\n      void main() {\n        ${dtype} resRC = getOutputCoords();\n        int index = int(getIndices(resRC.x, resRC.z));\n        float inBounds = (index >= 0) && (index < ${aShape[2]}) ? 1.0 : 0.0;\n        setOutput(inBounds * getA(${sourceCoords}));\n      }\n    `}}function GatherV2_gatherV2(args){const{inputs,backend,attrs}=args,{x,indices}=inputs,{axis,batchDims}=attrs,parsedAxis=dist.ZSL.parseAxisParam(axis,x.shape)[0];if((0,dist._K2)().get("DEBUG")){const indicesVals=backend.readSync(indices.dataId),axisDim=x.shape[parsedAxis];for(let i=0;i<indicesVals.length;++i){const index=indicesVals[i];dist.ZSL.assert(index<=axisDim-1&&index>=0,()=>`GatherV2: the index value ${index} is not in [0, ${axisDim-1}]`)}}const shapeInfo=dist.C0T.segment_util.collectGatherOpShapeInfo(x,indices,parsedAxis,batchDims),indicesSize=dist.ZSL.sizeFromShape(indices.shape),toDispose=[],flattenX=kernels_Reshape_reshape({inputs:{x},backend,attrs:{shape:[shapeInfo.batchSize,shapeInfo.outerSize,shapeInfo.dimSize,shapeInfo.sliceSize]}}),flattenIndex=kernels_Reshape_reshape({inputs:{x:indices},backend,attrs:{shape:[shapeInfo.batchSize,indicesSize/shapeInfo.batchSize]}});toDispose.push(flattenX),toDispose.push(flattenIndex);const flattenOutputShape=[shapeInfo.batchSize,shapeInfo.outerSize,indicesSize/shapeInfo.batchSize,shapeInfo.sliceSize];if(backend.shouldExecuteOnCPU([x,indices])||"string"===x.dtype){const indicesBuf=backend.bufferSync(flattenIndex),xBuf=backend.bufferSync(flattenX),outBuf=gatherV2ImplCPU(xBuf,indicesBuf,flattenOutputShape);return toDispose.forEach(t=>backend.disposeIntermediateTensorInfo(t)),backend.makeTensorInfo(shapeInfo.outputShape,outBuf.dtype,outBuf.values)}const program=new GatherProgram(flattenX.shape,flattenOutputShape),res=backend.runWebGLProgram(program,[flattenX,flattenIndex],flattenX.dtype);toDispose.push(res);const reshaped=kernels_Reshape_reshape({inputs:{x:res},backend,attrs:{shape:shapeInfo.outputShape}});return toDispose.forEach(t=>backend.disposeIntermediateTensorInfo(t)),reshaped}const GatherV2_gatherV2Config={kernelName:dist.mxL,backendName:"webgl",kernelFunc:GatherV2_gatherV2},kernels_Greater_greater=kernel_funcs_utils_binaryKernelFunc({opSnippet:"return float(a > b);",packedOpSnippet:"\n  return vec4(greaterThan(a, b));\n",cpuKernelImpl:greaterImplCPU,dtype:"bool"}),Greater_greaterConfig={kernelName:dist.XhZ,backendName:"webgl",kernelFunc:kernels_Greater_greater},GreaterEqual_greaterEqual=kernel_funcs_utils_binaryKernelFunc({opSnippet:"return float(a >= b);",packedOpSnippet:"\n  return vec4(greaterThanEqual(a, b));\n",dtype:"bool",cpuKernelImpl:greaterEqualImplCPU}),GreaterEqual_greaterEqualConfig={kernelName:dist.lLS,backendName:"webgl",kernelFunc:GreaterEqual_greaterEqual};const IFFT_ifftConfig={kernelName:dist.OAQ,backendName:"webgl",kernelFunc:function kernels_IFFT_ifft(args){const{inputs,backend}=args,{input}=inputs;return FFT_impl_fftImpl(input,!0,backend)}},kernels_IsFinite_isFinite=kernel_funcs_utils_unaryKernelFunc({opSnippet:"return float(!isnan(x) && !isinf(x));",dtype:"bool"}),IsFinite_isFiniteConfig={kernelName:dist.gIW,backendName:"webgl",kernelFunc:kernels_IsFinite_isFinite},IsInf_isInf=kernel_funcs_utils_unaryKernelFunc({opSnippet:"return float(isinf(x));",dtype:"bool"}),IsInf_isInfConfig={kernelName:dist.E3$,backendName:"webgl",kernelFunc:IsInf_isInf},kernels_IsNaN_isNaN=kernel_funcs_utils_unaryKernelFunc({opSnippet:"return float(isnan(x));",dtype:"bool"}),IsNaN_isNaNConfig={kernelName:dist.iPs,backendName:"webgl",kernelFunc:kernels_IsNaN_isNaN},kernels_Less_less=kernel_funcs_utils_binaryKernelFunc({opSnippet:"return float(a < b);",packedOpSnippet:"\n  return vec4(lessThan(a, b));\n",cpuKernelImpl:lessImplCPU,dtype:"bool"}),Less_lessConfig={kernelName:dist.mIA,backendName:"webgl",kernelFunc:kernels_Less_less},LessEqual_lessEqual=kernel_funcs_utils_binaryKernelFunc({opSnippet:"return float(a <= b);",packedOpSnippet:"\n  return vec4(lessThanEqual(a, b));\n",cpuKernelImpl:lessEqualImplCPU,dtype:"bool"}),LessEqual_lessEqualConfig={kernelName:dist.CwD,backendName:"webgl",kernelFunc:LessEqual_lessEqual};const LinSpace_linSpaceConfig={kernelName:dist.mnI,backendName:"webgl",kernelFunc:function LinSpace_linSpace(args){const{backend,attrs}=args,{start,stop,num}=attrs,outVals=linSpaceImplCPU(start,stop,num);return backend.makeTensorInfo([outVals.length],"float32",outVals)}},kernels_Log_log=kernel_funcs_utils_unaryKernelFunc({opSnippet:"if (isnan(x)) return x;\n  return x < 0.0 ? 0./0. : log(x);\n",packedOpSnippet:"\n  vec4 result = log(x);\n  bvec4 isNaN = isnan(x);\n  result.r = isNaN.r ? x.r : (x.r < 0.0 ? 0./0. : result.r);\n  result.g = isNaN.g ? x.g : (x.g < 0.0 ? 0./0. : result.g);\n  result.b = isNaN.b ? x.b : (x.b < 0.0 ? 0./0. : result.b);\n  result.a = isNaN.a ? x.a : (x.a < 0.0 ? 0./0. : result.a);\n  return result;\n",cpuKernelImpl:logImplCPU}),Log_logConfig={kernelName:dist.tG8,backendName:"webgl",kernelFunc:kernels_Log_log},kernels_Log1p_log1p=kernel_funcs_utils_unaryKernelFunc({opSnippet:"if (isnan(x)) return x;\n  return log(1.0 + x);\n"}),Log1p_log1pConfig={kernelName:dist.Cg$,backendName:"webgl",kernelFunc:kernels_Log1p_log1p},LogicalAnd_logicalAnd=kernel_funcs_utils_binaryKernelFunc({opSnippet:"return float(a >= 1.0 && b >= 1.0);",packedOpSnippet:"\n  return vec4(\n    vec4(greaterThanEqual(a, vec4(1.0))) *\n    vec4(greaterThanEqual(b, vec4(1.0))));\n",dtype:"bool"}),LogicalAnd_logicalAndConfig={kernelName:dist.RUm,backendName:"webgl",kernelFunc:LogicalAnd_logicalAnd},LogicalNot_logicalNot=kernel_funcs_utils_unaryKernelFunc({opSnippet:"return float(!(x >= 1.0));"}),LogicalNot_logicalNotConfig={kernelName:dist.nZd,backendName:"webgl",kernelFunc:LogicalNot_logicalNot},LogicalOr_logicalOr=kernel_funcs_utils_binaryKernelFunc({opSnippet:"return float(a >= 1.0 || b >= 1.0);",packedOpSnippet:"\n  return min(\n    vec4(greaterThanEqual(a, vec4(1.0))) +\n    vec4(greaterThanEqual(b, vec4(1.0))),\n    vec4(1.0));\n",dtype:"bool"}),LogicalOr_logicalOrConfig={kernelName:dist.LXA,backendName:"webgl",kernelFunc:LogicalOr_logicalOr};class LRNProgram{constructor(xShape,radius,bias,alpha,beta){this.variableNames=["x"],this.outputShape=[];const rad=radius,maxD=xShape[3]-1;let powOperator;this.outputShape=xShape;const basis=`float(${bias}) + float(${alpha}) * sum`;powOperator=.5===beta?`inversesqrt(${basis})`:1===beta?`1.0/(${basis})`:`exp(log(${basis}) * float(-${beta}));`,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n        int d = coords[3];\n        float x = getX(b, r, c, d);\n        float sum = 0.0;\n        for (int j = -${rad}; j <= ${rad}; j++) {\n          int idx = d + j;\n          if (idx >= 0 && idx <=  ${maxD}) {\n            float z = getX(b, r, c, idx);\n            sum += z * z;\n          }\n        }\n        float val = x * ${powOperator};\n        setOutput(val);\n      }\n    `}}class LRNPackedProgram{constructor(xShape,radius,bias,alpha,beta){this.variableNames=["x"],this.outputShape=[],this.packedInputs=!0,this.packedOutput=!0;const rad=radius,maxD=xShape[3]-1;let powOperator;this.outputShape=xShape;const basis=`float(${bias}) + float(${alpha}) * sum`;powOperator=.5===beta?`inversesqrt(${basis})`:1===beta?`1.0/(${basis})`:`exp(log(${basis}) * float(-${beta}));`,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords.x;\n        int r = coords.y;\n        int c = coords.z;\n        int d = coords.w;\n\n        bool hasNextCol = d < ${this.outputShape[3]};\n        bool hasNextRow = c < ${this.outputShape[2]};\n\n        vec4 sum = vec4(0.);\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\n\n        vec4 xAtOutputCoords = vec4(\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\n          hasNextCol ?\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\n          hasNextRow ?\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\n        );\n\n        int firstChannel = d - ${rad};\n        vec2 cache = vec2(0.);\n        if(firstChannel >= 0){\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\n            if(hasNextRow){\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\n            }\n        }\n\n        ivec2 depth = ivec2(d, d + 1);\n        for (int j = - ${rad}; j <= ${rad}; j++) {\n          ivec2 idx = depth + j;\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${maxD}));\n\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\n\n          if(depthInRange || depthPlusOneInRange){\n            vec4 z = vec4(0.);\n            vec4 xFragAtCurrentDepth;\n            z.xz = cache.xy;\n            if(depthPlusOneInRange && hasNextCol){\n              xFragAtCurrentDepth = idx.y != d ?\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\n              if(hasNextRow){\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\n              }\n            }\n            cache.xy = z.yw;\n            sum += z * z;\n          }\n        }\n        vec4 result = xAtOutputCoords * ${powOperator};\n        setOutput(result);\n      }\n    `}}const LRN_LRNConfig={kernelName:dist.jM4,backendName:"webgl",kernelFunc:args=>{const{inputs,backend,attrs}=args,{x}=inputs,{depthRadius,bias,alpha,beta}=attrs,program=(0,dist._K2)().getBool("WEBGL_PACK_NORMALIZATION")?new LRNPackedProgram(x.shape,depthRadius,bias,alpha,beta):new LRNProgram(x.shape,depthRadius,bias,alpha,beta);return backend.runWebGLProgram(program,[x],x.dtype)}};class LRNGradProgram{constructor(inputShape,depthRadius,bias,alpha,beta){this.variableNames=["inputImage","outputImage","dy"],this.outputShape=[],this.outputShape=inputShape,this.depth=inputShape[3],this.depthRadius=depthRadius,this.bias=bias,this.alpha=alpha,this.beta=beta,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n\n        float result = 0.0;\n        for (int d = 0; d < ${this.depth}; ++d) {\n          int depthBegin = int(max(0.0, float(d - ${depthRadius})));\n          int depthEnd = int(min(float(${this.depth}),\n              float(d + ${depthRadius} + 1)));\n\n          const int MIN_DEPTH_BEGIN = 0;\n          const int MAX_DEPTH_END = ${this.depth};\n\n          float norm = 0.0;\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd) {\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\n            }\n            else {\n              break;\n            }\n          }\n\n          norm = float(${alpha}) * norm + float(${bias});\n\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd){\n              float dyi = -2.0 * float(${alpha})\n                * float(${beta})\n                * getInputImage(b, r, c, k) * getOutputImage(b, r, c, d)\n                / norm;\n              if (k == d) {\n                dyi += pow(norm, -1.0 * ${beta});\n              }\n              if (k == coords[3]) {\n                dyi *= getDy(b, r, c, d);\n                result += dyi;\n              }\n            }\n            else {\n              break;\n            }\n          }\n      }\n      setOutput(result);\n      }\n    `}}const LRNGrad_LRNGradConfig={kernelName:dist.ToN,backendName:"webgl",kernelFunc:args=>{const{inputs,backend,attrs}=args,{x,y,dy}=inputs,{depthRadius,bias,alpha,beta}=attrs,program=new LRNGradProgram(x.shape,depthRadius,bias,alpha,beta);return backend.runWebGLProgram(program,[x,y,dy],x.dtype)}};function kernels_Max_max(args){const{inputs,backend,attrs}=args,{x}=inputs,{reductionIndices,keepDims}=attrs,xRank=x.shape.length,origAxes=dist.ZSL.parseAxisParam(reductionIndices,x.shape);let axes=origAxes;const permutedAxes=dist.C0T.getAxesPermutation(axes,xRank),maxInputIsTransposed=null!=permutedAxes,shouldExecuteOnCPU=backend.shouldExecuteOnCPU([x]);let maxInput=x;if(maxInputIsTransposed){if(shouldExecuteOnCPU){const values=backend.texData.get(maxInput.dataId).values,newShape=new Array(xRank);for(let i=0;i<newShape.length;i++)newShape[i]=x.shape[permutedAxes[i]];const maxInputValues=transposeImplCPU(values,x.shape,x.dtype,permutedAxes,newShape);maxInput=backend.makeTensorInfo(newShape,x.dtype);backend.texData.get(maxInput.dataId).values=maxInputValues}else maxInput=Transpose_impl_transposeImpl(x,permutedAxes,backend);axes=dist.C0T.getInnerMostAxes(axes.length,xRank)}dist.C0T.assertAxesAreInnerMostDims("max",axes,xRank);const[maxOutShape,reduceShape]=dist.C0T.computeOutAndReduceShapes(maxInput.shape,axes);let out,outShape=maxOutShape;if(keepDims&&(outShape=dist.C0T.expandShapeToKeepDim(maxOutShape,origAxes)),shouldExecuteOnCPU){const values=backend.texData.get(maxInput.dataId).values,outValues=maxImplCPU(values,dist.ZSL.sizeFromShape(reduceShape),outShape,x.dtype);out=backend.makeTensorInfo(outShape,x.dtype);backend.texData.get(out.dataId).values=outValues}else out=function Max_impl_maxImpl(x,reduceShape,outShape,backend){const inSize=dist.ZSL.sizeFromShape(reduceShape),reshapedInput=kernels_Reshape_reshape({inputs:{x},attrs:{shape:[dist.ZSL.sizeFromShape(x.shape)/inSize,inSize]},backend}),reduced=reduce(reshapedInput,x.dtype,"max",backend),reshapedOutput=kernels_Reshape_reshape({inputs:{x:reduced},attrs:{shape:outShape},backend});return backend.disposeIntermediateTensorInfo(reshapedInput),backend.disposeIntermediateTensorInfo(reduced),reshapedOutput}(maxInput,reduceShape,outShape,backend);return maxInputIsTransposed&&backend.disposeIntermediateTensorInfo(maxInput),out}const Max_maxConfig={kernelName:dist.VAI,backendName:"webgl",kernelFunc:kernels_Max_max},kernels_Maximum_maximum=kernel_funcs_utils_binaryKernelFunc({opSnippet:"\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n\n  return max(a, b);\n",packedOpSnippet:"\n  vec4 result = vec4(max(a, b));\n  bvec4 isNaNA = isnan(a);\n  bvec4 isNaNB = isnan(b);\n  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);\n  "+CHECK_NAN_SNIPPET_PACKED+"\n  return result;\n",cpuKernelImpl:maximumImplCPU}),Maximum_maximumConfig={kernelName:dist.LDN,backendName:"webgl",kernelFunc:kernels_Maximum_maximum};const MaxPool_maxPoolConfig={kernelName:dist.t3d,backendName:"webgl",kernelFunc:function MaxPool_maxPool(args){const{inputs,backend,attrs}=args,{x}=inputs;assertNotComplex(x,"maxPool");const{filterSize,strides,pad,dimRoundingMode}=attrs;dist.ZSL.assert(dist.C0T.eitherStridesOrDilationsAreOne(strides,1),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '1'`);const convInfo=dist.C0T.computePool2DInfo(x.shape,filterSize,strides,1,pad,dimRoundingMode);if(1===convInfo.filterWidth&&1===convInfo.filterHeight&&dist.ZSL.arraysEqual(convInfo.inShape,convInfo.outShape))return kernels_Identity_identity({inputs:{x},backend});const maxPoolProgram=new Pool2DProgram(convInfo,"max",!1);return backend.runWebGLProgram(maxPoolProgram,[x],x.dtype)}};const MaxPool3D_maxPool3DConfig={kernelName:dist.ySp,backendName:"webgl",kernelFunc:function maxPool3d(args){const{inputs,backend,attrs}=args,{x}=inputs,{filterSize,strides,pad,dataFormat,dimRoundingMode}=attrs,convInfo=dist.C0T.computePool3DInfo(x.shape,filterSize,strides,[1,1,1],pad,dimRoundingMode,dataFormat),maxPoolProgram=new Pool3DProgram(convInfo,"max",!1);return backend.runWebGLProgram(maxPoolProgram,[x],x.dtype)}};class MaxPool2DBackpropProgram{constructor(convInfo){this.variableNames=["dy","maxPos"],this.outputShape=convInfo.inShape;const strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationHeight=convInfo.dilationHeight,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padTop=effectiveFilterHeight-1-convInfo.padInfo.top,padLeft=effectiveFilterWidth-1-convInfo.padInfo.left,lastIndex=effectiveFilterHeight*effectiveFilterWidth-1;this.userCode=`\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${effectiveFilterHeight};\n          wR += ${dilationHeight}) {\n          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${effectiveFilterWidth}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n            int maxPosValue = ${lastIndex} - int(getMaxPos(b, idyR, idyC, d));\n\n            // Get the current value, check it against the value from the\n            // position matrix.\n            int curPosValue = wR * ${effectiveFilterWidth} + wC;\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n            dotProd += dyValue * mask;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class MaxPool3DBackpropProgram{constructor(convInfo){this.variableNames=["dy","maxPos"],this.outputShape=convInfo.inShape;const strideDepth=convInfo.strideDepth,strideHeight=convInfo.strideHeight,strideWidth=convInfo.strideWidth,dilationDepth=convInfo.dilationDepth,dilationHeight=convInfo.dilationHeight,dilationWidth=convInfo.dilationWidth,effectiveFilterDepth=convInfo.effectiveFilterDepth,effectiveFilterHeight=convInfo.effectiveFilterHeight,effectiveFilterWidth=convInfo.effectiveFilterWidth,padFront=effectiveFilterDepth-1-convInfo.padInfo.front,padTop=effectiveFilterHeight-1-convInfo.padInfo.top,padLeft=effectiveFilterWidth-1-convInfo.padInfo.left,lastIndex=effectiveFilterDepth*effectiveFilterHeight*effectiveFilterWidth-1;this.userCode=`\n      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${effectiveFilterDepth};\n           wD += ${dilationDepth}) {\n          float dyD = float(dyDCorner + wD) / ${strideDepth}.0;\n\n          if (dyD < 0.0 || dyD >= ${convInfo.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${effectiveFilterHeight};\n              wR += ${dilationHeight}) {\n            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${effectiveFilterWidth};\n                wC += ${dilationWidth}) {\n              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              int maxPosValue = ${lastIndex} -\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\n\n              // Get the current value, check it against the value from the\n              // position matrix.\n              int curPosValue =\n                  wD * ${effectiveFilterHeight} * ${effectiveFilterWidth} +\n                  wR * ${effectiveFilterWidth} + wC;\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n              dotProd += dyValue * mask;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}const kernels_MaxPool3DGrad_maxPool3DGradConfig={kernelName:dist.cHb,backendName:"webgl",kernelFunc:function MaxPool3DGrad_maxPool3DGrad(args){const{inputs,backend,attrs}=args,{dy,input}=inputs,x=input,{filterSize,strides,pad,dimRoundingMode}=attrs,convInfo=dist.C0T.computePool3DInfo(x.shape,filterSize,strides,[1,1,1],pad,dimRoundingMode),maxPool3dPositionsProgram=new Pool3DProgram(convInfo,"max",!0),maxPool3dPositions=backend.runWebGLProgram(maxPool3dPositionsProgram,[x],x.dtype),maxPoolBackpropProgram=new MaxPool3DBackpropProgram(convInfo),result=backend.runWebGLProgram(maxPoolBackpropProgram,[dy,maxPool3dPositions],x.dtype);return backend.disposeIntermediateTensorInfo(maxPool3dPositions),result}};const kernels_MaxPoolGrad_maxPoolGradConfig={kernelName:dist.RXX,backendName:"webgl",kernelFunc:function kernels_MaxPoolGrad_maxPoolGrad(args){const{inputs,backend,attrs}=args,{dy,input,output}=inputs,x=input;assertNotComplex([input,output],"maxPoolGrad");const{filterSize,strides,pad,dimRoundingMode}=attrs,convInfo=dist.C0T.computePool2DInfo(x.shape,filterSize,strides,1,pad,dimRoundingMode),maxPoolPositionsProgram=new Pool2DProgram(convInfo,"max",!0),maxPoolPositions=backend.runWebGLProgram(maxPoolPositionsProgram,[x],x.dtype),maxPoolBackPropProgram=new MaxPool2DBackpropProgram(convInfo),result=backend.runWebGLProgram(maxPoolBackPropProgram,[dy,maxPoolPositions],x.dtype);return backend.disposeIntermediateTensorInfo(maxPoolPositions),result}};const MaxPoolWithArgmax_maxPoolWithArgmaxConfig={kernelName:dist.TL8,backendName:"webgl",kernelFunc:({inputs,attrs,backend})=>{const{x}=inputs,{filterSize,strides,pad,includeBatchInIndex}=attrs,webglBackend=backend;dist.ZSL.assert(4===x.shape.length,()=>`Error in maxPool: input must be rank 4 but got rank ${x.shape.length}.`);const dilations=[1,1];dist.ZSL.assert(dist.C0T.eitherStridesOrDilationsAreOne(strides,dilations),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);const convInfo=dist.C0T.computePool2DInfo(x.shape,filterSize,strides,dilations,pad),[result,indexes]=function MaxPoolWithArgmax_impl_maxPoolWithArgmaxImpl(x,includeBatchInIndex,convInfo,backend){let program=new Pool2DProgram(convInfo,"max",!1);const poolOutput=backend.runWebGLProgram(program,[x],"float32");return program=new Pool2DProgram(convInfo,"max",!0,!0,includeBatchInIndex),[poolOutput,backend.runWebGLProgram(program,[x],"float32")]}(x,includeBatchInIndex,convInfo,webglBackend);return[result,indexes]}};const Mean_meanConfig={kernelName:dist.g5A,backendName:"webgl",kernelFunc:({inputs,attrs,backend})=>{const{x}=inputs,{keepDims,axis}=attrs,webglBackend=backend,xRank=x.shape.length,origAxes=dist.ZSL.parseAxisParam(axis,x.shape);let axes=origAxes;const permutedAxes=dist.C0T.getAxesPermutation(axes,xRank),meanInputIsTransposed=null!=permutedAxes,shouldExecuteOnCPU=webglBackend.shouldExecuteOnCPU([x]),intermediates=[];let meanInput=x;if(meanInputIsTransposed){if(shouldExecuteOnCPU){const values=webglBackend.texData.get(meanInput.dataId).values,newShape=new Array(xRank);for(let i=0;i<newShape.length;i++)newShape[i]=x.shape[permutedAxes[i]];const meanInputValues=transposeImplCPU(values,x.shape,x.dtype,permutedAxes,newShape);meanInput=webglBackend.makeTensorInfo(newShape,x.dtype);webglBackend.texData.get(meanInput.dataId).values=meanInputValues}else meanInput=Transpose_impl_transposeImpl(x,permutedAxes,webglBackend);intermediates.push(meanInput),axes=dist.C0T.getInnerMostAxes(axes.length,xRank)}dist.C0T.assertAxesAreInnerMostDims("sum",axes,xRank);const[meanOutShape,reduceShape]=dist.C0T.computeOutAndReduceShapes(meanInput.shape,axes);let outShape=meanOutShape;keepDims&&(outShape=dist.C0T.expandShapeToKeepDim(meanOutShape,origAxes));const out=function meanImpl(x,reduceShape,outShape,backend){const inSize=dist.ZSL.sizeFromShape(reduceShape),reshapedInput=kernels_Reshape_reshape({inputs:{x},attrs:{shape:[dist.ZSL.sizeFromShape(x.shape)/inSize,inSize]},backend}),reduced=reduce(reshapedInput,"float32","mean",backend),reshapedOutput=kernels_Reshape_reshape({inputs:{x:reduced},attrs:{shape:outShape},backend});return backend.disposeIntermediateTensorInfo(reshapedInput),backend.disposeIntermediateTensorInfo(reduced),reshapedOutput}(meanInput,reduceShape,outShape,webglBackend);for(const i of intermediates)webglBackend.disposeIntermediateTensorInfo(i);return out}};const Min_minConfig={kernelName:dist.lNG,backendName:"webgl",kernelFunc:function kernels_Min_min(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,keepDims}=attrs,xRank=x.shape.length,origAxes=dist.ZSL.parseAxisParam(axis,x.shape);let axes=origAxes;const permutedAxes=dist.C0T.getAxesPermutation(axes,xRank);let permutedX=x;null!=permutedAxes&&(permutedX=kernels_Transpose_transpose({inputs:{x},backend,attrs:{perm:permutedAxes}}),axes=dist.C0T.getInnerMostAxes(axes.length,x.shape.length)),dist.C0T.assertAxesAreInnerMostDims("min",axes,xRank);const[outShape,reduceShape]=dist.C0T.computeOutAndReduceShapes(permutedX.shape,axes),a2D=kernels_Reshape_reshape({inputs:{x:permutedX},backend,attrs:{shape:[-1,dist.ZSL.sizeFromShape(reduceShape)]}}),reduced=reduce(a2D,a2D.dtype,"min",backend);let res;if(keepDims){res=kernels_Reshape_reshape({inputs:{x:reduced},backend,attrs:{shape:dist.C0T.expandShapeToKeepDim(outShape,origAxes)}})}else res=kernels_Reshape_reshape({inputs:{x:reduced},backend,attrs:{shape:outShape}});return backend.disposeIntermediateTensorInfo(a2D),backend.disposeIntermediateTensorInfo(reduced),null!=permutedAxes&&backend.disposeIntermediateTensorInfo(permutedX),res}},kernels_Minimum_minimum=kernel_funcs_utils_binaryKernelFunc({opSnippet:"\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n\n  return min(a, b);\n",packedOpSnippet:"\n  vec4 result = vec4(min(a, b));\n  bvec4 isNaNA = isnan(a);\n  bvec4 isNaNB = isnan(b);\n  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);\n  "+CHECK_NAN_SNIPPET_PACKED+"\n  return result;\n",cpuKernelImpl:minimumImplCPU}),Minimum_minimumConfig={kernelName:dist.LG0,backendName:"webgl",kernelFunc:kernels_Minimum_minimum};class MirrorPadProgram{constructor(xShape,paddings,mode){this.variableNames=["x"],this.outputShape=paddings.map((p,i)=>p[0]+xShape[i]+p[1]);const rank=xShape.length,dtype=getCoordsDataType(rank),start=paddings.map(p=>p[0]).join(","),end=paddings.map((p,i)=>p[0]+xShape[i]).join(","),unpackedCoords=["coords[0]","coords[1]","coords[2]","coords[3]"].slice(0,rank),offset="reflect"===mode?0:1;this.userCode=1!==rank?`\n      ${dtype} start = ${dtype}(${start});\n      ${dtype} end = ${dtype}(${end});\n\n      void main() {\n        ${dtype} outC = getOutputCoords();\n        for (int i = 0; i < ${rank}; i++) {\n          if (outC[i] < start[i]) {\n            outC[i] = start[i] * 2 - outC[i] - ${offset};\n          } else if(outC[i] >= end[i]) {\n            outC[i] = (end[i] - 1) * 2 - outC[i] + ${offset};\n          }\n        }\n        ${dtype} coords = outC - start;\n        setOutput(getX(${unpackedCoords}));\n      }\n    `:`\n        int start = ${start};\n        int end = ${end};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start) {\n            outC = start * 2 - outC - ${offset};\n          } else if(outC >= end) {\n            outC = (end - 1) * 2 - outC + ${offset};\n          }\n          setOutput(getX(outC - start));\n        }\n      `}}class MirrorPadPackedProgram{constructor(xShape,paddings,mode){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=paddings.map((p,i)=>p[0]+xShape[i]+p[1]);const rank=xShape.length,dtype=getCoordsDataType(rank),start=paddings.map(p=>p[0]).join(","),end=paddings.map((p,i)=>p[0]+xShape[i]).join(","),coords=getChannels("rc",rank),source=getChannels("source",rank),cLimit=`${coords[rank-1]} < ${this.outputShape[rank-1]}`,innerDims=1===rank?"source":`vec2(${source.slice(-2).join()})`,offset="reflect"===mode?0:1;let mainLoop="";if(1===rank){const padSetup=`\n        ${dtype} source = rc;\n        if (source < start) {\n          source = start * 2 - source - ${offset};\n        } else if (source >= end) {\n          source = (end - 1) * 2 - source + ${offset};\n        }\n        source -= start;\n      `;mainLoop=`\n        ${dtype} rc = outputLoc;\n        ${padSetup}\n        result[0] = getChannel(getX(${source.join()}), ${innerDims});\n        ${coords[rank-1]} += 1;\n        if(${cLimit}) {\n          ${padSetup}\n          result[1] = getChannel(getX(${source.join()}), ${innerDims});\n        }\n      `}else{const padSetup=`\n        ${dtype} source = rc;\n        ${dtype} lt = ${dtype}(lessThan(source, start));\n        ${dtype} gte = ${dtype}(greaterThanEqual(source, end));\n        ${dtype} orig = 1 - (lt + gte);\n        source = orig * source +\n                lt * (start * 2 - source - ${offset}) +\n                gte * ((end - 1) * 2 - source + ${offset});\n        source -= start;\n      `;mainLoop=`\n        ${dtype} rc = outputLoc;\n        ${padSetup}\n        result[0] = getChannel(getX(${source.join()}), ${innerDims});\n        ${coords[rank-1]} += 1;\n        if(${cLimit}) {\n          ${padSetup}\n          result[1] = getChannel(getX(${source.join()}), ${innerDims});\n        }\n        rc = outputLoc;\n        ${coords[rank-2]} += 1;\n        if(${coords[rank-2]} < ${this.outputShape[rank-2]}) {\n          ${padSetup}\n          result[2] = getChannel(getX(${source.join()}), ${innerDims});\n          ${coords[rank-1]} += 1;\n          if(${cLimit}) {\n            ${padSetup}\n            result[3] = getChannel(getX(${source.join()}), ${innerDims});\n          }\n        }\n      `}this.userCode=`\n      const ${dtype} start = ${dtype}(${start});\n      const ${dtype} end = ${dtype}(${end});\n\n      void main() {\n        ${dtype} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${mainLoop}\n        setOutput(result);\n      }\n    `}}const MirrorPad_mirrorPadConfig={kernelName:dist.x7F,backendName:"webgl",kernelFunc:({inputs,backend,attrs})=>{const{x}=inputs,{paddings,mode}=attrs,program=(0,dist._K2)().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new MirrorPadPackedProgram(x.shape,paddings,mode):new MirrorPadProgram(x.shape,paddings,mode);return backend.runWebGLProgram(program,[x],x.dtype)}},kernels_Mod_mod=kernel_funcs_utils_binaryKernelFunc({opSnippet:"if (b == 0.0) return NAN;\n  return mod(a, b);",packedOpSnippet:"\n  vec4 result = mod(a, b);\n  bvec4 isNaN = equal(b, vec4(0.0));\n  "+CHECK_NAN_SNIPPET_PACKED+"\n  return result;\n"}),Mod_modConfig={kernelName:dist.BLA,backendName:"webgl",kernelFunc:kernels_Mod_mod};class MultinomialProgram{constructor(batchSize,numOutcomes,numSamples){this.variableNames=["probs"],this.customUniforms=[{name:"seed",type:"float"}],this.outputShape=[batchSize,numSamples],this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n\n        float r = random(seed);\n        float cdf = 0.0;\n\n        for (int i = 0; i < ${numOutcomes-1}; i++) {\n          cdf += getProbs(batch, i);\n\n          if (r < cdf) {\n            setOutput(float(i));\n            return;\n          }\n        }\n\n        // If no other event happened, last event happened.\n        setOutput(float(${numOutcomes-1}));\n      }\n    `}}const realDiv=kernel_funcs_utils_binaryKernelFunc({opSnippet:"\nif (a == b) {\n  return 1.0;\n};\nreturn a / b;",packedOpSnippet:"\n  // vec4 one = vec4(equal(a, b));\n  // return one + (vec4(1.0) - one) * a / b;\n  vec4 result = a / b;\n  if(a.x == b.x) {\n    result.x = 1.;\n  }\n  if(a.y == b.y) {\n    result.y = 1.;\n  }\n  if(a.z == b.z) {\n    result.z = 1.;\n  }\n  if(a.w == b.w) {\n    result.w = 1.;\n  }\n\n  return result;\n",checkOutOfBounds:!0}),RealDiv_realDivConfig={kernelName:dist.sDr,backendName:"webgl",kernelFunc:realDiv},SUB="return a - b;",kernels_Sub_sub=kernel_funcs_utils_binaryKernelFunc({opSnippet:SUB,packedOpSnippet:SUB,supportsComplex:!0,cpuKernelImpl:subImplCPU}),Sub_subConfig={kernelName:dist.PbM,backendName:"webgl",kernelFunc:kernels_Sub_sub};function kernels_Softmax_softmax(args){const{inputs,backend,attrs}=args,{logits}=inputs,{dim}=attrs,axes=dist.ZSL.parseAxisParam([dim],logits.shape),maxLogit=kernels_Max_max({inputs:{x:logits},backend,attrs:{reductionIndices:axes,keepDims:!1}}),expandedShape=dist.C0T.expandShapeToKeepDim(maxLogit.shape,axes),maxLogitsReshaped=kernels_Reshape_reshape({inputs:{x:maxLogit},backend,attrs:{shape:expandedShape}}),a=kernels_Sub_sub({inputs:{a:logits,b:maxLogitsReshaped},backend}),b=kernels_Exp_exp({inputs:{x:a},backend}),sumExp=kernels_Sum_sum({inputs:{x:b},backend,attrs:{axis:axes,keepDims:!1}}),sumExpReshaped=kernels_Reshape_reshape({inputs:{x:sumExp},backend,attrs:{shape:expandedShape}}),res=realDiv({inputs:{a:b,b:sumExpReshaped},backend});return backend.disposeIntermediateTensorInfo(maxLogit),backend.disposeIntermediateTensorInfo(maxLogitsReshaped),backend.disposeIntermediateTensorInfo(a),backend.disposeIntermediateTensorInfo(b),backend.disposeIntermediateTensorInfo(sumExp),backend.disposeIntermediateTensorInfo(sumExpReshaped),res}const Softmax_softmaxConfig={kernelName:dist.rFG,backendName:"webgl",kernelFunc:kernels_Softmax_softmax};const Multinomial_multinomialConfig={kernelName:dist.WT3,backendName:"webgl",kernelFunc:function Multinomial_multinomial(args){const{inputs,backend,attrs}=args,{logits}=inputs,{numSamples,seed,normalized}=attrs,probs=normalized?logits:kernels_Softmax_softmax({inputs:{logits},backend,attrs:{dim:logits.shape.length-1}}),batchSize=probs.shape[0],numOutcomes=probs.shape[1],program=new MultinomialProgram(batchSize,numOutcomes,numSamples),customValues=[[seed]],res=backend.runWebGLProgram(program,[probs],"int32",customValues);return normalized||backend.disposeIntermediateTensorInfo(probs),res}},NEG=CHECK_NAN_SNIPPET+"\n  return -x;\n";const Neg_negConfig={kernelName:dist.l0G,backendName:"webgl",kernelFunc:function kernels_Neg_neg(args){const{inputs,backend}=args,{x}=inputs;if(backend.shouldExecuteOnCPU([x])){const xData=backend.texData.get(x.dataId),[outValues,newShape]=negImplCPU(xData.values,x.shape,x.dtype);return backend.makeTensorInfo(newShape,x.dtype,outValues)}let program;return program=(0,dist._K2)().getBool("WEBGL_PACK_UNARY_OPERATIONS")?new UnaryOpPackedProgram(x.shape,"\n  vec4 result = -x;\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n"):new UnaryOpProgram(x.shape,NEG),backend.runWebGLProgram(program,[x],x.dtype)}},NonMaxSuppressionV3_nonMaxSuppressionV3Impl=dist.kpo.nonMaxSuppressionV3Impl;const NonMaxSuppressionV3_nonMaxSuppressionV3Config={kernelName:dist.SDM,backendName:"webgl",kernelFunc:function NonMaxSuppressionV3_nonMaxSuppressionV3(args){dist.C0T.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{inputs,backend,attrs}=args,{boxes,scores}=inputs,{maxOutputSize,iouThreshold,scoreThreshold}=attrs,boxesVals=backend.readSync(boxes.dataId),scoresVals=backend.readSync(scores.dataId),{selectedIndices}=NonMaxSuppressionV3_nonMaxSuppressionV3Impl(boxesVals,scoresVals,maxOutputSize,iouThreshold,scoreThreshold);return backend.makeTensorInfo([selectedIndices.length],"int32",new Int32Array(selectedIndices))}},NonMaxSuppressionV4_nonMaxSuppressionV4Impl=dist.kpo.nonMaxSuppressionV4Impl;const NonMaxSuppressionV4_nonMaxSuppressionV4Config={kernelName:dist.Zl4,backendName:"webgl",kernelFunc:function NonMaxSuppressionV4_nonMaxSuppressionV4(args){dist.C0T.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{inputs,backend,attrs}=args,{boxes,scores}=inputs,{maxOutputSize,iouThreshold,scoreThreshold,padToMaxOutputSize}=attrs,boxesVals=backend.readSync(boxes.dataId),scoresVals=backend.readSync(scores.dataId),{selectedIndices,validOutputs}=NonMaxSuppressionV4_nonMaxSuppressionV4Impl(boxesVals,scoresVals,maxOutputSize,iouThreshold,scoreThreshold,padToMaxOutputSize);return[backend.makeTensorInfo([selectedIndices.length],"int32",new Int32Array(selectedIndices)),backend.makeTensorInfo([],"int32",new Int32Array([validOutputs]))]}},NonMaxSuppressionV5_nonMaxSuppressionV5Impl=dist.kpo.nonMaxSuppressionV5Impl;const NonMaxSuppressionV5_nonMaxSuppressionV5Config={kernelName:dist.e0f,backendName:"webgl",kernelFunc:function NonMaxSuppressionV5_nonMaxSuppressionV5(args){dist.C0T.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{inputs,backend,attrs}=args,{boxes,scores}=inputs,{maxOutputSize,iouThreshold,scoreThreshold,softNmsSigma}=attrs,boxesVals=backend.readSync(boxes.dataId),scoresVals=backend.readSync(scores.dataId),maxOutputSizeVal=maxOutputSize,iouThresholdVal=iouThreshold,scoreThresholdVal=scoreThreshold,softNmsSigmaVal=softNmsSigma,{selectedIndices,selectedScores}=NonMaxSuppressionV5_nonMaxSuppressionV5Impl(boxesVals,scoresVals,maxOutputSizeVal,iouThresholdVal,scoreThresholdVal,softNmsSigmaVal);return[backend.makeTensorInfo([selectedIndices.length],"int32",new Int32Array(selectedIndices)),backend.makeTensorInfo([selectedScores.length],"float32",new Float32Array(selectedScores))]}};class OneHotProgram{constructor(numIndices,depth,onValue,offValue){this.variableNames=["indices"],this.outputShape=[numIndices,depth],this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int index = round(getIndices(coords.x));\n        setOutput(mix(float(${offValue}), float(${onValue}),\n                      float(index == coords.y)));\n      }\n    `}}const OneHot_oneHotConfig={kernelName:dist.urI,backendName:"webgl",kernelFunc:args=>{const{inputs,backend,attrs}=args,{indices}=inputs,{dtype,depth,onValue,offValue}=attrs,indicesSize=dist.ZSL.sizeFromShape(indices.shape),program=new OneHotProgram(indicesSize,depth,onValue,offValue),reshaped=kernels_Reshape_reshape({inputs:{x:indices},backend,attrs:{shape:[indicesSize]}}),result=backend.runWebGLProgram(program,[reshaped],dtype);backend.disposeIntermediateTensorInfo(reshaped);const out=kernels_Reshape_reshape({inputs:{x:result},backend,attrs:{shape:[...indices.shape,depth]}});return backend.disposeIntermediateTensorInfo(result),out}};function kernels_ZerosLike_zerosLike(args){const{inputs,backend}=args,{x}=inputs;if("complex64"===x.dtype){const realPart=Real_real({inputs:{input:x},backend}),r=kernels_ZerosLike_zerosLike({inputs:{x:realPart},backend}),imagPart=Imag_imag({inputs:{input:x},backend}),i=kernels_ZerosLike_zerosLike({inputs:{x:imagPart},backend}),result=Complex_complex({inputs:{real:r,imag:i},backend});return backend.disposeIntermediateTensorInfo(realPart),backend.disposeIntermediateTensorInfo(r),backend.disposeIntermediateTensorInfo(imagPart),backend.disposeIntermediateTensorInfo(i),result}return Fill_fill({attrs:{shape:x.shape,dtype:x.dtype,value:"string"===x.dtype?"":0},backend})}const ZerosLike_zerosLikeConfig={kernelName:dist.xJ3,backendName:"webgl",kernelFunc:kernels_ZerosLike_zerosLike};const OnesLike_onesLikeConfig={kernelName:dist.LWX,backendName:"webgl",kernelFunc:function kernels_OnesLike_onesLike(args){const{inputs,backend}=args,{x}=inputs;if("string"===x.dtype)throw new Error("onesLike is not supported under string dtype");if("complex64"===x.dtype){const realPart=Real_real({inputs:{input:x},backend}),r=kernels_OnesLike_onesLike({inputs:{x:realPart},backend}),imagPart=Imag_imag({inputs:{input:x},backend}),i=kernels_ZerosLike_zerosLike({inputs:{x:imagPart},backend}),result=Complex_complex({inputs:{real:r,imag:i},backend});return backend.disposeIntermediateTensorInfo(realPart),backend.disposeIntermediateTensorInfo(r),backend.disposeIntermediateTensorInfo(imagPart),backend.disposeIntermediateTensorInfo(i),result}return Fill_fill({attrs:{shape:x.shape,dtype:x.dtype,value:1},backend})}};const Pack_packConfig={kernelName:dist.mM$,backendName:"webgl",kernelFunc:function Pack_pack(args){const{inputs,backend,attrs}=args,{axis}=attrs;if(1===inputs.length)return kernels_ExpandDims_expandDims({inputs:{input:inputs[0]},backend,attrs:{dim:axis}});const shape=inputs[0].shape,dtype=inputs[0].dtype;inputs.forEach(t=>{dist.ZSL.assertShapesMatch(shape,t.shape,"All tensors passed to stack must have matching shapes"),dist.ZSL.assert(dtype===t.dtype,()=>"All tensors passed to stack must have matching dtypes")});const intermediateTensorInfos=[],result=kernels_Concat_concat({inputs:inputs.map(t=>{const expandedT=kernels_ExpandDims_expandDims({inputs:{input:t},backend,attrs:{dim:axis}});return intermediateTensorInfos.push(expandedT),expandedT}),backend,attrs:{axis}});return intermediateTensorInfos.forEach(t=>backend.disposeIntermediateTensorInfo(t)),result}};class PadProgram{constructor(xShape,paddings,constantValue){this.variableNames=["x"],this.customUniforms=[{name:"value",type:"float"}],this.outputShape=paddings.map((p,i)=>p[0]+xShape[i]+p[1]);const rank=xShape.length,type=getCoordsDataType(rank),start=paddings.map(p=>p[0]).join(","),end=paddings.map((p,i)=>p[0]+xShape[i]).join(","),unpackedCoords=["coords[0]","coords[1]","coords[2]","coords[3]"].slice(0,rank);this.userCode=1!==rank?`\n      ${type} start = ${type}(${start});\n      ${type} end = ${type}(${end});\n\n      void main() {\n        ${type} outC = getOutputCoords();\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\n          setOutput(value);\n        } else {\n          ${type} coords = outC - start;\n          setOutput(getX(${unpackedCoords}));\n        }\n      }\n    `:`\n        int start = ${start};\n        int end = ${end};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start || outC >= end) {\n            setOutput(value);\n          } else {\n            setOutput(getX(outC - start));\n          }\n        }\n      `}}class PadPackedProgram{constructor(xShape,paddings,constantValue){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"value",type:"float"}],this.outputShape=paddings.map((p,i)=>p[0]+xShape[i]+p[1]);const rank=xShape.length,dtype=getCoordsDataType(rank),start=paddings.map(p=>p[0]).join(","),end=paddings.map((p,i)=>p[0]+xShape[i]).join(","),coords=getChannels("rc",rank),source=getChannels("source",rank),cLimit=`${coords[rank-1]} < ${this.outputShape[rank-1]}`,innerDims=1===rank?"source":`vec2(${source.slice(-2).join()})`,componentSetup=[`${dtype} rc = outputLoc;`,`${coords[rank-1]} += 1;\n       if(${cLimit}) {\n      `,1===rank?"":`}\n       rc = outputLoc;\n       ${coords[rank-2]} += 1;\n       if(${coords[rank-2]} < ${this.outputShape[rank-2]}) {`,1===rank?"":`  ${coords[rank-1]} += 1;\n         if(${cLimit}) {`],paddingArea=1===rank?"rc < start || rc >= end":"any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";let mainLoop="";for(let i=0,j=1===rank?2:4;i<j;i++)mainLoop+=`\n        ${componentSetup[i]}\n        if (${paddingArea}) {\n          result[${i}] = float(value);\n        } else {\n          ${dtype} source = rc - start;\n          result[${i}] = getChannel(getX(${source.join()}), ${innerDims});\n        }\n      `;mainLoop+=1===rank?"} ":"}}",this.userCode=`\n      const ${dtype} start = ${dtype}(${start});\n      const ${dtype} end = ${dtype}(${end});\n\n      void main() {\n        ${dtype} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${mainLoop}\n        setOutput(result);\n      }\n    `}}const PadV2_padV2=args=>{const{inputs,backend,attrs}=args,{x}=inputs,{paddings,constantValue}=attrs;if(0===dist.ZSL.sizeFromShape(x.shape)){const outputShape=paddings.map((p,i)=>p[0]+x.shape[i]+p[1]);return Fill_fill({backend,attrs:{shape:outputShape,value:constantValue,dtype:x.dtype}})}const program=(0,dist._K2)().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new PadPackedProgram(x.shape,paddings,constantValue):new PadProgram(x.shape,paddings,constantValue),customValues=[[constantValue]];return backend.runWebGLProgram(program,[x],x.dtype,customValues)},PadV2_padV2Config={kernelName:dist.ODT,backendName:"webgl",kernelFunc:PadV2_padV2},kernels_Pow_pow=kernel_funcs_utils_binaryKernelFunc({opSnippet:"\n  if(a < 0.0 && floor(b) < b){\n    return NAN;\n  }\n  if (b == 0.0) {\n    return 1.0;\n  }\n  return (round(mod(b, 2.0)) != 1) ?\n      pow(abs(a), b) : sign(a) * pow(abs(a), b);\n",packedOpSnippet:"\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\n  vec4 result = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  bvec4 isExpZero = equal(b, vec4(0.0));\n  result.r = isExpZero.r ? 1.0 : result.r;\n  result.g = isExpZero.g ? 1.0 : result.g;\n  result.b = isExpZero.b ? 1.0 : result.b;\n  result.a = isExpZero.a ? 1.0 : result.a;\n\n  bvec4 isNaN1 = lessThan(a, vec4(0.0));\n  bvec4 isNaN2 = lessThan(floor(b), b);\n  bvec4 isNaN = bvec4(isNaN1.x && isNaN2.x, isNaN1.y && isNaN2.y, isNaN1.z && isNaN2.z, isNaN1.w && isNaN2.w);\n  "+CHECK_NAN_SNIPPET_PACKED+"\n  return result;\n"}),Pow_powConfig={kernelName:dist.pyJ,backendName:"webgl",kernelFunc:kernels_Pow_pow};const Prod_prodConfig={kernelName:dist.kdj,backendName:"webgl",kernelFunc:function kernels_Prod_prod(args){const{inputs,backend,attrs}=args,{x}=inputs,{axis,keepDims}=attrs,xRank=x.shape.length,toDispose=[],origAxes=dist.ZSL.parseAxisParam(axis,x.shape);let axes=origAxes;const permutedAxes=dist.C0T.getAxesPermutation(axes,xRank);let res,permutedX=x;if(null!=permutedAxes&&(permutedX=kernels_Transpose_transpose({inputs:{x},backend,attrs:{perm:permutedAxes}}),axes=dist.C0T.getInnerMostAxes(axes.length,xRank),toDispose.push(permutedX)),dist.C0T.assertAxesAreInnerMostDims("prod",axes,xRank),backend.shouldExecuteOnCPU([permutedX])){const xVals=backend.texData.get(permutedX.dataId).values,{outVals,outShape,outDtype}=prodImplCPU(permutedX.shape,permutedX.dtype,xVals,axes);res=backend.makeTensorInfo(outShape,outDtype,outVals)}else{const[outShape,reduceShape]=dist.C0T.computeOutAndReduceShapes(permutedX.shape,axes),inSize=dist.ZSL.sizeFromShape(reduceShape),a2D=kernels_Reshape_reshape({inputs:{x:permutedX},backend,attrs:{shape:[-1,inSize]}}),reduced=reduce(a2D,(0,dist.chL)(x.dtype),"prod",backend);res=kernels_Reshape_reshape({inputs:{x:reduced},backend,attrs:{shape:outShape}}),toDispose.push(a2D),toDispose.push(reduced)}if(keepDims){toDispose.push(res);const newShape=dist.C0T.expandShapeToKeepDim(res.shape,origAxes);res=kernels_Reshape_reshape({inputs:{x:res},backend,attrs:{shape:newShape}})}return toDispose.forEach(t=>backend.disposeIntermediateTensorInfo(t)),res}};const RaggedGather_raggedGatherConfig={kernelName:dist.oJ2,backendName:"webgl",kernelFunc:function RaggedGather_raggedGather(args){const{inputs,backend,attrs}=args,{paramsNestedSplits,paramsDenseValues,indices}=inputs,{outputRaggedRank}=attrs,$paramsNestedSplits=paramsNestedSplits.map(t=>backend.readSync(t.dataId)),$paramsNestedSplitsShapes=paramsNestedSplits.map(t=>t.shape),$paramsDenseValues=backend.readSync(paramsDenseValues.dataId),$indices=backend.readSync(indices.dataId),[outputNestedSplits,outputDenseValues,outputDenseValuesShape]=raggedGatherImplCPU($paramsNestedSplits,$paramsNestedSplitsShapes,$paramsDenseValues,paramsDenseValues.shape,paramsDenseValues.dtype,$indices,indices.shape,outputRaggedRank),outputNestedSplitsTensors=outputNestedSplits.map(splits=>backend.makeTensorInfo([splits.length],"int32",splits)),outputDenseValuesTensor=backend.makeTensorInfo(outputDenseValuesShape,paramsDenseValues.dtype,outputDenseValues);return outputNestedSplitsTensors.concat([outputDenseValuesTensor])}};const RaggedRange_raggedRangeConfig={kernelName:dist.CQC,backendName:"webgl",kernelFunc:function RaggedRange_raggedRange(args){const{inputs,backend}=args,{starts,limits,deltas}=inputs,$starts=backend.readSync(starts.dataId),$limits=backend.readSync(limits.dataId),$deltas=backend.readSync(deltas.dataId),[rtNestedSplitsData,rtDenseValuesData]=raggedRangeImplCPU($starts,starts.shape,starts.dtype,$limits,limits.shape,$deltas,deltas.shape);return[backend.makeTensorInfo([rtNestedSplitsData.length],"int32",rtNestedSplitsData),backend.makeTensorInfo([rtDenseValuesData.length],starts.dtype,rtDenseValuesData)]}};const RaggedTensorToTensor_raggedTensorToTensorConfig={kernelName:dist.mH5,backendName:"webgl",kernelFunc:function RaggedTensorToTensor_raggedTensorToTensor(args){const{inputs,backend,attrs}=args,{shape,values,defaultValue,rowPartitionTensors}=inputs,{rowPartitionTypes}=attrs,$shape=backend.readSync(shape.dataId),$values=backend.readSync(values.dataId),$defaultValue=backend.readSync(defaultValue.dataId),$rowPartitionValues=rowPartitionTensors.map(t=>backend.readSync(t.dataId)),rowPartitionValuesShapes=rowPartitionTensors.map(t=>t.shape),[outputShape,output]=raggedTensorToTensorImplCPU($shape,shape.shape,$values,values.shape,values.dtype,$defaultValue,defaultValue.shape,$rowPartitionValues,rowPartitionValuesShapes,rowPartitionTypes);return backend.makeTensorInfo(outputShape,values.dtype,output)}},kernels_Range_range=args=>{const{backend,attrs}=args,{start,stop,step,dtype}=attrs,values=rangeImplCPU(start,stop,step,dtype);return backend.makeTensorInfo([values.length],dtype,values)},Range_rangeConfig={kernelName:dist.Q6t,backendName:"webgl",kernelFunc:kernels_Range_range},kernels_Reciprocal_reciprocal=kernel_funcs_utils_unaryKernelFunc({opSnippet:"return 1.0 / x;"}),Reciprocal_reciprocalConfig={kernelName:dist.huO,backendName:"webgl",kernelFunc:kernels_Reciprocal_reciprocal},kernels_Relu_relu=kernel_funcs_utils_unaryKernelFunc({opSnippet:CHECK_NAN_SNIPPET+"\n  return (x < 0.0) ? 0.0 : x;\n",packedOpSnippet:"\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n"}),Relu_reluConfig={kernelName:dist.fUj,backendName:"webgl",kernelFunc:kernels_Relu_relu},kernels_Relu6_relu6=kernel_funcs_utils_unaryKernelFunc({opSnippet:CHECK_NAN_SNIPPET+"\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",packedOpSnippet:"\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n"}),Relu6_relu6Config={kernelName:dist.P_L,backendName:"webgl",kernelFunc:kernels_Relu6_relu6};class ResizeBilinearProgram{constructor(inputShape,newHeight,newWidth,alignCorners,halfPixelCenters){this.variableNames=["A"],this.outputShape=[];const[batch,oldHeight,oldWidth,depth]=inputShape;this.outputShape=[batch,newHeight,newWidth,depth];const effectiveInSize=[alignCorners&&newHeight>1?oldHeight-1:oldHeight,alignCorners&&newWidth>1?oldWidth-1:oldWidth],effectiveOutSize=[alignCorners&&newHeight>1?newHeight-1:newHeight,alignCorners&&newWidth>1?newWidth-1:newWidth];let sourceFracIndexRC;sourceFracIndexRC=halfPixelCenters?"(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)":"vec2(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${effectiveInSize[0]/effectiveOutSize[0]},\n          ${effectiveInSize[1]/effectiveOutSize[1]});\n      const vec2 inputShapeRC = vec2(${oldHeight}.0, ${oldWidth}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ${sourceFracIndexRC};\n\n        // Compute the four integer indices.\n        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));\n        ivec2 sourceCeilRC = ivec2(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\n\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n        float newValue = top + (bottom - top) * fracRC.x;\n\n        setOutput(newValue);\n      }\n    `}}class ResizeBilinearPackedProgram{constructor(inputShape,newHeight,newWidth,alignCorners,halfPixelCenters){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[];const[batch,oldHeight,oldWidth,depth]=inputShape;this.outputShape=[batch,newHeight,newWidth,depth];const effectiveInSize=[alignCorners&&newHeight>1?oldHeight-1:oldHeight,alignCorners&&newWidth>1?oldWidth-1:oldWidth],effectiveOutSize=[alignCorners&&newHeight>1?newHeight-1:newHeight,alignCorners&&newWidth>1?newWidth-1:newWidth];let sourceFracIndexRC;sourceFracIndexRC=halfPixelCenters?"(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)":"vec3(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${effectiveInSize[0]/effectiveOutSize[0]},\n          ${effectiveInSize[1]/effectiveOutSize[1]},\n          ${effectiveInSize[1]/effectiveOutSize[1]});\n      const vec3 inputShapeRC = vec3(${oldHeight}.0, ${oldWidth}.0,\n                                     ${oldWidth}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ${sourceFracIndexRC};\n\n        // Compute the four integer indices.\n        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));\n        ivec3 sourceCeilRC = ivec3(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${depth-1};\n        bool hasNextRow = coords.z < ${newWidth-1};\n\n        // In parallel, construct four corners for all four components in\n        // packed 2x2 cell.\n        vec4 topLeft = vec4(\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 bottomLeft = vec4(\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 topRight = vec4(\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec4 bottomRight = vec4(\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\n\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\n        vec4 newValue = mix(top, bottom, fracRC.x);\n\n        setOutput(newValue);\n      }\n    `}}const ResizeBilinear_resizeBilinearConfig={kernelName:dist.hgw,backendName:"webgl",kernelFunc:function kernels_ResizeBilinear_resizeBilinear(args){const{inputs,backend,attrs}=args,{images}=inputs,{alignCorners,halfPixelCenters,size}=attrs,[newHeight,newWidth]=size,program=(0,dist._K2)().getBool("WEBGL_PACK_IMAGE_OPERATIONS")?new ResizeBilinearPackedProgram(images.shape,newHeight,newWidth,alignCorners,halfPixelCenters):new ResizeBilinearProgram(images.shape,newHeight,newWidth,alignCorners,halfPixelCenters);return backend.runWebGLProgram(program,[images],"float32")}};class ResizeBilinearBackpropProgram{constructor(dyShape,inputShape,alignCorners){this.variableNames=["dy"],this.outputShape=[],this.outputShape=inputShape;const[,xHeight,xWidth]=inputShape,[,yHeight,yWidth]=dyShape,effectiveXSize=[alignCorners&&yHeight>1?xHeight-1:xHeight,alignCorners&&yWidth>1?xWidth-1:xWidth],effectiveYSize=[alignCorners&&yHeight>1?yHeight-1:yHeight,alignCorners&&yWidth>1?yWidth-1:yWidth],heightScale=effectiveXSize[0]/effectiveYSize[0],widthScale=effectiveXSize[1]/effectiveYSize[1],invHeightScale=1/heightScale,invWidthScale=1/widthScale,winHeight=2*Math.ceil(invHeightScale)+2,winWidth=2*Math.ceil(invWidthScale)+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${heightScale});\n        const float widthScale = float(${widthScale});\n\n        const float invHeightScale = float(${invHeightScale});\n        const float invWidthScale = float(${invWidthScale});\n\n        const int winHeight = int(${winHeight});\n        const int winWidth = int(${winWidth});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(startRLerp - float(winHeight / 2));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(startCLerp - float(winWidth / 2));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${yHeight}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${yWidth}) {\n              continue;\n            }\n\n            float dxR = float(dyR) * heightScale;\n            int topDxRIndex = int(floor(dxR));\n            int bottomDxRIndex = int(min(ceil(dxR), ${xHeight-1}.0));\n            float dxRLerp = dxR - float(topDxRIndex);\n            float inverseDxRLerp = 1.0 - dxRLerp;\n\n            float dxC = float(dyC) * widthScale;\n            int leftDxCIndex = int(floor(dxC));\n            int rightDxCIndex = int(min(ceil(dxC), ${xWidth-1}.0));\n            float dxCLerp = dxC - float(leftDxCIndex);\n            float inverseDxCLerp = 1.0 - dxCLerp;\n\n            if (r == topDxRIndex && c == leftDxCIndex) {\n              // topLeft\n              accumulator +=\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\n            }\n\n            if (r == topDxRIndex && c == rightDxCIndex) {\n              // topRight\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\n              // bottomLeft\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\n              // bottomRight\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}const kernels_ResizeBilinearGrad_resizeBilinearGradConfig={kernelName:dist.FCQ,backendName:"webgl",kernelFunc:function ResizeBilinearGrad_resizeBilinearGrad(args){const{inputs,backend,attrs}=args,{images,dy}=inputs,{alignCorners}=attrs,program=new ResizeBilinearBackpropProgram(dy.shape,images.shape,alignCorners);return backend.runWebGLProgram(program,[dy],dy.dtype)}};class ResizeNearestNeighborProgram{constructor(inputShape,newHeight,newWidth,alignCorners,halfPixelCenters){this.variableNames=["A"],this.outputShape=[];const[batch,oldHeight,oldWidth,depth]=inputShape;this.outputShape=[batch,newHeight,newWidth,depth];const effectiveInSize=[alignCorners&&newHeight>1?oldHeight-1:oldHeight,alignCorners&&newWidth>1?oldWidth-1:oldWidth],effectiveOutSize=[alignCorners&&newHeight>1?newHeight-1:newHeight,alignCorners&&newWidth>1?newWidth-1:newWidth],roundBase=alignCorners?"0.5":"0.0";let sourceFracIndexRC;sourceFracIndexRC=halfPixelCenters?"max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))":"vec2(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${effectiveInSize[0]/effectiveOutSize[0]},\n          ${effectiveInSize[1]/effectiveOutSize[1]});\n      const vec2 inputShapeRC = vec2(${oldHeight}.0, ${oldWidth}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ${sourceFracIndexRC};\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec2 sourceNearestRC = ivec2(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${roundBase})));\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n        setOutput(newValue);\n      }\n    `}}class ResizeNearestNeighborPackedProgram{constructor(inputShape,newHeight,newWidth,alignCorners,halfPixelCenters){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[];const[batch,oldHeight,oldWidth,depth]=inputShape;this.outputShape=[batch,newHeight,newWidth,depth];const effectiveInSize=[alignCorners&&newHeight>1?oldHeight-1:oldHeight,alignCorners&&newWidth>1?oldWidth-1:oldWidth],effectiveOutSize=[alignCorners&&newHeight>1?newHeight-1:newHeight,alignCorners&&newWidth>1?newWidth-1:newWidth],roundBase=alignCorners?"0.5":"0.0";let sourceFracIndexRC;sourceFracIndexRC=halfPixelCenters?"max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))":"vec3(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${effectiveInSize[0]/effectiveOutSize[0]},\n          ${effectiveInSize[1]/effectiveOutSize[1]},\n          ${effectiveInSize[1]/effectiveOutSize[1]});\n      const vec3 inputShapeRC = vec3(${oldHeight}.0, ${oldWidth}.0,\n                                     ${oldWidth}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ${sourceFracIndexRC};\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec3 sourceNearestRC = ivec3(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${roundBase})));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${depth-1};\n        bool hasNextRow = coords.z < ${newWidth-1};\n\n        vec4 newValue = vec4(\n          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),\n          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);\n\n        setOutput(newValue);\n      }\n    `}}const ResizeNearestNeighbor_resizeNearestNeighborConfig={kernelName:dist.jOE,backendName:"webgl",kernelFunc:function ResizeNearestNeighbor_resizeNearestNeighbor(args){const{inputs,backend,attrs}=args,{images}=inputs,{alignCorners,halfPixelCenters,size}=attrs,[newHeight,newWidth]=size,program=(0,dist._K2)().getBool("WEBGL_PACK_IMAGE_OPERATIONS")?new ResizeNearestNeighborPackedProgram(images.shape,newHeight,newWidth,alignCorners,halfPixelCenters):new ResizeNearestNeighborProgram(images.shape,newHeight,newWidth,alignCorners,halfPixelCenters);return backend.runWebGLProgram(program,[images],images.dtype)}};class ResizeNearestNeigborBackpropProgram{constructor(dyShape,inputShape,alignCorners){this.variableNames=["dy"],this.outputShape=[],this.outputShape=inputShape;const[,xHeight,xWidth]=inputShape,[,yHeight,yWidth]=dyShape,effectiveXSize=[alignCorners&&yHeight>1?xHeight-1:xHeight,alignCorners&&yWidth>1?xWidth-1:xWidth],effectiveYSize=[alignCorners&&yHeight>1?yHeight-1:yHeight,alignCorners&&yWidth>1?yWidth-1:yWidth],heightScale=effectiveXSize[0]/effectiveYSize[0],widthScale=effectiveXSize[1]/effectiveYSize[1],invHeightScale=1/heightScale,invWidthScale=1/widthScale,winHeight=2*Math.ceil(invHeightScale)+2,winWidth=2*Math.ceil(invWidthScale)+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${heightScale});\n        const float widthScale = float(${widthScale});\n\n        const float invHeightScale = float(${invHeightScale});\n        const float invWidthScale = float(${invWidthScale});\n\n        const int winHeight = int(${winHeight});\n        const int winWidth = int(${winWidth});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${yHeight}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${yWidth}) {\n              continue;\n            }\n\n            float sourceFracRow =\n              float(${effectiveXSize[0]}) *\n                (float(dyR) / float(${effectiveYSize[0]}));\n\n            float sourceFracCol =\n                float(${effectiveXSize[1]}) *\n                  (float(dyC) / float(${effectiveYSize[1]}));\n\n            int sourceNearestRow = int(min(\n                float(int(${xHeight}) - 1),\n                ${alignCorners} ? float(round(sourceFracRow)) :\n                                  float(floor(sourceFracRow))));\n\n            int sourceNearestCol = int(min(\n                float(int(${xWidth}) - 1),\n                ${alignCorners} ? float(round(sourceFracCol)) :\n                                  float(floor(sourceFracCol))));\n\n            if (r == sourceNearestRow && c == sourceNearestCol) {\n              accumulator += getDy(b, dyR, dyC, d);\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}const kernels_ResizeNearestNeighborGrad_resizeNearestNeighborGradConfig={kernelName:dist.XQy,backendName:"webgl",kernelFunc:function ResizeNearestNeighborGrad_resizeNearestNeighborGrad(args){const{inputs,backend,attrs}=args,{images,dy}=inputs,{alignCorners}=attrs,program=new ResizeNearestNeigborBackpropProgram(dy.shape,images.shape,alignCorners);return backend.runWebGLProgram(program,[dy],dy.dtype)}};class ReverseProgram{constructor(xShape,axis){this.variableNames=["x"];const rank=xShape.length;if(rank>4)throw new Error(`WebGL backend: Reverse of rank-${rank} tensor is not yet supported`);if(this.outputShape=xShape,1===rank)return void(this.userCode=`\n        void main() {\n          int coord = getOutputCoords();\n          setOutput(getX(${xShape[0]} - coord - 1));\n        }\n      `);const inCoords=xShape.map((_,i)=>(i=>-1!==axis.indexOf(i)&&1!==xShape[i]?`${xShape[i]} - coords[${i}] - 1`:`coords[${i}]`)(i)).join(","),type=getCoordsDataType(rank);this.userCode=`\n      void main() {\n        ${type} coords = getOutputCoords();\n        setOutput(getX(${inCoords}));\n      }\n    `}}class ReversePackedProgram{constructor(xShape,axis){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0;const rank=xShape.length;if(rank>4)throw new Error(`WebGL backend: Reverse of rank-${rank} tensor is not yet supported`);this.outputShape=xShape;const channels=getChannels("rc",rank),nextColumn=`${channels[rank-1]} + 1 < ${this.outputShape[rank-1]}`,nextRow=`${channels[rank-2]} + 1 < ${this.outputShape[rank-2]}`,type=getCoordsDataType(rank);function getChannel(channels){const inCoordsArray=xShape.map((_,i)=>function getInCoord(i,channels1){return-1!==axis.indexOf(i)&&1!==xShape[i]?`${xShape[i]} - ${channels1[i]} - 1`:`${channels1[i]}`}(i,channels));return`getChannel(getX(${inCoordsArray.join(",")}), vec2(${inCoordsArray.slice(-2).join(",")}))`}this.userCode=1===rank?`\n        void main(){\n          int rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = getChannel(getX(${xShape[0]} - rc - 1),\n            ${xShape[0]} - rc - 1);\n          if(${nextColumn}){\n              result.g = getChannel(getX(${xShape[0]} - (rc  + 1) - 1),\n                ${xShape[0]} - (rc  + 1) - 1);\n          }\n          setOutput(result);\n        }\n      `:`\n        void main() {\n          ${type} rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = ${function getR(channels){return getChannel(channels)}(channels.slice())};\n          if(${nextColumn}){\n            result.g = ${function getG(channels){return channels[rank-1]="("+channels[rank-1]+" + 1)",getChannel(channels)}(channels.slice())};\n          }\n          if(${nextRow}) {\n            result.b = ${function getB(channels){return channels[rank-2]="("+channels[rank-2]+" + 1)",getChannel(channels)}(channels.slice())};\n            if(${nextColumn}) {\n              result.a = ${function getA(channels){return channels[rank-1]="("+channels[rank-1]+" + 1)",channels[rank-2]="("+channels[rank-2]+" + 1)",getChannel(channels)}(channels.slice())};\n            }\n          }\n          setOutput(result);\n        }\n    `}}const Reverse_reverseConfig={kernelName:dist.D7i,backendName:"webgl",kernelFunc:function kernels_Reverse_reverse(args){const{inputs,backend,attrs}=args,{x}=inputs,{dims}=attrs,xRank=x.shape.length,$dims=dist.ZSL.parseAxisParam(dims,x.shape);if(0===xRank)return kernels_Identity_identity({inputs:{x},backend});const program=(0,dist._K2)().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new ReversePackedProgram(x.shape,$dims):new ReverseProgram(x.shape,$dims);return backend.runWebGLProgram(program,[x],x.dtype)}};class RotateProgram{constructor(imageShape,fillValue){this.variableNames=["Image"],this.outputShape=[],this.customUniforms=[{name:"params",type:"vec4"}];const imageHeight=imageShape[1],imageWidth=imageShape[2];this.outputShape=imageShape;let fillSnippet="";fillSnippet="number"==typeof fillValue?`float outputValue = ${fillValue.toFixed(2)};`:`\n        vec3 fill = vec3(${fillValue.join(",")});\n        float outputValue = fill[coords[3]];`,this.userCode=`\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n          int y = coords[1];\n          float coordXFloat = (float(x) - params[0]) * params[3] -\n            (float(y) - params[1]) * params[2];\n          float coordYFloat = (float(x) - params[0]) * params[2] +\n            (float(y) - params[1]) * params[3];\n          int coordX = int(round(coordXFloat + params[0]));\n          int coordY = int(round(coordYFloat + params[1]));\n          ${fillSnippet}\n          if(coordX >= 0 && coordX < ${imageWidth} && coordY >= 0 && coordY < ${imageHeight}) {\n            outputValue = getImage(coords[0], coordY, coordX, coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}}const RotateWithOffset_rotateWithOffsetConfig={kernelName:dist.BK4,backendName:"webgl",kernelFunc:({inputs,attrs,backend})=>{const{image}=inputs,{radians,fillValue,center}=attrs,webglBackend=backend,program=new RotateProgram(image.shape,fillValue),[centerX,centerY]=dist.C0T.getImageCenter(center,image.shape[1],image.shape[2]),customValues=[[centerX,centerY,Math.sin(radians),Math.cos(radians)]];return webglBackend.runWebGLProgram(program,[image],image.dtype,customValues)}},kernels_Round_round=kernel_funcs_utils_unaryKernelFunc({opSnippet:"\n  // OpenGL ES does not support round function.\n  // The algorithm is based on banker's rounding.\n  float base = floor(x);\n  if ((x - base) < 0.5) {\n    return floor(x);\n  } else if ((x - base) > 0.5) {\n    return ceil(x);\n  } else {\n    if (mod(base, 2.0) == 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n"}),Round_roundConfig={kernelName:dist.hVg,backendName:"webgl",kernelFunc:kernels_Round_round},kernels_Rsqrt_rsqrt=kernel_funcs_utils_unaryKernelFunc({opSnippet:"return inversesqrt(x);",cpuKernelImpl:rsqrtImplCPU}),Rsqrt_rsqrtConfig={kernelName:dist.TOR,backendName:"webgl",kernelFunc:kernels_Rsqrt_rsqrt};class ScatterProgram{constructor(updateSize,sliceDim,indicesRank,updatesRank,strides,shape,summingDupeIndex=!0,defaultIsTensor=!1){this.variableNames=["updates","indices","defaultValue"],this.outputShape=shape;const stridesType=getCoordsDataType(strides.length),dtype=getCoordsDataType(shape.length);let indicesString="";1===indicesRank?indicesString="i":2===indicesRank&&(indicesString="i, j");const indicesSnippet=`getIndices(${indicesString})`;let updatesString="";1===updatesRank?updatesString="i":2===updatesRank&&(updatesString="i, coords[1]");const updatesSnippet=`getUpdates(${updatesString})`;let defaultValuesString="";defaultIsTensor&&(defaultValuesString="coords[0], coords[1]");const defaultValueSnippet=`getDefaultValue(${defaultValuesString})`,strideString=sliceDim>1?"strides[j]":"strides";this.userCode=`\n        ${stridesType} strides = ${stridesType}(${strides});\n\n        void main() {\n          ${dtype} coords = getOutputCoords();\n          float sum = 0.0;\n          bool found = false;\n          for (int i = 0; i < ${updateSize}; i++) {\n            int flattenedIndex = 0;\n            for (int j = 0; j < ${sliceDim}; j++) {\n              int index = round(${indicesSnippet});\n              flattenedIndex += index * ${strideString};\n            }\n            if (flattenedIndex == coords[0]) {\n              sum += ${updatesSnippet};\n              found = true;\n            }\n          }\n          setOutput(mix(${defaultValueSnippet}, sum, float(found)));\n        }\n      `}}class ScatterPackedProgram{constructor(updateSize,sliceDim,indicesRank,updatesRank,strides,shape,summingDupeIndex=!0,defaultIsTensor=!1){this.variableNames=["updates","indices","defaultValue"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=shape;const stridesType=getCoordsDataType(strides.length),dtype=getCoordsDataType(shape.length);let indicesString="";1===indicesRank?indicesString="i":2===indicesRank&&(indicesString="i, j");const indicesSnippet=`getIndices(${indicesString})`;let updatesString="";1===updatesRank?updatesString="i":2===updatesRank&&(updatesString="i, coords[1]");const updatesSnippet=`getUpdates(${updatesString})`;let defaultValuesString="";defaultIsTensor&&(defaultValuesString="coords[0], coords[1]");const defaultValueSnippet=`getDefaultValue(${defaultValuesString})`,strideString=sliceDim>1?"strides[j]":"strides",strideString2=sliceDim>1?"strides[j + 1]":"strides";this.userCode=`\n        ${stridesType} strides = ${stridesType}(${strides});\n\n        void main() {\n          ${dtype} coords = getOutputCoords();\n          vec4 sum = vec4(0.);\n          vec4 found = vec4(0.);\n          for (int i = 0; i < ${updateSize}; i+=2) {\n            ivec2 flattenedIndex = ivec2(0);\n            for (int j = 0; j < ${sliceDim}; j+=2) {\n              ivec4 index = round(${indicesSnippet});\n              flattenedIndex += index.xz * ${strideString};\n              if (j + 1 < ${sliceDim}) {\n                flattenedIndex += index.yw * ${strideString2};\n              }\n            }\n            if (flattenedIndex[0] == coords[0] || flattenedIndex[1] == coords[0] ||\n                flattenedIndex[0] == coords[0] + 1 || flattenedIndex[1] == coords[0] + 1) {\n              vec4 updVals = ${updatesSnippet};\n              if (flattenedIndex[0] == coords[0]) {\n                sum.xy += updVals.xy;\n                found.xy = vec2(1.);\n              } else if (flattenedIndex[0] == coords[0] + 1) {\n                sum.zw += updVals.xy;\n                found.zw = vec2(1.);\n              }\n              if (flattenedIndex[1] == coords[0]) {\n                sum.xy += updVals.zw;\n                found.xy = vec2(1.);\n              } else if (flattenedIndex[1] == coords[0] + 1) {\n                sum.zw += updVals.zw;\n                found.zw = vec2(1.);\n              }\n            }\n          }\n          setOutput(mix(${defaultValueSnippet}, sum, found));\n        }\n      `}}const ScatterNd_scatterNdConfig={kernelName:dist.pJc,backendName:"webgl",kernelFunc:function ScatterNd_scatterNd(args){const{inputs,backend,attrs}=args,{indices,updates}=inputs,{shape}=attrs,{sliceRank,numUpdates,sliceSize,strides,outputSize}=dist.C0T.calculateShapes(updates,indices,shape),flattenShape=[outputSize/sliceSize,sliceSize];if(0===outputSize)return backend.makeTensorInfo(shape,indices.dtype);const flattenIndices=kernels_Reshape_reshape({inputs:{x:indices},backend,attrs:{shape:[numUpdates,sliceRank]}}),flattenX=kernels_Reshape_reshape({inputs:{x:updates},backend,attrs:{shape:[numUpdates,sliceSize]}}),defaultValue=backend.makeTensorInfo([],"float32",new Float32Array([0]));let program;program=(0,dist._K2)().getBool("WEBGL_PACK")?new ScatterPackedProgram(numUpdates,sliceRank,flattenIndices.shape.length,flattenX.shape.length,strides,flattenShape):new ScatterProgram(numUpdates,sliceRank,flattenIndices.shape.length,flattenX.shape.length,strides,flattenShape);const res=backend.runWebGLProgram(program,[flattenX,flattenIndices,defaultValue],flattenX.dtype),reshaped=kernels_Reshape_reshape({inputs:{x:res},backend,attrs:{shape}});return backend.disposeIntermediateTensorInfo(flattenIndices),backend.disposeIntermediateTensorInfo(flattenX),backend.disposeIntermediateTensorInfo(res),backend.disposeIntermediateTensorInfo(defaultValue),reshaped}};class SearchSortedProgram{constructor(batchSize,numInputs,numValues,side){this.variableNames=["sortedSequence","values"],this.customUniforms=[{name:"numInputs",type:"int"}],this.outputShape=[batchSize,numValues];const webGL1LoopHead=`for (int i = 0; i < ${Math.ceil(Math.log2(numInputs+1))}; ++i) { if (left >= right) break;`,loopHead=2===(0,dist._K2)().getNumber("WEBGL_VERSION")?"while (left < right) {":webGL1LoopHead,boundComparator="left"===side?"<":"<=";this.userCode=`\n       int findBound(int batch, float value) {\n         int left = 0;\n         int right = numInputs;\n         int mid;\n         ${loopHead}\n           mid = (left + right) / 2;\n           if (getSortedSequence(batch, mid) ${boundComparator} value) {\n             left = mid + 1;\n           } else {\n             right = mid;\n           }\n         }\n         return right;\n       }\n\n       void main() {\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int valueIndex = coords[1];\n\n         float value = getValues(batch, valueIndex);\n\n         setOutput(float(findBound(batch, value)));\n       }\n     `}}const SearchSorted_searchSortedConfig={kernelName:dist.uWl,backendName:"webgl",kernelFunc:function SearchSorted_searchSorted(args){const{inputs,backend,attrs}=args,{sortedSequence,values}=inputs,{side}=attrs,program=new SearchSortedProgram(sortedSequence.shape[0],sortedSequence.shape[1],values.shape[1],side),customValues=[[sortedSequence.shape[1]]];return backend.runWebGLProgram(program,[sortedSequence,values],"int32",customValues)}};class SelectProgram{constructor(cRank,shape,rank){let cCoords,abCoords;if(this.variableNames=["c","a","b"],this.outputShape=shape,rank>4)throw Error(`Where for rank ${rank} is not yet supported`);if(1===rank)abCoords="resRC",cCoords="resRC";else{const currentCoords=["resRC.x","resRC.y","resRC.z","resRC.w"],cCoordVars=[],abCoordVars=[];for(let i=0;i<shape.length;i++)abCoordVars.push(`${currentCoords[i]}`),i<cRank&&cCoordVars.push(`${currentCoords[i]}`);cCoords=cCoordVars.join(),abCoords=abCoordVars.join()}const dtype=getCoordsDataType(rank);this.userCode=`\n      void main() {\n        ${dtype} resRC = getOutputCoords();\n        float cVal = getC(${cCoords});\n        if (cVal >= 1.0) {\n          setOutput(getA(${abCoords}));\n        } else {\n          setOutput(getB(${abCoords}));\n        }\n      }\n    `}}const Select_selectConfig={kernelName:dist.l6P,backendName:"webgl",kernelFunc:function kernels_Select_select(args){const{inputs,backend}=args,{condition,t,e}=inputs,program=new SelectProgram(condition.shape.length,t.shape,t.shape.length);return backend.runWebGLProgram(program,[condition,t,e],(0,dist.TuY)(t.dtype,e.dtype))}},kernels_Selu_selu=kernel_funcs_utils_unaryKernelFunc({opSnippet:`\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n  // see: https://arxiv.org/abs/1706.02515\n  float scaleAlpha = ${dist.C0T.SELU_SCALEALPHA};\n  float scale = ${dist.C0T.SELU_SCALE};\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\n`}),Selu_seluConfig={kernelName:dist.u$b,backendName:"webgl",kernelFunc:kernels_Selu_selu},kernels_Sigmoid_sigmoid=kernel_funcs_utils_unaryKernelFunc({opSnippet:"if (isnan(x)) return x;\n  return 1.0 / (1.0 + exp(-1.0 * x));\n",packedOpSnippet:"\n  vec4 result = 1.0 / (1.0 + exp(-1.0 * x));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",cpuKernelImpl:sigmoidImplCPU}),Sigmoid_sigmoidConfig={kernelName:dist.vI1,backendName:"webgl",kernelFunc:kernels_Sigmoid_sigmoid},kernels_Sign_sign=kernel_funcs_utils_unaryKernelFunc({opSnippet:"\n  if (isnan(x)) { return 0.0; }\n  return sign(x);\n"}),Sign_signConfig={kernelName:dist.YVe,backendName:"webgl",kernelFunc:kernels_Sign_sign},kernels_Sin_sin=kernel_funcs_utils_unaryKernelFunc({opSnippet:"if (isnan(x)) return x;\n  return sin(x);\n",packedOpSnippet:`\n  vec4 result = sin(x);\n  bvec4 isNaN = isnan(x);\n  ${CHECK_NAN_SNIPPET_PACKED}\n  return result;\n`}),Sin_sinConfig={kernelName:dist.hql,backendName:"webgl",kernelFunc:kernels_Sin_sin},kernels_Sinh_sinh=kernel_funcs_utils_unaryKernelFunc({opSnippet:"\n  float e2x = exp(x);\n  return (e2x - 1.0 / e2x) / 2.0;\n"}),Sinh_sinhConfig={kernelName:dist.J3C,backendName:"webgl",kernelFunc:kernels_Sinh_sinh},kernels_Softplus_softplus=kernel_funcs_utils_unaryKernelFunc({opSnippet:"\n  float epsilon = 1.1920928955078125e-7;\n  float threshold = log(epsilon) + 2.0;\n\n  bool too_large = x > -threshold;\n  bool too_small = x < threshold;\n\n  float result;\n  float exp_x = exp(x);\n\n  if (too_large){\n    result = x;\n  }\n  else if (too_small){\n    result = exp_x;\n  }\n  else{\n    result = log(exp_x + 1.0);\n  }\n  return result;\n"}),Softplus_softplusConfig={kernelName:dist.Fin,backendName:"webgl",kernelFunc:kernels_Softplus_softplus},SpaceToBatchND_spaceToBatchNDConfig={kernelName:dist.A8B,backendName:"webgl",kernelFunc:args=>{const{inputs,backend,attrs}=args,{x}=inputs,{blockShape,paddings}=attrs;dist.ZSL.assert(x.shape.length<=4,()=>"spaceToBatchND for rank > 4 with a WebGL backend not implemented yet");const prod=blockShape.reduce((a,b)=>a*b),completePaddings=[[0,0]];completePaddings.push(...paddings);for(let i=1+blockShape.length;i<x.shape.length;++i)completePaddings.push([0,0]);const toDispose=[],paddedX=PadV2_padV2({inputs:{x},backend,attrs:{paddings:completePaddings,constantValue:0}}),reshapedPaddedShape=dist.C0T.getReshaped(paddedX.shape,blockShape,prod,!1),permutedReshapedPaddedPermutation=dist.C0T.getPermuted(reshapedPaddedShape.length,blockShape.length,!1),flattenShape=dist.C0T.getReshapedPermuted(paddedX.shape,blockShape,prod,!1),reshapedPaddedX=kernels_Reshape_reshape({inputs:{x:paddedX},backend,attrs:{shape:reshapedPaddedShape}}),paddedXT=kernels_Transpose_transpose({inputs:{x:reshapedPaddedX},backend,attrs:{perm:permutedReshapedPaddedPermutation}}),result=kernels_Reshape_reshape({inputs:{x:paddedXT},backend,attrs:{shape:flattenShape}});return toDispose.push(paddedX),toDispose.push(reshapedPaddedX),toDispose.push(paddedXT),toDispose.forEach(t=>backend.disposeIntermediateTensorInfo(t)),result}};const SparseFillEmptyRows_sparseFillEmptyRowsConfig={kernelName:dist.C8s,backendName:"webgl",kernelFunc:function SparseFillEmptyRows_sparseFillEmptyRows(args){const{inputs,backend}=args,{indices,values,denseShape,defaultValue}=inputs;if(1!==denseShape.shape.length)throw new Error(`Dense shape must be a vector, saw:\n         ${denseShape.shape}`);if(2!==indices.shape.length)throw new Error(`Indices must be a matrix, saw:\n         ${indices.shape}`);if(1!==values.shape.length)throw new Error(`Values must be a vector, saw:\n         ${values.shape}`);if(0!==defaultValue.shape.length)throw new Error(`Default value must be a scalar, saw:\n        ${defaultValue.shape}`);const $indices=backend.readSync(indices.dataId),$values=backend.readSync(values.dataId),$denseShape=backend.readSync(denseShape.dataId),$defaultValue=backend.readSync(defaultValue.dataId)[0],[outputIndices,outputIndicesShape,outputValues,emptyRowIndicator,reverseIndexMap]=sparseFillEmptyRowsImplCPU($indices,indices.shape,indices.dtype,$values,values.dtype,$denseShape,$defaultValue);return[backend.makeTensorInfo(outputIndicesShape,indices.dtype,outputIndices),backend.makeTensorInfo([outputIndicesShape[0]],values.dtype,outputValues),backend.makeTensorInfo([emptyRowIndicator.length],"bool",new Uint8Array(emptyRowIndicator.map(value=>Number(value)))),backend.makeTensorInfo([reverseIndexMap.length],indices.dtype,new Int32Array(reverseIndexMap))]}};const SparseReshape_sparseReshapeConfig={kernelName:dist.BoJ,backendName:"webgl",kernelFunc:function SparseReshape_sparseReshape(args){const{inputs,backend}=args,{inputIndices,inputShape,newShape}=inputs;if(2!==inputIndices.shape.length)throw new Error(`Input indices should be a matrix but received shape ${inputIndices.shape}`);if(1!==inputShape.shape.length)throw new Error(`Input shape should be a vector but received shape ${inputShape.shape}`);if(1!==newShape.shape.length)throw new Error(`Target shape should be a vector but received shape ${newShape.shape}`);const $inputShape=Array.from(backend.readSync(inputShape.dataId)),$inputIndices=backend.readSync(inputIndices.dataId),targetShape=Array.from(backend.readSync(newShape.dataId)),[newIndices,indicesShape,outputShape]=sparseReshapeImplCPU($inputIndices,inputIndices.shape,inputIndices.dtype,$inputShape,targetShape);return[backend.makeTensorInfo(indicesShape,inputIndices.dtype,newIndices),backend.makeTensorInfo([outputShape.length],newShape.dtype,new Int32Array(outputShape))]}};const SparseSegmentMean_sparseSegmentMeanConfig={kernelName:dist.L6G,backendName:"webgl",kernelFunc:function SparseSegmentMean_sparseSegmentMean(args){const{inputs,backend}=args,{data,indices,segmentIds}=inputs;if(data.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==indices.shape.length)throw new Error(`Indices should be a vector but received shape\n              ${indices.shape}`);if(1!==segmentIds.shape.length)throw new Error(`Segment ids should be a vector but received shape\n              ${segmentIds.shape}`);const $data=backend.readSync(data.dataId),$indices=backend.readSync(indices.dataId),$segmentIds=backend.readSync(segmentIds.dataId),[outputData,outputDataShape]=sparseSegmentReductionImplCPU($data,data.shape,data.dtype,$indices,$segmentIds,!0);return backend.makeTensorInfo(outputDataShape,data.dtype,outputData)}};const SparseSegmentSum_sparseSegmentSumConfig={kernelName:dist.DvZ,backendName:"webgl",kernelFunc:function SparseSegmentSum_sparseSegmentSum(args){const{inputs,backend}=args,{data,indices,segmentIds}=inputs;if(data.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==indices.shape.length)throw new Error(`Indices should be a vector but received shape\n             ${indices.shape}`);if(1!==segmentIds.shape.length)throw new Error(`Segment ids should be a vector but received shape\n             ${segmentIds.shape}`);const $data=backend.readSync(data.dataId),$indices=backend.readSync(indices.dataId),$segmentIds=backend.readSync(segmentIds.dataId),[outputData,outputDataShape]=sparseSegmentReductionImplCPU($data,data.shape,data.dtype,$indices,$segmentIds);return backend.makeTensorInfo(outputDataShape,data.dtype,outputData)}};const SparseToDense_sparseToDenseConfig={kernelName:dist.jgd,backendName:"webgl",kernelFunc:function SparseToDense_sparseToDense(args){const{inputs,backend,attrs}=args,{sparseIndices,sparseValues,defaultValue}=inputs,{outputShape}=attrs,{sliceRank,numUpdates,sliceSize,strides,outputSize}=dist.C0T.calculateShapes(sparseValues,sparseIndices,outputShape);if("string"===sparseValues.dtype){const indicesBuf=backend.bufferSync(sparseIndices),updatesBuf=backend.bufferSync(sparseValues),$defaultValue=dist.ZSL.decodeString(backend.readSync(defaultValue.dataId)[0]),outBuf=scatterImplCPU(indicesBuf,updatesBuf,outputShape,outputSize,sliceSize,numUpdates,sliceRank,strides,$defaultValue,false);return backend.makeTensorInfo(outputShape,outBuf.dtype,outBuf.values)}const program=new ScatterProgram(numUpdates,sliceRank,sparseIndices.shape.length,sparseValues.shape.length,strides,[outputSize,1],false),res=backend.runWebGLProgram(program,[sparseValues,sparseIndices,defaultValue],sparseValues.dtype),reshaped=kernels_Reshape_reshape({inputs:{x:res},backend,attrs:{shape:outputShape}});return backend.disposeIntermediateTensorInfo(res),reshaped}};const SplitV_splitVConfig={kernelName:dist.Blb,backendName:"webgl",kernelFunc:function SplitV_splitV(args){const{inputs,backend,attrs}=args,{x}=inputs,{numOrSizeSplits,axis}=attrs,$axis=dist.ZSL.parseAxisParam(axis,x.shape)[0],splitSizes=dist.C0T.prepareSplitSize(x,numOrSizeSplits,$axis),xRank=x.shape.length,begin=new Array(xRank).fill(0),size=x.shape.slice();return splitSizes.map(s=>{const sliceSize=[...size];sliceSize[$axis]=s;const sliceT=Slice_slice({inputs:{x},backend,attrs:{begin,size:sliceSize}});return begin[$axis]+=s,sliceT})}},SQRT="return sqrt(x);",kernels_Sqrt_sqrt=kernel_funcs_utils_unaryKernelFunc({opSnippet:SQRT,packedOpSnippet:SQRT,cpuKernelImpl:sqrtImplCPU}),Sqrt_sqrtConfig={kernelName:dist.dFH,backendName:"webgl",kernelFunc:kernels_Sqrt_sqrt},Square_square=kernel_funcs_utils_unaryKernelFunc({opSnippet:"return x * x;"}),Square_squareConfig={kernelName:dist.M6A,backendName:"webgl",kernelFunc:Square_square},SquaredDifference_squaredDifference=kernel_funcs_utils_binaryKernelFunc({opSnippet:"return (a - b) * (a - b);",packedOpSnippet:"return (a - b) * (a - b);"}),SquaredDifference_squaredDifferenceConfig={kernelName:dist.Ddj,backendName:"webgl",kernelFunc:SquaredDifference_squaredDifference};const StaticRegexReplace_staticRegexReplaceConfig={kernelName:dist.GZp,backendName:"webgl",kernelFunc:function StaticRegexReplace_staticRegexReplace(args){const{inputs,backend,attrs}=args,{x}=inputs;if("string"!==x.dtype)throw new Error("Input must be of datatype string");const $x=backend.readSync(x.dataId),stringInput=dist.C0T.fromUint8ToStringArray($x),output=staticRegexReplaceImplCPU(stringInput,"string",attrs);return backend.makeTensorInfo(x.shape,"string",output)}};const Step_stepConfig={kernelName:dist.pnw,backendName:"webgl",kernelFunc:function kernels_Step_step({inputs,attrs,backend}){const{x}=inputs,opSnippet=CHECK_NAN_SNIPPET+`\n    return x > 0.0 ? 1.0 : float(${attrs.alpha});\n  `,program=new UnaryOpProgram(x.shape,opSnippet);return backend.runWebGLProgram(program,[x],x.dtype)}};class StridedSliceProgram{constructor(begin,strides,size){this.variableNames=["x"],this.outputShape=size;const rank=size.length,inputDtype=getCoordsDataType(size.length),dtype=getCoordsDataType(size.length);let newCoords="";if(1===rank)newCoords="coords * strides + begin";else{let outputAxis=0;newCoords=size.map((_,i)=>(outputAxis++,1===size.length?`coords * strides[${i}] + begin[${i}]`:`coords[${outputAxis-1}] * strides[${i}] + begin[${i}]`)).join(",")}this.userCode=`\n      ${inputDtype} begin = ${inputDtype}(${begin});\n      ${inputDtype} strides = ${inputDtype}(${strides});\n\n      void main() {\n        ${dtype} coords = getOutputCoords();\n        setOutput(getX(${newCoords}));\n      }\n    `}}const StridedSlice_stridedSliceConfig={kernelName:dist.UcO,backendName:"webgl",kernelFunc:function StridedSlice_stridedSlice(args){const{inputs,backend,attrs}=args,{x}=inputs,{begin,end,strides,beginMask,endMask,ellipsisMask,newAxisMask,shrinkAxisMask}=attrs,{finalShapeSparse,finalShape,isIdentity,sliceDim0,isSimpleSlice,begin:$begin,end:$end,strides:$strides}=dist.Kro.sliceInfo(x.shape,begin,end,strides,beginMask,endMask,ellipsisMask,newAxisMask,shrinkAxisMask);let result;if(isIdentity)result=kernels_Reshape_reshape({inputs:{x},backend,attrs:{shape:finalShape}});else if(sliceDim0||isSimpleSlice){dist.ZSL.assert(x.shape.length>=1,()=>`Input must have rank at least 1, got: ${x.shape.length}`);const size=dist.Kro.computeOutShape($begin,$end,$strides),sliced=Slice_slice({inputs:{x},backend,attrs:{begin:$begin,size}});result=kernels_Reshape_reshape({inputs:{x:sliced},backend,attrs:{shape:finalShape}}),backend.disposeIntermediateTensorInfo(sliced)}else{if(backend.shouldExecuteOnCPU([x])){const values=backend.readSync(x.dataId),xBuf=(0,dist.ra8)(x.shape,x.dtype,values),resultValues=stridedSliceImplCPU(finalShapeSparse,xBuf,$strides,$begin);result=backend.makeTensorInfo(finalShape,x.dtype,resultValues.values)}else{const program=new StridedSliceProgram($begin,$strides,finalShapeSparse);result=backend.runWebGLProgram(program,[x],x.dtype)}}const resultReshaped=kernels_Reshape_reshape({inputs:{x:result},backend,attrs:{shape:finalShape}});return backend.disposeIntermediateTensorInfo(result),resultReshaped}};const StringNGrams_stringNGramsConfig={kernelName:dist.YAb,backendName:"webgl",kernelFunc:function StringNGrams_stringNGrams(args){const{inputs,backend,attrs}=args,{separator,nGramWidths,leftPad,rightPad,padWidth,preserveShortSequences}=attrs,{data,dataSplits}=inputs,$data=backend.readSync(data.dataId),$dataSplits=backend.readSync(dataSplits.dataId),[nGrams,nGramsSplits]=stringNGramsImplCPU($data,$dataSplits,separator,nGramWidths,leftPad,rightPad,padWidth,preserveShortSequences);return[backend.makeTensorInfo([nGrams.length],"string",nGrams),backend.makeTensorInfo(dataSplits.shape,"int32",nGramsSplits)]}};const StringSplit_stringSplitConfig={kernelName:dist.iW0,backendName:"webgl",kernelFunc:function StringSplit_stringSplit(args){const{inputs,backend,attrs}=args,{skipEmpty}=attrs,{input,delimiter}=inputs;if("string"!==input.dtype)throw new Error("Input must be of datatype string");if(1!==input.shape.length)throw new Error(`Input must be a vector, got shape: ${input.shape}`);if(0!==delimiter.shape.length)throw new Error(`Delimiter must be a scalar, got shape: ${delimiter.shape}`);const $input=backend.readSync(input.dataId),$delimiter=backend.readSync(delimiter.dataId)[0],[indices,values,shape]=stringSplitImplCPU($input,$delimiter,skipEmpty),outputSize=values.length;return[backend.makeTensorInfo([outputSize,2],"int32",indices),backend.makeTensorInfo([outputSize],"string",values),backend.makeTensorInfo([2],"int32",new Int32Array(shape))]}};const StringToHashBucketFast_stringToHashBucketFastConfig={kernelName:dist.$jE,backendName:"webgl",kernelFunc:function StringToHashBucketFast_stringToHashBucketFast(args){const{inputs,backend,attrs}=args,{numBuckets}=attrs,{input}=inputs;if("string"!==input.dtype)throw new Error("Input must be of datatype string");if(numBuckets<=0)throw new Error("Number of buckets must be at least 1");const $input=backend.readSync(input.dataId),output=stringToHashBucketFastImplCPU($input,numBuckets);return backend.makeTensorInfo(input.shape,"int32",output)}},kernels_Tan_tan=kernel_funcs_utils_unaryKernelFunc({opSnippet:"return tan(x);"}),Tan_tanConfig={kernelName:dist.oFs,backendName:"webgl",kernelFunc:kernels_Tan_tan},kernels_Tanh_tanh=kernel_funcs_utils_unaryKernelFunc({opSnippet:"\n  float e2x = exp(-2.0 * abs(x));\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\n"}),Tanh_tanhConfig={kernelName:dist.iuW,backendName:"webgl",kernelFunc:kernels_Tanh_tanh};const TensorScatterUpdate_tensorScatterUpdateConfig={kernelName:dist.X4r,backendName:"webgl",kernelFunc:function TensorScatterUpdate_tensorScatterUpdate(args){const{inputs,backend,attrs}=args,{tensor,indices,updates}=inputs,{}=attrs,{sliceRank,numUpdates,sliceSize,strides,outputSize}=dist.C0T.calculateShapes(updates,indices,tensor.shape),flattenShape=[outputSize/sliceSize,sliceSize];if(0===outputSize)return backend.makeTensorInfo(tensor.shape,indices.dtype);const flattenIndices=kernels_Reshape_reshape({inputs:{x:indices},backend,attrs:{shape:[numUpdates,sliceRank]}}),flattenX=kernels_Reshape_reshape({inputs:{x:updates},backend,attrs:{shape:[numUpdates,sliceSize]}}),flattenTensor=kernels_Reshape_reshape({inputs:{x:tensor},backend,attrs:{shape:flattenShape}}),program=new ScatterProgram(numUpdates,sliceRank,flattenIndices.shape.length,flattenX.shape.length,strides,flattenShape,!1,!0),res=backend.runWebGLProgram(program,[flattenX,flattenIndices,flattenTensor],flattenTensor.dtype),reshaped=kernels_Reshape_reshape({inputs:{x:res},backend,attrs:{shape:tensor.shape}});return backend.disposeIntermediateTensorInfo(flattenIndices),backend.disposeIntermediateTensorInfo(flattenX),backend.disposeIntermediateTensorInfo(flattenTensor),backend.disposeIntermediateTensorInfo(res),reshaped}};class TileProgram{constructor(aShape,reps){this.variableNames=["A"];const outputShape=new Array(aShape.length);for(let i=0;i<outputShape.length;i++)outputShape[i]=aShape[i]*reps[i];this.outputShape=outputShape,this.rank=outputShape.length;const dtype=getCoordsDataType(this.rank),sourceCoords=function tile_gpu_getSourceCoords(aShape){const rank=aShape.length;if(rank>5)throw Error(`Tile for rank ${rank} is not yet supported`);if(1===rank)return`imod(resRC, ${aShape[0]})`;const currentCoords=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u"],sourceCoords=[];for(let i=0;i<aShape.length;i++)sourceCoords.push(`imod(${currentCoords[i]}, ${aShape[i]})`);return sourceCoords.join()}(aShape);this.userCode=`\n      void main() {\n        ${dtype} resRC = getOutputCoords();\n        setOutput(getA(${sourceCoords}));\n      }\n    `}}function kernels_Tile_tile(params){const{inputs,backend,attrs}=params,{x}=inputs,{reps}=attrs;if("string"===x.dtype||x.shape.length>5){const data=backend.readSync(x.dataId),value="string"===x.dtype?data.map(d=>dist.ZSL.decodeString(d)):data,buf=(0,dist.ra8)(x.shape,x.dtype,value),outBuf=tileImplCPU(buf,reps);return backend.makeTensorInfo(outBuf.shape,outBuf.dtype,outBuf.values)}const program=new TileProgram(x.shape,reps);return backend.runWebGLProgram(program,[x],x.dtype)}const Tile_tileConfig={kernelName:dist.FAs,backendName:"webgl",kernelFunc:kernels_Tile_tile};class SwapProgram{constructor(shape){this.variableNames=["x","indices"],this.customUniforms=[{name:"n",type:"int"},{name:"firstPass",type:"int"},{name:"negativeInf",type:"float"},{name:"dir",type:"int"},{name:"inc",type:"int"}],this.outputShape=shape,this.userCode="\n       void main() {\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // We compare elements pair-wise within a group of size 2 * inc.\n         // The comparing rule for each group alternates between ascending\n         // and descending. Within each group, we compare each pair at\n         // positions i and i+inc. To decide whether an element at position i\n         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than\n         // inc, it is in the first half of the group, we denote it as x0,\n         // otherwise we denote it as x1.\n         // For example, as shown in the Bitonic top K paper referenced above,\n         // Figure5(a) shows that element[1] is in the\n         // second half of the group when group size is 2, but it is in the\n         // first half of the group when group size is 4.\n\n         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;\n         int i = isFirstInPair ? elemIdx : elemIdx - inc;\n\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));\n         float x0 = i0 < n ? getX(batch, i0) : negativeInf;\n         float x1 = i1 < n ? getX(batch, i1) : negativeInf;\n\n         // Denotes which direction indices are in (ascending or descending).\n         bool reverse = imod(elemIdx, 2 * dir) >= dir;\n         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);\n         if (reverse == isGreater) { // Elements in opposite order of direction\n           int iTemp = i0;\n           i0 = i1;\n           i1 = iTemp;\n         }\n         if (isFirstInPair) {\n            setOutput(float(i0));\n         } else {\n            setOutput(float(i1));\n         }\n       }\n     "}}class MergeProgram{constructor(shape){this.variableNames=["x","indices"],this.customUniforms=[{name:"n",type:"int"},{name:"firstPass",type:"int"},{name:"k",type:"int"}],this.outputShape=shape,this.userCode="\n    void main() {\n         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // The output size is half of the previous size.\n         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),\n         // we only need to output the indices at positions |, the indices at\n         // positions _ can be thrown away, see Figure5(b) After Phase 2\n         // (Merge phase) in the Bitonic Top K paper referenced above.\n         // For example, the paper shows we only need to output the orange bars.\n         // The output sequence should look like this | | | | | | | |.\n         // Because the sequence is halved, to map the output index back\n         // to the previous sequence to find the corresponding value,\n         // we need to double the index. When we double the index,\n         // we basically interpolate a position, so 2i looks like\n         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position\n         // of each 2k positions by - elemIdx % k. E.g. for output at\n         // index 4,5,6,7, we want to get the corresponding element at\n         // original index 8,9,10,11, for output at index 8,9,10,11,\n         // we want to get the corresponding element at original index\n         // 16,17,18,19, so on and so forth.\n\n         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));\n\n         float x0 = getX(batch, i0);\n         float x1 = i1 < n ? getX(batch, i1) : x0;\n\n         setOutput(x0 >= x1 ? float(i0) : float(i1));\n       }\n     "}}function disposeIntermediateTensorInfoOrNull(backend,tensorInfo){null!==tensorInfo&&backend.disposeIntermediateTensorInfo(tensorInfo)}function roundUpToPow2(num){let pow2=1;for(;pow2<num;)pow2*=2;return pow2}const TopK_topKConfig={kernelName:dist.TBb,backendName:"webgl",kernelFunc:function TopK_topK(args){const{inputs,backend,attrs}=args,{x}=inputs,{k,sorted}=attrs,TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD=(0,dist._K2)().getNumber("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD"),TOPK_K_CPU_HANDOFF_THRESHOLD=(0,dist._K2)().getNumber("TOPK_K_CPU_HANDOFF_THRESHOLD"),xShape=x.shape,lastDim=xShape[xShape.length-1];if(backend.shouldExecuteOnCPU([x])||lastDim<TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD||k>TOPK_K_CPU_HANDOFF_THRESHOLD){const xVals=backend.readSync(x.dataId),[allTopKVals,allTopKIndices]=topKImplCPU(xVals,xShape,x.dtype,k,sorted);return[backend.makeTensorInfo(allTopKVals.shape,allTopKVals.dtype,allTopKVals.values),backend.makeTensorInfo(allTopKIndices.shape,allTopKIndices.dtype,allTopKIndices.values)]}if(0===k)return xShape[xShape.length-1]=0,[backend.makeTensorInfo(xShape,x.dtype,[]),backend.makeTensorInfo(xShape,"int32",[])];if(1===lastDim)return[x,Fill_fill({attrs:{shape:xShape,dtype:"int32",value:0},backend})];const xtexData=backend.texData.get(x.dataId),xIsPacked=null!==xtexData&&xtexData.isPacked,xUnPacked=xIsPacked?backend.unpackTensor(x):x,batch=dist.ZSL.sizeFromShape(xShape)/lastDim,x2D=kernels_Reshape_reshape({inputs:{x:xUnPacked},attrs:{shape:[batch,lastDim]},backend});xIsPacked&&disposeIntermediateTensorInfoOrNull(backend,xUnPacked);const kPow2=roundUpToPow2(k),lastDimPow2=roundUpToPow2(lastDim);let indices=null;const getInputs=()=>null===indices?[x2D,x2D]:[x2D,indices],runSwap=(dir,inc,shape)=>{const inputs=getInputs(),program=new SwapProgram(shape),customValues=[[lastDim],[null===indices?1:0],[Number.NEGATIVE_INFINITY],[dir],[inc]],prevIndices=indices;indices=backend.runWebGLProgram(program,inputs,"int32",customValues),disposeIntermediateTensorInfoOrNull(backend,prevIndices)};for(let len=1;len<kPow2;len*=2){const dir=2*len;for(let inc=len;inc>=1;inc/=2)runSwap(dir,inc,[batch,lastDimPow2])}for(let indicesSize=lastDimPow2;indicesSize>kPow2;indicesSize/=2){const inputs=getInputs(),mergeProgram=new MergeProgram([batch,indicesSize/2]),customValues=[[lastDim],[null===indices?1:0],[kPow2]],prevIndices=indices;indices=backend.runWebGLProgram(mergeProgram,inputs,"int32",customValues),disposeIntermediateTensorInfoOrNull(backend,prevIndices);const len=kPow2/2,dir=2*len;for(let inc=len;inc>=1;inc/=2)runSwap(dir,inc,indices.shape)}let prevIndices=indices;indices=Slice_slice({inputs:{x:indices},backend,attrs:{begin:0,size:[batch,k]}}),disposeIntermediateTensorInfoOrNull(backend,prevIndices);let values=GatherV2_gatherV2({inputs:{x:x2D,indices},backend,attrs:{axis:1,batchDims:1}});disposeIntermediateTensorInfoOrNull(backend,x2D);const newShape=xShape.slice(0,-1);newShape.push(k),prevIndices=indices,indices=kernels_Reshape_reshape({inputs:{x:indices},attrs:{shape:newShape},backend}),disposeIntermediateTensorInfoOrNull(backend,prevIndices);const prevValues=values;return values=kernels_Reshape_reshape({inputs:{x:values},attrs:{shape:newShape},backend}),disposeIntermediateTensorInfoOrNull(backend,prevValues),[values,indices]}};class TransformProgram{constructor(imageHeight,imageWidth,interpolation,fillMode,fillValue,outShape){this.variableNames=["Image","Transforms"],this.outputShape=outShape;const interpolationModeId="nearest"===interpolation?1:2;let fillModeId;switch(fillMode){case"constant":default:fillModeId=1;break;case"reflect":fillModeId=2;break;case"wrap":fillModeId=3;break;case"nearest":fillModeId=4}this.userCode=`\n            float mapCoord(float outCoord, float len) {\n              float inCoord = outCoord;\n              if(${fillModeId} == 2) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    if (inCoord < sz2) {\n                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +\n                      inCoord;\n                    }\n                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    inCoord -= sz2 * float(int(float(inCoord / sz2)));\n                    if (inCoord >= len) {\n                      inCoord = sz2 - inCoord - 1.0;\n                    }\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (${fillModeId} == 3) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord -= len * float(int(float(inCoord / sz)));\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (${fillModeId} == 4) {\n                return clamp(outCoord, 0.0, len - 1.0);\n              } else {\n                return outCoord;\n              }\n            }\n\n            float readWithFillValue(int batch, int coordY, int coordX,\n              int channel) {\n              float outputValue;\n              if (0 <= coordY && coordY < ${imageHeight} && 0 <= coordX && coordX < ${imageWidth}) {\n                  outputValue = getImage(batch, coordY, coordX, channel);\n              } else {\n                outputValue = float(${fillValue});\n              }\n              return outputValue;\n            }\n\n            void main() {\n              ivec4 coords = getOutputCoords();\n              float outputValue;\n              int batch = coords[0];\n              int x = coords[2];\n              int y = coords[1];\n              int channel = coords[3];\n              float xf = float(x);\n              float yf = float(y);\n              float a1 = getTransforms(batch, 0);\n              float a2 = getTransforms(batch, 1);\n              float a3 = getTransforms(batch, 2);\n              float b1 = getTransforms(batch, 3);\n              float b2 = getTransforms(batch, 4);\n              float b3 = getTransforms(batch, 5);\n              float c1 = getTransforms(batch, 6);\n              float c2 = getTransforms(batch, 7);\n              float projection = c1 * xf + c2 * yf + 1.0;\n              if (projection == 0.0) {\n                outputValue = float(${fillValue});\n              } else {\n                float inX = (a1 * xf + a2 * yf + a3) / projection;\n                float inY = (b1 * xf + b2 * yf + b3) / projection;\n                float mapX = mapCoord(inX, float(${imageWidth}));\n                float mapY = mapCoord(inY, float(${imageHeight}));\n\n                if (${interpolationModeId} == 1) {\n                  int coordY = int(round(mapY));\n                  int coordX = int(round(mapX));\n                  outputValue = readWithFillValue(batch, coordY, coordX,\n                    channel);\n                } else {\n                  float yFloor = floor(mapY);\n                  float xFloor = floor(mapX);\n                  float yCeil = yFloor + 1.0;\n                  float xCeil = xFloor + 1.0;\n                  float valueYFloor = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);\n                  float valueYCeil = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);\n                  outputValue = (yCeil - mapY) * valueYFloor +\n                  (mapY - yFloor) * valueYCeil;\n                }\n              }\n              setOutput(outputValue);\n            }\n        `}}const Transform_transformConfig={kernelName:dist.dLy,backendName:"webgl",kernelFunc:function Transform_transform(args){const{inputs,backend,attrs}=args,{image,transforms}=inputs,{interpolation,fillMode,fillValue,outputShape}=attrs,[batch,imageHeight,imageWidth,numChannels]=image.shape,[outHeight,outWidth]=null!=outputShape?outputShape:[imageHeight,imageWidth],program=new TransformProgram(imageHeight,imageWidth,interpolation,fillMode,fillValue,[batch,outHeight,outWidth,numChannels]);return backend.runWebGLProgram(program,[image,transforms],"float32")}};var Unique_console=__webpack_require__("./node_modules/console-browserify/index.js");const Unique_uniqueConfig={kernelName:dist.EwU,backendName:"webgl",kernelFunc:function kernels_Unique_unique(args){const{inputs,attrs,backend}=args,{axis}=attrs,{x}=inputs;assertNotComplex(x,"unique"),Unique_console.warn("WARNING: ","UI might be locked temporarily as data is being downloaded");const values=backend.readSync(x.dataId),{outputValues,outputShape,indices}=uniqueImplCPU(values,axis,x.shape,x.dtype);return[backend.makeTensorInfo(outputShape,x.dtype,outputValues),backend.makeTensorInfo([indices.length],"int32",indices)]}};const Unpack_unpackConfig={kernelName:dist.dXR,backendName:"webgl",kernelFunc:function Unpack_unpack(args){const{inputs,backend,attrs}=args,{value}=inputs;let{axis}=attrs;axis<0&&(axis+=value.shape.length);const x=value,xRank=x.shape.length,num=value.shape[axis],outShape=new Array(xRank-1);let outIndex=0;for(let i=0;i<xRank;i++)i!==axis&&(outShape[outIndex++]=x.shape[i]);const toDispose=[],begin=new Array(xRank).fill(0),size=x.shape.slice();size[axis]=1;const res=new Array(num);for(let i=0;i<res.length;i++){begin[axis]=i;const sliced=Slice_slice({inputs:{x},backend,attrs:{begin,size}}),reshaped=kernels_Reshape_reshape({inputs:{x:sliced},backend,attrs:{shape:outShape}});res[i]=reshaped,toDispose.push(sliced)}return toDispose.forEach(t=>backend.disposeIntermediateTensorInfo(t)),res}};class SegmentOpProgram{constructor(segOpInfo,segOpType){this.variableNames=["x","segmentIds"];const windowSize=segOpInfo.windowSize,batchSize=segOpInfo.batchSize,inSize=segOpInfo.inSize,numSegments=segOpInfo.numSegments,outSize=numSegments*Math.ceil(inSize/windowSize);this.outputShape=[batchSize,outSize];const windowSizeNearestVec4=4*Math.floor(windowSize/4),windowSizeVec4Remainder=windowSize%4,updateSnippet="\n        sumValue += dot(values, segFilter);\n    ";let checkValueOutOfBounds="";inSize%windowSize>0&&(checkValueOutOfBounds=`\n        if (inIdx < 0 || inIdx >= ${inSize}) {\n          return initializationValue;\n        }\n      `);let checkSegmentIdOutOfBounds="";inSize%windowSize>0&&(checkSegmentIdOutOfBounds=`\n        if (inIdx < 0 || inIdx >= ${inSize}) {\n          return -1.0;\n        }\n      `),this.userCode=`\n      const float initializationValue = 0.0;\n\n      float getValue(int batch, int inIdx) {\n        ${checkValueOutOfBounds}\n        return getX(batch, inIdx);\n      }\n\n      float getSegmentIdAtIndex(int inIdx) {\n        ${checkSegmentIdOutOfBounds}\n        return getSegmentIds(inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = int(floor(float(outIdx) / float(\n          ${numSegments})) * float(${windowSize}));\n        int currentSeg = int(mod(float(outIdx), float(${numSegments})));\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\n          );\n\n          ${updateSnippet}\n        }\n\n        int inIdx = inOffset + ${windowSizeNearestVec4};\n        if (${1===windowSizeVec4Remainder}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            0,\n            0,\n            0\n          );\n\n          ${updateSnippet}\n        } else if (${2===windowSizeVec4Remainder}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n              0,\n              0\n          );\n\n          ${updateSnippet}\n        } else if (${3===windowSizeVec4Remainder}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            0\n          );\n\n          ${updateSnippet}\n        }\n        setOutput(sumValue);\n      }\n    `}}const UnsortedSegmentSum_unsortedSegmentSumConfig={kernelName:dist.pPe,backendName:"webgl",kernelFunc:function UnsortedSegmentSum_unsortedSegmentSum(args){const{inputs,backend,attrs}=args,{x,segmentIds}=inputs,{numSegments}=attrs,xRank=x.shape.length,toDispose=[];let axis=0;const permutation=dist.C0T.getAxesPermutation([axis],xRank);let permutedX=x;null!=permutation&&(permutedX=kernels_Transpose_transpose({inputs:{x},backend,attrs:{perm:permutation}}),toDispose.push(permutedX),axis=dist.C0T.getInnerMostAxes(1,xRank)[0]);const outShape=dist.C0T.segment_util.computeOutShape(permutedX.shape,axis,numSegments),inSize=dist.ZSL.sizeFromShape([permutedX.shape[axis]]),a2D=kernels_Reshape_reshape({inputs:{x:permutedX},backend,attrs:{shape:[-1,inSize]}});toDispose.push(a2D);const outputDType=(0,dist.chL)(x.dtype),segOpCompute=(x,segOpType,segmentIds,dtype,numSegments)=>{const batchSize=x.shape[0],inSize=x.shape[1],windowSize=dist.C0T.segment_util.segOpComputeOptimalWindowSize(inSize,numSegments),program=new SegmentOpProgram({windowSize,inSize,batchSize,numSegments},segOpType),output=backend.compileAndRun(program,[x,segmentIds],dtype);if(toDispose.push(output),output.shape[1]===numSegments)return output;const rangeInfo=kernels_Range_range({backend,attrs:{start:0,stop:numSegments,step:1,dtype:"float32"}}),tileInfo=kernels_Tile_tile({inputs:{x:rangeInfo},backend,attrs:{reps:[inSize/windowSize]}});toDispose.push(rangeInfo),toDispose.push(tileInfo);return segOpCompute(output,segOpType,tileInfo,dtype,numSegments)},reshaped=kernels_Reshape_reshape({inputs:{x:segOpCompute(a2D,"unsortedSegmentSum",segmentIds,outputDType,numSegments)},backend,attrs:{shape:outShape}});let result=reshaped;if(null!=permutation){toDispose.push(reshaped);const perm=dist.C0T.getUndoAxesPermutation(permutation);result=kernels_Transpose_transpose({inputs:{x:result},backend,attrs:{perm}})}return toDispose.forEach(t=>backend.disposeIntermediateTensorInfo(t)),result}},register_all_kernels_kernelConfigs=[_FusedMatMul_fusedMatMulConfig,Abs_absConfig,Acos_acosConfig,Acosh_acoshConfig,Add_addConfig,AddN_addNConfig,All_allConfig,Any_anyConfig,ArgMax_argMaxConfig,ArgMin_argMinConfig,Asin_asinConfig,Asinh_asinhConfig,Atan_atanConfig,Atan2_atan2Config,Atanh_atanhConfig,AvgPool_avgPoolConfig,AvgPool3D_avgPool3DConfig,kernels_AvgPool3DGrad_avgPool3DGradConfig,kernels_AvgPoolGrad_avgPoolGradConfig,BatchMatMul_batchMatMulConfig,BatchNorm_batchNormConfig,BatchToSpaceND_batchToSpaceNDConfig,Bincount_bincountConfig,BitwiseAnd_bitwiseAndConfig,BroadcastArgs_broadcastArgsConfig,Cast_castConfig,Ceil_ceilConfig,ClipByValue_clipByValueConfig,Complex_complexConfig,ComplexAbs_complexAbsConfig,Concat_concatConfig,Conv2D_conv2DConfig,Conv2DBackpropFilter_conv2DBackpropFilterConfig,Conv2DBackpropInput_conv2DBackpropInputConfig,Conv3D_conv3DConfig,Conv3DBackpropFilterV2_conv3DBackpropFilterV2Config,conv3DBackpropInputConfig,Cos_cosConfig,Cosh_coshConfig,CropAndResize_cropAndResizeConfig,Cumprod_cumprodConfig,Cumsum_cumsumConfig,DenseBincount_denseBincountConfig,DepthToSpace_depthToSpaceConfig,DepthwiseConv2dNative_depthwiseConv2dNativeConfig,DepthwiseConv2dNativeBackpropFilter_depthwiseConv2dNativeBackpropFilterConfig,DepthwiseConv2dNativeBackpropInput_depthwiseConv2dNativeBackpropInputConfig,Diag_diagConfig,Dilation2D_dilation2DConfig,Einsum_einsumConfig,Elu_eluConfig,kernels_EluGrad_eluGradConfig,Equal_equalConfig,Erf_erfConfig,Exp_expConfig,ExpandDims_expandDimsConfig,Expm1_expm1Config,FFT_fftConfig,Fill_fillConfig,FlipLeftRight_flipLeftRightConfig,Floor_floorConfig,FloorDiv_floorDivConfig,fromPixelsConfig,FusedConv2D_fusedConv2DConfig,FusedDepthwiseConv2D_fusedDepthwiseConv2DConfig,GatherNd_gatherNdConfig,GatherV2_gatherV2Config,Greater_greaterConfig,GreaterEqual_greaterEqualConfig,Identity_identityConfig,IFFT_ifftConfig,Imag_imagConfig,IsFinite_isFiniteConfig,IsInf_isInfConfig,IsNaN_isNaNConfig,LeakyRelu_leakyReluConfig,Less_lessConfig,LessEqual_lessEqualConfig,LinSpace_linSpaceConfig,Log_logConfig,Log1p_log1pConfig,LogicalAnd_logicalAndConfig,LogicalNot_logicalNotConfig,LogicalOr_logicalOrConfig,LRN_LRNConfig,LRNGrad_LRNGradConfig,Max_maxConfig,Maximum_maximumConfig,MaxPool_maxPoolConfig,MaxPool3D_maxPool3DConfig,kernels_MaxPool3DGrad_maxPool3DGradConfig,kernels_MaxPoolGrad_maxPoolGradConfig,MaxPoolWithArgmax_maxPoolWithArgmaxConfig,Mean_meanConfig,Min_minConfig,Minimum_minimumConfig,MirrorPad_mirrorPadConfig,Mod_modConfig,Multinomial_multinomialConfig,Multiply_multiplyConfig,Neg_negConfig,NonMaxSuppressionV3_nonMaxSuppressionV3Config,NonMaxSuppressionV4_nonMaxSuppressionV4Config,NonMaxSuppressionV5_nonMaxSuppressionV5Config,NotEqual_notEqualConfig,OneHot_oneHotConfig,OnesLike_onesLikeConfig,Pack_packConfig,PadV2_padV2Config,Pow_powConfig,Prelu_preluConfig,Prod_prodConfig,RaggedGather_raggedGatherConfig,RaggedRange_raggedRangeConfig,RaggedTensorToTensor_raggedTensorToTensorConfig,Range_rangeConfig,Real_realConfig,RealDiv_realDivConfig,Reciprocal_reciprocalConfig,Relu_reluConfig,Relu6_relu6Config,Reshape_reshapeConfig,ResizeBilinear_resizeBilinearConfig,kernels_ResizeBilinearGrad_resizeBilinearGradConfig,ResizeNearestNeighbor_resizeNearestNeighborConfig,kernels_ResizeNearestNeighborGrad_resizeNearestNeighborGradConfig,Reverse_reverseConfig,RotateWithOffset_rotateWithOffsetConfig,Round_roundConfig,Rsqrt_rsqrtConfig,ScatterNd_scatterNdConfig,SearchSorted_searchSortedConfig,Select_selectConfig,Selu_seluConfig,Sigmoid_sigmoidConfig,Sign_signConfig,Sin_sinConfig,Sinh_sinhConfig,sliceConfig,Softmax_softmaxConfig,Softplus_softplusConfig,SpaceToBatchND_spaceToBatchNDConfig,SparseFillEmptyRows_sparseFillEmptyRowsConfig,SparseReshape_sparseReshapeConfig,SparseSegmentMean_sparseSegmentMeanConfig,SparseSegmentSum_sparseSegmentSumConfig,SparseToDense_sparseToDenseConfig,SplitV_splitVConfig,Sqrt_sqrtConfig,Square_squareConfig,SquaredDifference_squaredDifferenceConfig,StaticRegexReplace_staticRegexReplaceConfig,Step_stepConfig,StridedSlice_stridedSliceConfig,StringNGrams_stringNGramsConfig,StringSplit_stringSplitConfig,StringToHashBucketFast_stringToHashBucketFastConfig,Sub_subConfig,Sum_sumConfig,Tan_tanConfig,Tanh_tanhConfig,TensorScatterUpdate_tensorScatterUpdateConfig,Tile_tileConfig,TopK_topKConfig,Transform_transformConfig,Transpose_transposeConfig,Unique_uniqueConfig,Unpack_unpackConfig,UnsortedSegmentSum_unsortedSegmentSumConfig,ZerosLike_zerosLikeConfig];for(const kernelConfig of register_all_kernels_kernelConfigs)(0,dist.tAK)(kernelConfig);const dist_version={"tfjs-core":dist.bgA,"tfjs-backend-cpu":tfjs_backend_cpu_dist_version_version,"tfjs-backend-webgl":tfjs_backend_webgl_dist_version_version,"tfjs-data":dist_version_version,"tfjs-layers":version,"tfjs-converter":version_version,tfjs:"4.22.0"}}}]);